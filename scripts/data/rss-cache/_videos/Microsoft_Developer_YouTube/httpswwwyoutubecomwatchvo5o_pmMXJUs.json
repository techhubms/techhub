{
  "Tags": [
    "Azure",
    "Cloud Computing",
    "Dev",
    "Development",
    "Microsoft",
    "Tech",
    "Technology"
  ],
  "Link": "https://www.youtube.com/watch?v=o5o_pmMXJUs",
  "OutputDir": "_videos",
  "Title": "Evaluating AI Models with Microsoft Foundry | MVP Unplugged",
  "FeedUrl": "https://www.youtube.com/feeds/videos.xml?channel_id=UCsMica-v34Irf9KVTh6xx-g",
  "Author": "Microsoft Developer",
  "EnhancedContent": null,
  "ProcessedDate": "2026-01-27 20:04:10",
  "FeedLevelAuthor": "Microsoft Developer",
  "FeedName": "Microsoft Developer YouTube",
  "PubDate": "2026-01-27T19:23:14+00:00",
  "Description": "Welcome to the next MVP Unplugged, where Microsoft MVPs share real-world projects and insights from the field! In this episode, host Justin Garrett sits down with Microsoft MVP Veronika Kolesnikova to explore how she picks the right AI model for common developer tasks using Evaluations in Microsoft Foundry, complete with query-context-results, Python SDK workflows, and measures for evaluation. We'll explore some fun datasets around hiking, acrobatics, and common developer terminology too! Veronika walks through her full processâ€”from generating datasets with GitHub Copilot, to running multi-model evaluations, to analyzing outputs in the Microsoft Foundry portal. Whether youâ€™re building agents, experimenting with models, or ensuring AI reliability at scale, this episode breaks down a repeatable and practical approach you can use today.\n\nIn this episode, youâ€™ll learn âœ…How to build custom evaluation datasets using AI âœ…How to compare outputs across models like GPTâ€‘5, Grok-4, and Claude Sonnet 4.5 âœ…How to run Evaluations programmatically using the new Microsoft Foundry SDK âœ…How to measure AI performance using F1, METEOR, similarity scores, and thresholds âœ…Tips for choosing the right model for your AI agent âœ…Practical debugging and iteration strategies for model quality âœ…How to store and version evaluation datasets in Microsoft Foundry\n\nğŸ”— Chapter Markers 00:00 â€“ Intro to MVP Unplugged 00:20 â€“ Meet Microsoft MVP Veronika Kolesnikova 02:20 â€“ Introducing Microsoft Foundry Evaluations 03:03 â€“ Circus, Hiking & Engineering: Creating AI Data Sets 04:55 â€“ Inside the Jupyter Notebooks & Evaluation Setup 06:11 â€“ Connecting to Azure AI Projects 07:55 â€“ Dataset Structure: Query, Context, Ground Truth 09:14 â€“ Why Evaluations Matter for Real AI Projects 10:42 â€“ Exploring the Foundry UI (Classic + New Portal) 12:04 â€“ Uploading and Versioning Data Sets in Foundry 13:37 â€“ Evaluation Results: GPTâ€‘5, Claude, Grok 18:29 â€“ Thresholds, System Prompts & Model Behavior 21:07 â€“ Deep Dive: Quad vs GPTâ€‘5 Performance 23:17 â€“ Short Answers vs Long Answers & Scoring 24:20 â€“ Circus Data Set Analysis 25:25 â€“ Software Engineering Data Set Results 27:51 â€“ Documentation & Learning Resources 29:04 â€“ Running Evaluations with the New Foundry SDK 31:12 â€“ Differences Between Old & New SDK 32:17 â€“ How Veronika Chooses the Best Model 35:22 â€“ GitHub Copilot for Model Testing 36:28 â€“ Microsoft Learn Resources 37:26 â€“ What Veronika Wants AI To Do Next 38:32 â€“ Final Advice for Developers 39:03 â€“ Closing\n\nğŸ‘‰ Subscribe for more MVP insights and AI-powered development tips!\n\n#microsoftdeveloper #MVPUnplugged #MicrosoftFoundry #AIEvaluations #AzureAI #GitHubCopilot #AIModels #MachineLearning #Claude #Grok #GPT5 #DeveloperCommunity #AIEngineering #JupyterNotebooks #pythondevelopers\n\nğŸ”— Resources & Links ğŸFree Microsoft Foundry Trial https://aka.ms/devrelft ğŸ“š Microsoft Foundry Observability https://learn.microsoft.com/azure/ai-foundry/concepts/observability ğŸ§ª Foundry Model Leaderboard https://ai.azure.com/explore/models/leaderboard ğŸ“˜ Evaluating AI Models https://learn.microsoft.com/azure/ai-services/foundry/evaluations ğŸ’» Veronikaâ€™s GitHub Repo (Evaluation Project) https://github.com/Veroni4ka/RAI\\_notebooks/ ğŸš€ Try GitHub Copilot https://github.com/features/copilot\n\nMVP Unplugged Playlist https://youtube.com/playlist?list=PLlrxD0HtieHhclud3yVB88znZPKCZYX\\_8&si=4HoycKJyUcl1qwV-\n\nAbout Veronika Veronika Kolesnikova is a Microsoft MVP in AI and a Principal AI Engineer at Liberty Mutual in Boston MA. Veronika started her career as a QA engineer and then moved to Software engineering and recently to AI engineering. She's an international public speaker, Boston Azure AI user group co-organizer and a tech mentor. Follow Veronika on LinkedIn\n\nAbout Justin Justin Garrett is host of MVP Unplugged, Principal PM in Developer Relations which is part of Microsoft Cloud + AI. Justinâ€™s career at Microsoft also spans 20 years across Windows, Bing, Edge, Web Platform, Students/ University Relations, Cloud Advocacy, and most recently a leader of the MVP Program at Microsoft. Follow Justin on LinkedIn. About MVP Unplugged\n\nAbout MVP Unplugged AI is reshaping how we work and live. And for developers and technologists alike, the pace of innovationâ€“new tools, new models, patterns & practices, and even culture itselfâ€“is changing even faster. It can be difficult to know what to learn, what to prioritize, what truly lives up to the promise of unlocking creativity and boosting productivity. Join Justin Garrett, Principal PM in DevRel and leader in the Microsoft MVP Program as he speaks with MVPs to share what theyâ€™re learning using a real-world project in this conversational series. In each episode, theyâ€™ll experiment, code, and share honest insights that can make a real difference for the audience. Justin and his guests share stories of navigating technological change and look ahead for whatâ€™s next in tech. Come discover with us how to thrive in this era of AI!"
}
