{
  "EnhancedContent": "**Join us for a new 6â€‘part livestream series where we explore the foundational concepts behind building AI agents in Python using the Microsoft Agent Framework.**\n\nThis series is for anyone who wants to understand how agents workâ€”how they call tools, use memory and context, and construct workflows on top of them. Over two weeks, weâ€™ll dive into the practical building blocks that shape real agent behavior.\n\nYouâ€™ll learn how to:\n\nðŸ”§ Register and structure tools ðŸ”— Connect local MCP servers ðŸ“š Add context with database calls ðŸ§  Add memory for personalization ðŸ“ˆ Monitor agent behavior with OpenTelemetry âœ… Evaluate the quality of agent output\n\nThroughout the series, weâ€™ll use Python for all live examples and share full code so you can run everything yourself. You can also follow along live using GitHub Models and GitHub Codespaces.\n\nðŸ‘‰ [Register for the full series.](https://aka.ms/PythonAgents/b)\n\nSpanish speaker?Â Â¡Tendremos una serie para hispanohablantes!Â [RegÃ­strese aquÃ­](https://aka.ms/PythonAgentes/b)\n\nIn addition to the live streams, you can also joinÂ [Join the Microsoft Foundry Discord](http://aka.ms/aipython/oh) to ask follow-up questions after each stream.\n\nIf you are brand new to generative AI with Python, start with ourÂ [9-part Python + AI series](https://aka.ms/pythonai/rewatch), which covers topics such as LLMs, embedding models, RAG, tool calling, MCP, and will prepare you perfectly for the agents series.\n\nTo learn more about each live stream or register for individual sessions, scroll down:\n\n## Python + Agents: Building your first agent in Python\n\n24 February, 2026 | 6:30 PM - 7:30 PM (UTC) Coordinated Universal Time\n\n[Register for the stream on Reactor](https://developer.microsoft.com/en-us/reactor/events/26688/)\n\nIn the first session of our Python + Agents series, weâ€™ll kick things off with the fundamentals: what AI agents are, how they work, and how to build your first one using the Microsoft Agent Framework. Weâ€™ll start with the core anatomy of an agent, then walk through how tool calling works in practiceâ€”beginning with a single tool, expanding to multiple tools, and finally connecting to tools exposed through local MCP servers. Weâ€™ll conclude with the supervisor agent pattern, where a single supervisor agent coordinates subtasks across multiple subagents, by treating each agent as a tool. Along the way, we'll share tips for debugging and inspecting agents, like using the DevUI interface from Microsoft Agent Framework for interacting with agent prototypes.\n\n[## Python + Agents: Adding context and memory to agents](https://developer.microsoft.com/en-us/reactor/events/26689/)\n\n25 February, 2026 | 6:30 PM - 7:30 PM (UTC) Coordinated Universal Time\n\n[Register for the stream on Reactor](https://developer.microsoft.com/en-us/reactor/events/26689/)\n\nIn the second session of our Python + Agents series, weâ€™ll extend agents built with the Microsoft Agent Framework by adding two essential capabilities: context and memory. Weâ€™ll begin with context, commonly known as Retrievalâ€‘Augmented Generation (RAG), and show how agents can ground their responses using knowledge retrieved from local data sources such as SQLite or PostgreSQL. This enables agents to provide accurate, domainâ€‘specific answers based on real information rather than model hallucination. Next, weâ€™ll explore memoryâ€”both shortâ€‘term, threadâ€‘level context and longâ€‘term, persistent memory. Youâ€™ll see how agents can store and recall information using solutions like Redis or openâ€‘source libraries such as Mem0, enabling them to remember previous interactions, user preferences, and evolving tasks across sessions. By the end, youâ€™ll understand how to build agents that are not only capable but contextâ€‘aware and memoryâ€‘efficient, resulting in richer, more personalized user experiences.\n\n[## Python + Agents: Monitoring and evaluating agents](https://developer.microsoft.com/en-us/reactor/events/26690/)\n\n26 February, 2026 | 6:30 PM - 7:30 PM (UTC) Coordinated Universal Time\n\n[Register for the stream on Reactor](https://developer.microsoft.com/en-us/reactor/events/26690/)\n\nIn the third session of our Python + Agents series, weâ€™ll focus on two essential components of building reliable agents: observability and evaluation. Weâ€™ll begin with observability, using OpenTelemetry to capture traces, metrics, and logs from agent actions. You'll learn how to instrument your agents and use a local Aspire dashboard to identify slowdowns and failures. From there, weâ€™ll explore how to evaluate agent behavior using the Azure AI Evaluation SDK. Youâ€™ll see how to define evaluation criteria, run automated assessments over a set of tasks, and analyze the results to measure accuracy, helpfulness, and task success. By the end of the session, youâ€™ll have practical tools and workflows for monitoring, measuring, and improving your agentsâ€”so theyâ€™re not just functional, but dependable and verifiably effective.\n\n[## Python + Agents: Building your first AI-driven workflows](https://developer.microsoft.com/en-us/reactor/events/26691/)\n\n3 March, 2026 | 6:30 PM - 7:30 PM (UTC) Coordinated Universal Time\n\n[Register for the stream on Reactor](https://developer.microsoft.com/en-us/reactor/events/26691/)\n\nIn Session 4 of our Python + Agents series, weâ€™ll explore the foundations of building AIâ€‘driven workflows using the Microsoft Agent Framework: defining workflow steps, connecting them, passing data between them, and introducing simple ways to guide the path a workflow takes. Weâ€™ll begin with a conceptual overview of workflows and walk through their core components: executors, edges, and events. Youâ€™ll learn how workflows can be composed of simple Python functions or powered by full AI agents when a step requires modelâ€‘driven behavior. From there, weâ€™ll dig into conditional branching, showing how workflows can follow different paths depending on model outputs, intermediate results, or lightweight decision functions. Weâ€™ll introduce structured outputs as a way to make branching more reliable and easier to maintainâ€”avoiding vague string checks and ensuring that workflow decisions are based on clear, typed data. We'll discover how the DevUI interface makes it easier to develop workflows by visualizing the workflow graph and surfacing the streaming events during a workflow's execution. Finally, we'll dive into an E2E demo application that uses workflows inside a user-facing application with a frontend and backend.\n\n[## Python + Agents: Orchestrating advanced multi-agent workflows](https://developer.microsoft.com/en-us/reactor/events/26692/)\n\n4 March, 2026 | 6:30 PM - 7:30 PM (UTC) Coordinated Universal Time\n\n[Register for the stream on Reactor](https://developer.microsoft.com/en-us/reactor/events/26692/)\n\nIn Session 5 of our Python + Agents series, weâ€™ll go beyond workflow fundamentals and explore how to orchestrate advanced, multiâ€‘agent workflows using the Microsoft Agent Framework. This session focuses on patterns that coordinate multiple steps or multiple agents at once, enabling more powerful and flexible AIâ€‘driven systems. Weâ€™ll begin by comparing sequential vs. concurrent execution, then dive into techniques for running workflow steps in parallel. Youâ€™ll learn how fanâ€‘out and fanâ€‘in edges enable multiple branches to run at the same time, how to aggregate their results, and how concurrency allows workflows to scale across tasks efficiently. From there, weâ€™ll introduce two multiâ€‘agent orchestration approaches that are built into the framework. Weâ€™ll start with handoff, where control moves entirely from one agent to another based on workflow logic, which is useful for routing tasks to the right agent as the workflow progresses. Weâ€™ll then look at Magentic, a planningâ€‘oriented supervisor that generates a highâ€‘level plan for completing a task and delegates portions of that plan to other agents. Finally, we'll wrap up with a demo of an E2E application that showcases a concurrent multi-agent workflow in action.\n\n[## Python + Agents: Adding a human in the loop to agentic workflows](https://developer.microsoft.com/en-us/reactor/events/26693/)\n\n5 March, 2026 | 6:30 PM - 7:30 PM (UTC) Coordinated Universal Time\n\n[Register for the stream on Reactor](https://developer.microsoft.com/en-us/reactor/events/26693/)\n\nIn the final session of our Python + Agents series, weâ€™ll explore how to incorporate humanâ€‘inâ€‘theâ€‘loop (HITL) interactions into agentic workflows using the Microsoft Agent Framework. This session focuses on adding points where a workflow can pause, request input or approval from a user, and then resume once the human has responded. HITL is especially important because LLMs can produce uncertain or inconsistent outputs, and human checkpoints provide an added layer of accuracy and oversight. Weâ€™ll begin with the frameworkâ€™s requestsâ€‘andâ€‘responses model, which provides a structured way for workflows to ask questions, collect human input, and continue execution with that data. We'll move onto tool approval, one of the most frequent reasons an agent requests input from a human, and see how workflows can surface pending tool calls for approval or rejection. Next, weâ€™ll cover checkpoints and resuming, which allow workflows to pause and be restarted later. This is especially important for HITL scenarios where the human may not be available immediately. Weâ€™ll walk through examples that demonstrate how checkpoints store progress, how resuming picks up the workflow state, and how this mechanism supports longerâ€‘running or multiâ€‘step review cycles. This session brings together everything from the seriesâ€”agents, workflows, branching, orchestrationâ€”and shows how to integrate humans thoughtfully into AIâ€‘driven processes, especially when reliability and judgment matter most.\n\nPublished Jan 15, 2026\n\nVersion 1.0\n\n[agents](/tag/agents?nodeId=board%3AAzureDevCommunityBlog)\n\n[gwyneth peÃ±a-siguenza](/tag/gwyneth%20pe%C3%B1a-siguenza?nodeId=board%3AAzureDevCommunityBlog)\n\n[pamela fox](/tag/pamela%20fox?nodeId=board%3AAzureDevCommunityBlog)\n\n[python](/tag/python?nodeId=board%3AAzureDevCommunityBlog)\n\n[!\\[Pamela_Fox&#x27;s avatar\\](https://techcommunity.microsoft.com/t5/s/gxcuf89792/images/dS0xNjA0MDc4LTQxODI4MWk5MjkyQjFBMEVGOUE5NkM5?image-dimensions=50x50)](/users/pamela_fox/1604078) [Pamela_Fox](/users/pamela_fox/1604078) ![Icon for Microsoft rank](https://techcommunity.microsoft.com/t5/s/gxcuf89792/images/cmstNC05WEo0blc?image-dimensions=100x16&amp;constrain-image=true)Microsoft\n\nJoined November 08, 2022\n\n[View Profile](/users/pamela_fox/1604078)\n\n/category/azure/blog/azuredevcommunityblog [Microsoft Developer Community Blog](/category/azure/blog/azuredevcommunityblog) Follow this blog board to get notified when there's new activity",
  "FeedName": "Microsoft Tech Community",
  "ProcessedDate": "2026-01-15 09:05:45",
  "Description": "**Join us for a new 6â€‘part livestream series where we explore the foundational concepts behind building AI agents in Python using the Microsoft Agent Framework.**\n\nThis series is for anyone who wants to understand how agents workâ€”how they call tools, use memory and context, and construct workflows on top of them. Over two weeks, weâ€™ll dive into the practical building blocks that shape real agent behavior.\n\nYouâ€™ll learn how to:\n\nðŸ”§ Register and structure tools ðŸ”— Connect local MCP servers ðŸ“š Add context with database calls ðŸ§  Add memory for personalization ðŸ“ˆ Monitor agent behavior with OpenTelemetry âœ… Evaluate the quality of agent output\n\nThroughout the series, weâ€™ll use Python for all live examples and share full code so you can run everything yourself. You can also follow along live using GitHub Models and GitHub Codespaces.\n\nðŸ‘‰ [Register for the full series.](https://aka.ms/PythonAgents/b)\n\nSpanish speaker? Â¡Tendremos una serie para hispanohablantes! [RegÃ­strese aquÃ­](https://aka.ms/PythonAgentes/b)\n\nIn addition to the live streams, you can also join [Join the Microsoft Foundry Discord](http://aka.ms/aipython/oh) to ask follow-up questions after each stream.\n\nIf you are brand new to generative AI with Python, start with our [9-part Python + AI series](https://aka.ms/pythonai/rewatch), which covers topics such as LLMs, embedding models, RAG, tool calling, MCP, and will prepare you perfectly for the agents series.\n\nTo learn more about each live stream or register for individual sessions, scroll down:\n\n## Python + Agents: Building your first agent in Python\n\n24 February, 2026 | 6:30 PM - 7:30 PM (UTC) Coordinated Universal Time\n\n[Register for the stream on Reactor](https://developer.microsoft.com/en-us/reactor/events/26688/)\n\nIn the first session of our Python + Agents series, weâ€™ll kick things off with the fundamentals: what AI agents are, how they work, and how to build your first one using the Microsoft Agent Framework. Weâ€™ll start with the core anatomy of an agent, then walk through how tool calling works in practiceâ€”beginning with a single tool, expanding to multiple tools, and finally connecting to tools exposed through local MCP servers. Weâ€™ll conclude with the supervisor agent pattern, where a single supervisor agent coordinates subtasks across multiple subagents, by treating each agent as a tool. Along the way, we'll share tips for debugging and inspecting agents, like using the DevUI interface from Microsoft Agent Framework for interacting with agent prototypes.\n\n[## Python + Agents: Adding context and memory to agents](https://developer.microsoft.com/en-us/reactor/events/26689/)\n\n25 February, 2026 | 6:30 PM - 7:30 PM (UTC) Coordinated Universal Time\n\n[Register for the stream on Reactor](https://developer.microsoft.com/en-us/reactor/events/26689/)\n\nIn the second session of our Python + Agents series, weâ€™ll extend agents built with the Microsoft Agent Framework by adding two essential capabilities: context and memory. Weâ€™ll begin with context, commonly known as Retrievalâ€‘Augmented Generation (RAG), and show how agents can ground their responses using knowledge retrieved from local data sources such as SQLite or PostgreSQL. This enables agents to provide accurate, domainâ€‘specific answers based on real information rather than model hallucination. Next, weâ€™ll explore memoryâ€”both shortâ€‘term, threadâ€‘level context and longâ€‘term, persistent memory. Youâ€™ll see how agents can store and recall information using solutions like Redis or openâ€‘source libraries such as Mem0, enabling them to remember previous interactions, user preferences, and evolving tasks across sessions. By the end, youâ€™ll understand how to build agents that are not only capable but contextâ€‘aware and memoryâ€‘efficient, resulting in richer, more personalized user experiences.\n\n[## Python + Agents: Monitoring and evaluating agents](https://developer.microsoft.com/en-us/reactor/events/26690/)\n\n26 February, 2026 | 6:30 PM - 7:30 PM (UTC) Coordinated Universal Time\n\n[Register for the stream on Reactor](https://developer.microsoft.com/en-us/reactor/events/26690/)\n\nIn the third session of our Python + Agents series, weâ€™ll focus on two essential components of building reliable agents: observability and evaluation. Weâ€™ll begin with observability, using OpenTelemetry to capture traces, metrics, and logs from agent actions. You'll learn how to instrument your agents and use a local Aspire dashboard to identify slowdowns and failures. From there, weâ€™ll explore how to evaluate agent behavior using the Azure AI Evaluation SDK. Youâ€™ll see how to define evaluation criteria, run automated assessments over a set of tasks, and analyze the results to measure accuracy, helpfulness, and task success. By the end of the session, youâ€™ll have practical tools and workflows for monitoring, measuring, and improving your agentsâ€”so theyâ€™re not just functional, but dependable and verifiably effective.\n\n[## Python + Agents: Building your first AI-driven workflows](https://developer.microsoft.com/en-us/reactor/events/26691/)\n\n3 March, 2026 | 6:30 PM - 7:30 PM (UTC) Coordinated Universal Time\n\n[Register for the stream on Reactor](https://developer.microsoft.com/en-us/reactor/events/26691/)\n\nIn Session 4 of our Python + Agents series, weâ€™ll explore the foundations of building AIâ€‘driven workflows using the Microsoft Agent Framework: defining workflow steps, connecting them, passing data between them, and introducing simple ways to guide the path a workflow takes. Weâ€™ll begin with a conceptual overview of workflows and walk through their core components: executors, edges, and events. Youâ€™ll learn how workflows can be composed of simple Python functions or powered by full AI agents when a step requires modelâ€‘driven behavior. From there, weâ€™ll dig into conditional branching, showing how workflows can follow different paths depending on model outputs, intermediate results, or lightweight decision functions. Weâ€™ll introduce structured outputs as a way to make branching more reliable and easier to maintainâ€”avoiding vague string checks and ensuring that workflow decisions are based on clear, typed data. We'll discover how the DevUI interface makes it easier to develop workflows by visualizing the workflow graph and surfacing the streaming events during a workflow's execution. Finally, we'll dive into an E2E demo application that uses workflows inside a user-facing application with a frontend and backend.\n\n[## Python + Agents: Orchestrating advanced multi-agent workflows](https://developer.microsoft.com/en-us/reactor/events/26692/)\n\n4 March, 2026 | 6:30 PM - 7:30 PM (UTC) Coordinated Universal Time\n\n[Register for the stream on Reactor](https://developer.microsoft.com/en-us/reactor/events/26692/)\n\nIn Session 5 of our Python + Agents series, weâ€™ll go beyond workflow fundamentals and explore how to orchestrate advanced, multiâ€‘agent workflows using the Microsoft Agent Framework. This session focuses on patterns that coordinate multiple steps or multiple agents at once, enabling more powerful and flexible AIâ€‘driven systems. Weâ€™ll begin by comparing sequential vs. concurrent execution, then dive into techniques for running workflow steps in parallel. Youâ€™ll learn how fanâ€‘out and fanâ€‘in edges enable multiple branches to run at the same time, how to aggregate their results, and how concurrency allows workflows to scale across tasks efficiently. From there, weâ€™ll introduce two multiâ€‘agent orchestration approaches that are built into the framework. Weâ€™ll start with handoff, where control moves entirely from one agent to another based on workflow logic, which is useful for routing tasks to the right agent as the workflow progresses. Weâ€™ll then look at Magentic, a planningâ€‘oriented supervisor that generates a highâ€‘level plan for completing a task and delegates portions of that plan to other agents. Finally, we'll wrap up with a demo of an E2E application that showcases a concurrent multi-agent workflow in action.\n\n[## Python + Agents: Adding a human in the loop to agentic workflows](https://developer.microsoft.com/en-us/reactor/events/26693/)\n\n5 March, 2026 | 6:30 PM - 7:30 PM (UTC) Coordinated Universal Time\n\n[Register for the stream on Reactor](https://developer.microsoft.com/en-us/reactor/events/26693/)\n\nIn the final session of our Python + Agents series, weâ€™ll explore how to incorporate humanâ€‘inâ€‘theâ€‘loop (HITL) interactions into agentic workflows using the Microsoft Agent Framework. This session focuses on adding points where a workflow can pause, request input or approval from a user, and then resume once the human has responded. HITL is especially important because LLMs can produce uncertain or inconsistent outputs, and human checkpoints provide an added layer of accuracy and oversight. Weâ€™ll begin with the frameworkâ€™s requestsâ€‘andâ€‘responses model, which provides a structured way for workflows to ask questions, collect human input, and continue execution with that data. We'll move onto tool approval, one of the most frequent reasons an agent requests input from a human, and see how workflows can surface pending tool calls for approval or rejection. Next, weâ€™ll cover checkpoints and resuming, which allow workflows to pause and be restarted later. This is especially important for HITL scenarios where the human may not be available immediately. Weâ€™ll walk through examples that demonstrate how checkpoints store progress, how resuming picks up the workflow state, and how this mechanism supports longerâ€‘running or multiâ€‘step review cycles. This session brings together everything from the seriesâ€”agents, workflows, branching, orchestrationâ€”and shows how to integrate humans thoughtfully into AIâ€‘driven processes, especially when reliability and judgment matter most.",
  "FeedLevelAuthor": "rss.livelink.threads-in-node",
  "Author": "Pamela_Fox",
  "FeedUrl": "https://techcommunity.microsoft.com/t5/s/gxcuf89792/rss/Category?category.id=Azure",
  "Link": "https://techcommunity.microsoft.com/t5/microsoft-developer-community/join-our-free-livestream-series-on-building-agents-in-python/ba-p/4485731",
  "PubDate": "2026-01-15T08:00:00+00:00",
  "OutputDir": "_community",
  "Tags": [],
  "Title": "Join our free livestream series on building agents in Python"
}
