{
  "Description": "## Introduction\n\nPicture this: You've built an AI agent that analyzes financial data. A user uploads a quarterly report and asks: *\"What are the top three expense categories?\"* Behind the scenes, your agent parses the spreadsheet, aggregates thousands of rows, and generates visualizations. All in 20 seconds. But the user? They see a loading spinner. Nothing else. No \"reading file\" message, no \"analyzing data\" indicator, no hint that progress is being made. They start wondering: Is it frozen? Should I refresh?\n\nThe problem isn't the agent's capabilities - it's the communication gap between the agent running on the backend and the user interface. When agents perform multi-step reasoning, call external APIs, or execute complex tool chains, users deserve to see what's happening. They need streaming updates, intermediate results, and transparent progress indicators. Yet most agent frameworks force developers to choose between simple request/response patterns or building custom solutions to stream updates to their UIs.\n\nThis is where **AG-UI** comes in. AG-UI is a fairly new event-based protocol that standardizes how agents communicate with user interfaces. Instead of every framework and development team inventing their own streaming solution, AG-UI provides a shared vocabulary of structured events that work consistently across different agent implementations. When an agent starts processing, calls a tool, generates text, or encounters an error, the UI receives explicit, typed events in real time.\n\nThe beauty of AG-UI is its framework-agnostic design. While this blog post demonstrates integration with **Microsoft Agent Framework (MAF)**, the same AG-UI protocol works with LangGraph, CrewAI, or any other compliant framework. Write your UI code once, and it works with any AG-UI-compliant backend. (Note: MAF supports both Python and .NET - this blog post focuses on the Python implementation.)\n\n## TL;DR\n\n**The Problem:** Users don't get real-time updates while AI agents work behind the scenes - no progress indicators, no transparency into tool calls, and no insight into what's happening.\n\n**The Solution:** AG-UI is an open, event-based protocol that standardizes real-time communication between AI agents and user interfaces. Instead of each development team and framework inventing custom streaming solutions, AG-UI provides a shared vocabulary of structured events (like TOOL\\_CALL\\_START, TEXT\\_MESSAGE\\_CONTENT, RUN\\_FINISHED) that work across any compliant framework.\n\n**Key Benefits:**\n\n- **Framework-agnostic** - Write UI code once, works with LangGraph, Microsoft Agent Framework, CrewAI, and more\n- **Real-time observability** - See exactly what your agent is doing as it happens\n- **Server-Sent Events** - Built on standard HTTP for universal compatibility\n- **Protocol-managed state** - No manual conversation history tracking\n\n**In This Post:** You'll learn why AG-UI exists, how it works, and build a complete working application using Microsoft Agent Framework with Python - from server setup to client implementation.\n\n## What You'll Learn\n\nThis blog post walks through:\n\n- **Why AG-UI exists** - how agent-UI communication has evolved and what problems current approaches couldn't solve\n- **How the protocol works** - the key design choices that make AG-UI simple, reliable, and framework-agnostic\n- **Protocol architecture** - the generic components and how AG-UI integrates with agent frameworks\n- **Building an AG-UI application** - a complete working example using Microsoft Agent Framework with server, client, and step-by-step setup\n- **Understanding events** - what happens under the hood when your agent runs and how to observe it\n- **Thinking in events** - how building with AG-UI differs from traditional APIs, and what benefits this brings\n- **Making the right choice** - when AG-UI is the right fit for your project and when alternatives might be better\n\n**Estimated reading time:** 15 minutes\n\n**Who this is for:** Developers building AI agents who want to provide real-time feedback to users, and teams evaluating standardized approaches to agent-UI communication\n\nTo appreciate why AG-UI matters, we need to understand the journey that led to its creation. Let's trace how agent-UI communication has evolved through three distinct phases.\n\n## The Evolution of Agent-UI Communication\n\nAI agents have become more capable over time. As they evolved, the way they communicated with user interfaces had to evolve as well. Here's how this evolution unfolded.\n\n### Phase 1: Simple Request/Response\n\nIn the early days of AI agent development, the interaction model was straightforward: send a question, wait for an answer, display the result. This synchronous approach mirrored traditional API calls and worked fine for simple scenarios.\n\n- # Simple, but limiting\nresponse = agent.run(\"What's the weather in Paris?\") display(response) # User waits... and waits...\n\n**Works for:** Quick queries that complete in seconds, simple Q&A interactions where immediate feedback and interactivity aren't critical.\n\n**Breaks down:** When agents need to call multiple tools, perform multi-step reasoning, or process complex queries that take 30+ seconds. Users see nothing but a loading spinner, with no insight into what's happening or whether the agent is making progress. This creates a poor user experience and makes it impossible to show intermediate results or allow user intervention.\n\nRecognizing these limitations, development teams began experimenting with more sophisticated approaches.\n\n### Phase 2: Custom Streaming Solutions\n\nAs agents became more sophisticated, teams recognized the need for incremental feedback and interactivity. Rather than waiting for the complete response, they implemented custom streaming solutions to show partial results as they became available.\n- # Every team invents their own format\nfor chunk in agent.stream(\"What's the weather?\"): display(chunk) # But what about tool calls? Errors? Progress?\n\nThis was a step forward for building interactive agent UIs, but each team solved the problem differently. Also, different frameworks had incompatible approaches - some streamed only text tokens, others sent structured JSON, and most provided no visibility into critical events like tool calls or errors.\n\n**The problem:**\n\n- No standardization across frameworks - client code that works with LangGraph won't work with Crew AI, requiring separate implementations for each agent backend\n- Each implementation handles tool calls differently - some send nothing during tool execution, others send unstructured messages\n- Complex state management - clients must track conversation history, manage reconnections, and handle edge cases manually\n\nThe industry needed a better solution - a common protocol that could work across all frameworks while maintaining the benefits of streaming.\n\n### Phase 3: Standardized Protocol (AG-UI)\n\nAG-UI emerged as a response to the fragmentation problem. Instead of each framework and development team inventing their own streaming solution, AG-UI provides a shared vocabulary of events that work consistently across different agent implementations.\n- # Standardized events everyone understands\nasync for event in agent.run\\_stream(\"What's the weather?\"): if event.type == \"TEXT\\_MESSAGE\\_CONTENT\": display\\_text(event.delta) elif event.type == \"TOOL\\_CALL\\_START\": show\\_tool\\_indicator(event.tool\\_name) elif event.type == \"TOOL\\_CALL\\_RESULT\": show\\_tool\\_result(event.result)\n\nThe key difference is **structured observability**. Rather than guessing what the agent is doing from unstructured text, clients receive explicit events for every stage of execution: when the agent starts, when it generates text, when it calls a tool, when that tool completes, and when the entire run finishes.\n\n**What's different:** A standardized vocabulary of event types, complete observability into agent execution, and framework-agnostic clients that work with any AG-UI-compliant backend. You write your UI code once, and it works whether the backend uses Microsoft Agent Framework, LangGraph, or any other framework that speaks AG-UI.\n\nNow that we've seen why AG-UI emerged and what problems it solves, let's examine the specific design decisions that make the protocol work. These choices weren't arbitrary - each one addresses concrete challenges in building reliable, observable agent-UI communication.\n\n## The Design Decisions Behind AG-UI\n\n### Why Server-Sent Events (SSE)?\n\n| Aspect | WebSockets | SSE (AG-UI) | | --- | --- | --- | | Complexity | Bidirectional | Unidirectional (simpler) | | Firewall/Proxy | Sometimes blocked | Standard HTTP | | Reconnection | Manual implementation | Built-in browser support | | Use case | Real-time games, chat | Agent responses (one-way) |\n\nFor agent interactions, you typically only need server→client communication, making SSE a simpler choice.\n\nSSE solves the *transport* problem - how events travel from server to client. But once connected, how does the protocol handle conversation state across multiple interactions?\n\n### Why Protocol-Managed Threads?\n- # Without protocol threads (client manages):\nconversation\\_history = [] conversation\\_history.append({\"role\": \"user\", \"content\": message}) response = agent.complete(conversation\\_history) conversation\\_history.append({\"role\": \"assistant\", \"content\": response})\n# Complex, error-prone, doesn't work with multiple clients\n\n# With AG-UI (protocol manages):\nthread = agent.get\\_new\\_thread() # Server creates and manages thread agent.run\\_stream(message, thread=thread) # Server maintains context\n# Simple, reliable, shareable across clients\n\nWith transport and state management handled, the final piece is the actual messages flowing through the connection. What information should the protocol communicate, and how should it be structured?\n\n### Why Standardized Event Types?\n\nInstead of parsing unstructured text, clients get typed events:\n\n- RUN\\_STARTED - Agent begins (start loading UI)\n- TEXT\\_MESSAGE\\_CONTENT - Text chunk (stream to user)\n- TOOL\\_CALL\\_START - Tool invoked (show \"searching...\", \"calculating...\")\n- TOOL\\_CALL\\_RESULT - Tool finished (show result, update UI)\n- RUN\\_FINISHED - Complete (hide loading)\n\nThis lets UIs react intelligently without custom parsing logic.\n\nNow that we understand the protocol's design choices, let's see how these pieces fit together in a complete system.\n\n## Architecture Overview\n\nHere's how the components interact:\n\n![]()\n\nThe communication between these layers relies on a well-defined set of event types. Here are the core events that flow through the SSE connection:\n\n### Core Event Types\n\nAG-UI provides a standardized set of event types to describe what's happening during an agent's execution:\n\n- RUN\\_STARTED - agent begins execution\n- TEXT\\_MESSAGE\\_START, TEXT\\_MESSAGE\\_CONTENT, TEXT\\_MESSAGE\\_END - streaming segments of text\n- TOOL\\_CALL\\_START, TOOL\\_CALL\\_ARGS, TOOL\\_CALL\\_END, TOOL\\_CALL\\_RESULT - tool execution events\n- RUN\\_FINISHED - agent has finished execution\n- RUN\\_ERROR - error information\n\nThis model lets the UI update as the agent runs, rather than waiting for the final response.\n\nThe generic architecture above applies to any AG-UI implementation. Now let's see how this translates to Microsoft Agent Framework.\n\n## AG-UI with Microsoft Agent Framework\n\nWhile AG-UI is framework-agnostic, this blog post demonstrates integration with Microsoft Agent Framework (MAF) using Python. MAF is available in both **Python** and **.NET**, giving you flexibility to build AG-UI applications in your preferred language. Understanding how MAF implements the protocol will help you build your own applications or work with other compliant frameworks.\n\n### Integration Architecture\n\nThe Microsoft Agent Framework integration involves several specialized layers that handle protocol translation and execution orchestration:\n\n![]()\n\n**Understanding each layer:**\n\n- **FastAPI Endpoint** - Handles HTTP requests and establishes SSE connections for streaming\n- **AgentFrameworkAgent** - Protocol wrapper that translates between AG-UI events and Agent Framework operations\n- **Orchestrators** - Manage execution flow, coordinate tool calling sequences, and handle state transitions\n- **ChatAgent** - Your agent implementation with instructions, tools, and business logic\n- **ChatClient** - Interface to the underlying language model (Azure OpenAI, OpenAI, or other providers)\n\nThe good news? When you call add\\_agent\\_framework\\_fastapi\\_endpoint, all the middleware layers are configured automatically. You simply provide your ChatAgent, and the integration handles protocol translation, event streaming, and state management behind the scenes.\n\nNow that we understand both the protocol architecture and the Microsoft Agent Framework integration, let's build a working application.\n\n## Hands-On: Building Your First AG-UI Application\n\nThis section demonstrates how to build an AG-UI server and client using Microsoft Agent Framework and FastAPI.\n\n### Prerequisites\n\nBefore building your first AG-UI application, ensure you have:\n\n- **Python 3.10 or later** installed\n- **Basic understanding** of async/await patterns in Python\n- **Azure CLI** installed and authenticated (az login)\n- **Azure OpenAI service** endpoint and deployment configured ([setup guide](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/how-to/create-resource))\n- **Cognitive Services OpenAI Contributor** role for your Azure OpenAI resource\n\nYou'll also need to install the AG-UI integration package:\n- pip install agent-framework-ag-ui --pre\n\nThis automatically installs agent-framework-core, fastapi, and uvicorn as dependencies.\n\nWith your environment configured, let's create the server that will host your agent and expose it via the AG-UI protocol.\n\n### Building the Server\n\nLet's create a FastAPI server that hosts an AI agent and exposes it via AG-UI:\n- # server.py\nimport os from typing import Annotated from dotenv import load\\_dotenv from fastapi import FastAPI from pydantic import Field from agent\\_framework import ChatAgent, ai\\_function from agent\\_framework.azure import AzureOpenAIChatClient from agent\\_framework\\_ag\\_ui import add\\_agent\\_framework\\_fastapi\\_endpoint from azure.identity import DefaultAzureCredential\n\n# Load environment variables from .env file\nload\\_dotenv()\n\n# Validate environment configuration\nopenai\\_endpoint = os.getenv(\"AZURE\\_OPENAI\\_ENDPOINT\") model\\_deployment = os.getenv(\"AZURE\\_OPENAI\\_DEPLOYMENT\\_NAME\")\n\nif not openai\\_endpoint: raise RuntimeError(\"Missing required environment variable: AZURE\\_OPENAI\\_ENDPOINT\") if not model\\_deployment: raise RuntimeError(\"Missing required environment variable: AZURE\\_OPENAI\\_DEPLOYMENT\\_NAME\")\n\n# Define tools the agent can use\n@ai\\_function def get\\_order\\_status( order\\_id: Annotated[str, Field(description=\"The order ID to look up (e.g., ORD-001)\")] ) -> dict: \"\"\"Look up the status of a customer order.\n\nReturns order status, tracking number, and estimated delivery date. \"\"\"\n# Simulated order lookup\norders = { \"ORD-001\": {\"status\": \"shipped\", \"tracking\": \"1Z999AA1\", \"eta\": \"Jan 25, 2026\"}, \"ORD-002\": {\"status\": \"processing\", \"tracking\": None, \"eta\": \"Jan 23, 2026\"}, \"ORD-003\": {\"status\": \"delivered\", \"tracking\": \"1Z999AA3\", \"eta\": \"Delivered Jan 20\"}, } return orders.get(order\\_id, {\"status\": \"not\\_found\", \"message\": \"Order not found\"})\n\n# Initialize Azure OpenAI client\nchat\\_client = AzureOpenAIChatClient( credential=DefaultAzureCredential(), endpoint=openai\\_endpoint, deployment\\_name=model\\_deployment, )\n\n# Configure the agent with custom instructions and tools\nagent = ChatAgent( name=\"CustomerSupportAgent\", instructions=\"\"\"You are a helpful customer support assistant.\n\nYou have access to a get\\_order\\_status tool that can look up order information.\n\nIMPORTANT: When a user mentions an order ID (like ORD-001, ORD-002, etc.), you MUST call the get\\_order\\_status tool to retrieve the actual order details. Do NOT make up or guess order information.\n\nAfter calling get\\_order\\_status, provide the actual results to the user in a friendly format.\"\"\", chat\\_client=chat\\_client, tools=[get\\_order\\_status], )\n\n# Initialize FastAPI application\napp = FastAPI( title=\"AG-UI Customer Support Server\", description=\"Interactive AI agent server using AG-UI protocol with tool calling\" )\n\n# Mount the AG-UI endpoint\nadd\\_agent\\_framework\\_fastapi\\_endpoint(app, agent, path=\"/chat\")\n\ndef main(): \"\"\"Entry point for the AG-UI server.\"\"\" import uvicorn print(\"Starting AG-UI server on http://localhost:8000\") uvicorn.run(app, host=\"0.0.0.0\", port=8000, log\\_level=\"info\")\n\n# Run the application\nif \\_\\_name\\_\\_ == \"\\_\\_main\\_\\_\": main()\n\n**What's happening here:**\n\n- We define a tool: get\\_order\\_status with the [AI​](javascript:void%280%29)\\_function decorator\n- Use Annotated and Field for parameter descriptions to help the agent understand when and how to use the tool\n- We create an Azure OpenAI chat client with credential authentication\n- The ChatAgent is configured with domain-specific instructions and the tools parameter\n- add\\_agent\\_framework\\_fastapi\\_endpoint automatically handles SSE streaming and tool execution\n- The server exposes the agent at the /chat endpoint\n\n> >\n> **Note:** This example uses Azure OpenAI, but AG-UI works with any chat model. You can also integrate with Azure AI Foundry's model catalog or use other LLM providers. Tool calling is supported by most modern LLMs including GPT-4, GPT-4o, and Claude models.\n> >\n\nTo run this server:\n- # Set your Azure OpenAI credentials\nexport AZURE\\_OPENAI\\_ENDPOINT=\"https://your-resource.openai.azure.com/\" export AZURE\\_OPENAI\\_DEPLOYMENT\\_NAME=\"gpt-4o\"\n\n# Start the server\npython server.py\n\nWith your server running and exposing the AG-UI endpoint, the next step is building a client that can connect and consume the event stream.\n\n## Streaming Results to Clients\n\nWith the server running, clients can connect and stream events as the agent processes requests. Here's a Python client that demonstrates the streaming capabilities:\n- # client.py\nimport asyncio import os from dotenv import load\\_dotenv from agent\\_framework import ChatAgent, FunctionCallContent, FunctionResultContent from agent\\_framework\\_ag\\_ui import AGUIChatClient\n\n# Load environment variables from .env file\nload\\_dotenv()\n\nasync def interactive\\_chat(): \"\"\"Interactive chat session with streaming responses.\"\"\"\n\n# Connect to the AG-UI server\nbase\\_url = os.getenv(\"AGUI\\_SERVER\\_URL\", \"http://localhost:8000/chat\") print(f\"Connecting to: {base\\_url}\\n\")\n\n# Initialize the AG-UI client\nclient = AGUIChatClient(endpoint=base\\_url)\n\n# Create a local agent representation\nagent = ChatAgent(chat\\_client=client)\n\n# Start a new conversation thread\nconversation\\_thread = agent.get\\_new\\_thread()\n\nprint(\"Chat started! Type 'exit' or 'quit' to end the session.\\n\")\n\ntry: while True:\n# Collect user input\nuser\\_message = input(\"You: \")\n\n# Handle empty input\nif not user\\_message.strip(): print(\"Please enter a message.\\n\") continue\n\n# Check for exit commands\nif user\\_message.lower() in [\"exit\", \"quit\", \"bye\"]: print(\"\\nGoodbye!\") break\n\n# Stream the agent's response\nprint(\"Agent: \", end=\"\", flush=True)\n\n# Track tool calls to avoid duplicate prints\nseen\\_tools = set()\n\nasync for update in agent.run\\_stream(user\\_message, thread=conversation\\_thread):\n# Display text content\nif update.text: print(update.text, end=\"\", flush=True)\n\n# Display tool calls and results\nfor content in update.contents: if isinstance(content, FunctionCallContent):\n# Only print each tool call once\nif content.call\\_id not in seen\\_tools: seen\\_tools.add(content.call\\_id) print(f\"\\n[Calling tool: {content.name}]\", flush=True) elif isinstance(content, FunctionResultContent):\n# Only print each result once\nresult\\_id = f\"result\\_{content.call\\_id}\" if result\\_id not in seen\\_tools: seen\\_tools.add(result\\_id) result\\_text = content.result if isinstance(content.result, str) else str(content.result) print(f\"[Tool result: {result\\_text}]\", flush=True)\n\nprint(\"\\n\") # New line after response completes\n\nexcept KeyboardInterrupt: print(\"\\n\\nChat interrupted by user.\") except ConnectionError as e: print(f\"\\nConnection error: {e}\") print(\"Make sure the server is running.\") except Exception as e: print(f\"\\nUnexpected error: {e}\")\n\ndef main(): \"\"\"Entry point for the AG-UI client.\"\"\" asyncio.run(interactive\\_chat())\n\nif \\_\\_name\\_\\_ == \"\\_\\_main\\_\\_\": main()\n\n**Key features:**\n\n- The client connects to the AG-UI endpoint using AGUIChatClient with the endpoint parameter\n- run\\_stream() yields updates containing text and content as they arrive\n- Tool calls are detected using FunctionCallContent and displayed with [Calling tool: ...]\n- Tool results are detected using FunctionResultContent and displayed with [Tool result: ...]\n- Deduplication logic (seen\\_tools set) prevents printing the same tool call multiple times as it streams\n- Thread management maintains conversation context across messages\n- Graceful error handling for connection issues\n\nTo use the client:\n- # Optional: specify custom server URL\nexport AGUI\\_SERVER\\_URL=\"http://localhost:8000/chat\"\n\n# Start the interactive chat\npython client.py\n\n**Example Session:**\n- Connecting to: http://localhost:8000/chat\n\nChat started! Type 'exit' or 'quit' to end the session.\n\nYou: What's the status of order ORD-001? Agent: [Calling tool: get\\_order\\_status] [Tool result: {\"status\": \"shipped\", \"tracking\": \"1Z999AA1\", \"eta\": \"Jan 25, 2026\"}] Your order ORD-001 has been shipped!\n\n- Tracking Number: 1Z999AA1\n- Estimated Delivery Date: January 25, 2026\n\nYou can use the tracking number to monitor the delivery progress.\n\nYou: Can you check ORD-002? Agent: [Calling tool: get\\_order\\_status] [Tool result: {\"status\": \"processing\", \"tracking\": null, \"eta\": \"Jan 23, 2026\"}] Your order ORD-002 is currently being processed.\n\n- Status: Processing\n- Estimated Delivery: January 23, 2026\n\nYour order should ship soon, and you'll receive a tracking number once it's on the way.\n\nYou: exit\n\nGoodbye!\n\nThe client we just built handles events at a high level, abstracting away the details. But what's actually flowing through that SSE connection? Let's peek under the hood.\n\n## Event Types You'll See\n\nAs the server streams back responses, clients receive a series of structured events. If you were to observe the raw SSE stream (e.g., using curl), you'd see events like:\n- curl -N http://localhost:8000/chat \\\n-H \"Content-Type: application/json\" \\ -H \"Accept: text/event-stream\" \\ -d '{\"messages\": [{\"role\": \"user\", \"content\": \"What'\\''s the status of order ORD-001?\"}]}'\n\n**Sample event stream (with tool calling):**\n- data: {\"type\":\"RUN\\_STARTED\",\"threadId\":\"eb4d9850-14ef-446c-af4b-23037acda9e8\",\"runId\":\"chatcmpl-xyz\"}\n\ndata: {\"type\":\"TEXT\\_MESSAGE\\_START\",\"messageId\":\"e8648880-a9ff-4178-a17d-4a6d3ec3d39c\",\"role\":\"assistant\"}\n\ndata: {\"type\":\"TOOL\\_CALL\\_START\",\"toolCallId\":\"call\\_GTWj2N3ZyYiiQIjg3fwmiQ8y\",\"toolCallName\":\"get\\_order\\_status\",\"parentMessageId\":\"e8648880-a9ff-4178-a17d-4a6d3ec3d39c\"}\n\ndata: {\"type\":\"TOOL\\_CALL\\_ARGS\",\"toolCallId\":\"call\\_GTWj2N3ZyYiiQIjg3fwmiQ8y\",\"delta\":\"{\\\"\"}\n\ndata: {\"type\":\"TOOL\\_CALL\\_ARGS\",\"toolCallId\":\"call\\_GTWj2N3ZyYiiQIjg3fwmiQ8y\",\"delta\":\"order\"}\n\ndata: {\"type\":\"TOOL\\_CALL\\_ARGS\",\"toolCallId\":\"call\\_GTWj2N3ZyYiiQIjg3fwmiQ8y\",\"delta\":\"\\_id\"}\n\ndata: {\"type\":\"TOOL\\_CALL\\_ARGS\",\"toolCallId\":\"call\\_GTWj2N3ZyYiiQIjg3fwmiQ8y\",\"delta\":\"\\\":\\\"\"}\n\ndata: {\"type\":\"TOOL\\_CALL\\_ARGS\",\"toolCallId\":\"call\\_GTWj2N3ZyYiiQIjg3fwmiQ8y\",\"delta\":\"ORD\"}\n\ndata: {\"type\":\"TOOL\\_CALL\\_ARGS\",\"toolCallId\":\"call\\_GTWj2N3ZyYiiQIjg3fwmiQ8y\",\"delta\":\"-\"}\n\ndata: {\"type\":\"TOOL\\_CALL\\_ARGS\",\"toolCallId\":\"call\\_GTWj2N3ZyYiiQIjg3fwmiQ8y\",\"delta\":\"001\"}\n\ndata: {\"type\":\"TOOL\\_CALL\\_ARGS\",\"toolCallId\":\"call\\_GTWj2N3ZyYiiQIjg3fwmiQ8y\",\"delta\":\"\\\"}\"}\n\ndata: {\"type\":\"TOOL\\_CALL\\_END\",\"toolCallId\":\"call\\_GTWj2N3ZyYiiQIjg3fwmiQ8y\"}\n\ndata: {\"type\":\"TOOL\\_CALL\\_RESULT\",\"messageId\":\"f048cb0a-a049-4a51-9403-a05e4820438a\",\"toolCallId\":\"call\\_GTWj2N3ZyYiiQIjg3fwmiQ8y\",\"content\":\"{\\\"status\\\": \\\"shipped\\\", \\\"tracking\\\": \\\"1Z999AA1\\\", \\\"eta\\\": \\\"Jan 25, 2026\\\"}\",\"role\":\"tool\"}\n\ndata: {\"type\":\"TEXT\\_MESSAGE\\_START\",\"messageId\":\"8215fc88-8cb6-4ce4-8bdb-a8715dcd26cf\",\"role\":\"assistant\"}\n\ndata: {\"type\":\"TEXT\\_MESSAGE\\_CONTENT\",\"messageId\":\"8215fc88-8cb6-4ce4-8bdb-a8715dcd26cf\",\"delta\":\"Your\"}\n\ndata: {\"type\":\"TEXT\\_MESSAGE\\_CONTENT\",\"messageId\":\"8215fc88-8cb6-4ce4-8bdb-a8715dcd26cf\",\"delta\":\" order\"}\n\ndata: {\"type\":\"TEXT\\_MESSAGE\\_CONTENT\",\"messageId\":\"8215fc88-8cb6-4ce4-8bdb-a8715dcd26cf\",\"delta\":\" ORD\"}\n\ndata: {\"type\":\"TEXT\\_MESSAGE\\_CONTENT\",\"messageId\":\"8215fc88-8cb6-4ce4-8bdb-a8715dcd26cf\",\"delta\":\"-\"}\n\ndata: {\"type\":\"TEXT\\_MESSAGE\\_CONTENT\",\"messageId\":\"8215fc88-8cb6-4ce4-8bdb-a8715dcd26cf\",\"delta\":\"001\"}\n\ndata: {\"type\":\"TEXT\\_MESSAGE\\_CONTENT\",\"messageId\":\"8215fc88-8cb6-4ce4-8bdb-a8715dcd26cf\",\"delta\":\" has\"}\n\ndata: {\"type\":\"TEXT\\_MESSAGE\\_CONTENT\",\"messageId\":\"8215fc88-8cb6-4ce4-8bdb-a8715dcd26cf\",\"delta\":\" been\"}\n\ndata: {\"type\":\"TEXT\\_MESSAGE\\_CONTENT\",\"messageId\":\"8215fc88-8cb6-4ce4-8bdb-a8715dcd26cf\",\"delta\":\" shipped\"}\n\ndata: {\"type\":\"TEXT\\_MESSAGE\\_CONTENT\",\"messageId\":\"8215fc88-8cb6-4ce4-8bdb-a8715dcd26cf\",\"delta\":\"!\"}\n\n... (additional TEXT\\_MESSAGE\\_CONTENT events streaming the response) ...\n\ndata: {\"type\":\"TEXT\\_MESSAGE\\_END\",\"messageId\":\"8215fc88-8cb6-4ce4-8bdb-a8715dcd26cf\"}\n\ndata: {\"type\":\"RUN\\_FINISHED\",\"threadId\":\"eb4d9850-14ef-446c-af4b-23037acda9e8\",\"runId\":\"chatcmpl-xyz\"}\n\n**Understanding the flow:**\n\n1. RUN\\_STARTED - Agent begins processing the request\n2. TEXT\\_MESSAGE\\_START - First message starts (will contain tool calls)\n3. TOOL\\_CALL\\_START - Agent invokes the get\\_order\\_status tool\n4. Multiple TOOL\\_CALL\\_ARGS events - Arguments stream incrementally as JSON chunks ({\"order\\_id\":\"ORD-001\"})\n5. TOOL\\_CALL\\_END - Tool invocation structure complete\n6. TOOL\\_CALL\\_RESULT - Tool execution finished with result data\n7. TEXT\\_MESSAGE\\_START - Second message starts (the final response)\n8. Multiple TEXT\\_MESSAGE\\_CONTENT events - Response text streams word-by-word\n9. TEXT\\_MESSAGE\\_END - Response message complete\n10. RUN\\_FINISHED - Entire run completed successfully\n\nThis granular event model enables rich UI experiences - showing tool execution indicators (\"Searching...\", \"Calculating...\"), displaying intermediate results, and providing complete transparency into the agent's reasoning process.\n\nSeeing the raw events helps, but truly working with AG-UI requires a shift in how you think about agent interactions. Let's explore this conceptual change.\n\n## The Mental Model Shift\n\n### Traditional API Thinking\n- # Imperative: Call and wait\nresponse = agent.run(\"What's 2+2?\") print(response) # \"The answer is 4\"\n\n**Mental model:** Function call with return value\n\n### AG-UI Thinking\n- # Reactive: Subscribe to events\nasync for event in agent.run\\_stream(\"What's 2+2?\"): match event.type: case \"RUN\\_STARTED\": show\\_loading() case \"TEXT\\_MESSAGE\\_CONTENT\": display\\_chunk(event.delta) case \"RUN\\_FINISHED\": hide\\_loading()\n\n**Mental model:** Observable stream of events\n\nThis shift feels similar to:\n\n- Moving from synchronous to async code\n- Moving from REST to event-driven architecture\n- Moving from polling to pub/sub\n\nThis mental shift isn't just philosophical - it unlocks concrete benefits that weren't possible with request/response patterns.\n\n### What You Gain\n\n#### Observability\n- # You can SEE what the agent is doing\nTOOL\\_CALL\\_START: \"get\\_order\\_status\" TOOL\\_CALL\\_ARGS: {\"order\\_id\": \"ORD-001\"} TOOL\\_CALL\\_RESULT: {\"status\": \"shipped\", \"tracking\": \"1Z999AA1\", \"eta\": \"Jan 25, 2026\"} TEXT\\_MESSAGE\\_START: \"Your order ORD-001 has been shipped...\"\n\n#### Interruptibility\n- # Future: Cancel long-running operations\nasync for event in agent.run\\_stream(query): if user\\_clicked\\_cancel: await agent.cancel(thread\\_id, run\\_id) break\n\n#### Transparency\n- # Users see the reasoning process\n\"Looking up order ORD-001...\" \"Order found: Status is 'shipped'\" \"Retrieving tracking information...\" \"Your order has been shipped with tracking number 1Z999AA1...\"\n\nTo put these benefits in context, here's how AG-UI compares to traditional approaches across key dimensions:\n\n### AG-UI vs. Traditional Approaches\n\n| Aspect | Traditional REST | Custom Streaming | AG-UI | | --- | --- | --- | --- | | Connection Model | Request/Response | Varies | Server-Sent Events | | State Management | Manual | Manual | Protocol-managed | | Tool Calling | Invisible | Custom format | Standardized events | | Framework | Varies | Framework-locked | Framework-agnostic | | Browser Support | Universal | Varies | Universal | | Implementation | Simple | Complex | Moderate | | Ecosystem | N/A | Isolated | Growing |\n\nYou've now seen AG-UI's design principles, implementation details, and conceptual foundations. But the most important question remains: should you actually use it?\n\n## Conclusion: Is AG-UI Right for Your Project?\n\nAG-UI represents a shift toward standardized, observable agent interactions. Before adopting it, understand where the protocol stands and whether it fits your needs.\n\n### Protocol Maturity\n\nThe protocol is stable enough for production use but still evolving:\n\n**Ready now:** Core specification stable, Microsoft Agent Framework integration available, FastAPI/Python implementation mature, basic streaming and threading work reliably.\n\n### Choose AG-UI If You\n\n- **Building new agent projects** - No legacy API to maintain, want future compatibility with emerging ecosystem\n- **Need streaming observability** - Multi-step workflows where users benefit from seeing each stage of execution\n- **Want framework flexibility** - Same client code works with any AG-UI-compliant backend\n- **Comfortable with evolving standards** - Can adapt to protocol changes as it matures\n\n### Stick with Alternatives If You\n\n- **Have working solutions** - Custom streaming working well, migration cost not justified\n- **Need guaranteed stability** - Mission-critical systems where breaking changes are unacceptable\n- **Build simple agents** - Single-step request/response without tool calling or streaming needs\n- **Risk-averse environment** - Large existing implementations where proven approaches are required\n\nBeyond individual project decisions, it's worth considering AG-UI's role in the broader ecosystem.\n\n### The Bigger Picture\n\nWhile this blog post focused on Microsoft Agent Framework, AG-UI's true power lies in its broader mission: creating a common language for agent-UI communication across the entire ecosystem. As more frameworks adopt it, the real value emerges: **write your UI once, work with any compliant agent framework**.\n\nThink of it like GraphQL for APIs or OpenAPI for REST - a standardization layer that benefits the entire ecosystem.\n\n**The protocol is young, but the problem it solves is real.** Whether you adopt it now or wait for broader adoption, understanding AG-UI helps you make informed architectural decisions for your agent applications.\n\nReady to dive deeper? Here are the official resources to continue your AG-UI journey.\n\n## Resources\n\n### AG-UI & Microsoft Agent Framework\n\n- [Getting Started with AG-UI (Microsoft Learn)](https://learn.microsoft.com/en-us/agent-framework/integrations/ag-ui/getting-started?pivots=programming-language-python) - Official tutorial\n- [AG-UI Integration Overview](https://learn.microsoft.com/en-us/agent-framework/integrations/ag-ui/?pivots=programming-language-python) - Architecture and concepts\n- [AG-UI Protocol Specification](https://docs.ag-ui.com/introduction) - Official protocol documentation\n- [Backend Tool Rendering](https://learn.microsoft.com/en-us/agent-framework/integrations/ag-ui/backend-tool-rendering?pivots=programming-language-python) - Adding function tools\n- [Security Considerations](https://learn.microsoft.com/en-us/agent-framework/integrations/ag-ui/security-considerations) - Production security guidance\n- [Microsoft Agent Framework Documentation](https://learn.microsoft.com/en-us/agent-framework/overview/agent-framework-overview) - Framework overview\n- [AG-UI Dojo Examples](https://dojo.ag-ui.com/microsoft-agent-framework-dotnet) - Live demonstrations\n\n### UI Components & Integration\n\n- [CopilotKit for Microsoft Agent Framework](https://docs.copilotkit.ai/microsoft-agent-framework) - React component library\n\n### Community & Support\n\n- [Microsoft Q&A](https://learn.microsoft.com/answers/) - Community support\n- [Agent Framework GitHub](https://github.com/microsoft/agent-framework) - Source code and issues\n\n### Related Technologies\n\n- [Azure AI Foundry Documentation](https://learn.microsoft.com/azure/ai-foundry/) - Azure AI platform\n- [FastAPI Documentation](https://fastapi.tiangolo.com/) - Web framework\n- [Server-Sent Events (SSE) Specification](https://html.spec.whatwg.org/multipage/server-sent-events.html) - Protocol standard\n\n*This blog post introduces AG-UI with Microsoft Agent Framework, focusing on fundamental concepts and building your first interactive agent application.*",
  "FeedUrl": "https://techcommunity.microsoft.com/t5/s/gxcuf89792/rss/Category?category.id=Azure",
  "OutputDir": "_community",
  "FeedLevelAuthor": "rss.livelink.threads-in-node",
  "PubDate": "2026-01-29T08:00:00+00:00",
  "Link": "https://techcommunity.microsoft.com/t5/microsoft-developer-community/building-interactive-agent-uis-with-ag-ui-and-microsoft-agent/ba-p/4488249",
  "FeedName": "Microsoft Tech Community",
  "ProcessedDate": "2026-01-29 08:08:20",
  "EnhancedContent": "## Introduction\n\nPicture this: You've built an AI agent that analyzes financial data. A user uploads a quarterly report and asks: *\"What are the top three expense categories?\"* Behind the scenes, your agent parses the spreadsheet, aggregates thousands of rows, and generates visualizations. All in 20 seconds. But the user? They see a loading spinner. Nothing else. No \"reading file\" message, no \"analyzing data\" indicator, no hint that progress is being made. They start wondering: Is it frozen? Should I refresh?\n\nThe problem isn't the agent's capabilities - it's the communication gap between the agent running on the backend and the user interface. When agents perform multi-step reasoning, call external APIs, or execute complex tool chains, users deserve to see what's happening. They need streaming updates, intermediate results, and transparent progress indicators. Yet most agent frameworks force developers to choose between simple request/response patterns or building custom solutions to stream updates to their UIs.\n\nThis is where **AG-UI** comes in. AG-UI is a fairly new event-based protocol that standardizes how agents communicate with user interfaces. Instead of every framework and development team inventing their own streaming solution, AG-UI provides a shared vocabulary of structured events that work consistently across different agent implementations. When an agent starts processing, calls a tool, generates text, or encounters an error, the UI receives explicit, typed events in real time.\n\nThe beauty of AG-UI is its framework-agnostic design. While this blog post demonstrates integration with **Microsoft Agent Framework (MAF)**, the same AG-UI protocol works with LangGraph, CrewAI, or any other compliant framework. Write your UI code once, and it works with any AG-UI-compliant backend. (Note: MAF supports both Python and .NET - this blog post focuses on the Python implementation.)\n\n## TL;DR\n\n**The Problem:** Users don't get real-time updates while AI agents work behind the scenes - no progress indicators, no transparency into tool calls, and no insight into what's happening.\n\n**The Solution:** AG-UI is an open, event-based protocol that standardizes real-time communication between AI agents and user interfaces. Instead of each development team and framework inventing custom streaming solutions, AG-UI provides a shared vocabulary of structured events (like TOOL\\_CALL\\_START, TEXT\\_MESSAGE\\_CONTENT, RUN\\_FINISHED) that work across any compliant framework.\n\n**Key Benefits:**\n\n- **Framework-agnostic** - Write UI code once, works with LangGraph, Microsoft Agent Framework, CrewAI, and more\n- **Real-time observability** - See exactly what your agent is doing as it happens\n- **Server-Sent Events** - Built on standard HTTP for universal compatibility\n- **Protocol-managed state** - No manual conversation history tracking\n\n**In This Post:** You'll learn why AG-UI exists, how it works, and build a complete working application using Microsoft Agent Framework with Python - from server setup to client implementation.\n\n## What You'll Learn\n\nThis blog post walks through:\n\n- **Why AG-UI exists** - how agent-UI communication has evolved and what problems current approaches couldn't solve\n- **How the protocol works** - the key design choices that make AG-UI simple, reliable, and framework-agnostic\n- **Protocol architecture** - the generic components and how AG-UI integrates with agent frameworks\n- **Building an AG-UI application** - a complete working example using Microsoft Agent Framework with server, client, and step-by-step setup\n- **Understanding events** - what happens under the hood when your agent runs and how to observe it\n- **Thinking in events** - how building with AG-UI differs from traditional APIs, and what benefits this brings\n- **Making the right choice** - when AG-UI is the right fit for your project and when alternatives might be better\n\n**Estimated reading time:** 15 minutes\n\n**Who this is for:** Developers building AI agents who want to provide real-time feedback to users, and teams evaluating standardized approaches to agent-UI communication\n\nTo appreciate why AG-UI matters, we need to understand the journey that led to its creation. Let's trace how agent-UI communication has evolved through three distinct phases.\n\n## The Evolution of Agent-UI Communication\n\nAI agents have become more capable over time. As they evolved, the way they communicated with user interfaces had to evolve as well. Here's how this evolution unfolded.\n\n### Phase 1: Simple Request/Response\n\nIn the early days of AI agent development, the interaction model was straightforward: send a question, wait for an answer, display the result. This synchronous approach mirrored traditional API calls and worked fine for simple scenarios.\n\n```\n# Simple, but limiting\nresponse = agent.run(\"What's the weather in Paris?\") display(response) # User waits... and waits... ```\n\n**Works for:** Quick queries that complete in seconds, simple Q&A interactions where immediate feedback and interactivity aren't critical.\n\n**Breaks down:** When agents need to call multiple tools, perform multi-step reasoning, or process complex queries that take 30+ seconds. Users see nothing but a loading spinner, with no insight into what's happening or whether the agent is making progress. This creates a poor user experience and makes it impossible to show intermediate results or allow user intervention.\n\nRecognizing these limitations, development teams began experimenting with more sophisticated approaches.\n\n### Phase 2: Custom Streaming Solutions\n\nAs agents became more sophisticated, teams recognized the need for incremental feedback and interactivity. Rather than waiting for the complete response, they implemented custom streaming solutions to show partial results as they became available.\n\n```\n# Every team invents their own format\nfor chunk in agent.stream(\"What's the weather?\"): display(chunk) # But what about tool calls? Errors? Progress? ```\n\nThis was a step forward for building interactive agent UIs, but each team solved the problem differently. Also, different frameworks had incompatible approaches - some streamed only text tokens, others sent structured JSON, and most provided no visibility into critical events like tool calls or errors.\n\n**The problem:**\n\n- No standardization across frameworks - client code that works with LangGraph won't work with Crew AI, requiring separate implementations for each agent backend\n- Each implementation handles tool calls differently - some send nothing during tool execution, others send unstructured messages\n- Complex state management - clients must track conversation history, manage reconnections, and handle edge cases manually\n\nThe industry needed a better solution - a common protocol that could work across all frameworks while maintaining the benefits of streaming.\n\n### Phase 3: Standardized Protocol (AG-UI)\n\nAG-UI emerged as a response to the fragmentation problem. Instead of each framework and development team inventing their own streaming solution, AG-UI provides a shared vocabulary of events that work consistently across different agent implementations.\n\n```\n# Standardized events everyone understands\nasync for event in agent.run_stream(\"What's the weather?\"): if event.type == \"TEXT_MESSAGE_CONTENT\": display_text(event.delta) elif event.type == \"TOOL_CALL_START\": show_tool_indicator(event.tool_name) elif event.type == \"TOOL_CALL_RESULT\": show_tool_result(event.result) ```\n\nThe key difference is **structured observability**. Rather than guessing what the agent is doing from unstructured text, clients receive explicit events for every stage of execution: when the agent starts, when it generates text, when it calls a tool, when that tool completes, and when the entire run finishes.\n\n**What's different:** A standardized vocabulary of event types, complete observability into agent execution, and framework-agnostic clients that work with any AG-UI-compliant backend. You write your UI code once, and it works whether the backend uses Microsoft Agent Framework, LangGraph, or any other framework that speaks AG-UI.\n\nNow that we've seen why AG-UI emerged and what problems it solves, let's examine the specific design decisions that make the protocol work. These choices weren't arbitrary - each one addresses concrete challenges in building reliable, observable agent-UI communication.\n\n## The Design Decisions Behind AG-UI\n\n### Why Server-Sent Events (SSE)?\n\n| Aspect | WebSockets | SSE (AG-UI) | | --- | --- | --- | | Complexity | Bidirectional | Unidirectional (simpler) | | Firewall/Proxy | Sometimes blocked | Standard HTTP | | Reconnection | Manual implementation | Built-in browser support | | Use case | Real-time games, chat | Agent responses (one-way) |\n\nFor agent interactions, you typically only need server→client communication, making SSE a simpler choice.\n\nSSE solves the *transport* problem - how events travel from server to client. But once connected, how does the protocol handle conversation state across multiple interactions?\n\n### Why Protocol-Managed Threads?\n\n```\n# Without protocol threads (client manages):\nconversation_history = [] conversation_history.append({\"role\": \"user\", \"content\": message}) response = agent.complete(conversation_history) conversation_history.append({\"role\": \"assistant\", \"content\": response})\n# Complex, error-prone, doesn't work with multiple clients\n\n# With AG-UI (protocol manages):\nthread = agent.get_new_thread() # Server creates and manages thread agent.run_stream(message, thread=thread) # Server maintains context\n# Simple, reliable, shareable across clients\n```\n\nWith transport and state management handled, the final piece is the actual messages flowing through the connection. What information should the protocol communicate, and how should it be structured?\n\n### Why Standardized Event Types?\n\nInstead of parsing unstructured text, clients get typed events:\n\n- RUN\\_STARTED - Agent begins (start loading UI)\n- TEXT\\_MESSAGE\\_CONTENT - Text chunk (stream to user)\n- TOOL\\_CALL\\_START - Tool invoked (show \"searching...\", \"calculating...\")\n- TOOL\\_CALL\\_RESULT - Tool finished (show result, update UI)\n- RUN\\_FINISHED - Complete (hide loading)\n\nThis lets UIs react intelligently without custom parsing logic.\n\nNow that we understand the protocol's design choices, let's see how these pieces fit together in a complete system.\n\n## Architecture Overview\n\nHere's how the components interact:\n\nThe communication between these layers relies on a well-defined set of event types. Here are the core events that flow through the SSE connection:\n\n### Core Event Types\n\nAG-UI provides a standardized set of event types to describe what's happening during an agent's execution:\n\n- RUN\\_STARTED - agent begins execution\n- TEXT\\_MESSAGE\\_START, TEXT\\_MESSAGE\\_CONTENT, TEXT\\_MESSAGE\\_END - streaming segments of text\n- TOOL\\_CALL\\_START, TOOL\\_CALL\\_ARGS, TOOL\\_CALL\\_END, TOOL\\_CALL\\_RESULT - tool execution events\n- RUN\\_FINISHED - agent has finished execution\n- RUN\\_ERROR - error information\n\nThis model lets the UI update as the agent runs, rather than waiting for the final response.\n\nThe generic architecture above applies to any AG-UI implementation. Now let's see how this translates to Microsoft Agent Framework.\n\n## AG-UI with Microsoft Agent Framework\n\nWhile AG-UI is framework-agnostic, this blog post demonstrates integration with Microsoft Agent Framework (MAF) using Python. MAF is available in both **Python** and **.NET**, giving you flexibility to build AG-UI applications in your preferred language. Understanding how MAF implements the protocol will help you build your own applications or work with other compliant frameworks.\n\n### Integration Architecture\n\nThe Microsoft Agent Framework integration involves several specialized layers that handle protocol translation and execution orchestration:\n\n**Understanding each layer:**\n\n- **FastAPI Endpoint** - Handles HTTP requests and establishes SSE connections for streaming\n- **AgentFrameworkAgent** - Protocol wrapper that translates between AG-UI events and Agent Framework operations\n- **Orchestrators** - Manage execution flow, coordinate tool calling sequences, and handle state transitions\n- **ChatAgent** - Your agent implementation with instructions, tools, and business logic\n- **ChatClient** - Interface to the underlying language model (Azure OpenAI, OpenAI, or other providers)\n\nThe good news? When you call add\\_agent\\_framework\\_fastapi\\_endpoint, all the middleware layers are configured automatically. You simply provide your ChatAgent, and the integration handles protocol translation, event streaming, and state management behind the scenes.\n\nNow that we understand both the protocol architecture and the Microsoft Agent Framework integration, let's build a working application.\n\n## Hands-On: Building Your First AG-UI Application\n\nThis section demonstrates how to build an AG-UI server and client using Microsoft Agent Framework and FastAPI.\n\n### Prerequisites\n\nBefore building your first AG-UI application, ensure you have:\n\n- **Python 3.10 or later** installed\n- **Basic understanding** of async/await patterns in Python\n- **Azure CLI** installed and authenticated (az login)\n- **Azure OpenAI service** endpoint and deployment configured ([setup guide](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/how-to/create-resource))\n- **Cognitive Services OpenAI Contributor** role for your Azure OpenAI resource\n\nYou'll also need to install the AG-UI integration package:\n\n``` pip install agent-framework-ag-ui --pre ```\n\nThis automatically installs agent-framework-core, fastapi, and uvicorn as dependencies.\n\nWith your environment configured, let's create the server that will host your agent and expose it via the AG-UI protocol.\n\n### Building the Server\n\nLet's create a FastAPI server that hosts an AI agent and exposes it via AG-UI:\n\n```\n# server.py\nimport os from typing import Annotated from dotenv import load_dotenv from fastapi import FastAPI from pydantic import Field from agent_framework import ChatAgent, ai_function from agent_framework.azure import AzureOpenAIChatClient from agent_framework_ag_ui import add_agent_framework_fastapi_endpoint from azure.identity import DefaultAzureCredential\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Validate environment configuration\nopenai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\") model_deployment = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n\nif not openai_endpoint: raise RuntimeError(\"Missing required environment variable: AZURE_OPENAI_ENDPOINT\") if not model_deployment: raise RuntimeError(\"Missing required environment variable: AZURE_OPENAI_DEPLOYMENT_NAME\")\n\n# Define tools the agent can use\n@ai_function def get_order_status( order_id: Annotated[str, Field(description=\"The order ID to look up (e.g., ORD-001)\")] ) -> dict: \"\"\"Look up the status of a customer order.\n\nReturns order status, tracking number, and estimated delivery date. \"\"\"\n# Simulated order lookup\norders = { \"ORD-001\": {\"status\": \"shipped\", \"tracking\": \"1Z999AA1\", \"eta\": \"Jan 25, 2026\"}, \"ORD-002\": {\"status\": \"processing\", \"tracking\": None, \"eta\": \"Jan 23, 2026\"}, \"ORD-003\": {\"status\": \"delivered\", \"tracking\": \"1Z999AA3\", \"eta\": \"Delivered Jan 20\"}, } return orders.get(order_id, {\"status\": \"not_found\", \"message\": \"Order not found\"})\n\n# Initialize Azure OpenAI client\nchat_client = AzureOpenAIChatClient( credential=DefaultAzureCredential(), endpoint=openai_endpoint, deployment_name=model_deployment, )\n\n# Configure the agent with custom instructions and tools\nagent = ChatAgent( name=\"CustomerSupportAgent\", instructions=\"\"\"You are a helpful customer support assistant.\n\nYou have access to a get_order_status tool that can look up order information.\n\nIMPORTANT: When a user mentions an order ID (like ORD-001, ORD-002, etc.), you MUST call the get_order_status tool to retrieve the actual order details. Do NOT make up or guess order information.\n\nAfter calling get_order_status, provide the actual results to the user in a friendly format.\"\"\", chat_client=chat_client, tools=[get_order_status], )\n\n# Initialize FastAPI application\napp = FastAPI( title=\"AG-UI Customer Support Server\", description=\"Interactive AI agent server using AG-UI protocol with tool calling\" )\n\n# Mount the AG-UI endpoint\nadd_agent_framework_fastapi_endpoint(app, agent, path=\"/chat\")\n\ndef main(): \"\"\"Entry point for the AG-UI server.\"\"\" import uvicorn print(\"Starting AG-UI server on http://localhost:8000\") uvicorn.run(app, host=\"0.0.0.0\", port=8000, log_level=\"info\")\n\n# Run the application\nif __name__ == \"__main__\": main() ```\n\n**What's happening here:**\n\n- We define a tool: get\\_order\\_status with the [AI​](javascript:void%280%29)\\_function decorator\n- Use Annotated and Field for parameter descriptions to help the agent understand when and how to use the tool\n- We create an Azure OpenAI chat client with credential authentication\n- The ChatAgent is configured with domain-specific instructions and the tools parameter\n- add\\_agent\\_framework\\_fastapi\\_endpoint automatically handles SSE streaming and tool execution\n- The server exposes the agent at the /chat endpoint\n\n> >\n> **Note:** This example uses Azure OpenAI, but AG-UI works with any chat model. You can also integrate with Azure AI Foundry's model catalog or use other LLM providers. Tool calling is supported by most modern LLMs including GPT-4, GPT-4o, and Claude models.\n> >\n\nTo run this server:\n\n```\n# Set your Azure OpenAI credentials\nexport AZURE_OPENAI_ENDPOINT=\"https://your-resource.openai.azure.com/\" export AZURE_OPENAI_DEPLOYMENT_NAME=\"gpt-4o\"\n\n# Start the server\npython server.py ```\n\nWith your server running and exposing the AG-UI endpoint, the next step is building a client that can connect and consume the event stream.\n\n## Streaming Results to Clients\n\nWith the server running, clients can connect and stream events as the agent processes requests. Here's a Python client that demonstrates the streaming capabilities:\n\n```\n# client.py\nimport asyncio import os from dotenv import load_dotenv from agent_framework import ChatAgent, FunctionCallContent, FunctionResultContent from agent_framework_ag_ui import AGUIChatClient\n\n# Load environment variables from .env file\nload_dotenv()\n\nasync def interactive_chat(): \"\"\"Interactive chat session with streaming responses.\"\"\"\n\n# Connect to the AG-UI server\nbase_url = os.getenv(\"AGUI_SERVER_URL\", \"http://localhost:8000/chat\") print(f\"Connecting to: {base_url}\\n\")\n\n# Initialize the AG-UI client\nclient = AGUIChatClient(endpoint=base_url)\n\n# Create a local agent representation\nagent = ChatAgent(chat_client=client)\n\n# Start a new conversation thread\nconversation_thread = agent.get_new_thread()\n\nprint(\"Chat started! Type 'exit' or 'quit' to end the session.\\n\")\n\ntry: while True:\n# Collect user input\nuser_message = input(\"You: \")\n\n# Handle empty input\nif not user_message.strip(): print(\"Please enter a message.\\n\") continue\n\n# Check for exit commands\nif user_message.lower() in [\"exit\", \"quit\", \"bye\"]: print(\"\\nGoodbye!\") break\n\n# Stream the agent's response\nprint(\"Agent: \", end=\"\", flush=True)\n\n# Track tool calls to avoid duplicate prints\nseen_tools = set()\n\nasync for update in agent.run_stream(user_message, thread=conversation_thread):\n# Display text content\nif update.text: print(update.text, end=\"\", flush=True)\n\n# Display tool calls and results\nfor content in update.contents: if isinstance(content, FunctionCallContent):\n# Only print each tool call once\nif content.call_id not in seen_tools: seen_tools.add(content.call_id) print(f\"\\n[Calling tool: {content.name}]\", flush=True) elif isinstance(content, FunctionResultContent):\n# Only print each result once\nresult_id = f\"result_{content.call_id}\" if result_id not in seen_tools: seen_tools.add(result_id) result_text = content.result if isinstance(content.result, str) else str(content.result) print(f\"[Tool result: {result_text}]\", flush=True)\n\nprint(\"\\n\") # New line after response completes\n\nexcept KeyboardInterrupt: print(\"\\n\\nChat interrupted by user.\") except ConnectionError as e: print(f\"\\nConnection error: {e}\") print(\"Make sure the server is running.\") except Exception as e: print(f\"\\nUnexpected error: {e}\")\n\ndef main(): \"\"\"Entry point for the AG-UI client.\"\"\" asyncio.run(interactive_chat())\n\nif __name__ == \"__main__\": main() ```\n\n**Key features:**\n\n- The client connects to the AG-UI endpoint using AGUIChatClient with the endpoint parameter\n- run\\_stream() yields updates containing text and content as they arrive\n- Tool calls are detected using FunctionCallContent and displayed with [Calling tool: ...]\n- Tool results are detected using FunctionResultContent and displayed with [Tool result: ...]\n- Deduplication logic (seen\\_tools set) prevents printing the same tool call multiple times as it streams\n- Thread management maintains conversation context across messages\n- Graceful error handling for connection issues\n\nTo use the client:\n\n```\n# Optional: specify custom server URL\nexport AGUI_SERVER_URL=\"http://localhost:8000/chat\"\n\n# Start the interactive chat\npython client.py ```\n\n**Example Session:**\n\n``` Connecting to: http://localhost:8000/chat\n\nChat started! Type 'exit' or 'quit' to end the session.\n\nYou: What's the status of order ORD-001? Agent: [Calling tool: get_order_status] [Tool result: {\"status\": \"shipped\", \"tracking\": \"1Z999AA1\", \"eta\": \"Jan 25, 2026\"}] Your order ORD-001 has been shipped!\n\n- Tracking Number: 1Z999AA1\n- Estimated Delivery Date: January 25, 2026\n\nYou can use the tracking number to monitor the delivery progress.\n\nYou: Can you check ORD-002? Agent: [Calling tool: get_order_status] [Tool result: {\"status\": \"processing\", \"tracking\": null, \"eta\": \"Jan 23, 2026\"}] Your order ORD-002 is currently being processed.\n\n- Status: Processing\n- Estimated Delivery: January 23, 2026\n\nYour order should ship soon, and you'll receive a tracking number once it's on the way.\n\nYou: exit\n\nGoodbye! ```\n\nThe client we just built handles events at a high level, abstracting away the details. But what's actually flowing through that SSE connection? Let's peek under the hood.\n\n## Event Types You'll See\n\nAs the server streams back responses, clients receive a series of structured events. If you were to observe the raw SSE stream (e.g., using curl), you'd see events like:\n\n``` curl -N http://localhost:8000/chat \\ -H \"Content-Type: application/json\" \\ -H \"Accept: text/event-stream\" \\ -d '{\"messages\": [{\"role\": \"user\", \"content\": \"What'\\''s the status of order ORD-001?\"}]}' ```\n\n**Sample event stream (with tool calling):**\n\n``` data: {\"type\":\"RUN_STARTED\",\"threadId\":\"eb4d9850-14ef-446c-af4b-23037acda9e8\",\"runId\":\"chatcmpl-xyz\"}\n\ndata: {\"type\":\"TEXT_MESSAGE_START\",\"messageId\":\"e8648880-a9ff-4178-a17d-4a6d3ec3d39c\",\"role\":\"assistant\"}\n\ndata: {\"type\":\"TOOL_CALL_START\",\"toolCallId\":\"call_GTWj2N3ZyYiiQIjg3fwmiQ8y\",\"toolCallName\":\"get_order_status\",\"parentMessageId\":\"e8648880-a9ff-4178-a17d-4a6d3ec3d39c\"}\n\ndata: {\"type\":\"TOOL_CALL_ARGS\",\"toolCallId\":\"call_GTWj2N3ZyYiiQIjg3fwmiQ8y\",\"delta\":\"{\\\"\"}\n\ndata: {\"type\":\"TOOL_CALL_ARGS\",\"toolCallId\":\"call_GTWj2N3ZyYiiQIjg3fwmiQ8y\",\"delta\":\"order\"}\n\ndata: {\"type\":\"TOOL_CALL_ARGS\",\"toolCallId\":\"call_GTWj2N3ZyYiiQIjg3fwmiQ8y\",\"delta\":\"_id\"}\n\ndata: {\"type\":\"TOOL_CALL_ARGS\",\"toolCallId\":\"call_GTWj2N3ZyYiiQIjg3fwmiQ8y\",\"delta\":\"\\\":\\\"\"}\n\ndata: {\"type\":\"TOOL_CALL_ARGS\",\"toolCallId\":\"call_GTWj2N3ZyYiiQIjg3fwmiQ8y\",\"delta\":\"ORD\"}\n\ndata: {\"type\":\"TOOL_CALL_ARGS\",\"toolCallId\":\"call_GTWj2N3ZyYiiQIjg3fwmiQ8y\",\"delta\":\"-\"}\n\ndata: {\"type\":\"TOOL_CALL_ARGS\",\"toolCallId\":\"call_GTWj2N3ZyYiiQIjg3fwmiQ8y\",\"delta\":\"001\"}\n\ndata: {\"type\":\"TOOL_CALL_ARGS\",\"toolCallId\":\"call_GTWj2N3ZyYiiQIjg3fwmiQ8y\",\"delta\":\"\\\"}\"}\n\ndata: {\"type\":\"TOOL_CALL_END\",\"toolCallId\":\"call_GTWj2N3ZyYiiQIjg3fwmiQ8y\"}\n\ndata: {\"type\":\"TOOL_CALL_RESULT\",\"messageId\":\"f048cb0a-a049-4a51-9403-a05e4820438a\",\"toolCallId\":\"call_GTWj2N3ZyYiiQIjg3fwmiQ8y\",\"content\":\"{\\\"status\\\": \\\"shipped\\\", \\\"tracking\\\": \\\"1Z999AA1\\\", \\\"eta\\\": \\\"Jan 25, 2026\\\"}\",\"role\":\"tool\"}\n\ndata: {\"type\":\"TEXT_MESSAGE_START\",\"messageId\":\"8215fc88-8cb6-4ce4-8bdb-a8715dcd26cf\",\"role\":\"assistant\"}\n\ndata: {\"type\":\"TEXT_MESSAGE_CONTENT\",\"messageId\":\"8215fc88-8cb6-4ce4-8bdb-a8715dcd26cf\",\"delta\":\"Your\"}\n\ndata: {\"type\":\"TEXT_MESSAGE_CONTENT\",\"messageId\":\"8215fc88-8cb6-4ce4-8bdb-a8715dcd26cf\",\"delta\":\" order\"}\n\ndata: {\"type\":\"TEXT_MESSAGE_CONTENT\",\"messageId\":\"8215fc88-8cb6-4ce4-8bdb-a8715dcd26cf\",\"delta\":\" ORD\"}\n\ndata: {\"type\":\"TEXT_MESSAGE_CONTENT\",\"messageId\":\"8215fc88-8cb6-4ce4-8bdb-a8715dcd26cf\",\"delta\":\"-\"}\n\ndata: {\"type\":\"TEXT_MESSAGE_CONTENT\",\"messageId\":\"8215fc88-8cb6-4ce4-8bdb-a8715dcd26cf\",\"delta\":\"001\"}\n\ndata: {\"type\":\"TEXT_MESSAGE_CONTENT\",\"messageId\":\"8215fc88-8cb6-4ce4-8bdb-a8715dcd26cf\",\"delta\":\" has\"}\n\ndata: {\"type\":\"TEXT_MESSAGE_CONTENT\",\"messageId\":\"8215fc88-8cb6-4ce4-8bdb-a8715dcd26cf\",\"delta\":\" been\"}\n\ndata: {\"type\":\"TEXT_MESSAGE_CONTENT\",\"messageId\":\"8215fc88-8cb6-4ce4-8bdb-a8715dcd26cf\",\"delta\":\" shipped\"}\n\ndata: {\"type\":\"TEXT_MESSAGE_CONTENT\",\"messageId\":\"8215fc88-8cb6-4ce4-8bdb-a8715dcd26cf\",\"delta\":\"!\"}\n\n... (additional TEXT_MESSAGE_CONTENT events streaming the response) ...\n\ndata: {\"type\":\"TEXT_MESSAGE_END\",\"messageId\":\"8215fc88-8cb6-4ce4-8bdb-a8715dcd26cf\"}\n\ndata: {\"type\":\"RUN_FINISHED\",\"threadId\":\"eb4d9850-14ef-446c-af4b-23037acda9e8\",\"runId\":\"chatcmpl-xyz\"} ```\n\n**Understanding the flow:**\n\n1. RUN\\_STARTED - Agent begins processing the request\n2. TEXT\\_MESSAGE\\_START - First message starts (will contain tool calls)\n3. TOOL\\_CALL\\_START - Agent invokes the get\\_order\\_status tool\n4. Multiple TOOL\\_CALL\\_ARGS events - Arguments stream incrementally as JSON chunks ({\"order\\_id\":\"ORD-001\"})\n5. TOOL\\_CALL\\_END - Tool invocation structure complete\n6. TOOL\\_CALL\\_RESULT - Tool execution finished with result data\n7. TEXT\\_MESSAGE\\_START - Second message starts (the final response)\n8. Multiple TEXT\\_MESSAGE\\_CONTENT events - Response text streams word-by-word\n9. TEXT\\_MESSAGE\\_END - Response message complete\n10. RUN\\_FINISHED - Entire run completed successfully\n\nThis granular event model enables rich UI experiences - showing tool execution indicators (\"Searching...\", \"Calculating...\"), displaying intermediate results, and providing complete transparency into the agent's reasoning process.\n\nSeeing the raw events helps, but truly working with AG-UI requires a shift in how you think about agent interactions. Let's explore this conceptual change.\n\n## The Mental Model Shift\n\n### Traditional API Thinking\n\n```\n# Imperative: Call and wait\nresponse = agent.run(\"What's 2+2?\") print(response) # \"The answer is 4\" ```\n\n**Mental model:** Function call with return value\n\n### AG-UI Thinking\n\n```\n# Reactive: Subscribe to events\nasync for event in agent.run_stream(\"What's 2+2?\"): match event.type: case \"RUN_STARTED\": show_loading() case \"TEXT_MESSAGE_CONTENT\": display_chunk(event.delta) case \"RUN_FINISHED\": hide_loading() ```\n\n**Mental model:** Observable stream of events\n\nThis shift feels similar to:\n\n- Moving from synchronous to async code\n- Moving from REST to event-driven architecture\n- Moving from polling to pub/sub\n\nThis mental shift isn't just philosophical - it unlocks concrete benefits that weren't possible with request/response patterns.\n\n### What You Gain\n\n#### Observability\n\n```\n# You can SEE what the agent is doing\nTOOL_CALL_START: \"get_order_status\" TOOL_CALL_ARGS: {\"order_id\": \"ORD-001\"} TOOL_CALL_RESULT: {\"status\": \"shipped\", \"tracking\": \"1Z999AA1\", \"eta\": \"Jan 25, 2026\"} TEXT_MESSAGE_START: \"Your order ORD-001 has been shipped...\" ```\n\n#### Interruptibility\n\n```\n# Future: Cancel long-running operations\nasync for event in agent.run_stream(query): if user_clicked_cancel: await agent.cancel(thread_id, run_id) break ```\n\n#### Transparency\n\n```\n# Users see the reasoning process\n\"Looking up order ORD-001...\" \"Order found: Status is 'shipped'\" \"Retrieving tracking information...\" \"Your order has been shipped with tracking number 1Z999AA1...\" ```\n\nTo put these benefits in context, here's how AG-UI compares to traditional approaches across key dimensions:\n\n### AG-UI vs. Traditional Approaches\n\n| Aspect | Traditional REST | Custom Streaming | AG-UI | | --- | --- | --- | --- | | Connection Model | Request/Response | Varies | Server-Sent Events | | State Management | Manual | Manual | Protocol-managed | | Tool Calling | Invisible | Custom format | Standardized events | | Framework | Varies | Framework-locked | Framework-agnostic | | Browser Support | Universal | Varies | Universal | | Implementation | Simple | Complex | Moderate | | Ecosystem | N/A | Isolated | Growing |\n\nYou've now seen AG-UI's design principles, implementation details, and conceptual foundations. But the most important question remains: should you actually use it?\n\n## Conclusion: Is AG-UI Right for Your Project?\n\nAG-UI represents a shift toward standardized, observable agent interactions. Before adopting it, understand where the protocol stands and whether it fits your needs.\n\n### Protocol Maturity\n\nThe protocol is stable enough for production use but still evolving:\n\n**Ready now:** Core specification stable, Microsoft Agent Framework integration available, FastAPI/Python implementation mature, basic streaming and threading work reliably.\n\n### Choose AG-UI If You\n\n- **Building new agent projects** - No legacy API to maintain, want future compatibility with emerging ecosystem\n- **Need streaming observability** - Multi-step workflows where users benefit from seeing each stage of execution\n- **Want framework flexibility** - Same client code works with any AG-UI-compliant backend\n- **Comfortable with evolving standards** - Can adapt to protocol changes as it matures\n\n### Stick with Alternatives If You\n\n- **Have working solutions** - Custom streaming working well, migration cost not justified\n- **Need guaranteed stability** - Mission-critical systems where breaking changes are unacceptable\n- **Build simple agents** - Single-step request/response without tool calling or streaming needs\n- **Risk-averse environment** - Large existing implementations where proven approaches are required\n\nBeyond individual project decisions, it's worth considering AG-UI's role in the broader ecosystem.\n\n### The Bigger Picture\n\nWhile this blog post focused on Microsoft Agent Framework, AG-UI's true power lies in its broader mission: creating a common language for agent-UI communication across the entire ecosystem. As more frameworks adopt it, the real value emerges: **write your UI once, work with any compliant agent framework**.\n\nThink of it like GraphQL for APIs or OpenAPI for REST - a standardization layer that benefits the entire ecosystem.\n\n**The protocol is young, but the problem it solves is real.** Whether you adopt it now or wait for broader adoption, understanding AG-UI helps you make informed architectural decisions for your agent applications.\n\nReady to dive deeper? Here are the official resources to continue your AG-UI journey.\n\n## Resources\n\n### AG-UI & Microsoft Agent Framework\n\n- [Getting Started with AG-UI (Microsoft Learn)](https://learn.microsoft.com/en-us/agent-framework/integrations/ag-ui/getting-started?pivots=programming-language-python) - Official tutorial\n- [AG-UI Integration Overview](https://learn.microsoft.com/en-us/agent-framework/integrations/ag-ui/?pivots=programming-language-python) - Architecture and concepts\n- [AG-UI Protocol Specification](https://docs.ag-ui.com/introduction) - Official protocol documentation\n- [Backend Tool Rendering](https://learn.microsoft.com/en-us/agent-framework/integrations/ag-ui/backend-tool-rendering?pivots=programming-language-python) - Adding function tools\n- [Security Considerations](https://learn.microsoft.com/en-us/agent-framework/integrations/ag-ui/security-considerations) - Production security guidance\n- [Microsoft Agent Framework Documentation](https://learn.microsoft.com/en-us/agent-framework/overview/agent-framework-overview) - Framework overview\n- [AG-UI Dojo Examples](https://dojo.ag-ui.com/microsoft-agent-framework-dotnet) - Live demonstrations\n\n### UI Components & Integration\n\n- [CopilotKit for Microsoft Agent Framework](https://docs.copilotkit.ai/microsoft-agent-framework) - React component library\n\n### Community & Support\n\n- [Microsoft Q&A](https://learn.microsoft.com/answers/) - Community support\n- [Agent Framework GitHub](https://github.com/microsoft/agent-framework) - Source code and issues\n\n### Related Technologies\n\n- [Azure AI Foundry Documentation](https://learn.microsoft.com/azure/ai-foundry/) - Azure AI platform\n- [FastAPI Documentation](https://fastapi.tiangolo.com/) - Web framework\n- [Server-Sent Events (SSE) Specification](https://html.spec.whatwg.org/multipage/server-sent-events.html) - Protocol standard\n\n*This blog post introduces AG-UI with Microsoft Agent Framework, focusing on fundamental concepts and building your first interactive agent application.*\n\nUpdated Jan 21, 2026\n\nVersion 1.0\n\n[agents](/tag/agents?nodeId=board%3AAzureDevCommunityBlog)\n\n[ai](/tag/ai?nodeId=board%3AAzureDevCommunityBlog)\n\n[ai foundry](/tag/ai%20foundry?nodeId=board%3AAzureDevCommunityBlog)\n\n[azure](/tag/azure?nodeId=board%3AAzureDevCommunityBlog)\n\n[azure ai foundry](/tag/azure%20ai%20foundry?nodeId=board%3AAzureDevCommunityBlog)\n\n[best practices](/tag/best%20practices?nodeId=board%3AAzureDevCommunityBlog)\n\n[developer](/tag/developer?nodeId=board%3AAzureDevCommunityBlog)\n\n[get started](/tag/get%20started?nodeId=board%3AAzureDevCommunityBlog)\n\n[learning](/tag/learning?nodeId=board%3AAzureDevCommunityBlog)\n\n[llm](/tag/llm?nodeId=board%3AAzureDevCommunityBlog)\n\n[!\\[pratikpanda&#x27;s avatar\\](https://techcommunity.microsoft.com/t5/s/gxcuf89792/images/dS0xMjc0MjQzLTMzOTI1MGk4NTAyREFGNDFEQzkxQTE2?image-dimensions=50x50)](/users/pratikpanda/1274243) [pratikpanda](/users/pratikpanda/1274243) ![Icon for Microsoft rank](https://techcommunity.microsoft.com/t5/s/gxcuf89792/images/cmstNC05WEo0blc?image-dimensions=100x16&amp;constrain-image=true)Microsoft\n\nJoined January 12, 2022\n\n[View Profile](/users/pratikpanda/1274243)\n\n/category/azure/blog/azuredevcommunityblog [Microsoft Developer Community Blog](/category/azure/blog/azuredevcommunityblog) Follow this blog board to get notified when there's new activity",
  "Author": "pratikpanda",
  "Tags": [],
  "Title": "Building Interactive Agent UIs with AG-UI and Microsoft Agent Framework"
}
