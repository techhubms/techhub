{
  "Link": "https://techcommunity.microsoft.com/t5/microsoft-developer-community/building-a-privacy-first-hybrid-ai-briefing-tool-with-foundry/ba-p/4490535",
  "PubDate": "2026-02-26T08:00:00+00:00",
  "EnhancedContent": "## The Challenge: Balancing Speed, Privacy, and Quality in Client Work\n\n## Introduction\n\nManagement consultants face a critical challenge: they need instant AI-powered insights from sensitive client documents, but traditional cloud-only AI solutions create unacceptable data privacy risks. Every document uploaded to a cloud API potentially exposes confidential client information, violates data residency requirements, and creates compliance headaches.\n\nThe solution lies in a hybrid architecture that combines the speed and privacy of on-device AI with the sophistication of cloud models‚Äîbut only when explicitly requested. This article walks through building a production-ready briefing assistant that runs AI inference locally first, then optionally refines outputs using Azure OpenAI for executive-quality presentations.\n\nWe'll explore a sample implementation using [FL-Client-Briefing-Assistant](https://github.com/leestott/FL-Client-Briefing-Assistant), built with Next.js 14, TypeScript, and Microsoft Foundry Local. You'll learn how to architect privacy-first AI applications, implement sub-second local inference, and design transparent hybrid workflows that give users complete control over their data.\n\n## Why Hybrid AI Architecture Matters for Enterprise Applications\n\nBefore diving into implementation details, let's understand why a hybrid approach is essential for enterprise AI applications, particularly in consulting and professional services.\n\nCloud-only AI services like OpenAI's GPT-4 offer remarkable capabilities, but they introduce several critical challenges. First, every API call sends your data to external servers, creating audit trails and potential exposure points. For consultants handling merger documents, financial reports, or strategic plans, this is often a non-starter. Second, cloud APIs introduce latency, typically 2-5 seconds per request due to network round-trips and queue times. Third, costs scale linearly with usage, making high-volume document analysis expensive at scale.\n\nLocal-only AI solves privacy and latency concerns but sacrifices quality. Small language models (SLMs) running on laptops produce quick summaries, but they lack the nuanced reasoning and polish needed for C-suite presentations. You get fast, private results that may require significant manual refinement.\n\nThe hybrid approach gives you the best of both worlds: instant, private local processing as the default, with optional cloud refinement only when quality matters most. This architecture respects data privacy by default while maintaining the flexibility to produce executive-grade outputs when needed.\n\n## Architecture Overview: Three-Layer Design for Privacy and Performance\n\nThe FL-Client-Briefing-Assistant implements a clean three-layer architecture that separates concerns and ensures privacy at every level.\n\nAt the frontend, a Next.js 14 application provides the user interface with strong TypeScript typing throughout. Users interact with four quick-action templates: document summarization, talking points generation, risk analysis, and executive summaries. The UI clearly indicates which model (local or cloud) processed each request, ensuring transparency.\n\nThe middle tier consists of Next.js API routes that act as orchestration endpoints. These routes validate requests using Zod schemas, route to appropriate inference services, and enforce privacy settings. Critically, the API layer never persists user content unless explicitly opted in via privacy settings.\n\nThe inference layer contains two distinct services. The local service uses Foundry Local SDK to communicate with a locally running Phi-4 model (or similar SLM). This provides sub-second inference, typical 500ms-1s response times, completely offline. The cloud service connects to Azure OpenAI using the official JavaScript SDK, accessed via Managed Identity or API keys, with proper timeout and retry logic.\n\n## Setting Up Foundry Local for On-Device Inference\n\nFoundry Local is Microsoft's runtime for running AI models entirely on your device‚Äîno internet required, no data leaving your machine. Here's how to get it running for this application.\n\nFirst, install Foundry Local on Windows using Windows Package Manager:\n\n``` winget install Microsoft.FoundryLocal ```\n\nAfter installation, verify the service is ready:\n\n``` foundry service start foundry service status ```\n\nThe status command will show you the service endpoint, typically running on a dynamic port like `http://127.0.0.1:5272` . This port changes between restarts, so your application must query it programmatically.\n\nNext, load an appropriate model. For briefing tasks, Phi-4 Mini provides an excellent balance of quality and speed:\n\n``` foundry model load phi-4 ```\n\nThe model downloads (approximately 3.6GB) and loads into memory. This takes 2-5 minutes on first run but persists between sessions. Once loaded, inference is nearly instant, most requests complete in under 1 second.\n\nIn your application, configure the connection in `.env.local` : the port for foundry local is dynamic so please ensure you add the correct port.\n\n``` FOUNDRY_LOCAL_ENDPOINT=http://127.0.0.1:**** ```\n\nThe application uses the Foundry Local SDK to query the running service:\n\n``` import { FoundryLocalClient } from 'foundry-local-sdk';\n\nconst client = new FoundryLocalClient({ endpoint: process.env.FOUNDRY_LOCAL_ENDPOINT });\n\nconst response = await client.chat.completions.create({ model: 'phi-4', messages: [ { role: 'system', content: 'You are a professional consultant assistant.' }, { role: 'user', content: 'Summarize this document: ...' } ], max_tokens: 500, temperature: 0.3 }); ```\n\nThis code demonstrates several best practices:\n\n- **Explicit model specification**: Always name the model to ensure consistency across environments\n- **System message framing**: Set the appropriate professional context for consulting use cases\n- **Conservative temperature**: Use 0.3 for factual summarization tasks to reduce hallucination\n- **Token limits**: Cap outputs to prevent excessive generation times and costs\n\n## Implementing Privacy-First API Routes\n\nThe Next.js API routes form the security boundary of the application. Every request must be validated, sanitized, and routed according to privacy settings before reaching inference services.\n\nHere's the core local inference route (`app/api/briefing/local/route.ts` ):\n\n``` import { NextRequest, NextResponse } from 'next/server'; import { z } from 'zod'; import { FoundryLocalClient } from 'foundry-local-sdk';\n\nconst RequestSchema = z.object({ prompt: z.string().min(10).max(5000), template: z.enum(['summary', 'talking-points', 'risk-analysis', 'executive']), context: z.string().optional() });\n\nexport async function POST(request: NextRequest) { try { // Validate and parse request body const body = await request.json(); const validated = RequestSchema.parse(body);\n\n// Initialize Foundry Local client const client = new FoundryLocalClient({ endpoint: process.env.FOUNDRY_LOCAL_ENDPOINT! });\n\n// Build system prompt based on template const systemPrompts = { 'summary': 'You are a consultant creating concise document summaries.', 'talking-points': 'You are preparing structured talking points for meetings.', 'risk-analysis': 'You are analyzing risks and opportunities systematically.', 'executive': 'You are crafting executive-level briefing notes.' };\n\n// Execute local inference const startTime = Date.now(); const completion = await client.chat.completions.create({ model: 'phi-4', messages: [ { role: 'system', content: systemPrompts[validated.template] }, { role: 'user', content: validated.prompt } ], temperature: 0.3, max_tokens: 500 });\n\nconst latency = Date.now() - startTime;\n\n// Return structured response with metadata return NextResponse.json({ content: completion.choices[0].message.content, model: 'phi-4 (local)', latency_ms: latency, tokens: completion.usage?.total_tokens, timestamp: new Date().toISOString() });\n\n} catch (error) { if (error instanceof z.ZodError) { return NextResponse.json( { error: 'Invalid request format', details: error.errors }, { status: 400 } ); }\n\nconsole.error('Local inference error:', error); return NextResponse.json( { error: 'Inference failed', message: error.message }, { status: 500 } ); } } ```\n\nThis implementation demonstrates several critical security and quality patterns:\n\n- **Request validation with Zod**: Every field is type-checked and bounded before processing, preventing injection attacks and malformed inputs\n- **Template-based system prompts**: Different use cases get optimized prompts, improving output quality and consistency\n- **Comprehensive error handling**: Validation errors, inference failures, and network issues are caught and reported with appropriate HTTP status codes\n- **Performance tracking**: Latency measurement enables monitoring and helps users understand response times\n- **Metadata enrichment**: Responses include model attribution, token usage, and timestamps for auditing\n\nThe cloud refinement route follows a similar pattern but adds privacy checks:\n\n``` export async function POST(request: NextRequest) { try { const body = await request.json(); const validated = RequestSchema.parse(body);\n\n// Check privacy settings from cookie/header const confidentialMode = request.cookies.get('confidential-mode')?.value === 'true';\n\nif (confidentialMode) { return NextResponse.json( { error: 'Cloud refinement disabled in confidential mode' }, { status: 403 } ); }\n\n// Proceed with Azure OpenAI call only if privacy allows const client = new OpenAI({ apiKey: process.env.AZURE_OPENAI_KEY, baseURL: process.env.AZURE_OPENAI_ENDPOINT, defaultHeaders: { 'api-key': process.env.AZURE_OPENAI_KEY } });\n\nconst completion = await client.chat.completions.create({ model: process.env.AZURE_OPENAI_DEPLOYMENT!, messages: [/* ... */], temperature: 0.5, // Slightly higher for creative refinement max_tokens: 800 });\n\nreturn NextResponse.json({ content: completion.choices[0].message.content, model: `${process.env.AZURE_OPENAI_DEPLOYMENT} (cloud)`, privacy_notice: 'Content processed by Azure OpenAI', // ... metadata });\n\n} catch (error) { // Error handling } } ```\n\nThe confidential mode check is crucial‚Äîit ensures that even if a user accidentally clicks the refinement button, no data leaves the device when privacy mode is enabled. This fail-safe design prevents data leakage through UI mistakes or automated workflows.\n\n## Building the Frontend: Transparent Privacy Controls\n\nThe user interface must make privacy decisions explicit and visible. Users need to understand which AI service processed their content and make informed choices about cloud refinement.\n\nThe main briefing interface (`app/page.tsx` ) implements this transparency through clear visual indicators:\n\n``` 'use client'; import { useState, useEffect } from 'react'; import { PrivacySettings } from '@/components/PrivacySettings';\n\nexport default function BriefingAssistant() { const [confidentialMode, setConfidentialMode] = useState(true); // Privacy by default const [content, setContent] = useState(''); const [result, setResult] = useState(null); const [loading, setLoading] = useState(false);\n\n// Load privacy preference from localStorage useEffect(() => { const saved = localStorage.getItem('confidential-mode'); if (saved !== null) { setConfidentialMode(saved === 'true'); } }, []);\n\nasync function generateBriefing(template: string, useCloud: boolean = false) { if (useCloud && confidentialMode) { alert('Cloud refinement is disabled in confidential mode. Adjust settings to enable.'); return; }\n\nsetLoading(true); const endpoint = useCloud ? '/api/briefing/cloud' : '/api/briefing/local';\n\ntry { const response = await fetch(endpoint, { method: 'POST', headers: { 'Content-Type': 'application/json' }, body: JSON.stringify({ prompt: content, template }) });\n\nconst data = await response.json(); setResult({ ...data, processedBy: useCloud ? 'cloud' : 'local' }); } catch (error) { console.error('Briefing generation failed:', error); } finally { setLoading(false); } }\n\nreturn ( <div className=\"briefing-assistant\"> <header> <h1>Client Briefing Assistant</h1> <div className=\"status-bar\"> <span className={confidentialMode ? 'confidential' : 'standard'}> {confidentialMode ? 'üîí Confidential Mode' : 'üåê Standard Mode'} </span> <PrivacySettings confidentialMode={confidentialMode} onChange={setConfidentialMode} /> </div> </header>\n\n<div className=\"quick-actions\"> <button onClick={() => generateBriefing('summary')}> üìÑ Summarize Document </button> <button onClick={() => generateBriefing('talking-points')}> üí¨ Generate Talking Points </button> <button onClick={() => generateBriefing('risk-analysis')}> üéØ Risk Analysis </button> <button onClick={() => generateBriefing('executive')}> üìä Executive Summary </button> </div>\n\n<textarea value={content} onChange={(e) => setContent(e.target.value)} placeholder=\"Paste client document or meeting notes here...\" />\n\n{result && ( <div className=\"result-card\"> <div className=\"result-header\"> <span className=\"model-badge\">{result.model}</span> <span className=\"latency\">{result.latency_ms}ms</span> </div> <div className=\"result-content\">{result.content}</div>\n\n{result.processedBy === 'local' && !confidentialMode && ( <button onClick={() => generateBriefing(result.template, true)} className=\"refine-btn\" > ‚ú® Refine for Executive Presentation </button> )} </div> )} </div> ); } ```\n\nThis interface design embodies several principles of responsible AI UX:\n\n- **Privacy by default**: Confidential mode is enabled unless explicitly changed, ensuring accidental cloud usage requires multiple intentional actions\n- **Clear attribution**: Every result shows which model generated it and how long it took, building user trust through transparency\n- **Conditional refinement**: The cloud refinement button only appears when privacy allows and local inference has completed, preventing premature cloud requests\n- **Persistent settings**: Privacy preferences save to localStorage, respecting user choices across sessions\n- **Visual status indicators**: The header always shows current privacy mode with recognizable icons (üîí for confidential, üåê for standard)\n\n## Testing Privacy and Performance Requirements\n\nA privacy-first application demands rigorous testing to ensure data never leaks unintentionally. The project includes comprehensive test suites using Vitest for unit tests and Playwright for end-to-end scenarios.\n\nHere's a critical privacy test (`tests/privacy.test.ts` ):\n\n``` import { describe, it, expect, beforeEach } from 'vitest'; import { TestUtils } from './utils/test-helpers';\n\ndescribe('Privacy Controls', () => { let testUtils: TestUtils;\n\nbeforeEach(() => { testUtils = new TestUtils(); testUtils.enableConfidentialMode(); });\n\nit('should prevent cloud API calls when confidential mode is enabled', async () => { const response = await testUtils.requestBriefing({ template: 'summary', prompt: 'Confidential merger document...', cloud: true });\n\nexpect(response.status).toBe(403); expect(response.error).toContain('disabled in confidential mode'); });\n\nit('should allow local inference in confidential mode', async () => { const response = await testUtils.requestBriefing({ template: 'summary', prompt: 'Confidential merger document...', cloud: false });\n\nexpect(response.status).toBe(200); expect(response.model).toContain('local'); expect(response.content).toBeTruthy(); });\n\nit('should not persist sensitive content without opt-in', async () => { await testUtils.requestBriefing({ template: 'executive', prompt: 'Strategic acquisition plan...', cloud: false });\n\nconst history = await testUtils.getConversationHistory(); expect(history).toHaveLength(0); // No storage by default });\n\nit('should support opt-in history with explicit consent', async () => { testUtils.enableHistorySaving();\n\nawait testUtils.requestBriefing({ template: 'executive', prompt: 'Strategic acquisition plan...', cloud: false });\n\nconst history = await testUtils.getConversationHistory(); expect(history).toHaveLength(1); expect(history[0].prompt).toContain('acquisition'); }); }); ```\n\nPerformance testing ensures local inference meets the sub-second requirement:\n\n``` describe('Performance SLA', () => { it('should complete local inference in under 1 second', async () => { const samples = [];\n\nfor (let i = 0; i < 10; i++) { const start = Date.now(); await testUtils.requestBriefing({ template: 'summary', prompt: 'Standard 500-word document...', cloud: false }); samples.push(Date.now() - start); }\n\nconst p95 = calculatePercentile(samples, 95); expect(p95).toBeLessThan(1000); // 95th percentile under 1s });\n\nit('should handle 5 concurrent requests without degradation', async () => { const requests = Array(5).fill(null).map(() => testUtils.requestBriefing({ template: 'talking-points', prompt: 'Meeting agenda...', cloud: false }) );\n\nconst results = await Promise.all(requests);\n\nexpect(results.every(r => r.status === 200)).toBe(true); expect(results.every(r => r.latency_ms < 2000)).toBe(true); }); }); ```\n\nThese tests validate the core promise: local inference is fast, private, and reliable under realistic loads.\n\n## Deployment Considerations and Production Readiness\n\nMoving from development to production requires addressing several operational concerns: model distribution, environment configuration, monitoring, and incident response.\n\nFor Foundry Local deployment, ensure IT teams pre-install the runtime and required models on consultant laptops. Use MDM (Mobile Device Management) systems or Group Policy to automate model downloads during onboarding. Models can be cached in shared network locations to avoid redundant downloads across teams.\n\nEnvironment configuration should separate local and cloud credentials cleanly:\n\n```\n# .env.local (local development)\nFOUNDRY_LOCAL_ENDPOINT=http://127.0.0.1:5272 AZURE_OPENAI_ENDPOINT=https://your-org.openai.azure.com AZURE_OPENAI_DEPLOYMENT=gpt-4o-mini AZURE_OPENAI_KEY=your-key-here\n\n# For production, use Azure Managed Identity instead of API keys\nUSE_MANAGED_IDENTITY=true ```\n\nManaged Identity eliminates API key management‚Äîthe application authenticates using Azure AD, with permissions controlled via IAM policies. This prevents key leakage and simplifies rotation.\n\nMonitoring should track both local and cloud usage patterns. Implement structured logging with clear privacy labels:\n\n``` logger.info('Briefing generated', { model: 'local', template: 'summary', latency_ms: 847, tokens: 312, privacy_mode: 'confidential', user_id: hash(userId), // Never log raw user IDs timestamp: new Date().toISOString() }); ```\n\nThis approach enables operational insights (average latency, most-used templates, error rates) without exposing sensitive content or user identities.\n\nFor incident response, establish clear escalation paths. If Foundry Local fails, the application should gracefully degrade‚Äîinform users that local inference is unavailable and offer cloud-only mode (with explicit consent). If cloud services fail, local inference continues uninterrupted, ensuring the application remains useful even during Azure outages.\n\n## Key Takeaways and Next Steps\n\nBuilding a privacy-first hybrid AI application requires careful architectural decisions that prioritize user data protection while maintaining high-quality outputs. The FL-Client-Briefing-Assistant demonstrates that you can achieve sub-second local inference, transparent privacy controls, and optional cloud refinement in a production-ready package.\n\nKey lessons from this implementation:\n\n- **Privacy must be the default**, not an opt-in feature‚Äîconfidential mode should require explicit action to disable\n- **Transparency builds trust**‚Äîalways show users which model processed their data and how long it took\n- **Fallback strategies ensure reliability**‚Äîgraceful degradation when services fail keeps the application useful\n- **Testing validates promises**‚Äîcomprehensive tests for privacy, performance, and functionality are non-negotiable\n- **Operational visibility without privacy leaks**‚Äîstructured logging enables monitoring without exposing sensitive content\n\nTo extend this application, consider adding:\n\n- **Document parsing**: Integrate PDF, DOCX, and PPTX extractors to analyze file uploads directly\n- **Multi-document synthesis**: Combine insights from multiple client documents into unified briefings\n- **Custom templates**: Allow consultants to define their own briefing formats and save them for reuse\n- **Offline mode indicators**: Detect network connectivity and disable cloud features automatically\n- **Audit logging**: For regulated industries, implement immutable audit trails showing when cloud refinement was used\n\nThe full implementation, including all code, tests, and deployment guides, is available at [github.com/leestott/FL-Client-Briefing-Assistant](https://github.com/leestott/FL-Client-Briefing-Assistant). Clone the repository, follow the setup guide, and experience privacy-first AI in action.\n\n## Resources and Further Reading\n\n- [FL-Client-Briefing-Assistant Repository](https://github.com/leestott/FL-Client-Briefing-Assistant) - Complete source code and documentation\n- [Microsoft Foundry Local Documentation](https://foundrylocal.ai) - Official runtime documentation and API reference\n- [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/) - Cloud refinement integration guide\n- [Project Specification](https://github.com/leestott/FL-Client-Briefing-Assistant/blob/main/specs/001-foundry-hybrid-app/spec.md) - Detailed requirements and acceptance criteria\n- [Implementation Guide](https://github.com/leestott/FL-Client-Briefing-Assistant/blob/main/IMPLEMENTATION.md) - Architecture decisions and design patterns\n- [Testing Guide](https://github.com/leestott/FL-Client-Briefing-Assistant/blob/main/TESTING.md) - How to run and interpret comprehensive test suites\n\nUpdated Jan 30, 2026\n\nVersion 1.0\n\n[ai](/tag/ai?nodeId=board%3AAzureDevCommunityBlog)\n\n[ai foundry](/tag/ai%20foundry?nodeId=board%3AAzureDevCommunityBlog)\n\n[azure](/tag/azure?nodeId=board%3AAzureDevCommunityBlog)\n\n[azure ai foundry](/tag/azure%20ai%20foundry?nodeId=board%3AAzureDevCommunityBlog)\n\n[javascript](/tag/javascript?nodeId=board%3AAzureDevCommunityBlog)\n\n[!\\[Lee_Stott&#x27;s avatar\\](https://techcommunity.microsoft.com/t5/s/gxcuf89792/images/dS0yMTA1NDYtODM5MjVpMDI2ODNGQTMwMzAwNDFGQQ?image-dimensions=50x50)](/users/lee_stott/210546) [Lee_Stott](/users/lee_stott/210546) ![Icon for Microsoft rank](https://techcommunity.microsoft.com/t5/s/gxcuf89792/images/cmstNC05WEo0blc?image-dimensions=100x16&amp;constrain-image=true)Microsoft\n\nJoined September 25, 2018\n\n[View Profile](/users/lee_stott/210546)\n\n/category/azure/blog/azuredevcommunityblog [Microsoft Developer Community Blog](/category/azure/blog/azuredevcommunityblog) Follow this blog board to get notified when there's new activity",
  "Title": "Building a Privacy-First Hybrid AI Briefing Tool with Foundry Local and Azure OpenAI",
  "Author": "Lee_Stott",
  "FeedUrl": "https://techcommunity.microsoft.com/t5/s/gxcuf89792/rss/Category?category.id=Azure",
  "Description": "## Introduction\n\nManagement consultants face a critical challenge: they need instant AI-powered insights from sensitive client documents, but traditional cloud-only AI solutions create unacceptable data privacy risks. Every document uploaded to a cloud API potentially exposes confidential client information, violates data residency requirements, and creates compliance headaches.\n\nThe solution lies in a hybrid architecture that combines the speed and privacy of on-device AI with the sophistication of cloud models‚Äîbut only when explicitly requested. This article walks through building a production-ready briefing assistant that runs AI inference locally first, then optionally refines outputs using Azure OpenAI for executive-quality presentations.\n\nWe'll explore a sample implementation using [FL-Client-Briefing-Assistant](https://github.com/leestott/FL-Client-Briefing-Assistant), built with Next.js 14, TypeScript, and Microsoft Foundry Local. You'll learn how to architect privacy-first AI applications, implement sub-second local inference, and design transparent hybrid workflows that give users complete control over their data.\n\n## Why Hybrid AI Architecture Matters for Enterprise Applications\n\nBefore diving into implementation details, let's understand why a hybrid approach is essential for enterprise AI applications, particularly in consulting and professional services.\n\nCloud-only AI services like OpenAI's GPT-4 offer remarkable capabilities, but they introduce several critical challenges. First, every API call sends your data to external servers, creating audit trails and potential exposure points. For consultants handling merger documents, financial reports, or strategic plans, this is often a non-starter. Second, cloud APIs introduce latency, typically 2-5 seconds per request due to network round-trips and queue times. Third, costs scale linearly with usage, making high-volume document analysis expensive at scale.\n\nLocal-only AI solves privacy and latency concerns but sacrifices quality. Small language models (SLMs) running on laptops produce quick summaries, but they lack the nuanced reasoning and polish needed for C-suite presentations. You get fast, private results that may require significant manual refinement.\n\nThe hybrid approach gives you the best of both worlds: instant, private local processing as the default, with optional cloud refinement only when quality matters most. This architecture respects data privacy by default while maintaining the flexibility to produce executive-grade outputs when needed.\n\n## Architecture Overview: Three-Layer Design for Privacy and Performance\n\nThe FL-Client-Briefing-Assistant implements a clean three-layer architecture that separates concerns and ensures privacy at every level.\n\nAt the frontend, a Next.js 14 application provides the user interface with strong TypeScript typing throughout. Users interact with four quick-action templates: document summarization, talking points generation, risk analysis, and executive summaries. The UI clearly indicates which model (local or cloud) processed each request, ensuring transparency.\n\nThe middle tier consists of Next.js API routes that act as orchestration endpoints. These routes validate requests using Zod schemas, route to appropriate inference services, and enforce privacy settings. Critically, the API layer never persists user content unless explicitly opted in via privacy settings.\n\nThe inference layer contains two distinct services. The local service uses Foundry Local SDK to communicate with a locally running Phi-4 model (or similar SLM). This provides sub-second inference, typical 500ms-1s response times, completely offline. The cloud service connects to Azure OpenAI using the official JavaScript SDK, accessed via Managed Identity or API keys, with proper timeout and retry logic.\n\n## Setting Up Foundry Local for On-Device Inference\n\nFoundry Local is Microsoft's runtime for running AI models entirely on your device‚Äîno internet required, no data leaving your machine. Here's how to get it running for this application.\n\nFirst, install Foundry Local on Windows using Windows Package Manager:\n\n``` winget install Microsoft.FoundryLocal ```\n\nAfter installation, verify the service is ready:\n\n``` foundry service start foundry service status ```\n\nThe status command will show you the service endpoint, typically running on a dynamic port like `http://127.0.0.1:5272` . This port changes between restarts, so your application must query it programmatically.\n\nNext, load an appropriate model. For briefing tasks, Phi-4 Mini provides an excellent balance of quality and speed:\n\n``` foundry model load phi-4 ```\n\nThe model downloads (approximately 3.6GB) and loads into memory. This takes 2-5 minutes on first run but persists between sessions. Once loaded, inference is nearly instant, most requests complete in under 1 second.\n\nIn your application, configure the connection in `.env.local` : the port for foundry local is dynamic so please ensure you add the correct port.\n\n``` FOUNDRY_LOCAL_ENDPOINT=http://127.0.0.1:**** ```\n\nThe application uses the Foundry Local SDK to query the running service:\n\n``` import { FoundryLocalClient } from 'foundry-local-sdk';\n\nconst client = new FoundryLocalClient({ endpoint: process.env.FOUNDRY_LOCAL_ENDPOINT });\n\nconst response = await client.chat.completions.create({ model: 'phi-4', messages: [ { role: 'system', content: 'You are a professional consultant assistant.' }, { role: 'user', content: 'Summarize this document: ...' } ], max_tokens: 500, temperature: 0.3 }); ```\n\nThis code demonstrates several best practices:\n\n- **Explicit model specification**: Always name the model to ensure consistency across environments\n- **System message framing**: Set the appropriate professional context for consulting use cases\n- **Conservative temperature**: Use 0.3 for factual summarization tasks to reduce hallucination\n- **Token limits**: Cap outputs to prevent excessive generation times and costs\n\n## Implementing Privacy-First API Routes\n\nThe Next.js API routes form the security boundary of the application. Every request must be validated, sanitized, and routed according to privacy settings before reaching inference services.\n\nHere's the core local inference route (`app/api/briefing/local/route.ts` ):\n\n``` import { NextRequest, NextResponse } from 'next/server'; import { z } from 'zod'; import { FoundryLocalClient } from 'foundry-local-sdk';\n\nconst RequestSchema = z.object({ prompt: z.string().min(10).max(5000), template: z.enum(['summary', 'talking-points', 'risk-analysis', 'executive']), context: z.string().optional() });\n\nexport async function POST(request: NextRequest) { try { // Validate and parse request body const body = await request.json(); const validated = RequestSchema.parse(body);\n\n// Initialize Foundry Local client const client = new FoundryLocalClient({ endpoint: process.env.FOUNDRY_LOCAL_ENDPOINT! });\n\n// Build system prompt based on template const systemPrompts = { 'summary': 'You are a consultant creating concise document summaries.', 'talking-points': 'You are preparing structured talking points for meetings.', 'risk-analysis': 'You are analyzing risks and opportunities systematically.', 'executive': 'You are crafting executive-level briefing notes.' };\n\n// Execute local inference const startTime = Date.now(); const completion = await client.chat.completions.create({ model: 'phi-4', messages: [ { role: 'system', content: systemPrompts[validated.template] }, { role: 'user', content: validated.prompt } ], temperature: 0.3, max_tokens: 500 });\n\nconst latency = Date.now() - startTime;\n\n// Return structured response with metadata return NextResponse.json({ content: completion.choices[0].message.content, model: 'phi-4 (local)', latency_ms: latency, tokens: completion.usage?.total_tokens, timestamp: new Date().toISOString() });\n\n} catch (error) { if (error instanceof z.ZodError) { return NextResponse.json( { error: 'Invalid request format', details: error.errors }, { status: 400 } ); }\n\nconsole.error('Local inference error:', error); return NextResponse.json( { error: 'Inference failed', message: error.message }, { status: 500 } ); } } ```\n\nThis implementation demonstrates several critical security and quality patterns:\n\n- **Request validation with Zod**: Every field is type-checked and bounded before processing, preventing injection attacks and malformed inputs\n- **Template-based system prompts**: Different use cases get optimized prompts, improving output quality and consistency\n- **Comprehensive error handling**: Validation errors, inference failures, and network issues are caught and reported with appropriate HTTP status codes\n- **Performance tracking**: Latency measurement enables monitoring and helps users understand response times\n- **Metadata enrichment**: Responses include model attribution, token usage, and timestamps for auditing\n\nThe cloud refinement route follows a similar pattern but adds privacy checks:\n\n``` export async function POST(request: NextRequest) { try { const body = await request.json(); const validated = RequestSchema.parse(body);\n\n// Check privacy settings from cookie/header const confidentialMode = request.cookies.get('confidential-mode')?.value === 'true';\n\nif (confidentialMode) { return NextResponse.json( { error: 'Cloud refinement disabled in confidential mode' }, { status: 403 } ); }\n\n// Proceed with Azure OpenAI call only if privacy allows const client = new OpenAI({ apiKey: process.env.AZURE_OPENAI_KEY, baseURL: process.env.AZURE_OPENAI_ENDPOINT, defaultHeaders: { 'api-key': process.env.AZURE_OPENAI_KEY } });\n\nconst completion = await client.chat.completions.create({ model: process.env.AZURE_OPENAI_DEPLOYMENT!, messages: [/* ... */], temperature: 0.5, // Slightly higher for creative refinement max_tokens: 800 });\n\nreturn NextResponse.json({ content: completion.choices[0].message.content, model: `${process.env.AZURE_OPENAI_DEPLOYMENT} (cloud)`, privacy_notice: 'Content processed by Azure OpenAI', // ... metadata });\n\n} catch (error) { // Error handling } } ```\n\nThe confidential mode check is crucial‚Äîit ensures that even if a user accidentally clicks the refinement button, no data leaves the device when privacy mode is enabled. This fail-safe design prevents data leakage through UI mistakes or automated workflows.\n\n## Building the Frontend: Transparent Privacy Controls\n\nThe user interface must make privacy decisions explicit and visible. Users need to understand which AI service processed their content and make informed choices about cloud refinement.\n\nThe main briefing interface (`app/page.tsx` ) implements this transparency through clear visual indicators:\n\n``` 'use client'; import { useState, useEffect } from 'react'; import { PrivacySettings } from '@/components/PrivacySettings';\n\nexport default function BriefingAssistant() { const [confidentialMode, setConfidentialMode] = useState(true); // Privacy by default const [content, setContent] = useState(''); const [result, setResult] = useState(null); const [loading, setLoading] = useState(false);\n\n// Load privacy preference from localStorage useEffect(() => { const saved = localStorage.getItem('confidential-mode'); if (saved !== null) { setConfidentialMode(saved === 'true'); } }, []);\n\nasync function generateBriefing(template: string, useCloud: boolean = false) { if (useCloud && confidentialMode) { alert('Cloud refinement is disabled in confidential mode. Adjust settings to enable.'); return; }\n\nsetLoading(true); const endpoint = useCloud ? '/api/briefing/cloud' : '/api/briefing/local';\n\ntry { const response = await fetch(endpoint, { method: 'POST', headers: { 'Content-Type': 'application/json' }, body: JSON.stringify({ prompt: content, template }) });\n\nconst data = await response.json(); setResult({ ...data, processedBy: useCloud ? 'cloud' : 'local' }); } catch (error) { console.error('Briefing generation failed:', error); } finally { setLoading(false); } }\n\nreturn (\n\nsetContent(e.target.value)} placeholder=\"Paste client document or meeting notes here...\" />\n\n{result && (\n\n{result.model} {result.latency_ms}ms\n\n{result.content}\n\n{result.processedBy === 'local' && !confidentialMode && (\n\n)}\n\n)}\n\n); } ```\n\nThis interface design embodies several principles of responsible AI UX:\n\n- **Privacy by default**: Confidential mode is enabled unless explicitly changed, ensuring accidental cloud usage requires multiple intentional actions\n- **Clear attribution**: Every result shows which model generated it and how long it took, building user trust through transparency\n- **Conditional refinement**: The cloud refinement button only appears when privacy allows and local inference has completed, preventing premature cloud requests\n- **Persistent settings**: Privacy preferences save to localStorage, respecting user choices across sessions\n- **Visual status indicators**: The header always shows current privacy mode with recognizable icons (üîí for confidential, üåê for standard)\n\n## Testing Privacy and Performance Requirements\n\nA privacy-first application demands rigorous testing to ensure data never leaks unintentionally. The project includes comprehensive test suites using Vitest for unit tests and Playwright for end-to-end scenarios.\n\nHere's a critical privacy test (`tests/privacy.test.ts` ):\n\n``` import { describe, it, expect, beforeEach } from 'vitest'; import { TestUtils } from './utils/test-helpers';\n\ndescribe('Privacy Controls', () => { let testUtils: TestUtils;\n\nbeforeEach(() => { testUtils = new TestUtils(); testUtils.enableConfidentialMode(); });\n\nit('should prevent cloud API calls when confidential mode is enabled', async () => { const response = await testUtils.requestBriefing({ template: 'summary', prompt: 'Confidential merger document...', cloud: true });\n\nexpect(response.status).toBe(403); expect(response.error).toContain('disabled in confidential mode'); });\n\nit('should allow local inference in confidential mode', async () => { const response = await testUtils.requestBriefing({ template: 'summary', prompt: 'Confidential merger document...', cloud: false });\n\nexpect(response.status).toBe(200); expect(response.model).toContain('local'); expect(response.content).toBeTruthy(); });\n\nit('should not persist sensitive content without opt-in', async () => { await testUtils.requestBriefing({ template: 'executive', prompt: 'Strategic acquisition plan...', cloud: false });\n\nconst history = await testUtils.getConversationHistory(); expect(history).toHaveLength(0); // No storage by default });\n\nit('should support opt-in history with explicit consent', async () => { testUtils.enableHistorySaving();\n\nawait testUtils.requestBriefing({ template: 'executive', prompt: 'Strategic acquisition plan...', cloud: false });\n\nconst history = await testUtils.getConversationHistory(); expect(history).toHaveLength(1); expect(history[0].prompt).toContain('acquisition'); }); }); ```\n\nPerformance testing ensures local inference meets the sub-second requirement:\n\n``` describe('Performance SLA', () => { it('should complete local inference in under 1 second', async () => { const samples = [];\n\nfor (let i = 0; i { const requests = Array(5).fill(null).map(() => testUtils.requestBriefing({ template: 'talking-points', prompt: 'Meeting agenda...', cloud: false }) );\n\nconst results = await Promise.all(requests);\n\nexpect(results.every(r => r.status === 200)).toBe(true); expect(results.every(r => r.latency_ms These tests validate the core promise: local inference is fast, private, and reliable under realistic loads.\n\nDeployment Considerations and Production Readiness\n\nMoving from development to production requires addressing several operational concerns: model distribution, environment configuration, monitoring, and incident response.\n\nFor Foundry Local deployment, ensure IT teams pre-install the runtime and required models on consultant laptops. Use MDM (Mobile Device Management) systems or Group Policy to automate model downloads during onboarding. Models can be cached in shared network locations to avoid redundant downloads across teams.\n\nEnvironment configuration should separate local and cloud credentials cleanly:\n\n# .env.local (local development)\nFOUNDRY_LOCAL_ENDPOINT=http://127.0.0.1:5272 AZURE_OPENAI_ENDPOINT=https://your-org.openai.azure.com AZURE_OPENAI_DEPLOYMENT=gpt-4o-mini AZURE_OPENAI_KEY=your-key-here\n\n# For production, use Azure Managed Identity instead of API keys\nUSE_MANAGED_IDENTITY=true\n\nManaged Identity eliminates API key management‚Äîthe application authenticates using Azure AD, with permissions controlled via IAM policies. This prevents key leakage and simplifies rotation.\n\nMonitoring should track both local and cloud usage patterns. Implement structured logging with clear privacy labels:\n\nlogger.info('Briefing generated', { model: 'local', template: 'summary', latency_ms: 847, tokens: 312, privacy_mode: 'confidential', user_id: hash(userId), // Never log raw user IDs timestamp: new Date().toISOString() });\n\nThis approach enables operational insights (average latency, most-used templates, error rates) without exposing sensitive content or user identities.\n\nFor incident response, establish clear escalation paths. If Foundry Local fails, the application should gracefully degrade‚Äîinform users that local inference is unavailable and offer cloud-only mode (with explicit consent). If cloud services fail, local inference continues uninterrupted, ensuring the application remains useful even during Azure outages.\n\nKey Takeaways and Next Steps\n\nBuilding a privacy-first hybrid AI application requires careful architectural decisions that prioritize user data protection while maintaining high-quality outputs. The FL-Client-Briefing-Assistant demonstrates that you can achieve sub-second local inference, transparent privacy controls, and optional cloud refinement in a production-ready package.\n\nKey lessons from this implementation: Privacy must be the default, not an opt-in feature‚Äîconfidential mode should require explicit action to disable\n\nTransparency builds trust‚Äîalways show users which model processed their data and how long it took\n\nFallback strategies ensure reliability‚Äîgraceful degradation when services fail keeps the application useful\n\nTesting validates promises‚Äîcomprehensive tests for privacy, performance, and functionality are non-negotiable\n\nOperational visibility without privacy leaks‚Äîstructured logging enables monitoring without exposing sensitive content\n\nTo extend this application, consider adding: Document parsing: Integrate PDF, DOCX, and PPTX extractors to analyze file uploads directly\n\nMulti-document synthesis: Combine insights from multiple client documents into unified briefings\n\nCustom templates: Allow consultants to define their own briefing formats and save them for reuse\n\nOffline mode indicators: Detect network connectivity and disable cloud features automatically\n\nAudit logging: For regulated industries, implement immutable audit trails showing when cloud refinement was used\n\nThe full implementation, including all code, tests, and deployment guides, is available at github.com/leestott/FL-Client-Briefing-Assistant. Clone the repository, follow the setup guide, and experience privacy-first AI in action.\n\nResources and Further Reading FL-Client-Briefing-Assistant Repository - Complete source code and documentation\n\nMicrosoft Foundry Local Documentation - Official runtime documentation and API reference\n\nAzure OpenAI Service - Cloud refinement integration guide\n\nProject Specification - Detailed requirements and acceptance criteria\n\nImplementation Guide - Architecture decisions and design patterns\n\nTesting Guide - How to run and interpret comprehensive test suites\n\n```",
  "ProcessedDate": "2026-02-26 08:11:04",
  "OutputDir": "_community",
  "FeedName": "Microsoft Tech Community",
  "Tags": [],
  "FeedLevelAuthor": "rss.livelink.threads-in-node"
}
