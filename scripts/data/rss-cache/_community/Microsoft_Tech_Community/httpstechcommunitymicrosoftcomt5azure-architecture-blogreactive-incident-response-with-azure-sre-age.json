{
  "Link": "https://techcommunity.microsoft.com/t5/azure-architecture-blog/reactive-incident-response-with-azure-sre-agent-from-alert-to/ba-p/4492938",
  "Title": "Reactive Incident Response with Azure SRE Agent: From Alert to Resolution in Minutes",
  "OutputDir": "_community",
  "FeedLevelAuthor": "rss.livelink.threads-in-node",
  "Author": "Sabyasachi-Samaddar",
  "FeedName": "Microsoft Tech Community",
  "ProcessedDate": "2026-02-19 07:22:04",
  "Tags": [],
  "EnhancedContent": "## When things break at 2 AM, your AI teammate is already investigating.\n\n*SRE Agent portal overview with incident list*\n\n**The Reactive Incident Challenge**\n\nYour monitoring is solid. Alerts fire when they should. But then what?\n\n- Alert lands in Teams/PagerDuty\n- On-call engineer wakes up, logs in\n- Starts investigating: \"What's broken? Why? How do I fix it?\"\n- 20 minutes later, they're still gathering context\n\nThe alert was fast. The human response? Not so much.\n\n**The Traditional Incident Response Flow**\n\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”Â Â Â  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”Â Â Â  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”Â Â Â  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n\nâ”‚Â Â  AlertÂ Â Â Â  â”‚â”€â”€â”€â–¶â”‚Â Â  HumanÂ Â Â Â  â”‚â”€â”€â”€â–¶â”‚Â  ManualÂ Â Â Â  â”‚â”€â”€â”€â–¶â”‚ ResolutionÂ  â”‚\n\nâ”‚Â Â  FiresÂ Â Â Â  â”‚Â Â Â  â”‚ Acknowledgesâ”‚Â Â Â  â”‚Investigationâ”‚Â Â Â  â”‚Â  (Maybe)Â Â Â  â”‚\n\nâ”‚Â Â Â Â Â Â Â Â Â Â Â Â  â”‚Â Â Â  â”‚Â  (5-15 min) â”‚Â Â Â  â”‚Â  (15-30 min)â”‚Â Â Â  â”‚Â Â Â Â Â Â Â Â Â Â Â Â  â”‚\n\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜Â Â Â  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜Â Â Â  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜Â Â Â  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nt=0Â Â Â Â Â Â Â Â Â Â Â Â Â  t=5-15minÂ Â Â Â Â Â Â Â  t=20-45minÂ Â Â Â Â Â Â Â  t=30-60min\n\n**The SRE Agent Flow**\n\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”Â Â Â  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”Â Â Â  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”Â Â Â  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n\nâ”‚Â Â  AlertÂ Â Â Â  â”‚â”€â”€â”€â–¶â”‚ SRE AgentÂ Â  â”‚â”€â”€â”€â–¶â”‚Â Â Â  AIÂ Â Â Â Â Â  â”‚â”€â”€â”€â–¶â”‚Â  HumanÂ Â Â Â Â  â”‚\n\nâ”‚Â Â  FiresÂ Â Â Â  â”‚Â Â Â  â”‚ Acknowledgesâ”‚Â Â Â  â”‚Investigationâ”‚Â Â Â  â”‚Â  ApprovesÂ Â  â”‚\n\nâ”‚Â Â Â Â Â Â Â Â Â Â Â Â  â”‚Â Â Â  â”‚Â  (Instant)Â  â”‚Â Â Â  â”‚Â  (2-10 min) â”‚Â Â Â  â”‚Â Â Â Â Â Â Â Â Â Â Â Â  â”‚\n\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜Â Â Â  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜Â Â Â  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜Â Â Â  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nt=0Â Â Â Â Â Â Â Â Â Â Â Â Â  t=0Â Â Â Â Â Â Â Â Â Â Â Â Â Â  t=2-10minÂ Â Â Â Â Â Â Â Â  t=10-15min\n\n**What if the investigation started the moment the alert fired?**\n\nThat's exactly what Azure SRE Agent does. It doesn't wait for humans to acknowledgeâ€”it starts investigating immediately, gathering context, identifying root causes, and preparing remediation options.\n\nI tested this with two real-world scenarios: a database connectivity outage and a VM CPU spike. Here's what happened.\n\n**Two Real-World Incidents**\n\n| **Scenario** | **Trigger** | **Root Cause** | **Resolution** | | --- | --- | --- | --- | | **Web App Health Failure** | Sev1 Alert - Health check failing | SQL Server public access disabled | Enabled public access + firewall rule | | **VM High CPU** | Sev2 Alert - CPU &gt; 85% for 5 mins | Runaway PowerShell processes | Identified and killed processes |\n\nBoth incidents were detected, diagnosed, and remediated by SRE Agent with minimal human interventionâ€”just approval clicks.\n\n**Incident 1: Azure SQL Database Connectivity Outage**\n\n**The Alert**\n\nðŸ”´ Sev1 Alert Fired\n\nAlert Rule: sre-demo-webapp-health-alert\n\nDescription: Alert when Web App health check fails - indicates backend/database connectivity issues\n\nTime: 02/04/2026 07:59:35 UTC\n\n**Alert Configuration Details**\n\nThe alert was configured using Azure Monitor metric alerts:\n\nresource webAppHealthAlert 'Microsoft.Insights/metricAlerts@2018-03-01' = {\n\nname: 'sre-demo-webapp-health-alert'\n\nproperties: {\n\nseverity: 1\n\nevaluationFrequency: 'PT1M'\n\nwindowSize: 'PT5M'\n\ncriteria: {\n\n'odata.type': 'Microsoft.Azure.Monitor.SingleResourceMultipleMetricCriteria'\n\nallOf: [\n\n{\n\nname: 'HealthCheckStatus'\n\nmetricName: 'HealthCheckStatus'\n\noperator: 'LessThan'\n\nthreshold: 100\n\ntimeAggregation: 'Average'\n\n}\n\n]\n\n}\n\ntargetResourceType: 'Microsoft.Web/sites'\n\ntargetResourceRegion: 'centralindia'\n\n}\n\n}\n\n**What SRE Agent Did (Autonomously)**\n\n*[SRE Agent chat showing the investigation steps and thinking process]*\n\nThe moment the alert fired, SRE Agent acknowledged and began investigating:\n\n1. **Symptom Assessment**\n\n- Pulled web app ARM configuration (AlwaysOn, Basic plan, system-assigned identity)\n- Analyzed HTTP 5xx and request metrics over 2 hours\n- Observed intermittent traffic spikes indicating service impact\n\n// KQL query SRE Agent ran against Application Insights\n\nrequests\n\n| where timestamp &gt; ago(2h)\n\n| summarize\n\nTotalRequests = count(),\n\nFailedRequests = countif(resultCode &gt;= 500),\n\nFailureRate = round(100.0 \\* countif(resultCode &gt;= 500) / count(), 2)\n\n| project TotalRequests, FailedRequests, FailureRate\n\n1. **Dependency Mapping**\n\n*[Application Insights showing SQL dependency failures at 100%]*\n\n- Queried Application Insights to identify failing backends\n- Found:Â sre-demo-sql-6o26gsgynw436.database.windows.netÂ failingÂ **100% (80/80 calls)**Â in last 30 minutes\n- Result code:Â 503Â on \"SQL Health Check\" and \"GetProducts\" operations\n\n// Dependency failure analysis\n\ndependencies\n\n| where timestamp &gt; ago(30m)\n\n| where target contains \"database.windows.net\"\n\n| summarize\n\nTotalCalls = count(),\n\nFailedCalls = countif(success == false),\n\nFailureRate = round(100.0 \\* countif(success == false) / count(), 2)\n\n| project TotalCalls, FailedCalls, FailureRate\n\n1. **Network Validation**\n\n- Tested DNS resolution from web app to SQL endpoint âœ… Success\n- Tested TCP reachability on port 1433 âœ… Success\n- Conclusion: Network path is healthy; issue is at access/auth layer\n\n*# SRE Agent validated network connectivity using:*\n\n*# DNS Resolution Test*\n\nnslookup sre-demo-sql-6o26gsgynw436.database.windows.net\n\n*# TCP Port Test (from App Service)*\n\ntcpping sre-demo-sql-6o26gsgynw436.database.windows.net:1433\n\n1. **Configuration Analysis**\n\n*# SRE Agent queried SQL server configuration*\n\naz sql server show -g rg-sre-demo-india -n sre-demo-sql-6o26gsgynw436 \\\n\n--query \"{publicNetworkAccess:publicNetworkAccess, fullyQualifiedDomainName:fullyQualifiedDomainName}\"\n\n*# Output:*\n\n{\n\n\"publicNetworkAccess\": \"Disabled\",Â  *#*\n\n\"fullyQualifiedDomainName\": \"sre-demo-sql-6o26gsgynw436.database.windows.net\"\n\n}\n\n- Discovered:Â **Azure SQL public network access = Disabled**\n- Web app has no VNet integration or Private Endpoint\n- Root cause identified: Access model mismatch\n\n**The Root Cause Analysis**\n\n**Root cause: Azure SQL public network access is Disabled while the web app has no VNet integration/private endpoint, so the app cannot reach SQL at the access model layer.**\n\nSRE Agent presented two remediation options:\n\n| **Option** | **Approach** | **Speed** | **Security** | **Use Case** | | --- | --- | --- | --- | --- | | **A** | Enable public access + Allow Azure Services (0.0.0.0) | âš¡ Fast | ðŸŸ¡ Moderate | Quick restore, non-prod | | **B** | Add web app's specific outbound IPs to firewall | ðŸ¢ Slower | ðŸŸ¢ Stricter | Production environments | | **C** | Configure Private Endpoint + VNet Integration | ðŸ¢ðŸ¢ Slowest | ðŸŸ¢ðŸŸ¢ Best | Long-term solution |\n\n**Remediation (With Approval)**\n\n*[SRE Agent asking for approval before executing remediation]*\n\nI approved Option A for rapid restoration. SRE Agent executed:\n\n*# Step 1: Enable public network access*\n\naz sql server update -g rg-sre-demo-india -n sre-demo-sql-6o26gsgynw436 \\\n\n--subscription &lt;subid&gt; \\\n\n--set publicNetworkAccess=Enabled\n\n*# Step 2: Add Azure Services firewall rule*\n\naz sql server firewall-rule create \\\n\n-g rg-sre-demo-india \\\n\n-s sre-demo-sql-6o26gsgynw436 \\\n\n-n AllowAzureServices \\\n\n--subscription &lt;subid&gt; \\\n\n--start-ip-address 0.0.0.0 \\\n\n--end-ip-address 0.0.0.0\n\nâš ï¸Â **Security Note**: TheÂ 0.0.0.0Â rule allows traffic fromÂ *any*Â Azure service, not just your web app. For production, use Option B (specific IPs) or Option C (Private Endpoint).\n\n**Recovery Verified**\n\nSRE Agent automatically verified recovery by re-querying Application Insights:\n\n// Post-remediation verification\n\ndependencies\n\n| where timestamp &gt; ago(10m)\n\n| where target contains \"database.windows.net\"\n\n| summarize\n\nTotalCalls = count(),\n\nSuccessfulCalls = countif(success == true),\n\nSuccessRate = round(100.0 \\* countif(success == true) / count(), 2)\n\nResults:\n\n- SQL dependencies:Â **65/65 successful**Â (100% success rate)\n- HTTP 5xx errors:Â **Dropped to 0**\n- Service restored âœ…\n\n**Timeline**\n\n| **Time (UTC)** | **Event** | **Duration** | | --- | --- | --- | | 07:59:35 | Alert fired | - | | 07:59:36 | SRE Agent acknowledged | +1s | | 08:00:00 | Started symptom assessment | +25s | | 08:05:00 | Dependency mapping complete | +5m | | 08:08:00 | Network validation complete | +3m | | 08:10:00 | Root cause identified | +2m | | 08:16:00 | Remediation approved | +6m (human) | | 08:17:00 | Remediation executed | +1m | | 08:20:00 | Recovery verified | +3m |\n\n**Total time from alert to resolution: ~20 minutes**Â (6 minutes waiting for human approval)\n\n**Incident 2: VM High CPU Spike**\n\n**The Alert**\n\n*[Azure VM showing Average CPU metric is increasing]*\n\nðŸŸ¡ Sev2 Alert Fired\n\nAlert Rule: sre-demo-vm-cpu-alert\n\nDescription: Alert when VM CPU exceeds 85% - indicates runaway process or resource exhaustion\n\nResource: sre-demo-vm\n\nTime: 02/04/2026 16:16:18 UTC\n\n**Alert Configuration Details**\n\nThe VM CPU alert was configured as a metric alert:\n\nresource vmCpuAlert 'Microsoft.Insights/metricAlerts@2018-03-01' = {\n\nname: 'sre-demo-vm-cpu-alert'\n\nproperties: {\n\nseverity: 2\n\nevaluationFrequency: 'PT1M'\n\nwindowSize: 'PT5M'\n\ncriteria: {\n\n'odata.type': 'Microsoft.Azure.Monitor.SingleResourceMultipleMetricCriteria'\n\nallOf: [\n\n{\n\nname: 'HighCPU'\n\nmetricName: 'Percentage CPU'\n\noperator: 'GreaterThan'\n\nthreshold: 85\n\ntimeAggregation: 'Average'\n\n}\n\n]\n\n}\n\ntargetResourceType: 'Microsoft.Compute/virtualMachines'\n\n}\n\n}\n\n**What SRE Agent Did**\n\n*[SRE Agent chat showing VM investigation and Run Command execution]*\n\n1. **Process Capture via VM Run Command**\n\nSRE Agent requested approval to run a safe, read-only command to capture top CPU processes:\n\n*# Read-only diagnostic command*\n\nGet-Process | Sort-Object CPU -Descending | Select-Object -First 10 Name,CPU,Id | ConvertTo-Json\n\nThe agent used Azure VM Run Command (az vm run-command invoke) to execute PowerShell remotely:\n\naz vm run-command invoke \\\n\n-g rg-sre-demo-india \\\n\n-n sre-demo-vm \\\n\n--subscription &lt;subid&gt; \\\n\n--command-id RunPowerShellScript \\\n\n--scripts \"Get-Process | Sort-Object CPU -Descending | Select-Object -First 10 Name,CPU,Id | ConvertTo-Json\"\n\n1. **Runaway Process Identification**\n\nResults revealed two PowerShell processes consuming excessive CPU:\n\n[\n\n{ \"Name\": \"powershell\", \"CPU\": 683.45, \"Id\": 3164 },\n\n{ \"Name\": \"powershell\", \"CPU\": 652.12, \"Id\": 2776 },\n\n{ \"Name\": \"MsMpEng\",Â Â Â  \"CPU\": 54.23,Â  \"Id\": 1892 },\n\n{ \"Name\": \"svchost\",Â Â Â  \"CPU\": 12.34,Â  \"Id\": 1024 }\n\n]\n\n| **Process** | **PID** | **CPU Time (seconds)** | **Assessment** | **Reasoning** | | --- | --- | --- | --- | --- | | powershell | 3164 | 683.45s (~11 min) | ðŸ”´ Runaway | CPU time &gt; 60s threshold from IRP | | powershell | 2776 | 652.12s (~10 min) | ðŸ”´ Runaway | CPU time &gt; 60s threshold from IRP | | MsMpEng | 1892 | 54.23s | âœ… Normal | Windows Defender - expected | | svchost | 1024 | 12.34s | âœ… Normal | System process - expected |\n\nSRE Agent correctly identified these as stress/runaway processes based on the custom instructions I provided in the Incident Response Plan:\n\n*\"If process is 'powershell' with CPU &gt; 80 seconds â†’ LIKELY stress script\"*\n\n1. **Targeted Remediation**\n\nWith my approval, SRE Agent executed targeted process termination:\n\naz vm run-command invoke \\\n\n-g rg-sre-demo-india \\\n\n-n sre-demo-vm \\\n\n--subscription &lt;subid&gt; \\\n\n--command-id RunPowerShellScript \\\n\n--scripts \"Stop-Process -Id 3164 -Force -ErrorAction SilentlyContinue; Stop-Process -Id 2776 -Force -ErrorAction SilentlyContinue; Write-Output 'Stopped'\"\n\nðŸ’¡Â **Why specific PIDs?**Â SRE Agent targeted only the identified runaway processes (PIDs 3164, 2776) rather than killing all PowerShell processes. This minimizes blast radius and avoids disrupting legitimate automation.\n\n1. **Recovery Verification**\n\nPost-remediation check showed:\n\n*// After remediation - Top processes*\n\n[\n\n{ \"Name\": \"MsMpEng\",Â  \"CPU\": 54.23, \"Id\": 1892 },Â  *// Now the top consumer*\n\n{ \"Name\": \"svchost\",Â  \"CPU\": 12.34, \"Id\": 1024 },\n\n{ \"Name\": \"WmiPrvSE\", \"CPU\": 8.12,Â  \"Id\": 2048 }\n\n]\n\n- âœ… PowerShell processes no longer in top CPU list\n- âœ… Highest CPU consumer:Â MsMpEngÂ (Windows Defender) at ~54s -Â **normal baseline**\n- âœ… VM CPU normalized\n\n**Technical Deep Dive: Understanding CPU Metrics**\n\nAn important learning from this incident:\n\n| **Metric** | **What It Measures** | **When to Use** | | --- | --- | --- | | Get-Process.CPU | **Cumulative**Â CPU time in seconds since process start | Identifying long-running resource hogs | | Get-Counter '\\Processor(\\_Total)\\% Processor Time' | **Instantaneous**Â CPU percentage | Validating current system state | | Get-CimInstance Win32\\_Processor | CPU load percentage | Quick health check |\n\nSRE Agent initially tried to verify recovery using performance counters but encountered parsing issues. The Session Insights captured this learning for future incidents.\n\n**Timeline**\n\n| **Time (UTC)** | **Event** | **Duration** | | --- | --- | --- | | 16:16:18 | Alert fired (CPU &gt; 85% for 5 min) | - | | 16:16:20 | SRE Agent acknowledged | +2s | | 16:48:00 | Process capture approved | +32m (human delay) | | 16:48:30 | Top processes captured | +30s | | 16:51:00 | Runaway processes identified | +2.5m | | 16:52:00 | Remediation approved | +1m | | 16:52:30 | Processes terminated | +30s | | 16:55:00 | Recovery verified | +2.5m |\n\n**Total time from alert to resolution: ~39 minutes**Â (32 minutes waiting for initial human approval)\n\n**Why Custom Instructions Matter**\n\nOut of the box, SRE Agent knows Azure. But it doesn't knowÂ *your*Â environment.\n\nFor the VM CPU scenario, I created anÂ **Incident Response Plan**Â with custom instructions that taught the agent:\n\n- What \"HighCpuProcess\" means (it's our test stress process)\n- When it's safe to kill PowerShell processes (CPU &gt; 60 seconds)\n- How to validate recovery (check CPU percentage)\n- When to escalate vs. auto-remediate\n\n**Full Custom Instructions for VM CPU Scenario**\n\nYou are investigating a high CPU alert on a Windows Virtual Machine.\n\nINVESTIGATION METHODOLOGY:\n\n1. Connect to the VM and query current CPU usage\n2. Identify which process is consuming the most CPU\n3. Determine if the process is legitimate or a runaway/malicious process\n4. Take appropriate action based on findings\n\nDIAGNOSTIC STEPS:\n\n1. Use Azure VM Run Command to execute diagnostic scripts on the VM\n2. Query the top CPU-consuming processes using:\n\n- Get-Process | Sort-Object CPU -Descending | Select-Object -First 10 Name, CPU, Id\n\n1. Check for known runaway process indicators:\n\n- Process name contains \"HighCpuProcess\" â†’ This is a test stress process, safe to kill\n\n- PowerShell process with unusually high CPU â†’ Likely a stress script, investigate further\n\n- Unknown process consuming &gt;50% CPU â†’ Potential runaway, gather more info before killing\n\nIDENTIFICATION CRITERIA:\n\n- If process name is \"HighCpuProcess\" â†’ CONFIRMED runaway test process\n\n- If process is \"powershell\" with CPU &gt; 80 seconds â†’ LIKELY stress script\n\n- If multiple PowerShell background jobs named \"HighCpuProcess-*\\*\" exist â†’ CONFIRMED stress test*\n\n*REMEDIATION ACTIONS:*\n\n*For PowerShell stress jobs:*\n\n*Get-Job -Name \"HighCpuProcess\\**\" | Stop-Job\n\nFor high-CPU PowerShell processes:\n\nGet-Process -Name \"powershell*\\*\" | Where-Object { $\\_.CPU -gt 60 } | Stop-Process -Force*\n\n*General process termination (use process ID from investigation):*\n\n*Stop-Process -Id &lt;ProcessId&gt; -Force*\n\n*VALIDATION:*\n\n*After remediation, verify CPU has returned to normal:*\n\n*$cpu = (Get-Counter '\\Processor(\\_Total)\\% Processor Time' -SampleInterval 2 -MaxSamples 3 |*\n\n*Select-Object -ExpandProperty CounterSamples |*\n\n*Measure-Object -Property CookedValue -Average).Average*\n\n*Write-Host \"Current CPU: $([math]::Round($cpu, 1))%\"*\n\n*ESCALATION:*\n\n*- If CPU remains high after killing identified processes, escalate to human operator*\n\n*- If process is a critical system process, do NOT kill - escalate instead*\n\n*- If unable to connect to VM, check VM health and network connectivity first*\n\n**How Custom Instructions Change Agent Behavior**\n\n| **Without Custom Instructions** | **With Custom Instructions** | | --- | --- | | \"I see high CPU on this VM\" | \"PowerShell PID 3164 has 683s CPU time, exceeding 60s threshold - confirmed runaway\" | | \"Should I investigate?\" | \"Based on IRP criteria, this matches stress script pattern - recommending termination\" | | Generic troubleshooting | Targeted, context-aware remediation | | May escalate unnecessarily | Knows when to act vs. escalate |\n\nThis context transformed SRE Agent from a generic troubleshooter into a teammate who understands our specific runbooks.\n\n**What SRE Agent Learned (Session Insights)**\n\nAfter each incident, SRE Agent generatesÂ **Session Insights**â€”a structured summary of what happened, what went well, and what to improve. These become organizational knowledge.\n\n**Session Insights Structure**\n\nTIMELINE\n\nâ”œâ”€â”€ Event 1: Initial acknowledgment\n\nâ”œâ”€â”€ Event 2: Symptom assessment\n\nâ”œâ”€â”€ Event 3: Root cause identified\n\nâ”œâ”€â”€ Event 4: Remediation executed\n\nâ””â”€â”€ Event 5: Recovery verified\n\nEVALUATION\n\nâ”œâ”€â”€ What Went Well\n\nâ”‚Â Â  â””â”€â”€ Specific actions that succeeded\n\nâ””â”€â”€ What Didn't Go Well\n\nâ””â”€â”€ Issues encountered + better approaches\n\nDERIVED LEARNING\n\nâ”œâ”€â”€ System Design Knowledge\n\nâ”‚Â Â  â””â”€â”€ Azure-specific learnings\n\nâ””â”€â”€ Investigation Pattern\n\nâ””â”€â”€ Reusable troubleshooting approaches\n\n**From Incident 1 (SQL Connectivity):**\n\n**What Went Well:**\n\n- Rapid isolation of failing backend: Used Application Insights to pinpoint the SQL dependency target with 80/80 failures\n- Layered validation before change: Validated DNS and TCP connectivity to confirm network path\n- Targeted remediation with verification: Enabled SQL public access and confirmed recovery through dependency metrics\n\n**What Didn't Go Well:**\n\n- Metric query failed for HealthCheckStatus: \"cannot support requested time grain: 00:01:00\"\n- **Better approach**: Use supported grains (00:05:00, 01:00:00) or query Requests/Http5xx instead\n\n**System Design Knowledge:**\n\nAzure SQL: Disabling publicNetworkAccess blocks App Service access unless a Private Endpoint + VNet integration is in place; enabling PNA plus an appropriate firewall rule restores reachability quickly.\n\n**Investigation Pattern:**\n\nTriage pattern: platform metrics (Requests/Http5xx) â†’ App Insights dependencies to find the failing backend â†’ connectivity probes (DNS/TCP) â†’ configuration check (PNA/firewall) â†’ minimal remediation â†’ telemetry verification.\n\n**From Incident 2 (VM CPU):**\n\n**What Went Well:**\n\n- Efficient diagnostics via Run Command: UsedÂ az vm run-command invokeÂ with a simple Get-Process pipeline\n- Targeted remediation: Stopped specific PIDs with minimal script lines\n- Clear verification step: Rechecked top processes to confirm normalization\n\n**What Didn't Go Well:**\n\n- Safety validation blockedÂ Remove-Job: \"Delete operations are not allowed for safety reasons\"\n- **Better approach**: UseÂ Stop-JobÂ only and avoidÂ Remove-Job\n- CPU percent checks failed due to quoting/escaping in Run Command\n- **Better approach**: UseÂ typeperfÂ orÂ Get-CimInstance Win32\\_Processor\n\n**System Design Knowledge:**\n\nWindows process metrics: Get-Process CPU is cumulative seconds, not percentage; use Get-Counter or typeperf for instantaneous CPU percent to verify recovery thresholds.\n\n**Investigation Pattern:**\n\nDiagnose-remediate-verify loop: capture top processes via Run Command, terminate only confirmed runaway PIDs, then re-run the same read to confirm normalization.\n\n**Component Details**\n\n| **Component** | **Purpose** | **Integration** | | --- | --- | --- | | **Azure Monitor** | Detect anomalies via metric/log alerts | Native alert routing to SRE Agent | | **Application Insights** | Dependency tracking, failure analysis | KQL queries for root cause | | **Log Analytics** | Centralized logging, performance data | KQL queries for investigation | | **VM Run Command** | Remote script execution on VMs | az vm run-command invoke | | **ARM API** | Resource configuration queries | Read/write resource properties |\n\n**Setting Up Your Own Demo**\n\n**Prerequisites**\n\n- Azure subscription with SRE Agent Preview access\n- Permissions: RBAC Admin or User Access Admin (for role assignments)\n- Region: East US 2 (required for preview)\n- Tools: Azure CLI, PowerShell 7+, Node.js 18+ (optional for web app)\n\n**Infrastructure Overview**\n\n| **Resource** | **Purpose** | **SKU/Tier** | | --- | --- | --- | | Azure SQL Server | Backend database | Serverless | | Azure SQL Database | Product data | Basic | | App Service Plan | Web app hosting | B1 (Basic) | | Web App | Frontend + API | Node.js 18 | | Windows VM | CPU spike demo | Standard\\_B2s | | Application Insights | Telemetry & dependencies | - | | Log Analytics Workspace | Centralized logging | - |\n\n**Step 1: Deploy Infrastructure**\n\n*# Clone the demo repo*\n\ngit clone https://github.com/Saby007/SREAgentDemo.git\n\ncd SREAgent\n\n*# Deploy SQL scenario (Web App + SQL Database)*\n\n.\\scripts\\deploy.ps1 -ResourceGroupName \"rg-sre-demo\" -Location \"eastus2\"\n\n*# Wait for deployment (~5-10 minutes)*\n\n*# This creates: SQL Server, Database, App Service, Application Insights, Alerts*\n\n*# Deploy VM scenario*\n\ncd scenario-vm-cpu\n\n.\\deploy-vm.ps1 -AdminPassword (ConvertTo-SecureString \"YourP@ss123!\" -AsPlainText -Force)\n\n*# Wait for VM + Azure Monitor Agent (~10 minutes)*\n\n**Step 2: Create SRE Agent**\n\n1. Go toÂ [Azure SRE Agent Portal](https://aka.ms/sreagent/portal)\n2. ClickÂ **Create**Â â†’ Select subscription â†’ Name:Â sre-agent-demo\n3. Region:Â **East US 2**Â (required for preview)\n4. Add resource group:Â rg-sre-demo\n5. ClickÂ **Create**\n\nâš ï¸Â **Important**: SRE Agent needs appropriate RBAC permissions on the resource group. The agent will requestÂ ContributorÂ access during setup.\n\n**Step 3: Configure Incident Response Plans**\n\nCreate two Incident Response Plans:\n\n**Plan 1: Web App Health (SQL Connectivity)**\n\n| **Setting** | **Value** | | --- | --- | | Incident Type | Default | | Impacted Service | App Services | | Priority | Sev 1 | | Title Contains | health | | Autonomy | Review (approval required) |\n\n**Plan 2: VM High CPU**\n\n| **Setting** | **Value** | | --- | --- | | Incident Type | Default | | Impacted Service | Virtual Machines | | Priority | Sev 2 | | Title Contains | CPU | | Autonomy | Review (approval required) |\n\nAdd custom instructions fromÂ [scenario-vm-cpu/README.md](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/ssamadda/OneDrive%20-%20Microsoft/Documents/Work/SfMC/Cognizant/SREAgent/scenario-vm-cpu/README.md).\n\n**Step 4: Trigger Incidents**\n\n*# Scenario 1: Cause SQL connectivity failure*\n\n*# This disables public network access on SQL Server*\n\n.\\scripts\\trigger-incident.ps1 -Action \"pause\"\n\n*# Wait 5-10 minutes for alert to fire*\n\n*# Scenario 2: Cause CPU spike on VM*\n\n.\\scenario-vm-cpu\\trigger-cpu-spike.ps1 -Action start\n\n*# This runs background PowerShell jobs that consume ~90% CPU*\n\n*# Wait 5-10 minutes for alert to fire (CPU &gt; 85% for 5 min window)*\n\n**Step 5: Watch SRE Agent Work**\n\nOpen the SRE Agent portal and watch it:\n\n1. âœ… Acknowledge the alert (instant)\n2. ðŸ” Investigate autonomously (metrics, logs, config)\n3. ðŸŽ¯ Identify root cause\n4. ðŸ’¡ Propose remediation options\n5. âœ‹ Wait for your approval\n6. ðŸ”§ Execute remediation\n7. âœ… Verify recovery\n8. ðŸ“ Generate Session Insights\n\n**Step 6: Cleanup**\n\n*# Remove all demo resources*\n\n.\\scripts\\cleanup.ps1 -ResourceGroupName \"rg-sre-demo\"\n\n*# Or manually via Azure CLI*\n\naz group delete --name rg-sre-demo --yes --no-wait\n\n**Key Takeaways**\n\n**Quantitative Results**\n\n| **Metric** | **Incident 1 (SQL)** | **Incident 2 (VM)** | | --- | --- | --- | | Time to Acknowledge | 1 second | 2 seconds | | Time to Root Cause | ~10 minutes | ~3 minutes | | Human Time Required | ~6 minutes (approval) | ~33 minutes (approvals) | | Total Resolution Time | ~20 minutes | ~39 minutes | | Automated Steps | 12 | 8 |\n\n**Before vs. After Comparison**\n\n| **Before SRE Agent** | **After SRE Agent** | | --- | --- | | Alert fires â†’ Wait for human to wake up | Alert fires â†’ Investigation starts immediately | | Engineer manually queries metrics, logs | Agent queries metrics, logs, ARM configs in seconds | | Root cause found after 20-30 mins of digging | Root cause identified in &lt;10 mins automatically | | Remediation requires tribal knowledge | Custom instructions encode runbooks in IRP | | Post-incident docs written (maybe, days later) | Session Insights auto-generated immediately | | Knowledge stays in engineer's head | Learnings captured and reusable |\n\n**Key Benefits**\n\n1. **Faster MTTR**Â - Investigation starts instantly, not when humans are available\n2. **Consistent Triage**Â - Same investigation pattern every time\n3. **Knowledge Capture**Â - Session Insights preserve learnings\n4. **Reduced Toil**Â - Automated data gathering and correlation\n5. **Guardrails**Â - Approval workflow for remediation actions\n\n**Lessons Learned & Best Practices**\n\n**Do's** **âœ…**\n\n| **Practice** | **Why** | | --- | --- | | **Write specific IRP instructions** | Generic instructions = generic responses | | **Include identification criteria** | Help agent distinguish safe vs. risky remediations | | **Define escalation triggers** | Know when NOT to auto-remediate | | **Test in Review mode first** | Validate agent behavior before enabling Autonomous | | **Use supported metric time grains** | Avoid query failures (5m, 1h, not 1m for some metrics) |\n\n**Don'ts** **âŒ**\n\n| **Anti-Pattern** | **Issue** | | --- | --- | | **Overly broad permissions** | Security risk; use least-privilege RBAC | | **Complex PowerShell in Run Command** | Parsing/escaping issues; keep scripts simple | | **Skipping recovery verification** | Agent should always validate the fix worked | | **Using** **Remove-Job** **in remediations** | May trigger safety blocks; useÂ Stop-Job | | **Enabling Autonomous mode without testing** | Unintended remediations on production resources |\n\n**What's Next?**\n\n**Immediate Next Steps**\n\n- **Autonomous Mode**: For trusted, well-tested scenarios, skip approval and let SRE Agent remediate automatically\n- **More Scenarios**: Add database pause/resume, storage throttling, AKS pod failures\n- **Teams Integration**: Get incident updates and approve remediations directly in Teams\n\n**Future Enhancements**\n\n- **Scheduled Checks**: Combine reactive response with proactive optimization (seeÂ [Proactive Cloud Ops blog](https://techcommunity.microsoft.com/blog/appsonazureblog/proactive-cloud-ops-with-sre-agent-scheduled-checks-for-cloud-optimization/4487261))\n- **GitHub Issues**: Auto-create issues for infrastructure problems linked to repos\n- **Knowledge Base**: Upload runbooks, architecture docs to improve agent context\n- **MCP Servers**: Connect external tools (Datadog, PagerDuty, Splunk) for broader observability\n\n**Conclusion**\n\nAzure SRE Agent transforms incident response from a reactive, human-dependent process into an AI-assisted workflow that starts investigating the moment an alert fires.\n\nIn these two real-world scenarios:\n\n- **SQL Connectivity Outage**: Agent identified misconfigured public network access and restored connectivity in ~20 minutes\n- **VM CPU Spike**: Agent captured process data, identified runaway PowerShell, and terminated the culprits in ~39 minutes\n\nThe key differentiator?Â **Custom Instructions**. By encoding our team's runbooks and identification criteria into Incident Response Plans, SRE Agent became a context-aware teammateâ€”not just a generic troubleshooter.\n\n**Is it perfect?**Â No. We encountered metric query failures, CLI escaping issues, and safety blocks. But the Session Insights captured these learnings, making the agent better for next time.\n\n**Is it valuable?**Â Absolutely. Even with human approval delays, we resolved both incidents faster than traditional triageâ€”and with comprehensive documentation auto-generated.\n\n**Learn More**\n\n- [Azure SRE Agent Documentation](https://aka.ms/sreagent/docs)\n- [Azure SRE Agent Blogs](http://aka.ms/sreagent/blogs)\n- [Azure SRE Agent Community](https://aka.ms/sreagent/discussions)\n- [Azure SRE Agent Home Page](http://www.azure.com/sreagent)\n- [Azure SRE Agent Pricing](http://aka.ms/sreagent/pricing)\n\n**Azure SRE Agent is currently in preview.**Â [Get Started â†’](https://aka.ms/sreagent/portal)\n\nUpdated Feb 18, 2026\n\nVersion 1.0\n\n[!\\[Sabyasachi-Samaddar&#x27;s avatar\\](https://techcommunity.microsoft.com/t5/s/gxcuf89792/images/dS0xMTI2NjM2LTMwMjYyMWlGOTY4OTkzMzY3MzQzMTRB?image-dimensions=50x50)](/users/sabyasachi-samaddar/1126636) [Sabyasachi-Samaddar](/users/sabyasachi-samaddar/1126636) ![Icon for Microsoft rank](https://techcommunity.microsoft.com/t5/s/gxcuf89792/images/cmstNC05WEo0blc?image-dimensions=100x16&amp;constrain-image=true)Microsoft\n\nJoined August 11, 2021\n\n[View Profile](/users/sabyasachi-samaddar/1126636)\n\n/category/azure/blog/azurearchitectureblog [Azure Architecture Blog](/category/azure/blog/azurearchitectureblog) Follow this blog board to get notified when there's new activity",
  "PubDate": "2026-02-19T06:44:39+00:00",
  "FeedUrl": "https://techcommunity.microsoft.com/t5/s/gxcuf89792/rss/Category?category.id=Azure",
  "Description": "![]()\n\n*SRE Agent portal overview with incident list*\n\n**The Reactive Incident Challenge**\n\nYour monitoring is solid. Alerts fire when they should. But then what?\n\n- Alert lands in Teams/PagerDuty\n- On-call engineer wakes up, logs in\n- Starts investigating: \"What's broken? Why? How do I fix it?\"\n- 20 minutes later, they're still gathering context\n\nThe alert was fast. The human response? Not so much.\n\n**The Traditional Incident Response Flow**\n\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n\nâ”‚ Alert â”‚â”€â”€â”€â–¶â”‚ Human â”‚â”€â”€â”€â–¶â”‚ Manual â”‚â”€â”€â”€â–¶â”‚ Resolution â”‚\n\nâ”‚ Fires â”‚ â”‚ Acknowledgesâ”‚ â”‚Investigationâ”‚ â”‚ (Maybe) â”‚\n\nâ”‚ â”‚ â”‚ (5-15 min) â”‚ â”‚ (15-30 min)â”‚ â”‚ â”‚\n\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nt=0 t=5-15min t=20-45min t=30-60min\n\n**The SRE Agent Flow**\n\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n\nâ”‚ Alert â”‚â”€â”€â”€â–¶â”‚ SRE Agent â”‚â”€â”€â”€â–¶â”‚ AI â”‚â”€â”€â”€â–¶â”‚ Human â”‚\n\nâ”‚ Fires â”‚ â”‚ Acknowledgesâ”‚ â”‚Investigationâ”‚ â”‚ Approves â”‚\n\nâ”‚ â”‚ â”‚ (Instant) â”‚ â”‚ (2-10 min) â”‚ â”‚ â”‚\n\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nt=0 t=0 t=2-10min t=10-15min\n\n**What if the investigation started the moment the alert fired?**\n\nThat's exactly what Azure SRE Agent does. It doesn't wait for humans to acknowledgeâ€”it starts investigating immediately, gathering context, identifying root causes, and preparing remediation options.\n\nI tested this with two real-world scenarios: a database connectivity outage and a VM CPU spike. Here's what happened.\n\n**Two Real-World Incidents**\n\n| **Scenario** | **Trigger** | **Root Cause** | **Resolution** | | --- | --- | --- | --- | | **Web App Health Failure** | Sev1 Alert - Health check failing | SQL Server public access disabled | Enabled public access + firewall rule | | **VM High CPU** | Sev2 Alert - CPU > 85% for 5 mins | Runaway PowerShell processes | Identified and killed processes |\n\nBoth incidents were detected, diagnosed, and remediated by SRE Agent with minimal human interventionâ€”just approval clicks.\n\n**Incident 1: Azure SQL Database Connectivity Outage**\n\n**The Alert**\n\nðŸ”´ Sev1 Alert Fired\n\nAlert Rule: sre-demo-webapp-health-alert\n\nDescription: Alert when Web App health check fails - indicates backend/database connectivity issues\n\nTime: 02/04/2026 07:59:35 UTC\n\n**Alert Configuration Details**\n\nThe alert was configured using Azure Monitor metric alerts:\n\nresource webAppHealthAlert 'Microsoft.Insights/metricAlerts@2018-03-01' = {\n\nname: 'sre-demo-webapp-health-alert'\n\nproperties: {\n\nseverity: 1\n\nevaluationFrequency: 'PT1M'\n\nwindowSize: 'PT5M'\n\ncriteria: {\n\n'odata.type': 'Microsoft.Azure.Monitor.SingleResourceMultipleMetricCriteria'\n\nallOf: [\n\n{\n\nname: 'HealthCheckStatus'\n\nmetricName: 'HealthCheckStatus'\n\noperator: 'LessThan'\n\nthreshold: 100\n\ntimeAggregation: 'Average'\n\n}\n\n]\n\n}\n\ntargetResourceType: 'Microsoft.Web/sites'\n\ntargetResourceRegion: 'centralindia'\n\n}\n\n}\n\n**What SRE Agent Did (Autonomously)**\n\n![]()\n\n*[SRE Agent chat showing the investigation steps and thinking process]*\n\nThe moment the alert fired, SRE Agent acknowledged and began investigating:\n\n1. **Symptom Assessment**\n\n- Pulled web app ARM configuration (AlwaysOn, Basic plan, system-assigned identity)\n- Analyzed HTTP 5xx and request metrics over 2 hours\n- Observed intermittent traffic spikes indicating service impact\n\n// KQL query SRE Agent ran against Application Insights\n\nrequests\n\n| where timestamp > ago(2h)\n\n| summarize\n\nTotalRequests = count(),\n\nFailedRequests = countif(resultCode >= 500),\n\nFailureRate = round(100.0 \\* countif(resultCode >= 500) / count(), 2)\n\n| project TotalRequests, FailedRequests, FailureRate\n\n1. **Dependency Mapping**\n\n![]()\n\n*[Application Insights showing SQL dependency failures at 100%]*\n\n- Queried Application Insights to identify failing backends\n- Found: sre-demo-sql-6o26gsgynw436.database.windows.net failing **100% (80/80 calls)** in last 30 minutes\n- Result code: 503 on \"SQL Health Check\" and \"GetProducts\" operations\n\n// Dependency failure analysis\n\ndependencies\n\n| where timestamp > ago(30m)\n\n| where target contains \"database.windows.net\"\n\n| summarize\n\nTotalCalls = count(),\n\nFailedCalls = countif(success == false),\n\nFailureRate = round(100.0 \\* countif(success == false) / count(), 2)\n\n| project TotalCalls, FailedCalls, FailureRate\n\n1. **Network Validation**\n\n- Tested DNS resolution from web app to SQL endpoint âœ… Success\n- Tested TCP reachability on port 1433 âœ… Success\n- Conclusion: Network path is healthy; issue is at access/auth layer\n\n*# SRE Agent validated network connectivity using:*\n\n*# DNS Resolution Test*\n\nnslookup sre-demo-sql-6o26gsgynw436.database.windows.net\n\n*# TCP Port Test (from App Service)*\n\ntcpping sre-demo-sql-6o26gsgynw436.database.windows.net:1433\n\n1. **Configuration Analysis**\n\n*# SRE Agent queried SQL server configuration*\n\naz sql server show -g rg-sre-demo-india -n sre-demo-sql-6o26gsgynw436 \\\n\n--query \"{publicNetworkAccess:publicNetworkAccess, fullyQualifiedDomainName:fullyQualifiedDomainName}\"\n\n*# Output:*\n\n{\n\n\"publicNetworkAccess\": \"Disabled\", *#*\n\n\"fullyQualifiedDomainName\": \"sre-demo-sql-6o26gsgynw436.database.windows.net\"\n\n}\n\n- Discovered: **Azure SQL public network access = Disabled**\n- Web app has no VNet integration or Private Endpoint\n- Root cause identified: Access model mismatch\n\n**The Root Cause Analysis**\n\n**Root cause: Azure SQL public network access is Disabled while the web app has no VNet integration/private endpoint, so the app cannot reach SQL at the access model layer.**\n\nSRE Agent presented two remediation options:\n\n| **Option** | **Approach** | **Speed** | **Security** | **Use Case** | | --- | --- | --- | --- | --- | | **A** | Enable public access + Allow Azure Services (0.0.0.0) | âš¡ Fast | ðŸŸ¡ Moderate | Quick restore, non-prod | | **B** | Add web app's specific outbound IPs to firewall | ðŸ¢ Slower | ðŸŸ¢ Stricter | Production environments | | **C** | Configure Private Endpoint + VNet Integration | ðŸ¢ðŸ¢ Slowest | ðŸŸ¢ðŸŸ¢ Best | Long-term solution |\n\n**Remediation (With Approval)**\n\n![]()\n\n*[SRE Agent asking for approval before executing remediation]*\n\nI approved Option A for rapid restoration. SRE Agent executed:\n\n*# Step 1: Enable public network access*\n\naz sql server update -g rg-sre-demo-india -n sre-demo-sql-6o26gsgynw436 \\\n\n--subscription \\\n\n--set publicNetworkAccess=Enabled\n\n*# Step 2: Add Azure Services firewall rule*\n\naz sql server firewall-rule create \\\n\n-g rg-sre-demo-india \\\n\n-s sre-demo-sql-6o26gsgynw436 \\\n\n-n AllowAzureServices \\\n\n--subscription \\\n\n--start-ip-address 0.0.0.0 \\\n\n--end-ip-address 0.0.0.0\n\nâš ï¸ **Security Note**: The 0.0.0.0 rule allows traffic from *any* Azure service, not just your web app. For production, use Option B (specific IPs) or Option C (Private Endpoint).\n\n**Recovery Verified**\n\nSRE Agent automatically verified recovery by re-querying Application Insights:\n\n// Post-remediation verification\n\ndependencies\n\n| where timestamp > ago(10m)\n\n| where target contains \"database.windows.net\"\n\n| summarize\n\nTotalCalls = count(),\n\nSuccessfulCalls = countif(success == true),\n\nSuccessRate = round(100.0 \\* countif(success == true) / count(), 2)\n\nResults:\n\n- SQL dependencies: **65/65 successful** (100% success rate)\n- HTTP 5xx errors: **Dropped to 0**\n- Service restored âœ…\n\n**Timeline**\n\n| **Time (UTC)** | **Event** | **Duration** | | --- | --- | --- | | 07:59:35 | Alert fired | - | | 07:59:36 | SRE Agent acknowledged | +1s | | 08:00:00 | Started symptom assessment | +25s | | 08:05:00 | Dependency mapping complete | +5m | | 08:08:00 | Network validation complete | +3m | | 08:10:00 | Root cause identified | +2m | | 08:16:00 | Remediation approved | +6m (human) | | 08:17:00 | Remediation executed | +1m | | 08:20:00 | Recovery verified | +3m |\n\n**Total time from alert to resolution: ~20 minutes** (6 minutes waiting for human approval)\n\n**Incident 2: VM High CPU Spike**\n\n**The Alert**\n\n![]()\n\n*[Azure VM showing Average CPU metric is increasing]*\n\nðŸŸ¡ Sev2 Alert Fired\n\nAlert Rule: sre-demo-vm-cpu-alert\n\nDescription: Alert when VM CPU exceeds 85% - indicates runaway process or resource exhaustion\n\nResource: sre-demo-vm\n\nTime: 02/04/2026 16:16:18 UTC\n\n**Alert Configuration Details**\n\nThe VM CPU alert was configured as a metric alert:\n\nresource vmCpuAlert 'Microsoft.Insights/metricAlerts@2018-03-01' = {\n\nname: 'sre-demo-vm-cpu-alert'\n\nproperties: {\n\nseverity: 2\n\nevaluationFrequency: 'PT1M'\n\nwindowSize: 'PT5M'\n\ncriteria: {\n\n'odata.type': 'Microsoft.Azure.Monitor.SingleResourceMultipleMetricCriteria'\n\nallOf: [\n\n{\n\nname: 'HighCPU'\n\nmetricName: 'Percentage CPU'\n\noperator: 'GreaterThan'\n\nthreshold: 85\n\ntimeAggregation: 'Average'\n\n}\n\n]\n\n}\n\ntargetResourceType: 'Microsoft.Compute/virtualMachines'\n\n}\n\n}\n\n**What SRE Agent Did**\n\n![]()\n\n*[SRE Agent chat showing VM investigation and Run Command execution]*\n\n1. **Process Capture via VM Run Command**\n\nSRE Agent requested approval to run a safe, read-only command to capture top CPU processes:\n\n*# Read-only diagnostic command*\n\nGet-Process | Sort-Object CPU -Descending | Select-Object -First 10 Name,CPU,Id | ConvertTo-Json\n\nThe agent used Azure VM Run Command (az vm run-command invoke) to execute PowerShell remotely:\n\naz vm run-command invoke \\\n\n-g rg-sre-demo-india \\\n\n-n sre-demo-vm \\\n\n--subscription \\\n\n--command-id RunPowerShellScript \\\n\n--scripts \"Get-Process | Sort-Object CPU -Descending | Select-Object -First 10 Name,CPU,Id | ConvertTo-Json\"\n\n1. **Runaway Process Identification**\n\nResults revealed two PowerShell processes consuming excessive CPU:\n\n[\n\n{ \"Name\": \"powershell\", \"CPU\": 683.45, \"Id\": 3164 },\n\n{ \"Name\": \"powershell\", \"CPU\": 652.12, \"Id\": 2776 },\n\n{ \"Name\": \"MsMpEng\", \"CPU\": 54.23, \"Id\": 1892 },\n\n{ \"Name\": \"svchost\", \"CPU\": 12.34, \"Id\": 1024 }\n\n]\n\n| **Process** | **PID** | **CPU Time (seconds)** | **Assessment** | **Reasoning** | | --- | --- | --- | --- | --- | | powershell | 3164 | 683.45s (~11 min) | ðŸ”´ Runaway | CPU time > 60s threshold from IRP | | powershell | 2776 | 652.12s (~10 min) | ðŸ”´ Runaway | CPU time > 60s threshold from IRP | | MsMpEng | 1892 | 54.23s | âœ… Normal | Windows Defender - expected | | svchost | 1024 | 12.34s | âœ… Normal | System process - expected |\n\nSRE Agent correctly identified these as stress/runaway processes based on the custom instructions I provided in the Incident Response Plan:\n\n*\"If process is 'powershell' with CPU > 80 seconds â†’ LIKELY stress script\"*\n\n1. **Targeted Remediation**\n\nWith my approval, SRE Agent executed targeted process termination:\n\naz vm run-command invoke \\\n\n-g rg-sre-demo-india \\\n\n-n sre-demo-vm \\\n\n--subscription \\\n\n--command-id RunPowerShellScript \\\n\n--scripts \"Stop-Process -Id 3164 -Force -ErrorAction SilentlyContinue; Stop-Process -Id 2776 -Force -ErrorAction SilentlyContinue; Write-Output 'Stopped'\"\n\nðŸ’¡ **Why specific PIDs?** SRE Agent targeted only the identified runaway processes (PIDs 3164, 2776) rather than killing all PowerShell processes. This minimizes blast radius and avoids disrupting legitimate automation.\n\n1. **Recovery Verification**\n\nPost-remediation check showed:\n\n*// After remediation - Top processes*\n\n[\n\n{ \"Name\": \"MsMpEng\", \"CPU\": 54.23, \"Id\": 1892 }, *// Now the top consumer*\n\n{ \"Name\": \"svchost\", \"CPU\": 12.34, \"Id\": 1024 },\n\n{ \"Name\": \"WmiPrvSE\", \"CPU\": 8.12, \"Id\": 2048 }\n\n]\n\n- âœ… PowerShell processes no longer in top CPU list\n- âœ… Highest CPU consumer: MsMpEng (Windows Defender) at ~54s - **normal baseline**\n- âœ… VM CPU normalized\n\n**Technical Deep Dive: Understanding CPU Metrics**\n\nAn important learning from this incident:\n\n| **Metric** | **What It Measures** | **When to Use** | | --- | --- | --- | | Get-Process.CPU | **Cumulative** CPU time in seconds since process start | Identifying long-running resource hogs | | Get-Counter '\\Processor(\\_Total)\\% Processor Time' | **Instantaneous** CPU percentage | Validating current system state | | Get-CimInstance Win32\\_Processor | CPU load percentage | Quick health check |\n\nSRE Agent initially tried to verify recovery using performance counters but encountered parsing issues. The Session Insights captured this learning for future incidents.\n\n**Timeline**\n\n| **Time (UTC)** | **Event** | **Duration** | | --- | --- | --- | | 16:16:18 | Alert fired (CPU > 85% for 5 min) | - | | 16:16:20 | SRE Agent acknowledged | +2s | | 16:48:00 | Process capture approved | +32m (human delay) | | 16:48:30 | Top processes captured | +30s | | 16:51:00 | Runaway processes identified | +2.5m | | 16:52:00 | Remediation approved | +1m | | 16:52:30 | Processes terminated | +30s | | 16:55:00 | Recovery verified | +2.5m |\n\n**Total time from alert to resolution: ~39 minutes** (32 minutes waiting for initial human approval)\n\n**Why Custom Instructions Matter**\n\nOut of the box, SRE Agent knows Azure. But it doesn't know *your* environment.\n\nFor the VM CPU scenario, I created an **Incident Response Plan** with custom instructions that taught the agent:\n\n- What \"HighCpuProcess\" means (it's our test stress process)\n- When it's safe to kill PowerShell processes (CPU > 60 seconds)\n- How to validate recovery (check CPU percentage)\n- When to escalate vs. auto-remediate\n\n**Full Custom Instructions for VM CPU Scenario**\n\nYou are investigating a high CPU alert on a Windows Virtual Machine.\n\nINVESTIGATION METHODOLOGY:\n\n1. Connect to the VM and query current CPU usage\n2. Identify which process is consuming the most CPU\n3. Determine if the process is legitimate or a runaway/malicious process\n4. Take appropriate action based on findings\n\nDIAGNOSTIC STEPS:\n\n1. Use Azure VM Run Command to execute diagnostic scripts on the VM\n2. Query the top CPU-consuming processes using:\n\n- Get-Process | Sort-Object CPU -Descending | Select-Object -First 10 Name, CPU, Id\n\n1. Check for known runaway process indicators:\n\n- Process name contains \"HighCpuProcess\" â†’ This is a test stress process, safe to kill\n\n- PowerShell process with unusually high CPU â†’ Likely a stress script, investigate further\n\n- Unknown process consuming >50% CPU â†’ Potential runaway, gather more info before killing\n\nIDENTIFICATION CRITERIA:\n\n- If process name is \"HighCpuProcess\" â†’ CONFIRMED runaway test process\n\n- If process is \"powershell\" with CPU > 80 seconds â†’ LIKELY stress script\n\n- If multiple PowerShell background jobs named \"HighCpuProcess-*\\*\" exist â†’ CONFIRMED stress test*\n\n*REMEDIATION ACTIONS:*\n\n*For PowerShell stress jobs:*\n\n*Get-Job -Name \"HighCpuProcess\\**\" | Stop-Job\n\nFor high-CPU PowerShell processes:\n\nGet-Process -Name \"powershell*\\*\" | Where-Object { $\\_.CPU -gt 60 } | Stop-Process -Force*\n\n*General process termination (use process ID from investigation):*\n\n*Stop-Process -Id -Force*\n\n*VALIDATION:*\n\n*After remediation, verify CPU has returned to normal:*\n\n*$cpu = (Get-Counter '\\Processor(\\_Total)\\% Processor Time' -SampleInterval 2 -MaxSamples 3 |*\n\n*Select-Object -ExpandProperty CounterSamples |*\n\n*Measure-Object -Property CookedValue -Average).Average*\n\n*Write-Host \"Current CPU: $([math]::Round($cpu, 1))%\"*\n\n*ESCALATION:*\n\n*- If CPU remains high after killing identified processes, escalate to human operator*\n\n*- If process is a critical system process, do NOT kill - escalate instead*\n\n*- If unable to connect to VM, check VM health and network connectivity first*\n\n**How Custom Instructions Change Agent Behavior**\n\n| **Without Custom Instructions** | **With Custom Instructions** | | --- | --- | | \"I see high CPU on this VM\" | \"PowerShell PID 3164 has 683s CPU time, exceeding 60s threshold - confirmed runaway\" | | \"Should I investigate?\" | \"Based on IRP criteria, this matches stress script pattern - recommending termination\" | | Generic troubleshooting | Targeted, context-aware remediation | | May escalate unnecessarily | Knows when to act vs. escalate |\n\nThis context transformed SRE Agent from a generic troubleshooter into a teammate who understands our specific runbooks.\n\n**What SRE Agent Learned (Session Insights)**\n\nAfter each incident, SRE Agent generates **Session Insights**â€”a structured summary of what happened, what went well, and what to improve. These become organizational knowledge.\n\n**Session Insights Structure**\n\nTIMELINE\n\nâ”œâ”€â”€ Event 1: Initial acknowledgment\n\nâ”œâ”€â”€ Event 2: Symptom assessment\n\nâ”œâ”€â”€ Event 3: Root cause identified\n\nâ”œâ”€â”€ Event 4: Remediation executed\n\nâ””â”€â”€ Event 5: Recovery verified\n\nEVALUATION\n\nâ”œâ”€â”€ What Went Well\n\nâ”‚ â””â”€â”€ Specific actions that succeeded\n\nâ””â”€â”€ What Didn't Go Well\n\nâ””â”€â”€ Issues encountered + better approaches\n\nDERIVED LEARNING\n\nâ”œâ”€â”€ System Design Knowledge\n\nâ”‚ â””â”€â”€ Azure-specific learnings\n\nâ””â”€â”€ Investigation Pattern\n\nâ””â”€â”€ Reusable troubleshooting approaches\n\n**From Incident 1 (SQL Connectivity):**\n\n**What Went Well:**\n\n- Rapid isolation of failing backend: Used Application Insights to pinpoint the SQL dependency target with 80/80 failures\n- Layered validation before change: Validated DNS and TCP connectivity to confirm network path\n- Targeted remediation with verification: Enabled SQL public access and confirmed recovery through dependency metrics\n\n**What Didn't Go Well:**\n\n- Metric query failed for HealthCheckStatus: \"cannot support requested time grain: 00:01:00\"\n- **Better approach**: Use supported grains (00:05:00, 01:00:00) or query Requests/Http5xx instead\n\n**System Design Knowledge:**\n\nAzure SQL: Disabling publicNetworkAccess blocks App Service access unless a Private Endpoint + VNet integration is in place; enabling PNA plus an appropriate firewall rule restores reachability quickly.\n\n**Investigation Pattern:**\n\nTriage pattern: platform metrics (Requests/Http5xx) â†’ App Insights dependencies to find the failing backend â†’ connectivity probes (DNS/TCP) â†’ configuration check (PNA/firewall) â†’ minimal remediation â†’ telemetry verification.\n\n**From Incident 2 (VM CPU):**\n\n**What Went Well:**\n\n- Efficient diagnostics via Run Command: Used az vm run-command invoke with a simple Get-Process pipeline\n- Targeted remediation: Stopped specific PIDs with minimal script lines\n- Clear verification step: Rechecked top processes to confirm normalization\n\n**What Didn't Go Well:**\n\n- Safety validation blocked Remove-Job: \"Delete operations are not allowed for safety reasons\"\n- **Better approach**: Use Stop-Job only and avoid Remove-Job\n- CPU percent checks failed due to quoting/escaping in Run Command\n- **Better approach**: Use typeperf or Get-CimInstance Win32\\_Processor\n\n**System Design Knowledge:**\n\nWindows process metrics: Get-Process CPU is cumulative seconds, not percentage; use Get-Counter or typeperf for instantaneous CPU percent to verify recovery thresholds.\n\n**Investigation Pattern:**\n\nDiagnose-remediate-verify loop: capture top processes via Run Command, terminate only confirmed runaway PIDs, then re-run the same read to confirm normalization.\n\n**Component Details**\n\n| **Component** | **Purpose** | **Integration** | | --- | --- | --- | | **Azure Monitor** | Detect anomalies via metric/log alerts | Native alert routing to SRE Agent | | **Application Insights** | Dependency tracking, failure analysis | KQL queries for root cause | | **Log Analytics** | Centralized logging, performance data | KQL queries for investigation | | **VM Run Command** | Remote script execution on VMs | az vm run-command invoke | | **ARM API** | Resource configuration queries | Read/write resource properties |\n\n**Setting Up Your Own Demo**\n\n**Prerequisites**\n\n- Azure subscription with SRE Agent Preview access\n- Permissions: RBAC Admin or User Access Admin (for role assignments)\n- Region: East US 2 (required for preview)\n- Tools: Azure CLI, PowerShell 7+, Node.js 18+ (optional for web app)\n\n**Infrastructure Overview**\n\n| **Resource** | **Purpose** | **SKU/Tier** | | --- | --- | --- | | Azure SQL Server | Backend database | Serverless | | Azure SQL Database | Product data | Basic | | App Service Plan | Web app hosting | B1 (Basic) | | Web App | Frontend + API | Node.js 18 | | Windows VM | CPU spike demo | Standard\\_B2s | | Application Insights | Telemetry & dependencies | - | | Log Analytics Workspace | Centralized logging | - |\n\n**Step 1: Deploy Infrastructure**\n\n*# Clone the demo repo*\n\ngit clone https://github.com/Saby007/SREAgentDemo.git\n\ncd SREAgent\n\n*# Deploy SQL scenario (Web App + SQL Database)*\n\n.\\scripts\\deploy.ps1 -ResourceGroupName \"rg-sre-demo\" -Location \"eastus2\"\n\n*# Wait for deployment (~5-10 minutes)*\n\n*# This creates: SQL Server, Database, App Service, Application Insights, Alerts*\n\n*# Deploy VM scenario*\n\ncd scenario-vm-cpu\n\n.\\deploy-vm.ps1 -AdminPassword (ConvertTo-SecureString \"YourP@ss123!\" -AsPlainText -Force)\n\n*# Wait for VM + Azure Monitor Agent (~10 minutes)*\n\n**Step 2: Create SRE Agent**\n\n1. Go to [Azure SRE Agent Portal](https://aka.ms/sreagent/portal)\n2. Click **Create** â†’ Select subscription â†’ Name: sre-agent-demo\n3. Region: **East US 2** (required for preview)\n4. Add resource group: rg-sre-demo\n5. Click **Create**\n\nâš ï¸ **Important**: SRE Agent needs appropriate RBAC permissions on the resource group. The agent will request Contributor access during setup.\n\n**Step 3: Configure Incident Response Plans**\n\nCreate two Incident Response Plans:\n\n**Plan 1: Web App Health (SQL Connectivity)**\n\n| **Setting** | **Value** | | --- | --- | | Incident Type | Default | | Impacted Service | App Services | | Priority | Sev 1 | | Title Contains | health | | Autonomy | Review (approval required) |\n\n**Plan 2: VM High CPU**\n\n| **Setting** | **Value** | | --- | --- | | Incident Type | Default | | Impacted Service | Virtual Machines | | Priority | Sev 2 | | Title Contains | CPU | | Autonomy | Review (approval required) |\n\nAdd custom instructions from [scenario-vm-cpu/README.md](https://file+.vscode-resource.vscode-cdn.net/c%3A/Users/ssamadda/OneDrive%20-%20Microsoft/Documents/Work/SfMC/Cognizant/SREAgent/scenario-vm-cpu/README.md).\n\n**Step 4: Trigger Incidents**\n\n*# Scenario 1: Cause SQL connectivity failure*\n\n*# This disables public network access on SQL Server*\n\n.\\scripts\\trigger-incident.ps1 -Action \"pause\"\n\n*# Wait 5-10 minutes for alert to fire*\n\n*# Scenario 2: Cause CPU spike on VM*\n\n.\\scenario-vm-cpu\\trigger-cpu-spike.ps1 -Action start\n\n*# This runs background PowerShell jobs that consume ~90% CPU*\n\n*# Wait 5-10 minutes for alert to fire (CPU > 85% for 5 min window)*\n\n**Step 5: Watch SRE Agent Work**\n\nOpen the SRE Agent portal and watch it:\n\n1. âœ… Acknowledge the alert (instant)\n2. ðŸ” Investigate autonomously (metrics, logs, config)\n3. ðŸŽ¯ Identify root cause\n4. ðŸ’¡ Propose remediation options\n5. âœ‹ Wait for your approval\n6. ðŸ”§ Execute remediation\n7. âœ… Verify recovery\n8. ðŸ“ Generate Session Insights\n\n**Step 6: Cleanup**\n\n*# Remove all demo resources*\n\n.\\scripts\\cleanup.ps1 -ResourceGroupName \"rg-sre-demo\"\n\n*# Or manually via Azure CLI*\n\naz group delete --name rg-sre-demo --yes --no-wait\n\n**Key Takeaways**\n\n**Quantitative Results**\n\n| **Metric** | **Incident 1 (SQL)** | **Incident 2 (VM)** | | --- | --- | --- | | Time to Acknowledge | 1 second | 2 seconds | | Time to Root Cause | ~10 minutes | ~3 minutes | | Human Time Required | ~6 minutes (approval) | ~33 minutes (approvals) | | Total Resolution Time | ~20 minutes | ~39 minutes | | Automated Steps | 12 | 8 |\n\n**Before vs. After Comparison**\n\n| **Before SRE Agent** | **After SRE Agent** | | --- | --- | | Alert fires â†’ Wait for human to wake up | Alert fires â†’ Investigation starts immediately | | Engineer manually queries metrics, logs | Agent queries metrics, logs, ARM configs in seconds | | Root cause found after 20-30 mins of digging | Root cause identified in <br> | | Remediation requires tribal knowledge | Custom instructions encode runbooks in IRP | | Post-incident docs written (maybe, days later) | Session Insights auto-generated immediately | | Knowledge stays in engineer's head | Learnings captured and reusable |\n\n**Key Benefits**\n\n1. **Faster MTTR** - Investigation starts instantly, not when humans are available\n2. **Consistent Triage** - Same investigation pattern every time\n3. **Knowledge Capture** - Session Insights preserve learnings\n4. **Reduced Toil** - Automated data gathering and correlation\n5. **Guardrails** - Approval workflow for remediation actions\n\n**Lessons Learned & Best Practices**\n\n**Do's** **âœ…**\n\n| **Practice** | **Why** | | --- | --- | | **Write specific IRP instructions** | Generic instructions = generic responses | | **Include identification criteria** | Help agent distinguish safe vs. risky remediations | | **Define escalation triggers** | Know when NOT to auto-remediate | | **Test in Review mode first** | Validate agent behavior before enabling Autonomous | | **Use supported metric time grains** | Avoid query failures (5m, 1h, not 1m for some metrics) |\n\n**Don'ts** **âŒ**\n\n| **Anti-Pattern** | **Issue** | | --- | --- | | **Overly broad permissions** | Security risk; use least-privilege RBAC | | **Complex PowerShell in Run Command** | Parsing/escaping issues; keep scripts simple | | **Skipping recovery verification** | Agent should always validate the fix worked | | **Using** **Remove-Job** **in remediations** | May trigger safety blocks; use Stop-Job | | **Enabling Autonomous mode without testing** | Unintended remediations on production resources |\n\n**What's Next?**\n\n**Immediate Next Steps**\n\n- **Autonomous Mode**: For trusted, well-tested scenarios, skip approval and let SRE Agent remediate automatically\n- **More Scenarios**: Add database pause/resume, storage throttling, AKS pod failures\n- **Teams Integration**: Get incident updates and approve remediations directly in Teams\n\n**Future Enhancements**\n\n- **Scheduled Checks**: Combine reactive response with proactive optimization (see [Proactive Cloud Ops blog](https://techcommunity.microsoft.com/blog/appsonazureblog/proactive-cloud-ops-with-sre-agent-scheduled-checks-for-cloud-optimization/4487261))\n- **GitHub Issues**: Auto-create issues for infrastructure problems linked to repos\n- **Knowledge Base**: Upload runbooks, architecture docs to improve agent context\n- **MCP Servers**: Connect external tools (Datadog, PagerDuty, Splunk) for broader observability\n\n**Conclusion**\n\nAzure SRE Agent transforms incident response from a reactive, human-dependent process into an AI-assisted workflow that starts investigating the moment an alert fires.\n\nIn these two real-world scenarios:\n\n- **SQL Connectivity Outage**: Agent identified misconfigured public network access and restored connectivity in ~20 minutes\n- **VM CPU Spike**: Agent captured process data, identified runaway PowerShell, and terminated the culprits in ~39 minutes\n\nThe key differentiator? **Custom Instructions**. By encoding our team's runbooks and identification criteria into Incident Response Plans, SRE Agent became a context-aware teammateâ€”not just a generic troubleshooter.\n\n**Is it perfect?** No. We encountered metric query failures, CLI escaping issues, and safety blocks. But the Session Insights captured these learnings, making the agent better for next time.\n\n**Is it valuable?** Absolutely. Even with human approval delays, we resolved both incidents faster than traditional triageâ€”and with comprehensive documentation auto-generated.\n\n**Learn More**\n\n- [Azure SRE Agent Documentation](https://aka.ms/sreagent/docs)\n- [Azure SRE Agent Blogs](http://aka.ms/sreagent/blogs)\n- [Azure SRE Agent Community](https://aka.ms/sreagent/discussions)\n- [Azure SRE Agent Home Page](http://www.azure.com/sreagent)\n- [Azure SRE Agent Pricing](http://aka.ms/sreagent/pricing)\n\n**Azure SRE Agent is currently in preview.** [Get Started â†’](https://aka.ms/sreagent/portal)"
}
