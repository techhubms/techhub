{
  "Description": "Security teams often spend days manually turning long incident reports and threat writeups into actionable detections by extracting TTPs. This blog post shows an AI-assisted workflow that does the same job in minutes. It extracts the TTPs, maps them to existing detection coverage, and flags potential gaps. Defenders can respond faster, with human experts still reviewing and validating the results.\n\nThe post [Turning threat reports into detection insights with AI](https://www.microsoft.com/en-us/security/blog/2026/01/29/turning-threat-reports-detection-insights-ai/) appeared first on [Microsoft Security Blog](https://www.microsoft.com/en-us/security/blog).",
  "Tags": [],
  "ProcessedDate": "2026-01-29 23:04:37",
  "FeedName": "Microsoft Security Blog",
  "FeedLevelAuthor": "Microsoft Security Blog",
  "EnhancedContent": "Security teams routinely need to transform unstructured threat knowledge, such as incident narratives, red team breach-path writeups, threat actor profiles, and public reports into concrete defensive action. The early stages of that work are often the slowest. These include extracting tactics, techniques, and procedures (TTPs) from long documents, mapping them to a standard taxonomy, and determining which TTPs are already covered by existing detections versus which represent potential gaps.\n\nComplex documents that mix prose, tables, screenshots, links, and code make it easy to miss key details. As a result, manual analysis can take days or even weeks, depending on the scope and telemetry involved.\n\nThis post outlines an AI-assisted workflow for detection analysis designed to accelerate detection engineering. The workflow generates a structured initial analysis from common security content, such as incident reports and threat writeups. It extracts candidate TTPs from the content, validates those TTPs, and normalizes them to a consistent format, including alignment with the MITRE ATT&CK framework.\n\nThe workflow then performs coverage and gap analysis by comparing the extracted TTPs against an existing detection catalog. It combines similarity search with LLM-based validation to improve accuracy. The goal is to give defenders a high-quality starting point by quickly surfacing likely coverage areas and potential detection gaps.\n\nThis approach saves time and allows analysts to focus where they add the most value: validating findings, confirming what telemetry actually captures, and implementing or tuning detections.\n\n## Technical details\n\n![](https://www.microsoft.com/en-us/security/blog/wp-content/uploads/2026/01/image-28.webp)**Figure 1: Overall flow of the analysis**.\n\n**Figure 1: Overall flow of the analysis**\n\nFigure 1 illustrates the overall architecture of the workflow for analyzing threat data. The system accepts multiple content types and processes them through three main stages: TTP extraction, MITRE ATT&CK mapping, and detection coverage analysis.\n\nThe workflow ingests artifacts that describe adversary behavior, including documents and web-based content. These artifacts include:\n\n- Red team reports\n- Threat intelligence (TI) reports\n- Threat actor (TA) profiles.\n\nThe system supports multiple content formats, allowing teams to process both internal and external reports without manual reformatting.\n\nDuring ingestion, the system breaks each document into machine-readable segments, such as text blocks, headings, and lists. It retains the original document structure to preserve context. This is important because the location of information, such as whether it appears in an appendix or in key findings, can affect how the data is interpreted. This is especially relevant for long reports that combine narrative text with supporting evidence.\n\n### 1) TTP and metadata extraction\n\nThe first major technical step extracts candidate TTPs from the ingested content. The workflow identifies technique-like behaviors described in free text and converts them into a structured format for review and downstream mapping.\n\nThe system uses specialized Large Language Model (LLM) prompts to extract this information from raw content. In addition to candidate TTPs, the system extracts supporting metadata, including:\n\n- Relevant cloud stack layers\n- Detection opportunities\n- Telemetry required for detection authoring\n\n### 2) MITRE ATT&CK mapping\n\nThe system validates MITRE ATT&CK mappings by normalizing extracted behaviors to specific technique identifiers and names. This process highlights areas of uncertainty for review and correction, helping standardize visibility into attack observations and potential protection gaps.\n\nThe goal is to map all relevant layers, including tactics, techniques, and sub-techniques, by assigning each extracted TTP to the appropriate level of the MITRE ATT&CK hierarchy. Each TTP is mapped using a single LLM call with Retrieval Augmented Generation (RAG). To maintain accuracy, the system uses a focused, one-at-a-time approach to mapping.\n\n### 3) Existing detections mapping and gap analysis\n\nA key workflow step is mapping extracted TTPs against existing detections to determine which behaviors are already covered and where gaps may exist. This allows defenders to assess current coverage and prioritize detection development or tuning efforts.\n\n![](https://www.microsoft.com/en-us/security/blog/wp-content/uploads/2026/01/image-29.webp)Figure 2: Detection Mapping Process.\n\nFigure 2 illustrates the end-to-end detection mapping process. This phase includes the following:\n\n- **Vector similarity search:** The system uses this to identify potential detection matches for each extracted TTP.\n- **LLM-based validation: The system uses this** to minimize false positives and provide determinations of “likely covered” versus “likely gap” outcomes.\n\nThe vector similarity search process begins by standardizing all detections, including their metadata and code, during an offline preprocessing step. This information is stored in a relational database and includes details such as titles, descriptions, and MITRE ATT&CK mappings. In federated environments, detections may come from multiple repositories, so this standardization streamlines access during detection mapping. Selected fields are then used to build a vector database, enabling semantic search across detections.\n\nVector search uses approximate nearest neighbor algorithms and produces a similarity-based confidence score. Because setting effective thresholds for these scores can be challenging, the workflow includes a second validation step using an LLM. This step evaluates whether candidate mappings are valid for a given TTP using a tailored prompt.\n\nThe final output highlights prioritized detection opportunities and identifies potential gaps. These results are intended as recommendations that defenders should confirm based on their environment and available telemetry. Because the analysis relies on extracted text and metadata, which may be ambiguous, these mappings do not guarantee detection coverage. Organizations should supplement this approach with real-world simulations to further validate the results.\n\n## Human-in-the-loop: why validation remains essential\n\nFinal confirmation requires human expertise and empirical validation. The workflow identifies promising detection opportunities and potential gaps, but confirmation depends on testing with real telemetry, simulation, and review of detection logic in context.\n\nThis boundary is important because coverage in this approach is primarily based on text similarity and metadata alignment. A detection may exist but operate at a different scope, depend on telemetry that is not universally available, or require correlation across multiple data sources. The purpose of the workflow is to reduce time to initial analysis so experts can focus on high-value validation and implementation work.\n\n## Practical advice for using AI\n\nLarge language models are powerful for accelerating security analysis, but they can be inconsistent across runs, especially when prompts, context, or inputs vary. Output quality depends heavily on the prompt. Long prompts might not transmit intent effectively to the model.\n\n### 1) Plan for inconsistency and make critical steps deterministic\n\nFor high-impact steps, such as TTP extraction or mapping behaviors to a taxonomy, prioritize stability over creativity:\n\n- Use stronger models for the most critical steps and reserve smaller or cheaper models for tasks like summarization or formatting. Reasoning models are often more effective than non-reasoning models.\n- Use structured outputs, such as JSON schemas, and explicit formatting requirements to reduce variance. Most state-of-the-art models now support structured output.\n- Include a self-critique or answer review step in the model output. Use sequential LLM calls or a multi-turn agentic workflow to ensure a satisfactory result.\n\n### 2) Insert reviewer checkpoints where mistakes are costly\n\nEven high-performing models can miss details in long or heterogeneous documents. To reduce the risk of omissions or incorrect mappings, add human-in-the-loop reviewer gates:\n\n- Reviewer checkpoints are especially valuable for final TTP lists and any “coverage vs. gap” conclusions.\n- Treat automated outputs as a first-pass hypothesis. Require expert validation and, if possible, empirical checks before operational decisions.\n\n### 3) Optimize prompt context for better accuracy\n\nAvoid including too much information in prompts. While modern models have large token windows, excess content can dilute relevance, increase cost, and reduce accuracy.\n\nBest Practices:\n\n- Provide only the minimum necessary context. Focus on the information needed for the current step. Use RAG or staged, multi-step prompts instead of one large prompt.\n- Be specific. Use clear, direct instructions. Vague or open-ended requests often produce unclear results.\n\n### 4) Build an evaluation loop\n\nEstablish an evaluation process for production-quality results:\n\n- Develop gold datasets and ground-truth samples to track coverage and accuracy over time.\n- Use expert reviews to validate results instead of relying on offline metrics.\n- Use evaluations to identify regressions when prompts, models, or context packaging changes.\n\n## Where AI accelerates detection and experts validate\n\nDetection engineering is most effective when treated as a continuous loop:\n\n1. Gather new intelligence\n2. Extract relevant behaviors\n3. Check current coverage\n4. Set validation priorities\n5. Implementing improvements\n\nAI can accelerate the early stages of this loop by quickly structuring TTPs and enabling efficient matching against existing detections. This allows defenders to focus on higher-value work, such as validating coverage, investigating areas of uncertainty, and refining detection logic.\n\nIn evaluation, the AI-assisted approach to TTP extraction produced results comparable to those of security experts. By combining the speed of AI with expert review and validation, organizations can scale detection coverage analysis more effectively, even during periods of high reporting volume.\n\n*This research is provided by Microsoft Defender Security Research with contributions from Fatih Bulut*.\n\n### References\n\n1. MITRE ATT&CK Framework: [https://attack.mitre.org](https://attack.mitre.org/)\n2. Fatih Bulut, Anjali Mangal. “Towards Autonomous Detection Engineering”. Annual Computer Security Applications Conference (ACSAC) 2025. Link: [https://www.acsac.org/2025/files/web/acsac25-casestudy-bulut.pdf](https://www.acsac.org/2025/files/web/acsac25-casestudy-bulut.pdf)",
  "FeedUrl": "https://www.microsoft.com/en-us/security/blog/feed/",
  "PubDate": "2026-01-29T21:20:18+00:00",
  "Author": "Microsoft Defender Security Research Team",
  "Link": "https://www.microsoft.com/en-us/security/blog/2026/01/29/turning-threat-reports-detection-insights-ai/",
  "OutputDir": "_news",
  "Title": "Turning threat reports into detection insights with AI"
}
