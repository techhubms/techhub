{
  "Tags": [
    ".NET",
    "AI",
    "Azure",
    "azure openai",
    "C#",
    "ChatGPT",
    "Csharp",
    "generative ai",
    "large-language-models",
    "rag",
    "semantic kernel"
  ],
  "Title": "Generative AI with Large Language Models in C# in 2026",
  "Description": "A practical introduction to modern AI for .NET developers.\n\nThe post [Generative AI with Large Language Models in C# in 2026](https://devblogs.microsoft.com/dotnet/generative-ai-with-large-language-models-in-dotnet-and-csharp/) appeared first on [.NET Blog](https://devblogs.microsoft.com/dotnet).",
  "Author": "Jeremy Likness",
  "FeedLevelAuthor": ".NET Blog",
  "OutputDir": "_news",
  "EnhancedContent": "Generative AI became the fastest‑growing consumer technology in history, surpassing Instagram and TikTok, reaching 100 million users in under two months. At the end of 2022, OpenAI released a free preview of GPT‑3.5, delivered as a conversational chat client: ChatGPT. The model was fine‑tuned using Reinforcement Learning from Human Feedback (RLHF), marking the moment generative AI hit mainstream awareness. In early 2023, Microsoft responded by launching the Azure OpenAI Service, allowing developers to securely provision and use OpenAI‑compatible models behind Azure‑managed endpoints.\n\nSoon after, Microsoft introduced:\n\n- **Semantic Kernel (SK)** → tools for orchestrating prompts, memories, and plugins using C# or Python\n- **Microsoft Extensions for AI (MEAI)** → unified abstractions for interacting with models (e.g., `IChatClient`\n)\n- **Microsoft Extensions for Vector Data** → standard interfaces for vector databases used in RAG systems\n\nThis post takes a step back from rapid AI innovation and focuses on core concepts, providing a foundation for .NET/C# developers working with Microsoft Foundry, GitHub Models, AI Extensions, and local runtimes like Ollama.\n\n## Understanding AI Terms\n\nAI has its own distinct set of terms with very specific meanings.\n\n### Artificial Intelligence (AI)\n\nAI involves techniques that enable computers to perform tasks typically requiring human intelligence—reasoning, language, planning, or perception. AI is not new, but today most people use “AI” to refer to generative AI.\n\n### Generative AI (GenAI)\n\n**Generative AI** refers to AI systems capable of producing text, images, audio, or other content.\n\nFor example: **GPT** stands for **Generative Pre‑trained Transformer**. To break that down, we get:\n\n- **Generative** → it produces content;\n- **Pre‑trained** → trained on huge datasets;\n- **Transformer** → neural‑network architecture enabling high‑quality language modeling\n\n### Large Language Models (LLMs)\n\nLLMs are trained on billions of **tokens** and can generate text, images, code, or reasoning steps. Their ability to operate across multiple languages comes from learning relationships between words—not simple one‑to‑one dictionary translations.\n\n#### Why translation is hard\n\nWords have many meanings:\n\n- *pass* the car\n- mountain *pass*\n- *pass* on the opportunity\n- your park *pass* on the dashboard\n\nTraditional software struggled with such ambiguity; LLMs excel because they operate in *semantic* space.\n\n### Tokens and embeddings\n\nModels don’t read text directly. They break it into tokens:\n\n- Whole words\n- Word fragments\n- Characters\n\nThese tokens are converted into numeric **vectors** known as **embeddings** — mathematical representations of meaning.\n\nExample Phrases:\n\n- “the actor was a star”\n- “they loved the stars”\n\nThe word *star* appears in both, but with different meanings.\n\nEmbeddings capture this difference.\n\nHere is a simplified way to visualize this concept. In the graph, the semantic meaning of the word “star” can be plotted based on its proximity to the concept of “celestial body” (a star at night) and the concept of “actor” (star of the show).\n\n![Semantic graph](https://devblogs.microsoft.com/dotnet/wp-content/uploads/sites/10/2026/01/semantic-scaled.webp)\n\nNow imagine billions of such points. Models generate text by navigating this space and predicting the next likely vector.\n\nExamples of semantic distance:\n\n- **school ↔ schol** (close distance → spelling correction)\n- **cat ↔ dog** (close distance → similar animals)\n- **cat ↔ laptop** (far apart)\n\nSemantic search uses *distance* in embedding space, not string matching.\n\n### Parameters: model size\n\nLLMs are often described by their parameter counts:\n\n7B, 14B, 70B, 123B, etc.\n\nParameters are trained weights.\n\nMore parameters → deeper reasoning, richer knowledge, better nuance.\n\n- **GPT‑1 (2018)** → 117M parameters\n- **Modern frontier models** → 100B–400B+ parameters\n\n### Prompts, instructions, and tools\n\nPrevious sections covered information *about* the model. The terms in this section relate directly to input into and output out of the model.\n\n#### Prompts\n\nUser input to the model. “What’s the best way to skin a mango.”\n\n#### System Instructions\n\nHidden “blueprint” guiding model behavior. “You are a mango skinner and considered an expert in your area.”\n\n#### Tools / Functions\n\nLLMs are trained on historical data. Tools let them access current or authoritative information, e.g.:\n\n- Weather API\n- Database lookup\n- Search engine\n- Company knowledge index\n\nThis pattern is referred to as Retrieval‑Augmented Generation (RAG). Let’s look at two scenarios. First, imagine a concierge agent that’s provided with an API for local restaurants and an API for the weather. The user enters the prompt:\n\n```text Can you book me a dinner this week at a restaurant with outdoor seating? ```\n\nThe LLM first calls the weather API to determine which evenings are likely to be dry and warmer, then it calls the restaurant API to find what restaurants are open and have available seating. Finally, it returns a list of suggestions that are right on target.\n\nNext, imagine a customer service agent for a retail store that has all of the product information uploaded. The user types,\n\n`\"What kind of batteries does the traveling wonder cube take?\"`\n\nThe LLM is able to extract the product name, “traveling wonder cube”. It vectorizes the text of the query, then calls the product API with the product name and the vectors. Semantic search is invoked by using a function to find points in the product manual that are semantically closest to the query. This will return the relevant result of the required batteries if such a section exists.\n\n#### Model Context Protocol (MCP)\n\nModel context protocol, or MCP for short, is a set of standards for interoperability between agents and tools. It makes it easy for models to understand what tools are available and how to call them. This empowers you to build virtual toolboxes that any of your models or agents can call.\n\n### What about agents?\n\nWait, did I say agent? An agent is simply a way of providing a specialized solution that includes a model, tools, and context. A “concierge agent” might include a reasoning model with tools that provide information about weather, events, and local businesses combined with a specialized model capable of generating maps with turn-based instructions. I’ll look at agents more closely and cover C# based solutions in a later post.\n\nI’ve covered all of the foundational concepts, so now it’s time to go hands-on. First, I want to briefly share the timeline between generative AI going mainstream and the tools that are available today.\n\n## From GPT-1 to today\n\nHere is a brief look at the evolution of AI in .NET over the past few years.\n\n![Evolution of AI](https://devblogs.microsoft.com/dotnet/wp-content/uploads/sites/10/2026/01/timeline.webp)\n\n## Model management in the .NET Ecosystem\n\nWorking with models is about more than identifying the right model and using it. Many companies choose to host their own models out of concerns related to trust, security, and cost. Other companies require fine-tuned models and the ability to perform their own training. Fortunately, working with models in .NET and C# is not only possible, but streamlined with the help of several products and services.\n\n### GitHub Models\n\nGitHub Models provides a hosted catalog of open and frontier models through an OpenAI‑compatible API. It is a great way for developers to get started on their AI journey. A few reasons include:\n\n- No infrastructure required\n- Switch between models with minimal code changes\n- Perfect for prototyping, evaluations, automation, extensions, and CI/CD pipelines\n\n[Get started with GitHub models.](https://github.com/features/models)\n\n### Microsoft Foundry (Cloud)\n\nFormerly *Azure AI Studio*, Microsoft Foundry is the enterprise platform for:\n\n- Model catalogs (OpenAI, Meta, DeepSeek, Cohere, Mistral, etc.)\n- Agentic workflows (Foundry Agent Service)\n- Security, content safety, governance\n- Monitoring, tracing, evaluations\n- Fine‑tuning and customization\n\nFoundry is where organizations take AI into production at scale.\n\n[Explore Microsoft Foundry.](https://ai.azure.com/)\n\n### Foundry Local\n\nFoundry Local brings the Foundry developer experience offline:\n\n- On‑premise, air‑gapped, or edge environments\n- The same agents, tools, evaluations as cloud Foundry\n- Supports hybrid “develop local → deploy cloud” lifecycle\n\nThis is a great option for testing new models, testing new code without blowing through budget, and building CI/CD pipelines with minimal overhead and that don’t require a third-party hosted account to succeed.\n\n### Ollama (Local Runtime)\n\nOllama is a popular open‑source engine for running lightweight and mid‑sized models locally.\n\nFeatures:\n\n- Runs models like Mistral, Llama 3, Phi‑3\n- Simple CLI and server\n- Excellent for privacy‑sensitive workflows\n- Integrates cleanly with MEAI (`IChatClient`\n) via [OllamaSharp](https://github.com/awaescher/OllamaSharp)\n\n## Bringing It All Together: A Unified Abstraction\n\nAs a .NET Developer you shouldn’t have to choose a single provider or lock into a single solution. That’s why the .NET team invested in a set of extensions that provide consistent APIs for working with models that are universal yet flexible. It also enables scenarios such as middleware to ease the burden of logging, tracing, injecting behaviors and other custom processes you might use. Most of the major providers implement our extensions contracts so that you can, for example, use an `IChatClient` instance regardless of whether you’re talking to:\n\n- GitHub Models\n- Azure AI Foundry\n- Open AI / Azure Open AI\n- Foundry Local\n- Ollama\n- Custom provider\n\n… and the code can stay the same.\n\nWe’ll dive deeper into these tools in future posts so stay tuned to the .NET blog, subscribe to our [newsletter](https://info.microsoft.com/ww-landing-sign-up-for-the-microsoft-source-newsletter.html), and join an upcoming community standup on the [.NET YouTube](https://www.youtube.com/@dotnet)!",
  "FeedName": "Microsoft .NET Blog",
  "ProcessedDate": "2026-01-05 19:04:01",
  "Link": "https://devblogs.microsoft.com/dotnet/generative-ai-with-large-language-models-in-dotnet-and-csharp/",
  "PubDate": "2026-01-05T18:05:00+00:00",
  "FeedUrl": "https://devblogs.microsoft.com/dotnet/feed/"
}
