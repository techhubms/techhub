{
  "Title": "Zero-copy access to OneLake data in Azure Databricks (Preview)",
  "Author": "Microsoft Fabric Blog",
  "PubDate": "2026-02-23T12:00:00+00:00",
  "FeedLevelAuthor": "Microsoft Fabric Blog",
  "ProcessedDate": "2026-02-23 19:23:19",
  "EnhancedContent": "Most data estates are not single platform, and that is not a problem. The challenge is what usually comes next: extra copies, extra pipelines, extra refresh schedules, and endless debates about which version is the truth.\n\nToday, we are introducing OneLake catalog federation (Beta) in Azure Databricks Lakehouse Federation, which simplifies multi-engine analytics by enabling Unity Catalog in Azure Databricks to query data stored in OneLake. This allows you to analyze Fabric tables without copying the data.\n\n![A Microsoft Fabric and Azure Databricks integration diagram showing metadata syncing from Fabric Items to Unity Catalog and zero-copy query access from OneLake to Databricks compute. The visual highlights how Fabric data stored in OneLake can be queried directly by Databricks without moving or duplicating data](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2026/02/a-microsoft-fabric-and-azure-databricks-integratio-1024x682.png)\n\n*Figure: Diagram Azure Databricks reading OneLake data*\n\n## Why this matters\n\nFabric is built around a simple idea: your data should be usable the moment it lands, and it should stay governed and consistent wherever it is consumed. OneLake is the foundation that makes that real by giving your organization a single, shared data lake that is easy to manage, secure, and scale.\n\nOneLake catalog federation extends that promise even further. It allows more teams to use the same curated data products in OneLake without creating additional copies or building parallel pipelines just to satisfy different tools. That means fewer moving parts, fewer refresh problems, and far less time spent reconciling datasets. You keep OneLake as the source of truth and the Fabric experience intact, while expanding how broadly those OneLake data products can be used across the organization.\n\n## What you can do\n\n- Discover Fabric tables from Unity CatalogOnce connected, your Fabric schemas and tables show up in Unity Catalog through a foreign catalog that stays in sync.\n- Query OneLake data from Databricks compute\n\nYou run Databricks SQL and notebooks as usual, using catalog.schema.table naming.\n- Keep OneLake as the source of truth\n\nNo extra storage copies. No extra refresh jobs.\n\n## Conceptual overview\n\n1. You create a OneLake connection in Unity Catalog.\n2. You create a foreign catalog that points to a specific Fabric item.\n3. Databricks syncs the metadata, so schemas and tables appear in Unity Catalog.\n4. Queries run on Databricks compute while reading the data in OneLake.\n\nFollow the full walkthrough in the documentation: [Enable OneLake catalog federation – Azure Databricks | Microsoft Learn](https://learn.microsoft.com/azure/databricks/query-federation/onelake)\n\n## Beta limitations\n\nThis capability is in Beta. Explore the specific requirements and supported configurations detailed in the Beta limitations [documentation](https://learn.microsoft.com/azure/databricks/admin/workspace-settings/manage-previews).\n\n## Try it out\n\nOneLake is about removing friction between data and value. OneLake catalog federation is another step in that direction: fewer copies, simpler architecture, and broader reuse of the data products you already build in Fabric.\n\nA shared OneLake foundation unlocks new possibilities for what teams can build next.",
  "Description": "Most data estates are not single platform, and that is not a problem. The challenge is what usually comes next: extra copies, extra pipelines, extra refresh schedules, and endless debates about which version is the truth. Today, we are introducing OneLake catalog federation (Beta) in Azure Databricks Lakehouse Federation, which simplifies multi-engine analytics by enabling …\n\n[Continue reading “Zero-copy access to OneLake data in Azure Databricks (Preview)”](https://blog.fabric.microsoft.com/en-us/blog/zero-copy-access-to-onelake-data-in-azure-databricks-preview/)",
  "OutputDir": "_news",
  "Link": "https://blog.fabric.microsoft.com/en-US/blog/zero-copy-access-to-onelake-data-in-azure-databricks-preview/",
  "FeedUrl": "https://blog.fabric.microsoft.com/en-us/blog/feed/",
  "FeedName": "Microsoft Fabric Blog",
  "Tags": []
}
