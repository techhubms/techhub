{
  "ProcessedDate": "2026-01-15 22:01:48",
  "Tags": [
    "agentic memory",
    "agentic workflows",
    "AI & ML",
    "GitHub Copilot",
    "GitHub Copilot CLI",
    "GitHub Copilot code review",
    "GitHub Copilot coding agent"
  ],
  "Author": "Tiferet Gazit",
  "FeedLevelAuthor": "The GitHub Blog",
  "FeedName": "The GitHub Blog",
  "Link": "https://github.blog/ai-and-ml/github-copilot/building-an-agentic-memory-system-for-github-copilot/",
  "Title": "Building an agentic memory system for GitHub Copilot",
  "OutputDir": "_news",
  "Description": "Copilot‚Äôs cross-agent memory system lets agents learn and improve across your development workflow, starting with coding agent, CLI, and code review.\n\nThe post [Building an agentic memory system for GitHub Copilot](https://github.blog/ai-and-ml/github-copilot/building-an-agentic-memory-system-for-github-copilot/) appeared first on [The GitHub Blog](https://github.blog).",
  "PubDate": "2026-01-15T21:31:10+00:00",
  "EnhancedContent": "Our vision is to evolve [GitHub Copilot](https://github.com/features/copilot?utm_source=blog-copilot-memory&amp;utm_medium=blog&amp;utm_campaign=dec25postuniverse) into an ecosystem of agents that collaborate across the entire development lifecycle from coding and code review to security, debugging, deployment, and maintenance. To unlock the full potential of multi-agent workflows, we need to move beyond isolated interactions‚Äîthat start from scratch each session‚Äîand toward a cumulative knowledge base that grows with every use.\n\n**Cross-agent memory allows agents to remember and learn from experiences across your development workflow, without relying on explicit user instructions.**\n\nEach interaction teaches Copilot more about your codebase and conventions, making it increasingly effective over time. For example, if Copilot coding agent learns how your repository handles database connections as it‚Äôs fixing a security vulnerability, Copilot code review can then use that knowledge to spot inconsistent patterns in future pull requests. Or if Copilot code review notices that certain files must stay synchronized, in the future Copilot coding agent will automatically update them together when generating new code.\n\n# The challenge: What to remember and when to forget\n\nOur agents continuously improve at extracting the context needed for specific tasks. The core challenge for memory systems isn‚Äôt about information retrieval, but ensuring that any stored knowledge remains valid as code evolves across branches and time.\n\nIn practice, this means a memory system must handle changes to code, abandoned branches, and conflicting observations‚Äîall while ensuring that agents only act on information that‚Äôs relevant to the current task and code state. For example, a logging convention observed in one branch may later be modified, superseded, or never merged at all.\n\nOne option would be to implement an offline curation service to deduplicate, resolve conflicts, track branch status, and expire stale information. At GitHub‚Äôs scale, however, such an approach would introduce significant engineering complexity and LLM costs, while still requiring mechanisms to reconcile changes at read time. We started by exploring a simpler, more efficient approach.\n\n# Our solution: just-in-time verification\n\nInformation retrieval is an asymmetrical problem: It‚Äôs hard to solve, but easy to verify. By using real-time verification, we gain the power of pre-stored memories while avoiding the risk of outdated or misleading information.\n\nInstead of offline memory curation, we store memories with **citations**: references to specific code locations that support each fact. When an agent encounters a stored memory, it verifies the citations in real-time, validating that the information is accurate and relevant to the current branch before using it. This verification boils down to a small number of simple read operations, adding no significant latency to agent sessions in our testing.\n\n## Memory creation as a tool call\n\nWe implemented memory creation as a tool that agents can invoke when they discover something that‚Äôs likely to have actionable implications for future tasks.\n\n![A flow chart showing how Copilot agents store learnings worth remembering as they carry out their tasks.](https://github.blog/wp-content/uploads/2025/12/image1.jpg?resize=1024%2C538)How Copilot agents store learnings worth remembering as they carry out their tasks.\n\nConsider this example: While reviewing a pull request from an experienced developer, Copilot code review discovers that API version tracking must stay synchronized across different parts of a codebase. It might encounter these three updates in the same pull request:\n\n- In src/client/sdk/constants.ts:\n\n``` export const API_VERSION = \"v2.1.4\"; ```\n\n- In server/routes/api.go:\n\n``` const APIVersion = \"v2.1.4\" ```\n\n- In docs/api-reference.md:\n\n``` Version: v2.1.4 ```\n\nIn response, Copilot code review can invoke the memory storage tool to create a memory like this:\n\n``` { subject: \"API version synchronization\", fact: \"API version must match between client SDK, server routes, and documentation.\", citations: [\"src/client/sdk/constants.ts:12\", \"server/routes/api.go:8\", \"docs/api-reference.md:37\"], reason: \"If the API version is not kept properly synchronized, the integration can fail or exhibit subtle bugs. Remembering these locations will help ensure they are kept syncronized in future updates.\" } ```\n\n**The result:** The next time an agent updates the API version in any of these locations, it will see this memory and realize that it must update the other locations too, preventing a versioning mismatch that could break integrations. Similarly, if an inexperienced developer opens a pull request that updates only one of these locations, Copilot code review will flag the omission and suggest the missing updates, *automatically transferring knowledge from a more experienced team member to a newer one.* üí•\n\n## Memory usage\n\n### Retrieval\n\nWhen an agent starts a new session, we retrieve the most recent memories for the target repository and include them in the prompt. Future implementations will enable additional retrieval techniques, such as a search tool and weighted prioritization.\n\n![A flow chart showing how Copilot enriches agent prompts with memories from previous tasks.](https://github.blog/wp-content/uploads/2025/12/image2.jpg?resize=1024%2C662)How Copilot enriches agent prompts with memories from previous tasks.\n\n### Verification\n\nBefore applying any memory, the agent is prompted to verify its accuracy and relevance by checking the cited code locations. If the code contradicts the memory, or if the citations are invalid (e.g. point to nonexistent locations), the agent is encouraged to store a corrected version of the memory reflecting the new evidence. If the citations check out and the memory is deemed useful, the agent is encouraged to store it again in order to refresh its timestamp.\n\n### Privacy and security\n\nIt‚Äôs important to note that memories are tightly scoped. Memories for a given repository can only be created in response to actions taken within that repository by contributors with write permissions, and can only be used in tasks on that same repository initiated by users with read permissions. Much like the source code itself, memories about a repository stay within that repository, ensuring privacy and security.\n\n## Cross-agent memory sharing\n\nThe full power of our memory system emerges as different Copilot agents learn from one another.\n\n1. **Copilot code review** discovers a logging convention while reviewing a pull request: ‚ÄúLog file names should follow pattern ‚Äòapp-YYYYMMDD.log‚Äô. Use Winston for logging with format: timestamp, error code, user ID.‚Äù\n2. **Copilot coding agent** is later assigned a task to implement a new microservice. It sees and verifies the memory and automatically applies the same logging format.\n3. **Copilot CLI** helps a developer debug an issue, efficiently retrieving the correct log file and finding the relevant timestamps based on the logging format learned by the code review agent.\n\nEach agent contributes to and benefits from the shared knowledge base, allowing agents to reuse validated repository knowledge across tasks. As additional agents adopt memory‚Äîwhether for development workflows, debugging, or security analysis‚Äîthey‚Äôll contribute to and benefit from the same evolving understanding of your codebase.\n\n# Evaluation\n\n## Stress-testing agent resilience\n\nOur biggest concern was the impact of outdated, incorrect, or even maliciously injected memories. To test the system‚Äôs resilience, we deliberately seeded repositories with adversarial memories‚Äìfacts that contradicted the codebase‚Äìwith citations pointing to irrelevant or nonexistent code locations.\n\nAcross all test cases, agents consistently verified citations, discovered contradictions, and updated incorrect memories. The memory pool self-healed as agents stored corrected versions based on their observations. The citation verification mechanism robustly prevented the risk of misleading memories.\n\n## Simulating a realistic memory pool\n\nFor each repository in our evaluation set, we ran agents on diverse historical tasks (predating our target evaluation tasks) and let them populate the memory database organically, using the ‚Äústore\\_memory‚Äù tool we provided. To simulate worst-case conditions, we overrepresented memories from branches that were abandoned or closed without merging, ensuring realistically noisy memories.\n\n**When we ran Copilot code review on the pull requests in our evaluation set, memory usage led to 3% increase in precision and 4% increase in recall.**\n\n## Measuring impact on developers\n\nThe ultimate test of our memory system was its impact on real developers in their everyday workflows. We ran A/B tests on the first two Copilot agents to deploy memory, Copilot code review and Copilot coding agent, measuring the impact on key user metrics.\n\n- **Copilot coding agent**: 7% increase in pull request merge rates (90% with memories vs. 83% without). This means developers are saving more time and getting the desired results more often when they assign tasks to Copilot.\n- **Copilot code review**: 2% increase in positive feedback on comments (77% with memories vs 75% without). This means automated code review is yielding improved quality assurance.\n- Both increases are **highly statistically significant**, with p-value &lt;0.00001\n\nThese results demonstrate that cross-agent memory delivers measurable value to developers in their daily workflows.\n\n# What‚Äôs next\n\nWe‚Äôve deployed repository-scoped memory storage and usage in Copilot CLI, Copilot coding agent, and Copilot code review on an opt-in basis. We‚Äôre listening to user feedback and tracking performance metrics closely as we iterate and prepare for a wider rollout across more Copilot workflows. We‚Äôre also exploring a range of approaches to tuning memory generation, curation, prioritization, and usage.\n\nCross-agent memory reduces the need to re-establish context at the start of each task by allowing validated information to persist across agentic workflows. We‚Äôre excited about the possibilities memory will unlock, and we‚Äôre just getting started. Happy coding!\n\n**[Read our Docs](https://docs.github.com/copilot/how-tos/use-copilot-agents/copilot-memory?utm_source=blog-copilot-memory&amp;utm_medium=blog&amp;utm_campaign=dec25postuniverse)** to learn how to enable memory in Copilot &gt;",
  "FeedUrl": "https://github.blog/feed/"
}
