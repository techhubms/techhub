{
  "FeedLevelAuthor": "The GitHub Blog",
  "Title": "AI-supported vulnerability triage with the GitHub Security Lab Taskflow Agent",
  "OutputDir": "_news",
  "Description": "Learn how we are using the newly released GitHub Security Lab Taskflow Agent to triage categories of vulnerabilities in GitHub Actions and JavaScript projects.\n\nThe post [AI-supported vulnerability triage with the GitHub Security Lab Taskflow Agent](https://github.blog/security/ai-supported-vulnerability-triage-with-the-github-security-lab-taskflow-agent/) appeared first on [The GitHub Blog](https://github.blog).",
  "Link": "https://github.blog/security/ai-supported-vulnerability-triage-with-the-github-security-lab-taskflow-agent/",
  "FeedName": "The GitHub Blog",
  "Author": "Man Yue Mo",
  "Tags": [
    "agentic AI",
    "AI & ML",
    "GitHub Security Lab",
    "MCP",
    "Open Source",
    "Security"
  ],
  "ProcessedDate": "2026-01-20 20:21:41",
  "FeedUrl": "https://github.blog/feed/",
  "PubDate": "2026-01-20T19:52:50+00:00",
  "EnhancedContent": "Triaging security alerts is often very repetitive because false positives are caused by patterns that are obvious to a human auditor but difficult to encode as a formal code pattern. But large language models (LLMs) excel at matching the fuzzy patterns that traditional tools struggle with, so we at the GitHub Security Lab have been experimenting with using them to triage alerts. We are using our recently announced [GitHub Security Lab Taskflow Agent](https://github.com/GitHubSecurityLab/seclab-taskflow-agent) AI framework to do this and are finding it to be very effective.\n\n*üí° Learn more about it and see how to activate the agent in our [previous blog post](https://github.blog/security/community-powered-security-with-ai-an-open-source-framework-for-security-research/).*\n\nIn this blog post, we‚Äôll introduce these triage taskflows, showcase results, and¬† share tips on how you can develop your own‚Äîfor triage or other security research workflows.\n\nBy using the [taskflows](https://github.com/GitHubSecurityLab/seclab-taskflows/tree/main/src/seclab_taskflows/taskflows/alert_triage_examples) described in this post, we quickly triaged a large number of code scanning alerts and discovered many (~30) real-world vulnerabilities since August, many of which have already been [fixed and published](http://securitylab.github.com/ai-agents). When triaging the alerts, the LLMs were only given tools to perform basic file fetching and searching. We have not used any static or dynamic code analysis tools other than to generate alerts from CodeQL.\n\nWhile this blog post showcases how we used LLM taskflows to triage CodeQL queries, the general process creates automation using LLMs and taskflows. Your process will be a good candidate for this if:\n\n1. You have a task that involves many repetitive steps, and each one has a clear and well-defined goal.\n2. Some of those steps involve looking for logic or semantics in code that are not easy for conventional programming to identify, but are fairly easy for a human auditor to identify. Trying to identify them often results in many monkey patching heuristics, badly written regexp, etc. (These are potential sweet spots for LLM automation!)\n\nIf your project meets those criteria, then you can create taskflows to automate these sweet spots using LLMs, and use MCP servers to perform tasks that are well suited for conventional programming.\n\nBoth the [seclab-taskflow-agent](https://github.com/GitHubSecurityLab/seclab-taskflow-agent) and [seclab-taskflows](https://github.com/GitHubSecurityLab/seclab-taskflows) repos are open source, allowing anyone to develop LLM taskflows to perform similar tasks. At the end of this blog post, we‚Äôll also give some development tips that we‚Äôve found useful.\n\n# Introduction to taskflows\n\nTaskflows are YAML files that describe a series of tasks that we want to do with an LLM. In this way, we can write prompts to complete different tasks and have tasks that depend on each other. The seclab-taskflow-agent framework takes care of running the tasks one after another and passing the results from one task to the next.\n\nFor example, when auditing CodeQL alert results, we first want to fetch the code scanning results. Then, for each result, we may have a list of tasks that we need to check. For example, we may want to check if an alert can be reached by an untrusted attacker and whether there are authentication checks in place. These become a list of tasks we specify in a taskflow file.\n\n![Simplified depiction of taskflow with three tasks in order: fetch code scanning results, audit each result, create issues containing verdict.](https://github.blog/wp-content/uploads/2026/01/01_sample-taskflow.png?resize=1024%2C209)\n\nWe use tasks instead of one big prompt because LLMs have limited context windows, and complex, multi-step tasks often are not completed properly. Some steps are frequently left out, so having a taskflow to organize the task avoids these problems. Even with LLMs that have larger context windows, we find that taskflows are useful to provide a way for us to control and debug the task, as well as to accomplish bigger and more complex tasks.\n\nThe seclab-taskflow-agent can also perform a batch ‚Äúfor loop‚Äù-style task asynchronously. When we audit alerts, we often want to apply the same prompts and tasks to every alert, but with different alert details. The seclab-taskflow-agent allows us to create templated prompts to iterate through the alerts and replace the details specific to each alert when running the task.\n\n# Triaging taskflows from a code scanning alert to a report\n\nThe GitHub Security Lab periodically runs a set of CodeQL queries against a selected set of open source repositories. The process of triaging these alerts is usually fairly repetitive, and for some alerts, the causes of false positives are usually fairly similar and can be spotted easily.\n\nFor example, when triaging alerts for GitHub Actions, false positives often result from some checks that have been put in place to make sure that only repo maintainers can trigger a vulnerable workflow, or that the vulnerable workflow is disabled in the configuration. These access control checks come in many different forms without an easily identifiable code pattern to match and are thus very difficult for a static analyzer like CodeQL to detect. However, a human auditor with general knowledge of code semantics can often identify them easily, so we expect an LLM to be able to identify these access control checks and remove false positives.\n\nOver the course of a couple of months, we‚Äôve tested our taskflows with a few CodeQL rules using mostly Claude Sonnet 3.5. We have identified a number of real, exploitable vulnerabilities. The taskflows do not perform an ‚Äúend-to-end‚Äù analysis, but rather produce a bug report with all the details and conclusions so that we can quickly verify the results. We did not instruct the LLM to validate the results by creating an exploit nor provide any runtime environment for it to test its conclusion. The results, however, remain fairly accurate even without an automated validation step and we were able to remove false positives in the CodeQL queries quickly.\n\nThe rules are chosen based on our own experience of triaging these types of alerts and whether the list of tasks can be formulated into clearly defined instructions for LLMs to consume.\n\n# General taskflow design\n\nTaskflows generally consist of tasks that are divided into a few different stages. In the first stage, the tasks collect various bits of information relevant to the alert. This information is then passed to an auditing stage, where the LLM looks for common causes of false positives from our own experience of triaging alerts. After the auditing stage, a bug report is generated using the information gathered. In the actual taskflows, the information gathering and audit stage are sometimes combined into a single task, or they may be separate tasks, depending on how complex the task is.\n\nTo ensure that the generated report has sufficient information for a human auditor to make a decision, an extra step checks that the report has the correct formatting and contains the correct information. After that, a GitHub Issue is created, ready to be reviewed.\n\nCreating a GitHub Issue not only makes it easy for us to review the results, but also provides a way to extend the analysis. After reviewing and checking the issues, we often find that there are causes for false positives that we missed during the auditing process. Also, if the agent determines that the alert is valid, but the human reviewer disagrees and finds that it‚Äôs a false positive for a reason that was unknown to the agent so far, the human reviewer can document this as an [alert dismissal](https://docs.github.com/en/code-security/code-scanning/managing-code-scanning-alerts/resolving-code-scanning-alerts#dismissing-alerts) reason or issue comment. When the agent analyzes similar cases in the future, it will be aware of all the past analysis stored in those issues and alert dismissal reasons, incorporate this new intelligence in its knowledge base, and be more effective at detecting false positives.\n\n## Information collection\n\nDuring this stage, we instruct the LLM (examples are provided in the Triage examples section below) to collect relevant information about the alert, which takes into account the threat model and human knowledge of the alert in general. For example, in the case of GitHub Actions alerts, it will look at what permissions are set in the GitHub workflow file, what are the events that trigger the GitHub workflow, whether the workflow is disabled, etc. These generally involve independent tasks that follow simple, well-defined instructions to ensure the information collected is consistent. For example, checking whether a GitHub workflow is disabled involves making a GitHub API call via an MCP server.\n\nTo ensure that the information collected is accurate and to reduce hallucination, we instruct the LLM to include precise references to the source code that includes both file and line number to back up the information it collected:\n\n``` You should include the line number where the untrusted code is invoked, as well as the untrusted code or package manager that is invoked in the notes. ```\n\nEach task then stores the information it collected in audit notes, which are kind of a running commentary of an alert. Once the task is completed, the notes are serialized to a database which the next task can then append their notes to when it is done.\n\n![Two tasks in order displaying which notes are added to the general notes in each step. With the step trigger analysis the notes added are triggers, permissions and secrets among others. The second task &ldquo;audit injection point&rdquo; potentially adds notes such as sanitizers and to the notes.](https://github.blog/wp-content/uploads/2026/01/02_note-taking3.excalidraw.png?resize=1024%2C347)\n\nIn general, each of the information gathering tasks is independent of each other and does not need to read each other‚Äôs notes. This helps each task to focus on its own scope without being distracted by previously collected information.\n\nThe end result is a ‚Äúbag of information‚Äù in the form of notes associated with an alert that is then passed to the auditing tasks.\n\n## Audit issue\n\nAt this stage, the LLM goes through the information gathered and performs a list of specific checks to reject alert results that turned out to be false positives. For example, when triaging a GitHub Actions alert, we may have collected information about the events that trigger the vulnerable workflow. In the audit stage, we‚Äôll check if these events can be triggered by an attacker or if they run in a privileged context. After this stage, a lot of the false positives that are obvious to a human auditor will be removed.\n\n## Decision-making and report generation\n\nFor alerts that have made it through the auditing stage, the next step is to create a bug report using the information gathered, as well as the reasoning for the decision at the audit stage. Again, in our prompt, we are being very precise about the format of the report and what information we need. In particular, we want it to be concise but also include information that makes it easy for us to verify the results, with precise code references and code blocks.\n\nThe report generated uses the information gathered from the notes in previous stages and only looks at the source code to fetch code snippets that are needed in the report. No further analysis is done at this stage. Again, the very strict and precise nature of the tasks reduces the amount of hallucination.\n\n## Report validation and issue creation\n\nAfter the report is written, we instruct the LLM to check the report to ensure that all the relevant information is contained in the report, as well as the consistency of the information:\n\n``` Check that the report contains all the necessary information:\n- This criteria only applies if the workflow containing the alert is a reusable action AND has no high privileged trigger.\nYou should check it with the relevant tools in the gh_actions toolbox. If that's not the case, ignore this criteria. In this case, check that the report contains a section that lists the vulnerable action users. If there isn't any vulnerable action users and there is no high privileged trigger, then mark the alert as invalid and using the alert_id and repo, then remove the memcache entry with the key {{ RESULT_key }}. ```\n\nMissing or inconsistent information often indicates hallucinations or other causes of false positives (for example, not being able to track down an attacker controlled input). In either case, we dismiss the report.\n\nIf the report contains all the information and is consistent, then we open a GitHub Issue to track the alert.\n\n## Issue review and repo-specific knowledge\n\nThe GitHub Issue created in the previous step contains all the information needed to verify the issue, with code snippets and references to lines and files. This provides a kind of ‚Äúcheckpoint‚Äù and a summary of the information that we have, so that we can easily extend the analysis.\n\nIn fact, after creating the issue, we often find that there are repo-specific permission checks or sanitizers that render the issue a false positive. We are able to incorporate these problems by creating taskflows that review these issues with repo-specific knowledge added in the prompts. One approach that we‚Äôve experimented with is to [collect dismissal reasons](https://github.com/GitHubSecurityLab/seclab-taskflows/blob/eadd066316e3d8a3933158de0bbe302fc8e4a9b5/src/seclab_taskflows/taskflows/alert_triage_examples/triage_taskflows/actions_common/collect_dismiss_reasons.yaml#L16) for alerts in a repo and instruct the LLM to take into account these dismissal reasons and review the GitHub issue. This allows us to remove false positives due to reasons specific to a repo.\n\n![Image showing LLM output that dismisses an alert.](https://github.blog/wp-content/uploads/2026/01/3-screenshot.png?resize=826%2C110)\n\nIn this case, the LLM is able to identify the alert as false positive after taking into account a custom `check-run` permission check that was recorded in the alert dismissal reasons.\n\n# Triage examples and results\n\nIn this section we‚Äôll give some examples of what these taskflows look like in practice. In particular, we‚Äôll show taskflows for triaging some GitHub actions and JavaScript alerts.\n\n## GitHub Actions alerts\n\nThe specific actions alerts that we triaged are [checkout of untrusted code in a privileged context](https://codeql.github.com/codeql-query-help/actions/actions-untrusted-checkout-critical/) and [code injection](https://codeql.github.com/codeql-query-help/actions/actions-code-injection-critical/).\n\nThe triaging of these queries shares a lot of similarities. For example, both involve checking the workflow triggering events, permissions of the vulnerable workflow, and tracking workflow callers. In fact, the main differences involve local analysis of specific details of the vulnerabilities. For code injection, this involves whether the injected code has been sanitized, how the expression is evaluated and whether the input is truly arbitrary (for example, pull request ID is unlikely to cause code injection issue). For untrusted checkout, this involves whether there is a valid code execution point after the checkout.\n\nSince many elements in these taskflows are the same, we‚Äôll use the code injection triage taskflow as an example. Note that because these taskflows have a lot in common, we made heavy use of reusable features in the `seclab-taskflow-agent` , such as [prompts](https://github.com/GitHubSecurityLab/seclab-taskflow-agent/blob/v0.0.9/doc/GRAMMAR.md#reusable-tasks) and [reusable tasks](https://github.com/GitHubSecurityLab/seclab-taskflow-agent/blob/v0.0.9/doc/GRAMMAR.md#reusable-tasks).\n\nWhen manually triaging GitHub Actions alerts for these rules, we commonly run into false positives because of:\n\n1. Vulnerable workflow doesn‚Äôt run in a privileged context. This is determined by the events that trigger the vulnerable workflow. For example, a workflow triggered by the `pull_request_target`\nruns in a privileged context, while a workflow triggered by the `pull_request` event does not. This can usually be determined by simply looking at the workflow file.\n2. Vulnerable workflow disabled explicitly in the repo. This can be checked easily by checking the workflow settings in the repo.\n3. Vulnerable workflow explicitly restricts permissions and does not use any secrets. In which case, there is little privilege to gain.\n4. Vulnerability specific issues, such as invalid user input or sanitizer in the case of code injection and the absence of a valid code execution point in the case of untrusted checkout.\n5. Vulnerable workflow is a reusable workflow but not reachable from any workflow that runs in privileged context.\n\nVery often, triaging these alerts involves many simple but tedious checks like the ones listed above, and an alert can be determined to be a false positive very quickly by one of the above criteria. We therefore model our triage taskflows based on these criteria.\n\nSo, our action-triage taskflows consist of the following tasks during information gathering and the auditing stage:\n\n- [Workflow trigger analysis](https://github.com/GitHubSecurityLab/seclab-taskflows/blob/eadd066316e3d8a3933158de0bbe302fc8e4a9b5/src/seclab_taskflows/taskflows/alert_triage_examples/triage_taskflows/triage_actions_code_injection.yaml#L40): This stage performs both information gathering and auditing. It first collects events that trigger the vulnerable workflow, as well as permission and secrets that are used in the vulnerable workflow. It also checks whether the vulnerable workflow is disabled in the repo. All information is local to the vulnerable workflow itself. This information is [stored in running notes](https://github.com/GitHubSecurityLab/seclab-taskflows/blob/eadd066316e3d8a3933158de0bbe302fc8e4a9b5/src/seclab_taskflows/taskflows/alert_triage_examples/triage_taskflows/actions_common/trigger_analysis.yaml#L49) which are then serialized to a database entry. As the task is simple and involves only looking at the vulnerable workflow, [preliminary auditing](https://github.com/GitHubSecurityLab/seclab-taskflows/blob/eadd066316e3d8a3933158de0bbe302fc8e4a9b5/src/seclab_taskflows/taskflows/alert_triage_examples/triage_taskflows/actions_common/trigger_analysis.yaml#L35-L39) based on the workflow trigger is also performed to remove some obvious false positives.\n- [Code injection point analysis](https://github.com/GitHubSecurityLab/seclab-taskflows/blob/eadd066316e3d8a3933158de0bbe302fc8e4a9b5/src/seclab_taskflows/taskflows/alert_triage_examples/triage_taskflows/triage_actions_code_injection.yaml#L58): This is another task that only analyzes the vulnerable workflow and combines information gathering and audit in a single task. This task collects information about the location of the code injection point, and the user input that is injected. It also performs local auditing to check whether a [user input is a valid injection risk](https://github.com/GitHubSecurityLab/seclab-taskflows/blob/eadd066316e3d8a3933158de0bbe302fc8e4a9b5/src/seclab_taskflows/taskflows/alert_triage_examples/triage_taskflows/triage_actions_code_injection.yaml#L105) and whether it has a [sanitizer](https://github.com/GitHubSecurityLab/seclab-taskflows/blob/eadd066316e3d8a3933158de0bbe302fc8e4a9b5/src/seclab_taskflows/taskflows/alert_triage_examples/triage_taskflows/triage_actions_code_injection.yaml#L122).\n- [Workflow user analysis](https://github.com/GitHubSecurityLab/seclab-taskflows/blob/eadd066316e3d8a3933158de0bbe302fc8e4a9b5/src/seclab_taskflows/taskflows/alert_triage_examples/triage_taskflows/triage_actions_code_injection.yaml#L226-L245): This performs a simple caller analysis that looks for the caller of the vulnerable workflow. As it can potentially retrieve and analyze a large number of files, this step is divided into two main tasks that perform information gathering and auditing separately. In the [information gathering task](https://github.com/GitHubSecurityLab/seclab-taskflows/blob/eadd066316e3d8a3933158de0bbe302fc8e4a9b5/src/seclab_taskflows/taskflows/alert_triage_examples/triage_taskflows/actions_common/track_workflow_users.yaml), callers of the vulnerable workflow are retrieved and their trigger events, permissions, use of secrets are recorded in the notes. This information is then used in the [auditing task](https://github.com/GitHubSecurityLab/seclab-taskflows/blob/eadd066316e3d8a3933158de0bbe302fc8e4a9b5/src/seclab_taskflows/taskflows/alert_triage_examples/triage_taskflows/actions_common/audit_workflow_users.yaml) to determine whether the vulnerable workflow is reachable by an attacker.\n\nEach of these tasks is applied to the alert and at each step, false positives are filtered out according to the criteria in the task.\n\nAfter the information gathering and audit stage, our notes will generally include information such as the events that trigger the vulnerable workflow, permissions and secrets involved, and (in case of a reusable workflow) other workflows that use the vulnerable workflow as well as their trigger events, permissions, and secrets. This information will form the basis for the bug report. As a sanity check to ensure that the information collected so far is complete and consistent, the [`review_report`](https://github.com/GitHubSecurityLab/seclab-taskflows/blob/eadd066316e3d8a3933158de0bbe302fc8e4a9b5/src/seclab_taskflows/taskflows/alert_triage_examples/triage_taskflows/triage_actions_code_injection.yaml#L257) task is used to check for missing or inconsistent information before a report is created.\n\nAfter that, the [`create_report`](https://github.com/GitHubSecurityLab/seclab-taskflows/blob/eadd066316e3d8a3933158de0bbe302fc8e4a9b5/src/seclab_taskflows/taskflows/alert_triage_examples/triage_taskflows/triage_actions_code_injection.yaml#L277) task is used to create a bug report which will form the basis of a GitHub Issue. Before creating an issue, we [double check](https://github.com/GitHubSecurityLab/seclab-taskflows/blob/eadd066316e3d8a3933158de0bbe302fc8e4a9b5/src/seclab_taskflows/taskflows/alert_triage_examples/triage_taskflows/triage_actions_code_injection.yaml#L310) that the report contains the necessary information and conforms to the format that we required. Missing information or inconsistencies are likely the results of some failed steps or hallucinations and we reject those cases.\n\nThe following diagram illustrates the main components of the `triage_actions_code_injection` taskflow:\n\n![Seven tasks of a taskflow connected in order with arrows: fetch alerts, trigger analysis, injection point analysis, workflow user analysis, review notes, create bug report and review bug report. All tasks but fetch alerts symbolize how they either iterate over alerts or alert notes.](https://github.blog/wp-content/uploads/2026/01/03_actions_code_injection.png?resize=1024%2C363)\n\nWe then create GitHub Issues using the [create_issue_actions](https://github.com/GitHubSecurityLab/seclab-taskflows/blob/eadd066316e3d8a3933158de0bbe302fc8e4a9b5/src/seclab_taskflows/taskflows/alert_triage_examples/triage_taskflows/create_issues_actions.yaml) taskflow. As mentioned before, the GitHub Issues created contain sufficient information and code references to verify the vulnerability quickly, as well as serving as a summary for the analysis so far, allowing us to continue further analysis using the issue. The following shows an example of an issue that is created:\n\n![Image showing an issue created by the LLM.](https://github.blog/wp-content/uploads/2026/01/4-screenshot.png?resize=887%2C996)\n\nIn particular, we can use GitHub Issues and alert dismissal reasons as a means to incorporate repo-specific security measures and to further the analysis. To do so, we use the [`review_actions_injection_issues`](https://github.com/GitHubSecurityLab/seclab-taskflows/blob/eadd066316e3d8a3933158de0bbe302fc8e4a9b5/src/seclab_taskflows/taskflows/alert_triage_examples/triage_taskflows/review_actions_injection_issues.yaml) taskflow to first [collect alert dismissal reasons](https://github.com/GitHubSecurityLab/seclab-taskflows/blob/eadd066316e3d8a3933158de0bbe302fc8e4a9b5/src/seclab_taskflows/taskflows/alert_triage_examples/triage_taskflows/review_actions_injection_issues.yaml#L22) from the repo. These dismissal reasons are then checked against the alert stated in the GitHub Issue. In this case, we simply use the issue as the starting point and instruct the LLM to audit the issue and check whether any of the alert dismissal reasons applies to the current issue. Since the issue contains all the relevant information and code references for the alert, the LLM is able to use the issue and the alert dismissal reasons to further the analysis and discover more false positives. The following shows an alert that is rejected based on the dismissal reasons:\n\n![Image showing LLM output of reasons to reject an alert after taking into account of the dismissal reasons.](https://github.blog/wp-content/uploads/2026/01/5-screenshot.png?resize=887%2C443)\n\nThe following diagram illustrates the main components of the issue creation and review taskflows:\n\n![Five tasks separated in two swim lanes: the first swim lane named &ldquo;create action issues&rdquo; depicts tasks that are used for the issue creation taskflow starting with dismissing false positives and continuing with the tasks for issue creation for true and false positives. The second swim lane is titled &ldquo;review action issues&rdquo; and contains the tasks &ldquo;collect alert dismissal reasons&rdquo; and &ldquo;review issues based on dismissal reasons.](https://github.blog/wp-content/uploads/2026/01/04_swimlanes_create_review.png?resize=1024%2C619)\n\n## JavaScript alerts\n\nSimilarly to triaging action alerts, we also triaged code scanning alerts for the JavaScript/TypeScript languages to a lesser extent. In the JavaScript world, we triaged code scanning alerts for the client-side cross-site-scripting CodeQL rule. ([js/xss](https://codeql.github.com/codeql-query-help/javascript/js-xss/))\n\nThe client-side cross-site scripting alerts have more variety with regards to their sources, sinks, and data flows when compared to the GitHub Actions alerts.\n\nThe prompts for analyzing those XSS vulnerabilities are focused on helping the person responsible for triage make an educated decision, not making the decision for them. This is done by highlighting the aspects that seem to make a given alert exploitable by an attacker and, more importantly, what likely prevents the exploitation of a given potential issue. Other than that, the taskflows follow a similar scheme as described in the GitHub Actions alerts section.\n\nWhile triaging XSS alerts manually, we‚Äôve often identified false positives due to these reasons:\n\n- Custom or unrecognized sanitization functions (e.g. using regex) that the SAST-tool cannot verify.\n- Reported sources that are likely unreachable in practice (e.g., would require an attacker to send a message directly from the webserver).\n- Untrusted data flowing into potentially dangerous sinks, whose output then is only used in an non-exploitable way.\n- The SAST-tool not knowing the full context where the given untrusted data ends up.\n\nBased on these false positives, the prompts in the relevant taskflow or even in the active personality were extended and adjusted. If you encounter certain false positives in a project, auditing it makes sense to extend the prompt so that false positives are correctly marked (and also if alerts for certain sources/sinks are not considered a vulnerability).\n\nIn the end, after executing the taskflows `triage_js_ts_client_side_xss` and `create_issues_js_ts` , the alert would result in GitHub issues such as:\n\n![A screenshot of a GitHub Issue titled 'Code scanning alert #72 triage report for js/xss,' showing two lists with reasons that make an alert and exploitable vulnerability or not.](https://github.blog/wp-content/uploads/2026/01/05_ai-triage-issue-tp-72.png?resize=1024%2C888)\n\nWhile this is a sample for an alert worthy of following up (which turned out to be a [true positive](https://securitylab.github.com/advisories/GHSL-2025-110_openlibrary/), being exploitable by using a `javascript:` URL), alerts that the taskflow agent decided were false positive get their issue labelled with ‚ÄúFP‚Äù (for false positive):\n\n![A screenshot of a GitHub Issue titled 'Code scanning alert #1694 triage report for js/xss.' While it would show factors that make an alert exploitable it shows none, because the taskflow identified none. However, the issue shows a list of 7 items describing why the vulnerability is not exploitable.](https://github.blog/wp-content/uploads/2026/01/06_ai-triage-issue-fp-1694.png?resize=1024%2C844)\n\n# Taskflows development tips\n\nIn this section we share some of our experiences when working on these taskflows, and what we think are useful in the development of taskflows. We hope that these will help others create their own taskflows.\n\n## Use of database to store intermediate state\n\nWhile developing a taskflow with multiple tasks, we sometimes encounter problems in tasks that run at a later stage. These can be simple software problems, such as API call failures, MCP server bugs, prompt-related problems, token problems, or quota problems.\n\nBy keeping tasks small and storing results of each task in a database, we avoided rerunning lengthy tasks when failure happens. When a task in a taskflow fails, we simply rerun the taskflow from the failed task and reuse the results from earlier tasks that are stored in the database. Apart from saving us time when a task failed, it also helped us to isolate effects of each task and tweak each task using the database created from the previous task as a starting point.\n\n## Breaking down complex tasks into smaller tasks\n\nWhen we were developing the triage taskflows, the models that we used did not handle large context and complex tasks very well. When trying to perform complex and multiple tasks within the same context, we often ran into problems such as tasks being skipped or instructions not being followed.\n\nTo counter that, we divided tasks into smaller, independent tasks. Each started with a fresh new context. This helped reduce the context window size and alleviated many of the problems that we had.\n\nOne particular example is the use of templated [repeat_prompt](https://github.com/GitHubSecurityLab/seclab-taskflow-agent/blob/main/doc/GRAMMAR.md#running-templated-tasks-in-a-loop) tasks, which loop over a list of tasks and start a new context for each of them. By doing this, instead of going through a list in the same prompt, we ensured that every single task was performed, while the context of each task was kept to a minimum.\n\n![A task named &ldquo;audit results&rdquo; which exemplifies the &ldquo;repeat prompt&rdquo; feature. It depicts that by containing three boxes of the same size called 'audit result #1,' 'audit result #2,' and 'audit result n,' while between the #2 and the n box an ellipsis is displayed.](https://github.blog/wp-content/uploads/2026/01/7-audit-results.png?resize=1024%2C414)\n\nAn added benefit is that we are able to tweak and debug the taskflows with more granularity. By having small tasks and storing results of each task in a database, we can easily separate out part of a taskflow and run it separately.\n\n## Delegate to MCP server whenever possible\n\nInitially, when checking and gathering information, such as workflow triggers, from the source code, we simply incorporated instructions in prompts because we thought the LLM should be able to gather the information from the source code. While this worked most of the time, we also noticed some inconsistencies due to the non-deterministic nature of the LLM. For example, the LLM sometimes would only record a subset of the events that trigger the workflow, or it would sometimes make inconsistent conclusions about whether the trigger runs the workflow in a privileged context or not.\n\nSince these information and checks can easily be performed programmatically, we ended up creating tools in the MCP servers to gather the information and perform these checks. This led to a much more consistent outcome.\n\nBy moving most of the tasks that can easily be done programmatically to MCP server tools while leaving the more complex logical reasoning tasks, such as finding permission checks for the LLM, we were able to leverage the power of LLM while keeping the results consistent.\n\n## Reusable taskflow to apply tweaks across taskflows\n\nAs we were developing the triage taskflows, we realized that many tasks can be shared between different triage taskflows. To make sure that tweaks in one taskflow can be applied to the rest and to reduce the amount of copy and paste, we needed to have some ways to refactor the taskflows and extract reusable components.\n\nWe added features like [reusable tasks](https://github.com/GitHubSecurityLab/seclab-taskflow-agent/blob/v0.0.9/doc/GRAMMAR.md#reusable-tasks) and [prompts](https://github.com/GitHubSecurityLab/seclab-taskflow-agent/blob/v0.0.9/README.md#prompts). Using these features allowed us to reuse and apply changes consistently across different taskflows.\n\n## Configuring models across taskflows\n\nAs LLMs are constantly developing and new versions are released frequently, it soon became apparent that we need a way to update model version numbers across taskflows. So, we added the [model configuration feature](https://github.com/GitHubSecurityLab/seclab-taskflow-agent/blob/main/README.md#model-configs) that allows us to change models across taskflows, which is useful when the model version needs updating or we just want to experiment and rerun the taskflows with a different model.\n\n# Closing\n\nIn this post we‚Äôve shown how we created taskflows for the `seclab-taskflow-agent` to triage code scanning alerts.\n\nBy breaking down the triage into precise and specific tasks, we were able to automate many of the more repetitive tasks using LLM. By setting out clear and precise criteria in the prompts and asking for precise answers from the LLM to include code references, the LLM was able to perform the tasks as instructed while keeping the amount of hallucination to a minimum. This allows us to leverage the power of LLM to triage alerts and reduces the amount of false positives greatly without the need to validate the alert dynamically.\n\nAs a result, we were able to discover ~30 real world vulnerabilities from CodeQL alerts after running the triaging taskflows.\n\nThe discussed taskflows are published in [our repo](https://github.com/GitHubSecurityLab/seclab-taskflows) and we‚Äôre looking forward to seeing what you‚Äôre going to build using them! More recently, we‚Äôve also done some further experiments in the area of AI assisted code auditing and vulnerability hunting, so stay tuned for what‚Äôs to come!\n\n[Get the guide to setting up the GitHub Security Lab Taskflow Agent &gt;](https://github.blog/security/community-powered-security-with-ai-an-open-source-framework-for-security-research/)\n\n### Disclaimers:\n\n1. When we use these taskflows to report vulnerabilities, our researchers review carefully all generated output before sending the report. We strongly recommend you do the same.\n2. Note that running the taskflows can result in many tool calls, which can easily consume a large amount of [quota](https://docs.github.com/en/billing/concepts/product-billing/github-models).\n3. The taskflows may create GitHub Issues. Please be considerate and seek the repo owner‚Äôs consent before running them on somebody else‚Äôs repo."
}
