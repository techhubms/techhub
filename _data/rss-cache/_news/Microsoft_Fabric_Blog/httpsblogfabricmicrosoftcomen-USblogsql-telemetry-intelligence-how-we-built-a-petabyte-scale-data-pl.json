{
  "FeedName": "Microsoft Fabric Blog",
  "FeedLevelAuthor": "Microsoft Fabric Blog",
  "FeedUrl": "https://blog.fabric.microsoft.com/en-us/blog/feed/",
  "Description": "Building a Petabyte-scale Data Platform with Fabric and SQL Telemetry and Intelligence Engineering team.",
  "Author": "Microsoft Fabric Blog",
  "PubDate": "2025-12-16T10:00:00+00:00",
  "OutputDir": "_news",
  "ProcessedDate": "2025-12-16 17:05:32",
  "Tags": [],
  "Link": "https://blog.fabric.microsoft.com/en-US/blog/sql-telemetry-intelligence-how-we-built-a-petabyte-scale-data-platform-with-fabric/",
  "EnhancedContent": "Over the last three years, the *SQL Telemetry & Intelligence (T&I)* Engineering team has built a **10+ Petabyte** Data Lake on Fabric, processing real-time data from globally distributed SQL Server Engines and Control Plane/Data Plane Services.\n\n![A ~5 Petabyte Silver Zone – Table size (Terabytes) over time – as observed by ADLS](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/12/silver-pb.png)A ~5 Petabyte Silver zone (compressed Parquet) – Table size (Terabytes) over time – as observed by ADLS\n\nThis article reflects on Modern Data Engineering Best-Practices and foundations that has served us well so far:\n\n![SQL T&amp;I – Data Platform Design Pillars on Fabric](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/12/how-we-built-1.png)SQL T&I – Data Platform Design Pillars\n\n## Architecture\n\nIn 2022, when deciding where to invest our codebase to express business logic, we performed an honest comparison of the various Fabric Engine APIs against our requirements:\n\n![Comparing Fabric Engine APIs to Modern Data Architecture pillars](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/12/fabric-mda.png)Comparing Fabric Engine APIs to Modern Data Architecture pillars (this view is not authoritative or exhaustive)\n\nToday, our [Lakehouse Architecture](https://learn.microsoft.com/fabric/onelake/onelake-medallion-lakehouse-architecture) follows the [Lambda](https://learn.microsoft.com/azure/architecture/databases/guide/big-data-architectures#lambda-architecture) pattern with a heavy bias towards Real-time:\n\n**Bronze** – reflects the source-system for backfills.\n\n**Silver –**exploded schema to maximize columnar compression.\n\n**Gold –**[Kimball STAR schema](https://www.kimballgroup.com/data-warehouse-business-intelligence-resources/kimball-techniques/dimensional-modeling-techniques/) with [SCD2 (Dimension)](https://en.wikipedia.org/wiki/Slowly_changing_dimension#Type_2:_add_new_row) tables, synchronous pre-commit quality checks in a [Write-Audit-Publish pattern](https://www.telm.ai/blog/what-is-write-audit-publish-in-apache-iceberg-and-why-it-matters-for-data-quality/), with post-commit latency SLAs, Anomaly Detection checks for [Natural/Business Keys](https://en.wikipedia.org/wiki/Natural_key).\n\n![SQL T&amp;I – Medallion Lakehouse Architecture implemented on Fabric](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/12/t-and-i-architecture.png)SQL T&I – Medallion Lakehouse Architecture\n\n**1. OpenTelemetry** – Our First Party (1P) services, as well as Customer-facing (3P) services are instrumented with [OpenTelemetry](https://opentelemetry.io/).\n\n**2. Event Hub** – Real-time Control plane events from [Azure Resource Notifications](https://learn.microsoft.com/azure/event-grid/event-schema-resource-notifications).\n\n**3. Azure Data Explorer** – Immutable time-series database.\n\n**4. Event** **Hub to Delta Lake Mirroring** – Similar to [Confluent’s Tableflow](https://www.confluent.io/product/tableflow/), we wrote a highly-performant C#/Rust service hosted on [AKS with KEDA](https://learn.microsoft.com/azure/aks/keda-about) with 27+ GB/minute throughput. Refer to [Data Ingestion: Introducing delta-dotnet for Delta Lake](https://www.youtube.com/watch?v=f8fnFzQFjZw) YouTube seminar.\n\n**5. Azure Data Explorer – APPEND-only to Delta Lake –** written directly into ADLS using [Continuous Export](https://learn.microsoft.com/kusto/management/data-export/continuous-data-export?view=microsoft-fabric#exactly-once-export).\n\n**6. Open Mirroring – APPEND-only to Delta Lake –** The OTeL Collector is written in Go –and does not have a matured Delta Lake SDK. Using [Open Mirroring](https://learn.microsoft.com/fabric/mirroring/open-mirroring), we APPEND-only flush Parquet files into the [Landing Zone](https://learn.microsoft.com/fabric/mirroring/open-mirroring-landing-zone-format) with massive concurrency.\n\n**7. Spark Streaming –** Applying [schema-on-read](https://developer.confluent.io/patterns/event/schema-on-read/) by supplying versioned sample payloads to transform tables, we also use Spark Streaming to combine many small files from regional tables ([maxFilesPerTrigger](https://delta-docs-incubator.netlify.app/delta-streaming/)) to generate optimally sized parquet files.\n\nThe key benefits of using Spark Streaming across the board are:\n\n- &lt;15-30 seconds latency, with [&lt;100 milliseconds coming in Spark 4.1](https://issues.apache.org/jira/browse/SPARK-52330).\n- All state inside isolated checkpoints with limited blast radius.\n- All transformations are horizontally scalable.\n- Stateful transformations (via [GroupState](https://spark.apache.org/docs/latest/api/java/org/apache/spark/sql/streaming/GroupState.html)).\n- [forEachBatch](https://spark.apache.org/docs/latest/api/scala/org/apache/spark/sql/streaming/DataStreamWriter.html) can fork to multiple sinks against a single read.\n- Incremental processing without using [brittle watermark columns](https://learn.microsoft.com/en-us/fabric/data-factory/tutorial-incremental-copy-data-warehouse-lakehouse).\n\n**8. Kimball SCD2 tables with Transaction grain**\n\nOur strict [Kimball Dimensional Model](https://www.kimballgroup.com/data-warehouse-business-intelligence-resources/kimball-techniques/dimensional-modeling-techniques/) offers these guarantees:\n\n- Unique Primary Keys.\n- Valid Foreign Key references.\n- Idempotent – replaying previously seen transactions are guaranteed to be no-op.\n- Reliable SCD2 columns based on source time (*is\\_row\\_effective, start\\_date, end\\_date* etc.).\n\nBringing relational-database style Primary Key enforcements into a large STAR schema was tricky – we designed our tables taking inspiration from Spark’s [Storage Partition Join](https://spark.apache.org/docs/latest/sql-performance-tuning.html#storage-partition-join), learning from [Hyperspace’s B-Tree indices](https://microsoft.github.io/hyperspace/) and taking heavy advantage of [BROADCAST joins](https://spark.apache.org/docs/latest/api/java/org/apache/spark/broadcast/Broadcast.html).\n\n**9. Kimball Periodic Snapshot tables for DirectLake**\n\nA single DirectLake Semantic Model that describes a full-360 view of SQL Server’s business using:\n\n- [Periodic Snapshot FACT](https://www.kimballgroup.com/data-warehouse-business-intelligence-resources/kimball-techniques/dimensional-modeling-techniques/periodic-snapshot-fact-table/) tables at the daily/weekly/monthly grain.\n- Removing high-cardinality dimensions to make pre-aggregations more effective.\n\n**10. Eventhouse Acceleration**\n\nWhile most of our silver tables are stored as Delta Lake on OneLake, a second copy of popular tables are easily made available in Eventhouse using [Query Acceleration Policy](https://learn.microsoft.com/fabric/real-time-intelligence/query-acceleration-overview), where [Azure Managed Grafana](https://azure.microsoft.com/products/managed-grafana) powers many of our live site KPI dashboards on top of the KQL endpoint.\n\n**11. Interactive Exploration** **with SSMS and Notebooks**\n\nSelf-explanatory.\n\n**12. DirectLake Semantic Model**\n\nA mixture of [Tabular Editor 3](https://tabulareditor.com/), Power BI Desktop, [DAX Studio](https://daxstudio.org/), and Fabric Web Editor are used to model relationships and measures – all contributions must go through Pull Requests via [TMDL](https://learn.microsoft.com/analysis-services/tmdl/tmdl-overview?view=sql-analysis-services-2025).\n\n## Problems & Solutions\n\nOperating a hyperscale data platform inevitably brings complex scalability challenges. In this section – we discuss specific Data Engineering problems and solutions.\n\n**VSCode Devcontainer for local development**\n\nSpark has a reputation of being difficult to run locally.\n\nWe invested in designing a [VSCode Devcontainer](https://code.visualstudio.com/docs/devcontainers/containers) that contains all of our development dependencies, including pinned versions of JDK, Spark Engine, and [VSCode Extensions](https://code.visualstudio.com/docs/configure/extensions/extension-marketplace). This enables every new developer to have a consistent development environment:\n\n![VSCode Devcontainer – 5 minutes to Debugger](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/12/devcontainer-build.png)VSCode Devcontainer – 5 minutes to Debugger\n\nOnce the code works locally, we rapidly build the whl/jar, upload and test it in Fabric Spark via the [VS Code Extension](https://marketplace.visualstudio.com/items?itemName=fabric.vscode-fabric) to invoke a [Spark Job Definition](https://learn.microsoft.com/fabric/data-engineering/spark-job-definition), all without leaving the IDE:\n\n![VSCode Devcontainer – Debugging capabilities](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/12/devcontainer-debug-2.png)VSCode Devcontainer – In the Debugger after 5 minutes using [Spark Java Debug Wire Protocol](https://spark.apache.org/developer-tools.html)\n\n**Fabric CI/CD at scale**\n\nEach member of the team must spin up a private fork of our ***entire*** Fabric Production stack, on-demand, with zero pre-requisites.\n\nOur observations:\n\n- [Fabric Deployment Pipelines](https://learn.microsoft.com/fabric/cicd/deployment-pipelines/intro-to-deployment-pipelines?tabs=new-ui) are low touch and low customizability.\n- [Fabric Terraform Provider](https://blog.fabric.microsoft.com/blog/terraform-provider-for-microsoft-fabric-now-generally-available/) does not have 100% API coverage surface area.\n- [Fabric-cli](https://microsoft.github.io/fabric-cli/) project does not also have 100% API coverage surface area.\n- [Fabric-cicd](https://microsoft.github.io/fabric-cicd/0.1.30/) package is limited to git integrated APIs.\n\nFor regions or restricted clouds where Fabric is unavailable today, we currently maintain 40+ Production Synapse Workspaces using the tremendously helpful [synapse-workspace-deployment](https://github.com/Azure/Synapse-workspace-deployment) project.\n\nUsing inspiration from it, we authored a fabric-workspace-deployment app, that wraps the fabric-cli, fabric-cicd, and API models in a GitOps manifest to achieve 100% automation:\n\n![A consistent, GitOps-driven source of truth to configure every API used in Production in Fabric](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/12/fabric-manifest-visual.png)A consistent, GitOps-driven source of truth to configure**every**API used in Production in Fabric ![100% version control of every Fabric API in git](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/12/fabric-manifest-actual-1.png)We even version control the Workspace PNG icon!\n\nWithin 10 minutes, the app spins up isolated capacities, workspaces, Autoscale billing etc. to give a new Engineer an exact functional replica of Production:\n\n![Hundreds of consistently deployed Fabric Workspaces and Capacities across T&amp;I](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/12/fabric-consistent-1.png)Hundreds of consistently deployed Fabric Workspaces and Capacities across T&I\n\nThe [application code is available](https://github.com/mdrakiburrahman/fabric-workspace-deployment) for inspiration, but the API contract is not fit for external consumption yet, as we are still making many breaking changes as we move fast to standardize T&I’s Fabric consumption.\n\n**Rapid test coverage**\n\nThe key design characteristic in being able to maintain robust Data Processing code that is near-regression proof is – to **force all changes to data to flow through a simple interface**that operates purely on the DataFrame API:\n\n![Encapsulating transformations in enclosed functions with transform chaining to make Spark Streaming trivial to adopt and test](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/12/transform.png)Encapsulating transformations in enclosed functions with [transform](https://www.mungingdata.com/apache-spark/chaining-custom-dataframe-transformations/) chaining to make Spark Streaming trivial to adopt and test\n\nTesting is an entire discipline area, so we will not go into any level of detail, but we mention two golden tips that will yield huge dividends to host production workloads on Fabric confidently, and specifically Spark:\n\n- Parallelized testing **significantly** speeds up test execution while using [sbt forking](https://www.scala-sbt.org/1.x/docs/Forking.html) to eliminate noisy-neighbor tests.\n- To **dramatically**speed up single-node Spark execution speeds on smaller datasets, [set spark.sql.shuffle.partitions = 1](https://github.com/holdenk/spark-testing-base/pull/291/files).\n\nBy making these two small changes we were able to reduce our test runtime by **67%**:\n\n![Reducing test execution time by 67% by two fairly simple Spark Devcontainer architectural changes](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/12/test-fast.png)Reducing test execution time by 67% by two fairly simple Spark Devcontainer architectural changes\n\n**Kimball STAR Schema**\n\nAfter referring to [The Data Warehouse Toolkit, 3rd Edition](https://www.kimballgroup.com/data-warehouse-business-intelligence-resources/books/data-warehouse-dw-toolkit/), we modelled all relevant data modelling concepts using Object-Oriented Programming principles:\n\n![Kimball’s teachings, captured as Object Oriented Programming principles](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/12/kimbal-oop-1.png)Kimball’s teachings, captured as Object Oriented Programming principles (traits and base classes)\n\nThe additional benefit of consistent interfaces is, we’re able to automatically generate [DBML (Database Markup Language)](https://dbml.dbdiagram.io/home/), which allows consistent generation of ERDs:\n\n![Auto-generated OpenTelemetry schema ERDs using DBML (Database Markup Language)](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/12/dbml.png)Auto-generated OpenTelemetry schema ERDs using DBML ([Database Markup Language](https://dbml.dbdiagram.io/home/))\n\nBy applying the following best practices, we’ve been able to **significantly** reduce the time it takes for loads to occur:\n\n- Liquid Clustering on Kimball key columns to reduce integrity enforcement runtime.\n- Instead of using JOINs to check for orphaned keys, use [WHERE EXISTS](https://spark.apache.org/docs/latest/sql-ref-syntax-qry-select-where.html).\n\n![An example of an integrity check for SCD2 columns](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/12/scd2-health.png)An example of an integrity check for SCD2 columns that significantly speeds up by clustering Natural Keys\n\n**OpenTelemetry with Custom Spark Metrics**\n\nGiven our deep investments in OpenTelemetry, to instrument our Spark Cluster with Custom Metrics, we took advantage of [Spark Plugins](https://github.com/apache/spark/blob/master/core/src/main/java/org/apache/spark/api/plugin/SparkPlugin.java). The use case is the ability to instantly gain deep visibility into a problematic Spark Jobs (e.g. ERROR 137) and understanding the memory profile with pinpoint precision:\n\n![](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/12/power-bi-fabric-metric.png)Visualizing exactly what occurs across a Spark Cluster moments before an ERROR 137 ![](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/12/heap-dump-1.png)Pictured heap dump, this is what a JOIN explosion causing ERROR 137 looks like on a 32 GB Executor, about 32 GBs of keys on the heap!\n\nFor more information, refer to [How to deeply instrument a Spark Cluster with OpenTelemetry (feat. real time Power BI report)](https://www.rakirahman.me/spark-otel-plugin/):\n\n![Using Spark Plugins to expose arbitrary OS-level Metrics as an OpenTelemetry Metric](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/12/spark-plugins-1.png)Using Spark Plugins to expose arbitrary OS-level Metrics as an OpenTelemetry Metric\n\n**Data Quality and Anomaly Detection**\n\nWe found [Deequ](https://github.com/awslabs/deequ) to have the richest API coverage with highest performance, including [Anomaly Detection](https://github.com/awslabs/deequ/tree/master/src/main/scala/com/amazon/deequ/anomalydetection), flexible [Metric Stores](https://github.com/awslabs/deequ/tree/master/src/main/scala/com/amazon/deequ/repository) (including Delta tables), and simple API constructs that can be extended to fit a particular codebase’s needs without requiring upstream changes.\n\nFurthermore, recent features in Deequ to include [Data Quality Definition Language (DQDL)](https://docs.aws.amazon.com/glue/latest/dg/dqdl.html) have been phenomenal. DQDL allows us to define a terse set of constraints about a table in a few lines of declarative code:\n\n![A Data Quality Definition Language (DQDL) rule](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/12/deequ.png)A Data Quality Definition Language (DQDL) rule\n\nThis simple, easy to follow API allows you to declare and document data quality expectations about the table right alongside the table definition.\n\n**Data Platform SLAs**\n\nOur Data Platform is built on top of operational data arriving from every major Azure region on Earth. Several issues can occur at any time – It’s important to offer end users a single pane of glass with regards to:\n\n- What the expected SLAs are for a particular dataset.\n- If SLAs are breached, what the justifications and outliers are.\n- When the expected mitigation is coming.\n- A top-level trend of the entire Data Platform.\n\nA simple YAML file that is git-checked in, with a simple *YAML -&gt; native object -&gt; DataFrame* converter:\n\n![YAML to define SLA's per GOLD table by dimensions (e.g. Azure regions)](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/12/yaml-sla-1.png)YAML to define SLA’s per GOLD table by dimensions (e.g. Azure regions)\n\nSLA failures are evaluated as a Spark DataFrame, and visible by dimension (in this case, region):\n\nStandardizing SLA evaluation through Spark SQL/DataFrame allows us to have robust test coverage with edge-cases captured for complex, maintainable business logic that operates on arbitrary sizes of data.\n\n**In an SLA breach:**\n\n- A health check job fails.\n- An incident is fired via [Fabric Activator](https://learn.microsoft.com/fabric/real-time-intelligence/data-activator/activator-introduction).\n- An on-call engineer investigates the alert, pushes an updated YAML file into OneLake via a PR. The stakeholders are kept up to date via a Delta table visualized in Power BI.\n\n![A Power BI report backed by SLA calculations combined with metadata from the YAML per data source per region](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/12/sla-powerbi-1.png)A Power BI report backed by SLA calculations combined with metadata from the YAML per data source per region\n\n**Fearless, idempotent backfills**\n\nDespite having all the unit test coverage in the world, it’s always possible to merge harmless looking changes—such as using an INNER rather than LEFT JOIN, that can cause unnatural drops in business metrics, such as unique natural keys.\n\nBackfilling the lost data to undo the damage is tricky if the source tables are extremely large. To solve this:\n\n- We capture all transformation logic in self-contained functions allows us to chain them together to backfill a particular table.\n- Having Primary Keys enforced in the GOLD zone allows us to replay transactions from SILVER—without fearing repercussions of duplicates.\n\n![Visualizing a backfill job](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/12/backfill-config.png)A backfill job configuration ![](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/12/backfill-visual-2.png)Enforcement of deterministic primary keys allows us to ensure replaying transactions during backfill does not insert duplicates or have side effects\n\nThis is idempotency in action—saving the Lakehouse from what would have been an extremely expensive full reprocess with downstream ripples that would have reset many Streaming Checkpoints:\n\n![Backfilling the damage from a PR containing a non-defensive INNER JOIN that impacted several FACT tables](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/12/idempotent-backfill-1.png)Backfilling the damage from a PR containing a non-defensive INNER JOIN that impacted several FACT tables\n\n**Autoscale Billing for Spark enables large, unpredictable workloads**\n\nOn an average day, we require about 8,000 cores at peak – as jobs are queued, they grab the cores, run, and exit. At other times, for example on November 23rd below, very large Spark Pools needed to be allocated for backfills over 2 days:\n\n![Spark peak vCore usage over time](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/12/core-peak.png)Spark peak vCore usage over time\n\nBefore [Fabric Spark Autoscale Billing](https://learn.microsoft.com/fabric/data-engineering/configure-autoscale-billing), even multiple F2048s would not have been sufficient for this workload profile. With Autoscale Billing, we simply allocate a small SKU against the workspace and use Autoscale Billing in true PAYG fashion.\n\n**Incremental View Maintenance to avoid fully reprocessing Petabytes of data during aggregations**\n\nThe pre-aggregated periodic-snapshot generation in our STAR schema is not incremental:\n\n![The red box represents the only part of the architecture that is not 100% incremental](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/12/kimball-periodic.png)The red box represents the only part of the architecture that is not 100% incremental\n\nWhile it is technically possible to take any SQL query, study the AST (Abstract Syntax Tree) and rewrite it such that it’s computed incrementally ([linkedin/coral on GitHub](https://github.com/linkedin/coral?tab=readme-ov-file)), this differential rewrite is a stateful operation, as it must keep track of the previous commit that was processed per table:\n\n![Taking a SQL AST and rewriting it to be incrementally evaluated using Linkedin Coral](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/12/linkedin-coral.png)Taking a [SQL AST](https://ns.inria.fr/ast/sql/index.html) and rewriting it to be incrementally evaluated\n\nSimply rewriting the query to be incremental isn’t guaranteed to be performant. Depending on the query, columns involved, clustering, table statistics, table/file layout, it’s possible for the original query plan that processes the full dataset to be more efficient than incremental.\n\nIt’s a fascinating optimization problem, that can sometimes benefit from Machine Learning over a historical heuristics feedback loop (i.e. evaluating cost over time to learn from the past). [Fabric Materialized Lake View Optimal Refresh](https://learn.microsoft.com/fabric/data-engineering/materialized-lake-views/refresh-materialized-lake-view) is precisely trying to solve this for all Fabric users and *significantly* improve COGS efficiency at scale.\n\nFor more information about this interesting problem space, refer to this academic paper: [DBSP: Automatic Incremental View Maintenance for Rich Query Languages](https://mihaibudiu.github.io/work/budiu-vldb25.pdf).\n\n## **What’s Next?**\n\nIn our experience, the best part about Fabric is how cohesively it brings together different, highly-specialized computes – such as Spark and the Analysis Services Engine – by unifying state on OneLake. Direct Lake and Spark go hand-in-hand.\n\nApplying the best-practices that has been ingrained in us about Parquet from years of Data Engineering feels extremely intuitive – there’s a minimal amount of new things to learn.\n\nOur Semantic Model is delightful – we’re able to enjoy incredible performance and squeeze fantastic scale (a single model with 100s of tables) out of the Analysis Services Engine via Direct Lake. The trick is to first apply Spark against the massive transaction grain fact tables and perform pre-aggregation using Kimball’s periodic snapshot modelling patterns.\n\nWith the core Production Medallion Architecture laid out end-to-end next, we want to polish our Data Platform further to enable a delightful self-serve model using [dbt on Fabric](https://blog.fabric.microsoft.com/blog/dbt-job-in-microsoft-fabric-ship-trustworthy-sql-models-faster-preview?ft=All), preferably with [the fabric-spark adapter](https://github.com/microsoft/dbt-fabricspark) to keep local development and PR tests as consistent as possible.\n\nWe also aim to apply consistent AI/ML across our data estate, starting with rich, stateful Anomaly Detection on our well-established KPIs and Metrics.\n\nIf you’d like a deeper dive on any specific topic discussed in this post, please leave a comment!",
  "Title": "SQL Telemetry & Intelligence – How we built a Petabyte-scale Data Platform with Fabric"
}
