{
  "FeedUrl": "https://www.reddit.com/r/MachineLearning/.rss",
  "Link": "https://www.reddit.com/r/MachineLearning/comments/1mjnrmg/d_have_any_bayesian_deep_learning_methods/",
  "Tags": [
    "MachineLearning"
  ],
  "OutputDir": "_community",
  "FeedName": "Reddit Machine Learning",
  "ProcessedDate": "2025-08-08 16:08:38",
  "Title": "[D] Have any Bayesian deep learning methods achieved SOTA performance in...anything?",
  "FeedLevelAuthor": "Machine Learning",
  "EnhancedContent": "If so, link the paper and the result. Very curious about this. Not even just metrics like accuracy, have BDL methods actually achieved better results in calibration or uncertainty quantification vs say, deep ensembles?\n\nMy understanding of the field is that BDL is currently still much too stymied by challenges in training. Actually fitting the posterior even in relatively shallow/less complex models becomes expensive very quickly, so implementations end up relying on methods like variational inference that introduce accuracy costs (eg, via oversimplification of the form of the posterior).\n\nCurrently, really good implementations of BDL I’m seeing aren’t Bayesian at all, but are rather “Bayesifying” non-Bayesian models, like applying Monte Carlo dropout to a non-Bayesian transformer model, or propagating a Gaussian process through the final model weights.\n\nIf BDL ever gets anywhere, it will have to come through some form of VI with lower accuracy tradeoff, or some kind of trick to make MCMC based methods to work faster.\n\nI guess it's also a semantic discussion around what is actually \"Bayesian\" or not. For me, simply ensembling a bunch of NNs isn't really Bayesian. Fitting Laplace approximation to weights learned via standard methods is also dubiously Bayesian imo.\n\n> > >\n> or some kind of trick to make MCMC based methods to work faster\n> > > >\n\nMy intuition, as somebody who's dabbled in trying to get these things to perform better in the past, is that the path forward (assuming there exists one) is probably *not* through MCMC, but an entirely separate approach that fundamentally outperforms it.\n\nMCMC is a cute trick, but ultimately that's all it is. It feels like the (hopefully local) minimum down that path has more or less already been reached, and while I'm sure some further improvement is still possible, it's not going to be of the breakthrough, \"many orders of magnitude\" type that would be necessary here.\n\nBut I could be entirely wrong, of course. A hunch isn't worth much.\n\nI’m not aware of Bayesian Deep Learning methods being SOTA on anything since Radford Neal won some variable importance competition in like the early 2000’s, which he won using a combination of shallow neural networks fit with HMC and Dirichlet diffusion trees (another pretty cool idea that doesn’t scale and was abandoned a long time ago). Since then I think the issue is that Bayesian approaches are just always going to be behind the Pareto frontier at any given point in time because they are computationally very intensive and unreliable, and there are better ways to spend the FLOPs than trying to force it to work.\n\nThat’s not to say Bayesian thinking is not useful. There are a lot of Bayesians working at the bleeding edge of deep learning, they just don’t apply it directly to training neural networks.\n\n> > >\n> There are a lot of Bayesians working at the bleeding edge of deep learning, they just don’t apply it directly to training neural networks.\n> > > >\n\nWould you mind linking one of them whose research you like? I, too, am a Bayesian slowly looking toward machine learning trying to figure out what works and what doesn't.\n\nGenerative models learned with variational inference are essentially a kind of posterior.\n\nA lot of SOTA models/algorithms can be thought of as instances of Bayes' rule. For example, there's a link between diffusion models and variational inference1, where diffusion models can be thought of as an infinitely deep VAE. Making this connection more exact leads to better performance2. Another example is the connection between all learning rules and (Bayesian) natural gradient descent3.\n\nAlso there's a more nuanced point, which is that marginalization (the key property of Bayesian DL) is important when the neural network is underspecified by the data, which is almost all the time. Here, specifying uncertainty becomes important, and marginalizing over possible hypotheses that explain your data leads to better performance compared to models that do not account for the uncertainty over all possible hypotheses. This is better articulated by Andrew Gordon Wilson4.\n\n1 A Variational Perspective on Diffusion-Based Generative Models and Score Matching. Huang et al. 2021\n\n2 Variational Diffusion Models. Kingma et al. 2023\n\n3 The Bayesian Learning Rule. Khan et al. 2021\n\n4 [https://cims.nyu.edu/~andrewgw/caseforbdl/](https://cims.nyu.edu/~andrewgw/caseforbdl/)\n\nAre we counting energy-based models as bayesian deep learning ?\n\nAll priors are wrong but some are useful.\n\nYes, if you use the uniform prior and do MAP estimation, it works pretty well with deep neural nets and lots of data ;)",
  "Author": "35nakedshorts",
  "PubDate": "2025-08-07T02:07:58+00:00",
  "Description": "If so, link the paper and the result. Very curious about this. Not even just metrics like accuracy, have BDL methods actually achieved better results in calibration or uncertainty quantification vs say, deep ensembles?"
}
