{
  "FeedUrl": "https://www.reddit.com/r/MachineLearning/.rss",
  "Link": "https://www.reddit.com/r/MachineLearning/comments/1mjqcas/d_training_whisper_tiny/",
  "Tags": [
    "MachineLearning"
  ],
  "OutputDir": "_community",
  "FeedName": "Reddit Machine Learning",
  "ProcessedDate": "2025-08-08 16:08:38",
  "Title": "[D] Training Whisper Tiny",
  "FeedLevelAuthor": "Machine Learning",
  "EnhancedContent": "I am trying to build an on device speech recognition engine for recognising kids’ voice better replacing speech framework I am using in my ios app right now.\n\nTo do this, I collect sample audio data from my app keeping the privacy concerns in mind and transcribe these audio files with whisper large v2 and then using it as pseudo labelling to train whisper tiny.\n\nI have following questions now:\n\n1. Is this a valid strategy or with low parameters of whisper tiny this is a futile exercise no matter how much I train it?\n2. Most of my data is not clean, meaning background and other noise is interspersed with kids’ speech. But it’s also important for my app to be accurate in these environment.\n3. How many hours of audio I need to train it on keeping the above audio quality in mind to achieve reasonable accuracy?\n4. Are there better solutions?\n\nFor anything meaningful to be done, you'll need the following:\n\n- a benchmark dataset for STT specifically made on children's speech. Something ASR related should be readily available but you'll likely need to take that and tune it to your usecase\n- the baseline metrics (ie what's the iOS App scoring on this?)\n- then, a process to either isolate noise to get only the correct speech, or enough data that is increasingly hard in speech clarity.\n- train and tune checkpoints with whisper tiny, but don't just stick to that. There's a few oss models now that you can find on hf. Give those a shot too.\n\nYou'll need a few tens-hundreds of hours of audio to make something really stand out, I think.\n\nDo try other readily available models first on your benchmark first; you may not even need to fine-tune one if something works reliably okay out of the box.\n\nBest of luck!\n\nI am unable to find any models tuned to kids’ speech. The datasets are expensive. I am leveraging the ones available freely.\n\nYou approach is ok but here are few suggestions:\n\n1. Instead of just training on the pseudo-labels produced by the large version, you can also leverage the token's probability distribution of the large version. You can find more details here [Distil whisper](https://arxiv.org/abs/2311.00430). In short your training objective would be a weighted sum of standard cross-entropy and KL divergence of the two probability distributions.\n2. Do a preprocessing step before creating the pseudo labels from the large model. At least remove the silent parts, as this is something whisper struggles with. This will give you better pseudo labels. Train on these preprocessed recordings, just keep in mind that you will have to apply this step during inference.\n3. Hard to say how much data you need. I would start incrementally and stop adding data when I'm happy with the results or reach a plateau. I wouldn't start with less than 50 hours of data.\n\nStill this approach will only yield a model AT MOST as good as the teacher model (large-v2 in your case). So If you are not happy with the quality of the teacher model, you will need human-annotated data.",
  "Author": "Realistic_Public_415",
  "PubDate": "2025-08-07T04:15:53+00:00",
  "Description": "I am trying to build an on device speech recognition engine for recognising kids’ voice better replacing speech framework I am using in my ios app right now.\n\nTo do this, I collect sample audio data from my app keeping the privacy concerns in mind and transcribe these audio files with whisper large v2 and then using it as pseudo labelling to train whisper tiny.\n\nI have following questions now:\n\n1. Is this a valid strategy or with low parameters of whisper tiny this is a futile exercise no matter how much I train it?\n2. Most of my data is not clean, meaning background and other noise is interspersed with kids’ speech. But it’s also important for my app to be accurate in these environment.\n3. How many hours of audio I need to train it on keeping the above audio quality in mind to achieve reasonable accuracy?\n4. Are there better solutions?"
}
