{
  "FeedName": "Microsoft Tech Community",
  "ProcessedDate": "2025-11-06 15:04:07",
  "Link": "https://techcommunity.microsoft.com/t5/microsoft-developer-community/unlock-structured-ocr-in-typescript-with-mistral-document-ai-on/ba-p/4466039",
  "Tags": [],
  "Description": "Mistral Document AI (available as a serverless model in Azure AI Foundry) brings multimodal, layout‑aware document understanding directly into a developer workflow without provisioning GPUs. Instead of receiving only raw text from Optical Character Recognition (OCR), you obtain markdown plus optional structured annotations that preserve tables, headings, figures, and multilingual content. This structural preservation enables more accurate and reliable downstream automation for AI agents, RAG workflows, and compliance tasks.\n\n## Mistral Document AI\n\nMistral Document AI combines vision + language understanding to interpret complex page layouts. Compared to traditional OCR approaches, it maintains structural semantics: tables remain tables, figures are preserved, headings stay delineated, and mathematical or LaTeX elements are not flattened into ambiguous text. The model supports 25+ languages and handles PDFs and images (including scanned, mixed‑content pages) with high accuracy. Published benchmarks indicate superior layout fidelity and text extraction accuracy versus several large general models and legacy OCR engines\n\nKey capabilities:\n\n- **Robust layout understanding**. Detects document regions (headings, paragraphs, lists, tables, and figures) and preserves their relationships so downstream code can treat them as structured objects instead of flat text.\n- **Preserves document structure** and returns markdown plus optional JSON annotations (bounding boxes, fields, or custom schema).\n- **Broad language and style support.** Accurately extracts text across many languages and common font/handwriting variations, improving reliability on scanned, photocopied, or noisy documents.\n- **Doc‑as‑prompt support**. For Agent systems that require clean, structured output, you can pass the extracted document content directly to tool invocations, RAG pipelines or agents for extraction, classification, or summarization.\n- **Serverless**, low‑latency processing designed for single‑document and batch workflows.\n\nAssume you own a collection of old handwritten or scanned family recipe PDFs and images passed down through generations. You want to digitize these recipes into a structured format for easy access, sharing across relatives and meal planner/ shopping list generation tools.\n\nYour pipeline may look like this:\n\n1. Ingest document (image or PDF) → call Mistral Document AI → receive markdown/json pages.\n2. Parse markdown to extract key information: recipe title, ingredients, cooking instructions, cooking time etc.\n3. Derive a shopping list.\n4. Feed structured output into downstream agent (e.g, *Suggest ingredient substitutions* or *Generate weekly shopping consolidation*).\n\n## How to use it (TypeScript)\n\n### Pre-requisites\n\n- An Azure AI Foundry project\n- *mistral-document-ai-2505* model deployment\n\nSet up your *endpoint* and *API\\_key* in your environment variables. The full sample will be referenced at the end of this blog, but here’s a minimal explanation of the core logic.\n\n### Demo scenario: Recipe PDF/ Image → Structured Data → Shopping List\n\nThe code snippets below illustrate the key steps to process a recipe PDF using Mistral Document AI and extract structured data.\n\n- First, encode the PDF to base64, as document URL or image URL is not supported directly.\n- Then invoke the Mistral Document AI endpoint with the appropriate payload.\n- Finally, save and read the output JSON for post-processing.\n\n- // Step 1\nfunction encodePdfToBase64(pdfPath: string): string { const pdfContent = fs.readFileSync(pdfPath); return pdfContent.toString('base64'); }\n\nconst base64Content = encodePdfToBase64(pdfPath);\n\n// Step 2 const headers = { 'Content-Type': 'application/json', Authorization: `Bearer ${apiKey}` }; const payload = { model: modelName, document: { type: 'document\\_url', document\\_url: `data:application/pdf;base64,${base64Content}` }, include\\_image\\_base64: true, };\n\nconst response = await axios.post(azureEndpoint!, payload, { headers });\n\n// Step 3 const outputFile = 'document\\_ai\\_result.json'; fs.writeFileSync(outputFile, JSON.stringify(result, null, 2), 'utf-8');\n\nconst jsonContent = fs.readFileSync(outputFile, 'utf-8');\n\nExpected output:\n\n![]()\n\nAfter OCR, we then proceed to extract structured recipe information (Ingredients, cooking steps, cooking time) and perform additional post-processing like normalization, for the shopping list.\n\n![]()\n\nWith your data in structured JSON, you can now build applications or agents that leverage this knowledge. Here is an example of a simple app (Web Components) that implements the above end-to-end flow, allowing users to upload recipe documents and see extracted structured data and shopping lists.\n\n![]()\n\n## Security, Privacy & Compliance\n\nRunning Mistral Document AI inside Azure AI Foundry provides:\n\n- Regional data residency as documents are processed inside your selected Azure region. Data is not forwarded to external third‑party endpoints beyond Azure’s managed hosting.\n- Enterprise isolation and governance alignment with standard Azure controls.\n- Ability to apply Responsible AI tooling (content filtering, monitoring) to downstream agent operations.\n- Content safety filters applied to document annotation outputs. Note that OCR output itself does not have content safety enforcement by default.\n- Selective self‑hosting for highly sensitive workloads, this way your data remains fully within your controlled environment.\n\nMistral Document AI enables a higher‑quality foundation for document‑driven AI features: better fidelity, multilingual support, structured outputs, and integration into Azure AI operational tooling. By preserving layout and enabling structured extractions, it reduces custom parsing overhead and accelerates agent and RAG development. The family recipe preservation scenario illustrates how unstructured cultural artifacts become actionable digital knowledge.\n\n## Resources\n\n- [Code examples (Python & TypeScript)](https://github.com/Azure-Samples/insideAIF/tree/main/Samples/Mistral-Document-AI)\n- [Mistral Document AI 2505 Model Card on AI Foundry](https://ai.azure.com/catalog/models/mistral-document-ai-2505)\n- [Azure AI Partnership Blog](https://aka.ms/insideAIF/mistral-document-AI)\n- [Mistral OCR Announcement](https://mistral.ai/news/mistral-ocr)",
  "PubDate": "2025-11-06T14:15:35+00:00",
  "FeedLevelAuthor": "rss.livelink.threads-in-node",
  "OutputDir": "_community",
  "EnhancedContent": "Mistral Document AI (available as a serverless model in Azure AI Foundry) brings multimodal, layout‑aware document understanding directly into a developer workflow without provisioning GPUs. Instead of receiving only raw text from Optical Character Recognition (OCR), you obtain markdown plus optional structured annotations that preserve tables, headings, figures, and multilingual content. This structural preservation enables more accurate and reliable downstream automation for AI agents, RAG workflows, and compliance tasks.\n\n## Mistral Document AI\n\nMistral Document AI combines vision + language understanding to interpret complex page layouts. Compared to traditional OCR approaches, it maintains structural semantics: tables remain tables, figures are preserved, headings stay delineated, and mathematical or LaTeX elements are not flattened into ambiguous text. The model supports 25+ languages and handles PDFs and images (including scanned, mixed‑content pages) with high accuracy. Published benchmarks indicate superior layout fidelity and text extraction accuracy versus several large general models and legacy OCR engines\n\nKey capabilities:\n\n- **Robust layout understanding**. Detects document regions (headings, paragraphs, lists, tables, and figures) and preserves their relationships so downstream code can treat them as structured objects instead of flat text.\n- **Preserves document structure** and returns markdown plus optional JSON annotations (bounding boxes, fields, or custom schema).\n- **Broad language and style support.** Accurately extracts text across many languages and common font/handwriting variations, improving reliability on scanned, photocopied, or noisy documents.\n- **Doc‑as‑prompt support**. For Agent systems that require clean, structured output, you can pass the extracted document content directly to tool invocations, RAG pipelines or agents for extraction, classification, or summarization.\n- **Serverless**, low‑latency processing designed for single‑document and batch workflows.\n\nAssume you own a collection of old handwritten or scanned family recipe PDFs and images passed down through generations. You want to digitize these recipes into a structured format for easy access, sharing across relatives and meal planner/ shopping list generation tools.\n\nYour pipeline may look like this:\n\n1. Ingest document (image or PDF) → call Mistral Document AI → receive markdown/json pages.\n2. Parse markdown to extract key information: recipe title, ingredients, cooking instructions, cooking time etc.\n3. Derive a shopping list.\n4. Feed structured output into downstream agent (e.g, *Suggest ingredient substitutions* or *Generate weekly shopping consolidation*).\n\n## How to use it (TypeScript)\n\n### Pre-requisites\n\n- An Azure AI Foundry project\n- *mistral-document-ai-2505* model deployment\n\nSet up your *endpoint* and *API\\_key* in your environment variables. The full sample will be referenced at the end of this blog, but here’s a minimal explanation of the core logic.\n\n### Demo scenario: Recipe PDF/ Image → Structured Data → Shopping List\n\nThe code snippets below illustrate the key steps to process a recipe PDF using Mistral Document AI and extract structured data.\n\n- First, encode the PDF to base64, as document URL or image URL is not supported directly.\n- Then invoke the Mistral Document AI endpoint with the appropriate payload.\n- Finally, save and read the output JSON for post-processing.\n\n``` // Step 1 function encodePdfToBase64(pdfPath: string): string { const pdfContent = fs.readFileSync(pdfPath); return pdfContent.toString('base64'); }\n\nconst base64Content = encodePdfToBase64(pdfPath);\n\n// Step 2 const headers = { 'Content-Type': 'application/json', Authorization: `Bearer ${apiKey}` }; const payload = { model: modelName, document: { type: 'document_url', document_url: `data:application/pdf;base64,${base64Content}` }, include_image_base64: true, };\n\nconst response = await axios.post<DocumentAIResponse>(azureEndpoint!, payload, { headers });\n\n// Step 3 const outputFile = 'document_ai_result.json'; fs.writeFileSync(outputFile, JSON.stringify(result, null, 2), 'utf-8');\n\nconst jsonContent = fs.readFileSync(outputFile, 'utf-8'); ```\n\nExpected output:\n\nAfter OCR, we then proceed to extract structured recipe information (Ingredients, cooking steps, cooking time) and perform additional post-processing like normalization, for the shopping list.\n\nWith your data in structured JSON, you can now build applications or agents that leverage this knowledge. Here is an example of a simple app (Web Components) that implements the above end-to-end flow, allowing users to upload recipe documents and see extracted structured data and shopping lists.\n\n## Security, Privacy & Compliance\n\nRunning Mistral Document AI inside Azure AI Foundry provides:\n\n- Regional data residency as documents are processed inside your selected Azure region. Data is not forwarded to external third‑party endpoints beyond Azure’s managed hosting.\n- Enterprise isolation and governance alignment with standard Azure controls.\n- Ability to apply Responsible AI tooling (content filtering, monitoring) to downstream agent operations.\n- Content safety filters applied to document annotation outputs. Note that OCR output itself does not have content safety enforcement by default.\n- Selective self‑hosting for highly sensitive workloads, this way your data remains fully within your controlled environment.\n\nMistral Document AI enables a higher‑quality foundation for document‑driven AI features: better fidelity, multilingual support, structured outputs, and integration into Azure AI operational tooling. By preserving layout and enabling structured extractions, it reduces custom parsing overhead and accelerates agent and RAG development. The family recipe preservation scenario illustrates how unstructured cultural artifacts become actionable digital knowledge.\n\n## Resources\n\n- [Code examples (Python & TypeScript)](https://github.com/Azure-Samples/insideAIF/tree/main/Samples/Mistral-Document-AI)\n- [Mistral Document AI 2505 Model Card on AI Foundry](https://ai.azure.com/catalog/models/mistral-document-ai-2505)\n- [Azure AI Partnership Blog](https://aka.ms/insideAIF/mistral-document-AI)\n- [Mistral OCR Announcement](https://mistral.ai/news/mistral-ocr)\n\nUpdated Oct 31, 2025\n\nVersion 1.0\n\n[azure ai foundry](/tag/azure%20ai%20foundry?nodeId=board%3AAzureDevCommunityBlog)\n\n[llm](/tag/llm?nodeId=board%3AAzureDevCommunityBlog)\n\n[!\\[Julia_Muiruri&#x27;s avatar\\](https://techcommunity.microsoft.com/t5/s/gxcuf89792/images/dS0xMzgyMDcyLTQ5NzkwN2k5QkM2MEJCQzA5ODNDN0Iy?image-dimensions=50x50)](/users/julia_muiruri/1382072) [Julia_Muiruri](/users/julia_muiruri/1382072) ![Icon for Microsoft rank](https://techcommunity.microsoft.com/t5/s/gxcuf89792/images/cmstNC05WEo0blc?image-dimensions=100x16&amp;constrain-image=true)Microsoft\n\nJoined May 05, 2022\n\n[View Profile](/users/julia_muiruri/1382072)\n\n/category/azure/blog/azuredevcommunityblog [Microsoft Developer Community Blog](/category/azure/blog/azuredevcommunityblog) Follow this blog board to get notified when there's new activity",
  "FeedUrl": "https://techcommunity.microsoft.com/t5/s/gxcuf89792/rss/Category?category.id=Azure",
  "Title": "Unlock Structured OCR in TypeScript with Mistral Document AI on AI Foundry",
  "Author": "Julia_Muiruri"
}
