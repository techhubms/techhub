{
  "FeedLevelAuthor": "rss.livelink.threads-in-node",
  "FeedName": "Microsoft Tech Community",
  "OutputDir": "_community",
  "PubDate": "2025-11-18T16:18:11+00:00",
  "Title": "What's new in Azure Container Apps at Ignite'25",
  "Tags": [],
  "ProcessedDate": "2025-11-18 17:08:36",
  "EnhancedContent": "[Azure Container Apps (ACA)](https://aka.ms/aca) is a fully managed serverless container platform that enables developers to design and deploy microservices and modern apps without requiring container expertise or needing infrastructure management.\n\nACA is rapidly emerging as the preferred platform for hosting AI workloads and intelligent agents in the cloud. With features like code interpreter, Serverless GPUs, simplified deployments, and per-second billing, ACA empowers developers to build, deploy, and scale AI-driven applications with exceptional agility. ACA makes it easy to integrate agent frameworks, leverage GPU acceleration, and manage complex, multi-container AI environments - all while benefiting from a serverless, fully managed infrastructure. External customers like [Replit](https://replit.com/news/microsoft-partnership), [NFL Combine](https://www.microsoft.com/en/customers/story/23954-nfl-combine-azure-ai-foundry), [Coca-Cola](https://www.microsoft.com/en/customers/story/22668-coca-cola-company-azure-ai-and-machine-learning), and [European Space Agency](https://www.microsoft.com/en/customers/story/24004-terra-mater-studios-azure-ai-foundry) as well as internal teams like [Microsoft Copilot](https://techcommunity.microsoft.com/blog/appsonazureblog/azure-container-apps-dynamic-sessions-general-availability-and-more/4303561) (as well as many others) have bet on ACA as their compute platform for AI workloads.\n\nACA is quickly becoming the leading platform for updating existing applications and moving them to a cloud-native setup. It allows organizations to seamlessly migrate legacy workloads - such as Java and .NET apps - by [using AI-powered tools like GitHub Copilot](https://learn.microsoft.com/en-us/azure/container-apps/modernize-ai) to automate code upgrades, analyze dependencies, and handle cloud transformations. ACA’s fully managed, serverless environment removes the complexity of container orchestration. This helps teams break down monolithic or on-premises applications into robust microservices, making use of features like version control, traffic management, and advanced networking for fast iteration and deployment. By following proven modernization strategies while ensuring strong security, scalability, and developer efficiency, ACA helps organizations continuously innovate and future-proof their applications in the cloud. Customers like [EY, London Stock Exchange, Chevron, and Paychex](https://youtu.be/JvZU2pm43Ms) have unlocked significant business value by modernizing their workloads onto ACA.\n\nThis blog presents the latest features and capabilities of ACA, enhancing its value for customers by enabling the rapid migration of existing workloads and development of new cloud applications, all while following cloud-native best practices.\n\n## Secure sandboxes for AI compute\n\nACA now supports [dynamic shell sessions](https://aka.ms/aca/dynamic-sessions-mcp), currently available in public preview. These shell sessions are platform-managed built-in containers designed to execute common shell commands within an isolated, sandboxed environment. With the addition of empty shell sessions and an integrated MCP server, ACA enables customers to provision secure, isolated sandboxes instantly - ideal for use cases such as code execution, tool testing, and workflow automation. This functionality facilitates seamless integration with agent frameworks, empowering agents to access disposable compute environments as needed. Customers can benefit from rapid provisioning, improved security, and decreased operational overhead when managing agentic workloads. To learn more about how to add secure sandbox shell sessions to Microsoft Foundry agents as a tool, visit the walkthrough at [https://aka.ms/aca/dynamic-sessions-mcp-tutorial](https://aka.ms/aca/dynamic-sessions-mcp-tutorial).\n\n## Docker Compose for Agents support\n\nACA has added [Docker Compose for Agents support](https://aka.ms/aca/agentic-compose) in public preview, making it easy for developers to define agentic applications stack-agnostic, with MCP and custom model support. Combined with native serverless GPU support, Docker Compose for Agents allows fast iteration and scaling for AI-driven agents and application using LangGraph, LangChain CrewAI, Spring AI, Vercel AI SDK and Agno. These enhancements provide a developer-focused platform that streamlines the process for modern AI workloads, bringing together both development and production cycles into one unified environment.\n\n## Additional regional availability for Serverless GPUs\n\nServerless GPU solutions offer capabilities such as automatic scaling with NVIDIA A100 or T4 GPUs, per-second billing, and strict data isolation within container boundaries. ACA Serverless GPUs are now generally available in 11 additional regions, further facilitating developers’ ability to deploy AI inference, model training, and GPU-accelerated workloads efficiently. For further details on supported regions, please visit [https://aka.ms/aca/serverless-gpu-regions](https://aka.ms/aca/serverless-gpu-regions).\n\n## New Flexible Workload Profile\n\nThe [Flexible workload profile](https://learn.microsoft.com/en-us/azure/container-apps/workload-profiles-overview) is a new option that combines the simplicity of serverless Consumption with the performance and control in Dedicated profiles. It offers a familiar pay-per-use model along with enhanced features like scheduled maintenance, dedicated networking, and support for larger replicas to meet demanding application needs. Customers can enjoy the advantages of dedicated resources together with effortless infrastructure management and billing from the Consumption model. Operating on a dedicated compute pool, this profile ensures better predictability and isolation without introducing extra operational complexity. It is designed for users who want the ease of serverless scaling, but also need more control over performance and environmental stability.\n\n## Confidential Computing\n\n[Confidential computing support](https://aka.ms/aca/confidential-computing) is now available in public preview for ACA, offering hardware-based Trusted Execution Environments (TEEs) to secure data in use. This adds to existing encryption of data at rest and in transit by encrypting memory and verifying the cloud environment before processing. It helps protect sensitive data from unauthorized access, including by cloud operators, and is useful for organizations with high security needs. Confidential computing can be enabled via workload profiles, with the preview limited to certain regions.\n\n## Extending Network capabilities\n\n**General Availability of Rule-based Routing**\n\n[Rule-based routing for ACA](https://aka.ms/aca/rule-based-routing) is now generally available, offering users improved flexibility and easier composition when designing microservice architectures, conducting A/B testing, or implementing blue-green deployments. With this feature, you can route incoming HTTP traffic to specific apps within your environment by specifying host names or paths - including support for custom domains. You no longer need to set up an extra reverse proxy (like NGINX); simply define routing rules for your environment, and traffic will be automatically directed to the appropriate target apps.\n\n**General Availability of Premium Ingress**\n\n[ACA support for Premium Ingress](https://aka.ms/aca/premium-ingress-learn) is now Generally Available. This feature introduces environment-level ingress configuration options, with the primary highlight being customizable ingress scaling. This capability supports the scaling of the ingress proxy, enabling customers to better handle higher demand workloads, such as large performance tests. By configuring your ingress proxy to run on workload profiles, you can scale out more ingress instances to handle more load. Running the ingress proxy on a workload profile will incur associated costs.  To further enhance the flexibility of your application, this release includes other ingress-related settings, such as termination grace period, idle request timeout, and header count.\n\n## Additional Management capabilities\n\n**Public Preview of Deployment labels**\n\nACA now offers [deployment labels](https://aka.ms/aca/deploymentlabels) in public preview, letting you assign names like dev, staging, or prod to container revisions which can be automatically assigned. This makes environment management easier and supports advanced strategies such as A/B testing and blue-green deployments. Labels help route traffic, control revisions, and streamline rollouts or rollbacks with minimal hassle. With deployment labels, you can manage app lifecycles more efficiently and reduce complexity across environments.\n\n**General Availability of Durable Task Scheduler support**\n\nDurable Task Scheduler (DTS) support is now generally available on ACA, empowering users with a [robust pro-code workflow solution](https://learn.microsoft.com/en-us/azure/container-apps/workflows-overview). With DTS, you can define reliable, containerized workflows as code, benefiting from built-in state persistence and fault-tolerant execution. This enhancement streamlines the creation and administration of complex workflows by boosting scalability, reliability, and enabling efficient monitoring capabilities.\n\n## What’s next\n\nACA is redefining how developers build and deploy intelligent agents. Agents deployed to Azure Container Apps with Microsoft Agent Framework and Open Telemetry can also be [plugged directly into Microsoft Foundry](http://aka.ms/aca/agent-foundry-integration), giving teams a single pane of glass for their agents in Azure. With serverless scale, GPU-on-demand, and enterprise-grade isolation, ACA provides the ideal foundation for hosting AI agents securely and cost-effectively. Utilizing open-source frameworks such as [n8n on ACA](https://aka.ms/aca/n8n) enables the deployment of no-code automation agents that integrate seamlessly with Azure OpenAI models, supporting intelligent routing, summarization, and adaptive decision-making processes. Similarly, running other agent frameworks like [Goose AI Agent on ACA](https://aka.ms/aca/goose) enables it to operate concurrently with model inference workloads (including Ollama and GPT-OSS) within a unified, secure environment. The inclusion of serverless GPU support allows for efficient hosting of large language models such as GPT-OSS, optimizing both cost and scalability for inference tasks. Furthermore, ACA facilitates the [remote hosting of Model Context Protocol (MCP) servers](https://aka.ms/aca/remote-mcp-http), granting agents secure access to external tools and APIs via streamable HTTP transport. Collectively, these features enable organizations to develop, scale, and manage complex agentic workloads - from workflow automation to AI-driven assistants - while leveraging ACA’s enterprise-grade security, autoscaling capabilities, and developer-centric user experience.\n\nIn addition to these, ACA also enables a wide range of cross-compatibility with various frameworks and services, making it an ideal platform for running [Azure Functions on ACA](https://aka.ms/fnoncav2), [Distributed Application Runtime (Dapr) microservices](https://learn.microsoft.com/en-us/azure/container-apps/dapr-overview), as well as polyglot apps across [.NET](https://learn.microsoft.com/en-us/azure/container-apps/dotnet-overview) / [Java](https://learn.microsoft.com/en-us/azure/container-apps/java-overview) / [JavaScript](https://learn.microsoft.com/en-us/azure/container-apps/javascript-overview).\n\nAs always, we invite you to visit our [GitHub page](https://github.com/microsoft/azure-container-apps/issues) for feedback, feature requests, or questions about Azure Container Apps, where you can open a new issue or up-vote existing ones. If you’re curious about what we’re working on next, check out our [roadmap](https://aka.ms/aca/roadmap). We look forward to hearing from you!\n\nUpdated Nov 18, 2025\n\nVersion 1.0\n\n[.net](/tag/.net?nodeId=board%3AAppsonAzureBlog)\n\n[.net core](/tag/.net%20core?nodeId=board%3AAppsonAzureBlog)\n\n[azure container apps](/tag/azure%20container%20apps?nodeId=board%3AAppsonAzureBlog)\n\n[azure functions](/tag/azure%20functions?nodeId=board%3AAppsonAzureBlog)\n\n[azure paas](/tag/azure%20paas?nodeId=board%3AAppsonAzureBlog)\n\n[azure spring apps](/tag/azure%20spring%20apps?nodeId=board%3AAppsonAzureBlog)\n\n[cloud native](/tag/cloud%20native?nodeId=board%3AAppsonAzureBlog)\n\n[containers](/tag/containers?nodeId=board%3AAppsonAzureBlog)\n\n[java](/tag/java?nodeId=board%3AAppsonAzureBlog)\n\n[microservices](/tag/microservices?nodeId=board%3AAppsonAzureBlog)\n\n[!\\[vyomnagrani&#x27;s avatar\\](https://techcommunity.microsoft.com/t5/s/gxcuf89792/images/dS0xMzk2MzUyLTU4MjU3MmlCMDE1N0NDNTNFNzE3REE2?image-dimensions=50x50)](/users/vyomnagrani/1396352) [vyomnagrani](/users/vyomnagrani/1396352) ![Icon for Microsoft rank](https://techcommunity.microsoft.com/t5/s/gxcuf89792/images/cmstNC05WEo0blc?image-dimensions=100x16&amp;constrain-image=true)Microsoft\n\nJoined May 20, 2022\n\n[View Profile](/users/vyomnagrani/1396352)\n\n/category/azure/blog/appsonazureblog [Apps on Azure Blog](/category/azure/blog/appsonazureblog) Follow this blog board to get notified when there's new activity",
  "Author": "vyomnagrani",
  "Link": "https://techcommunity.microsoft.com/t5/apps-on-azure-blog/what-s-new-in-azure-container-apps-at-ignite-25/ba-p/4470391",
  "FeedUrl": "https://techcommunity.microsoft.com/t5/s/gxcuf89792/rss/Category?category.id=Azure",
  "Description": "[Azure Container Apps (ACA)](https://aka.ms/aca) is a fully managed serverless container platform that enables developers to design and deploy microservices and modern apps without requiring container expertise or needing infrastructure management.\n\nACA is rapidly emerging as the preferred platform for hosting AI workloads and intelligent agents in the cloud. With features like code interpreter, Serverless GPUs, simplified deployments, and per-second billing, ACA empowers developers to build, deploy, and scale AI-driven applications with exceptional agility. ACA makes it easy to integrate agent frameworks, leverage GPU acceleration, and manage complex, multi-container AI environments - all while benefiting from a serverless, fully managed infrastructure. External customers like [Replit](https://replit.com/news/microsoft-partnership), [NFL Combine](https://www.microsoft.com/en/customers/story/23954-nfl-combine-azure-ai-foundry), [Coca-Cola](https://www.microsoft.com/en/customers/story/22668-coca-cola-company-azure-ai-and-machine-learning), and [European Space Agency](https://www.microsoft.com/en/customers/story/24004-terra-mater-studios-azure-ai-foundry) as well as internal teams like [Microsoft Copilot](https://techcommunity.microsoft.com/blog/appsonazureblog/azure-container-apps-dynamic-sessions-general-availability-and-more/4303561) (as well as many others) have bet on ACA as their compute platform for AI workloads.\n\nACA is quickly becoming the leading platform for updating existing applications and moving them to a cloud-native setup. It allows organizations to seamlessly migrate legacy workloads - such as Java and .NET apps - by [using AI-powered tools like GitHub Copilot](https://learn.microsoft.com/en-us/azure/container-apps/modernize-ai) to automate code upgrades, analyze dependencies, and handle cloud transformations. ACA’s fully managed, serverless environment removes the complexity of container orchestration. This helps teams break down monolithic or on-premises applications into robust microservices, making use of features like version control, traffic management, and advanced networking for fast iteration and deployment. By following proven modernization strategies while ensuring strong security, scalability, and developer efficiency, ACA helps organizations continuously innovate and future-proof their applications in the cloud. Customers like [EY, London Stock Exchange, Chevron, and Paychex](https://youtu.be/JvZU2pm43Ms) have unlocked significant business value by modernizing their workloads onto ACA.\n\nThis blog presents the latest features and capabilities of ACA, enhancing its value for customers by enabling the rapid migration of existing workloads and development of new cloud applications, all while following cloud-native best practices.\n\n## Secure sandboxes for AI compute\n\nACA now supports [dynamic shell sessions](https://aka.ms/aca/dynamic-sessions-mcp), currently available in public preview. These shell sessions are platform-managed built-in containers designed to execute common shell commands within an isolated, sandboxed environment. With the addition of empty shell sessions and an integrated MCP server, ACA enables customers to provision secure, isolated sandboxes instantly - ideal for use cases such as code execution, tool testing, and workflow automation. This functionality facilitates seamless integration with agent frameworks, empowering agents to access disposable compute environments as needed. Customers can benefit from rapid provisioning, improved security, and decreased operational overhead when managing agentic workloads. To learn more about how to add secure sandbox shell sessions to Microsoft Foundry agents as a tool, visit the walkthrough at [https://aka.ms/aca/dynamic-sessions-mcp-tutorial](https://aka.ms/aca/dynamic-sessions-mcp-tutorial).\n\n![]()\n\n## Docker Compose for Agents support\n\nACA has added [Docker Compose for Agents support](https://aka.ms/aca/agentic-compose) in public preview, making it easy for developers to define agentic applications stack-agnostic, with MCP and custom model support. Combined with native serverless GPU support, Docker Compose for Agents allows fast iteration and scaling for AI-driven agents and application using LangGraph, LangChain CrewAI, Spring AI, Vercel AI SDK and Agno. These enhancements provide a developer-focused platform that streamlines the process for modern AI workloads, bringing together both development and production cycles into one unified environment.\n\n![]()\n\n## Additional regional availability for Serverless GPUs\n\nServerless GPU solutions offer capabilities such as automatic scaling with NVIDIA A100 or T4 GPUs, per-second billing, and strict data isolation within container boundaries. ACA Serverless GPUs are now generally available in 11 additional regions, further facilitating developers’ ability to deploy AI inference, model training, and GPU-accelerated workloads efficiently. For further details on supported regions, please visit [https://aka.ms/aca/serverless-gpu-regions](https://aka.ms/aca/serverless-gpu-regions).\n\n## New Flexible Workload Profile\n\nThe [Flexible workload profile](https://learn.microsoft.com/en-us/azure/container-apps/workload-profiles-overview) is a new option that combines the simplicity of serverless Consumption with the performance and control in Dedicated profiles. It offers a familiar pay-per-use model along with enhanced features like scheduled maintenance, dedicated networking, and support for larger replicas to meet demanding application needs. Customers can enjoy the advantages of dedicated resources together with effortless infrastructure management and billing from the Consumption model. Operating on a dedicated compute pool, this profile ensures better predictability and isolation without introducing extra operational complexity. It is designed for users who want the ease of serverless scaling, but also need more control over performance and environmental stability.\n\n## Confidential Computing\n\n[Confidential computing support](https://aka.ms/aca/confidential-computing) is now available in public preview for ACA, offering hardware-based Trusted Execution Environments (TEEs) to secure data in use. This adds to existing encryption of data at rest and in transit by encrypting memory and verifying the cloud environment before processing. It helps protect sensitive data from unauthorized access, including by cloud operators, and is useful for organizations with high security needs. Confidential computing can be enabled via workload profiles, with the preview limited to certain regions.\n\n## Extending Network capabilities\n\n**General Availability of Rule-based Routing**\n\n[Rule-based routing for ACA](https://aka.ms/aca/rule-based-routing) is now generally available, offering users improved flexibility and easier composition when designing microservice architectures, conducting A/B testing, or implementing blue-green deployments. With this feature, you can route incoming HTTP traffic to specific apps within your environment by specifying host names or paths - including support for custom domains. You no longer need to set up an extra reverse proxy (like NGINX); simply define routing rules for your environment, and traffic will be automatically directed to the appropriate target apps.\n\n**General Availability of Premium Ingress**\n\n[ACA support for Premium Ingress](https://aka.ms/aca/premium-ingress-learn) is now Generally Available. This feature introduces environment-level ingress configuration options, with the primary highlight being customizable ingress scaling. This capability supports the scaling of the ingress proxy, enabling customers to better handle higher demand workloads, such as large performance tests. By configuring your ingress proxy to run on workload profiles, you can scale out more ingress instances to handle more load. Running the ingress proxy on a workload profile will incur associated costs. To further enhance the flexibility of your application, this release includes other ingress-related settings, such as termination grace period, idle request timeout, and header count.\n\n## Additional Management capabilities\n\n**Public Preview of Deployment labels**\n\nACA now offers [deployment labels](https://aka.ms/aca/deploymentlabels) in public preview, letting you assign names like dev, staging, or prod to container revisions which can be automatically assigned. This makes environment management easier and supports advanced strategies such as A/B testing and blue-green deployments. Labels help route traffic, control revisions, and streamline rollouts or rollbacks with minimal hassle. With deployment labels, you can manage app lifecycles more efficiently and reduce complexity across environments.\n\n![]()\n\n**General Availability of Durable Task Scheduler support**\n\nDurable Task Scheduler (DTS) support is now generally available on ACA, empowering users with a [robust pro-code workflow solution](https://learn.microsoft.com/en-us/azure/container-apps/workflows-overview). With DTS, you can define reliable, containerized workflows as code, benefiting from built-in state persistence and fault-tolerant execution. This enhancement streamlines the creation and administration of complex workflows by boosting scalability, reliability, and enabling efficient monitoring capabilities.\n\n## What’s next\n\nACA is redefining how developers build and deploy intelligent agents. Agents deployed to Azure Container Apps with Microsoft Agent Framework and Open Telemetry can also be [plugged directly into Microsoft Foundry](http://aka.ms/aca/agent-foundry-integration), giving teams a single pane of glass for their agents in Azure. With serverless scale, GPU-on-demand, and enterprise-grade isolation, ACA provides the ideal foundation for hosting AI agents securely and cost-effectively. Utilizing open-source frameworks such as [n8n on ACA](https://aka.ms/aca/n8n) enables the deployment of no-code automation agents that integrate seamlessly with Azure OpenAI models, supporting intelligent routing, summarization, and adaptive decision-making processes. Similarly, running other agent frameworks like [Goose AI Agent on ACA](https://aka.ms/aca/goose) enables it to operate concurrently with model inference workloads (including Ollama and GPT-OSS) within a unified, secure environment. The inclusion of serverless GPU support allows for efficient hosting of large language models such as GPT-OSS, optimizing both cost and scalability for inference tasks. Furthermore, ACA facilitates the [remote hosting of Model Context Protocol (MCP) servers](https://aka.ms/aca/remote-mcp-http), granting agents secure access to external tools and APIs via streamable HTTP transport. Collectively, these features enable organizations to develop, scale, and manage complex agentic workloads - from workflow automation to AI-driven assistants - while leveraging ACA’s enterprise-grade security, autoscaling capabilities, and developer-centric user experience.\n\nIn addition to these, ACA also enables a wide range of cross-compatibility with various frameworks and services, making it an ideal platform for running [Azure Functions on ACA](https://aka.ms/fnoncav2), [Distributed Application Runtime (Dapr) microservices](https://learn.microsoft.com/en-us/azure/container-apps/dapr-overview), as well as polyglot apps across [.NET](https://learn.microsoft.com/en-us/azure/container-apps/dotnet-overview) / [Java](https://learn.microsoft.com/en-us/azure/container-apps/java-overview) / [JavaScript](https://learn.microsoft.com/en-us/azure/container-apps/javascript-overview).\n\nAs always, we invite you to visit our [GitHub page](https://github.com/microsoft/azure-container-apps/issues) for feedback, feature requests, or questions about Azure Container Apps, where you can open a new issue or up-vote existing ones. If you’re curious about what we’re working on next, check out our [roadmap](https://aka.ms/aca/roadmap). We look forward to hearing from you!"
}
