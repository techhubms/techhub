{
  "Author": "BonnieAo",
  "OutputDir": "_community",
  "ProcessedDate": "2025-12-04 21:05:10",
  "Link": "https://techcommunity.microsoft.com/t5/analytics-on-azure-blog/architecting-the-next-generation-customer-tiering-system/ba-p/4475326",
  "Tags": [],
  "Description": "| **Authors**<br><br><br><br>[Sailing Ni](https://www.linkedin.com/in/sailing-ni-b5ab76180/)\\*, [Joy Yu](https://www.linkedin.com/in/joy-yu-hi/)\\*, Peng Yang\\*, [Richard Sie](https://www.linkedin.com/in/richard-sie/)\\*, [Yifei Wang](https://www.linkedin.com/in/russell-yifeiwang/)\\*<br>*\\*These authors contributed equally.*<br><br><br><br>**Affiliation**<br>Master of Science in Business Analytics (MSBA),<br>UCLA Anderson School of Management,<br>Los Angeles, California 90095, United States<br>*(Conducted December 2025)*<br><br><br><br>**Acknowledgment**<br>This research was conducted as part of a Microsoft-sponsored Capstone Project, led by [Juhi Singh](https://www.linkedin.com/in/singhj73/) and [Bonnie Ao](https://www.linkedin.com/in/bonnie-ao-5360b518b/) from the Microsoft MCAPS AI Transformation Office. | | --- |\n\nMicrosoft‚Äôs global B2B software business classifies customers into four tiers to guide coverage, investment, and sales strategy. However, the legacy tiering framework mixes historical rules with manual heuristics, causing several issues:\n\n- Tiers do not consistently reflect customer potential or revenue importance.\n- Statistical coherence and business KPIs (TPA, TCI, SFI) are not optimized or enforced.\n- Tier distributions are imbalanced due to legacy ¬±1 movement and capacity rules.\n- Sales coverage planning depends on a tier structure not grounded in data.\n\nTo address these limitations, we, UCLA Anderson MSBA class of Dec'25, designed a next-generation KPI-driven tiering architecture. Our objective was to move from a heuristic, static system toward a scalable, transparent, and business-aligned framework. Our redesigned tiering system follows five complementary analytical layers, each addressing a specific gap in the legacy process:\n\n- Natural Segmentation (Unsupervised Baseline): Identify the intrinsic structure of the customer base using clustering to understand how customers naturally group\n- Pure KPI-Based Tiering (Upper-Bound Benchmark): Show what tiers would look like if aligned *only* to business KPIs, quantifying the maximum potential lift and exposing trade-offs.\n- Hybrid KPI-Aware Segmentation (Our Contribution): Integrate clustering geometry with KPI optimization and business constraints to produce a realistic, interpretable, and deployable tiering system.\n- Dynamic Tiering (Longitudinal Diagnostics): Analyze historical patterns to understand how companies evolve over time, separating structural tier drift from noise.\n- Optimization & Resource Allocation (Proof of Concept): Demonstrate how the new tiers could feed into downstream coverage and whitespace prioritization through MIP- and heuristic-based approaches.\n\nTogether, these components answer a core strategic question:\n\n‚ÄúHow should Microsoft tier its global customer base so that investment, coverage, and growth strategy directly reflect business value?‚Äù\n\nOur final architecture transforms tiering from a static classification exercise into a KPI-driven, interpretable, and operationally grounded decision framework suitable for Microsoft‚Äôs future AI and data strategy.\n\n###### **Solution Architecture Diagram**\n\n![]()Fig 1. Solution Architecture Diagram\n\n###### **1. Success Metrics Definition**\n\nBefore designing any segmentation system, the first step is to establish success metrics that define what ‚Äúgood‚Äù looks like. Without these metrics, models can easily produce clusters that are statistically neat but misaligned with business needs. A clear KPI framework ensures that every model‚Äîregardless of method or complexity‚Äîis evaluated consistently on both analytical quality and real business impact.\n\nWe define success across two complementary dimensions:\n\n1.1 Alignment & Segmentation Quality:\n\nThese metrics evaluate whether the segmentation meaningfully separates customers based on business potential.\n\n1.1.1 Tier Potential Alignment (TPA)\n\nMeasures how well assigned tiers follow the rank order of *PI\\_acct*, our composite indicator of future growth potential. Implemented as a Spearman rank correlation, TPA tests whether higher-potential accounts systematically land in higher tiers.\n\nStep 1 - Formula for PI\\_acct (Potential Index per Account)\n\n![]()![]()\n\nStep 2 - Formula for TPA (Tier Potential Alignment)\n\n![]()\n\n- ùúå\\_ùë† = Spearman rank correlation\n- Tier Rank = ordinal tier number (Tier A = highest ‚Üí Tier D = lowest)\n\nInterpretation:\n\n- TPA=1 ‚áí Perfect alignment (higher potential ‚Üí higher tier)\n- TPA=0 ‚áí No statistical relationship\n- TPA\n\n1.1.2 Tier Compactness Index (TCI)\n\nMeasures how homogeneous each tier is. Low within-tier variance on *PI\\_acct* or Revenue indicates that customers grouped together truly share similar characteristics, improving interpretability and resource planning.\n\n(1) Potential-based Compactness - TCI\\_PI\n\n![]()\n\n(2) Revenue-based Compactness - TCI\\_REV\n\n![]()\n\n- TCI=1 ‚áí tiers are tight and well-separated\n- TCI=0 ‚áí tiers are random or overlapping\n- TCI\n\n1.2 Business Impact\n\nThese metrics test whether the segmentation supports strategic goals, not just statistical structure.\n\n1.2.1 Strategic Focus Index (SFI)\n\nQuantifies how much revenue comes from the company‚Äôs most strategically important tiers. High SFI means segmentation helps focus investments‚Äîsales coverage, specialist time, programs‚Äîon the customers that matter most.\n\nUnder the Tier Policy framework, the definition of ‚Äústrategic‚Äù automatically adapts to the number of tiers K - for example, taking the top L tiers (e.g., top 2) or top x % of tiers ranked by mean potential or revenue.\n\n![]()\n\n- High SFI: strong emphasis on top strategic segments (potentially efficient but watch concentration risk).\n- Moderate SFI: balanced focus across tiers.\n- Low SFI: diffuse portfolio, limited emphasis on priority segment\n\n1. **Static Segmentation**\n\n2.1 Pure Unsupervised Clustering\n\n2.1.1 Model Conclusions at a Glance\n\nAcross all unsupervised models evaluated‚ÄîWard, Weighted Ward, K-Medoids, K-Means / K-Means++, and HDBSCAN ‚Äî only the Ward model (K=4, Policy v2) provides a segmentation that is simultaneously:\n\n- statistically coherent,\n- business-aligned (high SFI),\n- geometrically stable (clean Silhouette), and\n- operationally interpretable.\n\nAll alternative models either distort cluster geometry, collapse SFI, or produce unstable/illogical tier structures. Final Recommendation**:** Use Ward (K=4, Policy v2) as the natural segmentation baseline.\n\n2.1.2 High-Level Algorithm Comparison\n\nTable 1. Algorithm Comparison\n\n| **Model** | **Algorithm Summary** | **Strengths** | **Weaknesses** | **Business Use** | | --- | --- | --- | --- | --- | | **Ward** | Variance-minimizing hierarchical merges | Best balance of TPA/TCI/SFI; stable geometry | Sensitive to correlated features | Primary model for segmentation | | **Weighted Ward** | Distance reweighted by PI + revenue | Higher TPA | Silhouette collapse; unstable | Not recommended | | **K-Medoids** | Medoid-based dissimilarity minimization | Robust to outliers | Cluster compression; weak SFI | Diagnostic only | | **K-Means / K-Means++** | Squared-distance minimization | Fast baseline | SFI collapse; over-tight clusters | Numeric benchmark only | | **HDBSCAN** | Density-based clustering with noise | Good for anomaly detection | TPA collapse; noisy tiers; broken PI ordering | Not suitable for tiering |\n\n2.1.3 Modeling Results\n\nTable 2. Unsupervised Clustering Model Results\n\n| Metric | FY26 Baseline (Legacy A+B) | Ward K=4 (Policy v2) | Weighted Ward2-B (Œ±=4, Œ≤=0.8, s=0.7, K=5) | Unweighted Ward (Policy v2, K=4) | Unweighted Ward (Policy v2, K=3) | K-Medoids B4 Behavior-only (K=3) | K-means K=4 (Policy v2) | K-means++ K=4 (Policy v2) | HDBSCAN (baseline settings) | | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | | **TPA** | 0.260 | 0.260 | 0.860 | 0.260 | 0.300 | 0.520 | 0.310 | 0.310 | 0.040 | | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | | **TCI\\_PI** | 0.222 | 0.461 | 0.772 | 0.461 | 0.405 | 0.173 | 0.476 | 0.476 | 0.004 | | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | | **TCI\\_REV** | 0.469 | 0.801 | 0.640 | 0.801 | 0.672 | 0.002 | 0.831 | 0.831 | 0.062 | | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | | **SFI** | 0.807 | 0.868 | 0.817 | 0.868 | 0.960 | 0.656 | 0.332 | 0.332 | 0.719 | | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | | **Silhouette** | nan | 0.560 | 0.145 | 0.560 | 0.604 | 0.466 | 0.523 | 0.523 | 0.186 | | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n\n- Ward (K=4, Policy v2) remains the strongest performer: SFI ‚âà 0.87, Silhouette ‚âà 0.56, stable geometric structure.\n- Weighted Ward raises TPA/PI slightly but Silhouette collapses (~0.15) ‚Üí structural instability ‚Üí not viable.\n- K-Medoids consistently compresses clusters; TPA/TCI gain is offset by TCI\\_REV collapse and low SFI.\n- K-Means / K-Means++ tighten numeric clusters but SFI drops to ~0.33 ‚Üí tiers lose strategic meaning.\n- HDBSCAN generates large noisy segments; TPA = 0.044, TCI\\_PI = 0.004, Silhouette = 0.186, and Tier A/B contain negative PI ‚Üí fundamentally unsuitable.\n\nConclusion: Only Ward (K=4) produces segmentation with both statistical integrity and business relevance.\n\n2.1.4 Implications, Limitations, Next Steps\n\nImplications\n\nOur current unsupervised segmentation delivers statistically coherent and operationally usable tiers, but several structural findings emerged:\n\n1. Unsupervised methods reveal the data‚Äôs natural shape, not business priorities.\n2. Ward/K-means/HDBSCAN can discover separations in the feature space but cannot move clusters toward preferred PI or revenue patterns.\n3. Cluster outcomes cannot guarantee business-desired constraints.\n- If Tier A‚Äôs PI mean is too low, the model cannot raise it.\n- If Tier C becomes too large, clustering cannot rebalance it.\n- If the business wants stronger SFI, clustering alone cannot optimize that objective.\n4. For example:\n5. Some business-critical metrics are only evaluated *after* clustering, not optimized *within* clustering.\n6. Tier size distributions, average PI per tier, and revenue share are structurally important but not part of the unsupervised objective.\n\nHence,\n\nUnsupervised clustering provides a statistically coherent view of the data‚Äôs natural structure, but it cannot guarantee business-preferred tier outcomes. The models cannot enforce hard constraints (e.g., desired A/B/C distribution, monotonic PI means, revenue share targets), nor can they adjust tiers when PI is too low or clusters become imbalanced. Additionally, key tier-level KPIs‚Äîsuch as average PI per tier, tier size stability, and revenue distribution‚Äîare only evaluated *after* clustering rather than optimized during it, limiting their influence on the final tier design.\n\nTo overcome these structural limitations, the next stage of the system must incorporate semi-supervised guidance and policy-based optimization, where business KPIs directly shape tier boundaries and ranking. Future iterations will expand the policy beyond PI and revenue to include behavioral and market signals and bring tier-level metrics into the objective function to better align the segmentation with real-world operational priorities.\n\n2.2 Semi-supervised KPI-Driven Learning\n\nComposite Score ‚Äî KPI-Driven Objective for Tiering\n\nTo guide our semi-supervised and hybrid methods, we define a Composite Score that unifies Microsoft‚Äôs key business KPIs into a single optimization target. It ensures that all modeling layers‚ÄîPure KPI-Based Tiering and Hybrid KPI-Aware Segmentation‚Äîoptimize toward the same business priorities. Unsupervised clustering cannot optimize business outcomes. A composite objective is needed to consistently evaluate and improve tiering performance across:\n\n- Potential uplift (TPA)\n- Stability of tier structure (SFI)\n- Within-tier improvement (TCI\\_PI)\n- Revenue scale (TCI\\_REV)\n\nTo align tiering with business priorities, we summarize four key KPIs‚ÄîTPA, SFI, TCI\\_PI, and TCI\\_REV‚Äîinto one normalized measure:\n\nComposite Score = 0.35√óTPA + 0.35√óSFI + 0.30√ó(TCI\\_PI + TCI\\_REV)\n\nThis score provides a single benchmark for comparing methods and serves as the optimization target in our semi-supervised and hybrid approaches.\n\nHow It Is Used\n\n- Benchmarking: Compare all methods on a unified scale.\n- Optimization: Serves as the objective in constrained local search (Method 3).\n- Rule Learning: Guides the decision-tree logic extracted after optimization.\n\nWhy It Matters\n\nThe Composite Score centers the analysis around a single question: ‚ÄúWhich tiering structure creates the strongest balance of growth potential, stability, and revenue impact?‚Äù\n\n2.3 Pure KPI-Based Tiering\n\n2.3.1 Model Conclusions at a Glance\n\nPure KPI-based tiering shows what the tiers would look like if Microsoft prioritized business KPIs above all else. It achieves the largest KPI improvements, but causes major distribution shifts and violates movement rules, making it operationally unrealistic.\n\nFinal takeaway: Pure KPI tiering is a valuable benchmark for understanding KPI potential, but cannot be operationalized.\n\n2.3.2 High-Level Algorithm Summary\n\nTable 3. Methods of KPI-Based Tiering\n\n| Method | Algorithm Summary | Strengths | Weaknesses | Business Use | | --- | --- | --- | --- | --- | | **New\\_Tier\\_Direct**(PI ranking only) | Rank accounts by PI/KPI score and assign tiers directly | **Highest KPI gains**; preserves overall tier distribution | Moves **~20‚Äì40%** companies; violates ¬±1 rule; disrupts continuity | KPI upper-bound benchmark | | --- | --- | --- | --- | --- | | **Tier\\_PI\\_Constrained**(PI ranking + ¬±1 rule) | Same as above but restrict movement to adjacent tiers | KPI lift + respects movement constraint | Still moves **~20‚Äì40%;** breaks tier distribution (Tier C inflation) | Diagnostic only | | --- | --- | --- | --- | --- |\n\n2.3.3 Modeling Results\n\nTable 4. Modeling Results for KPI-Based Tiering\n\n| KPI | FY26 Baseline | New\\_Tier\\_Direct | Tier\\_PI\\_Constrained | | --- | --- | --- | --- | | Composite Score | 0.5804 | 0.8105 | 0.763 | | TPA | 0.2590 | 0.8300 | 0.721 | | TCI\\_PI | 0.2220 | 0.5360 | 0.492 | | TCI\\_REV | 0.4690 | 0.3970 | 0.452 | | SFI | 0.8070 | 0.6860 | 0.650 |\n\nNew\\_Tier\\_Direct\n\n- Composite Score: 0.5804 ‚Üí 0.8105\n- TPA increases sharply (0.259 ‚Üí 0.830)\n- Violates ¬±1 rule; major reassignments (~20%‚Äì40%)\n\nTier\\_PI\\_Constrained\n\n- Respects ¬±1 movement\n- KPI still improves (Composite 0.763)\n- But tier distribution collapses (Tier C over-expands)\n- Still ~20‚Äì40% movement ‚Üí not feasible\n\nHence: No PI-only method balances KPI lift with operational feasibility.\n\n2.3.4 Limitations & Next Steps\n\nPure KPI tiering cannot simultaneously:\n\n- preserve tier distribution,\n- respect ¬±1 movement rule, and\n- deliver consistent KPI improvements.\n\nThis creates the need for a hybrid model that combines clustering structure with KPI-aligned tier ordering.\n\n2.4 Hybrid KPI-Aware Segmentation (Our Contribution)\n\n2.4.1 Model Conclusions at a Glance\n\nOur hybrid method blends clustering geometry with KPI-driven optimization, achieving a practical balance between:\n\n- statistical structure,\n- business constraints, and\n- KPI improvement.\n\nFinal Recommendation: This is the segmentation framework we recommend Microsoft to adopt.\n\n‚ûî It produces the most deployable segmentation by balancing KPI lift with stability and interpretability.\n\n‚ûî Delivers meaningful KPI improvement while changing only ~5% of accounts, compared to Model B‚Äôs 20‚Äì40%.\n\n2.4.2 High-Level Algorithm Summary\n\nTable 5. Algorithm Comparison\n\n| **Component** | **Purpose** | **Strengths** | **Notes** | | --- | --- | --- | --- | | **Constrained Local Search** | Optimize composite KPI score starting from FY26 tiers | KPI uplift with strict constraints | Only small movements allowed (~5%) | | **Tier Movement Constraint (+1/‚Äì1)** | Ensure realistic transitions | Guarantees business rules; keeps structure stable | Limits improvement ceiling | | **Decision Tree** | Learn interpretable rules from optimized tiers | Deployable, explainable, reusable | Accuracy ~80%; tunable with weighting | | **Closed Loop Optimization** | Improve both rules and allocation iteratively | Stable + interpretable | Future extension |\n\n2.4.3 Modeling Results\n\nTable 6. Modeling Results for Hybrid Segmentation\n\n| KPI | FY26 Baseline | New\\_Tier\\_Direct | Tier\\_PI\\_Constrained | ImprovedTier | | --- | --- | --- | --- | --- | | Composite Score | 0.5804 | 0.8105 | 0.763 | 0.6512 | | TPA | 0.2590 | 0.8300 | 0.721 | 0.2990 | | TCI\\_PI | 0.2220 | 0.5360 | 0.492 | 0.3450 | | TCI\\_REV | 0.4690 | 0.3970 | 0.452 | 0.5250 | | SFI | 0.8070 | 0.6860 | 0.650 | 0.8160 |\n\n![]()\n\nFig 2. Visualization of Decision Tree\n\n![]()\n\nFig 3. Explanation of Decision Tree\n\nInterpretation of Hybrid Model (Improved Tier)\n\n- Composite Score: 0.5804 ‚Üí 0.6512\n- TPA improvement (0.259 ‚Üí 0.299)\n- TCI\\_PI and TCI\\_REV both rise\n- SFI improves compared to constrained PI method\n- Only ~5% of companies move tiers, versus Method 2‚Äôs 20‚Äì40%\n\nThis makes Method 3 the only method that simultaneously satisfies:\n\n- KPI improvement\n- original tier distribution\n- ¬±1 movement rule\n- low operational disruption\n- interpretability (via decision tree)\n\n2.4.4 Conclusion\n\nModel C offers a pragmatic middle ground: KPI lift close to pure PI tiering, operational impact close to clustering, and full interpretability.\n\nFor Microsoft, this hybrid framework is the most realistic and sustainable segmentation approach\n\n###### **3. Dynamic Tier Progression**\n\n3.1 Model Conclusions at a Glance\n\nOur benchmarking shows that CatBoost and XGBoost consistently deliver the strongest overall performance, achieving the highest macro-F1 (~0.76) across all tested methods. However, despite these gains, the underlying business pattern remains dominant: tier changes are extremely rare (‚âà5.4%), and Microsoft‚Äôs one-step movement rule severely limits model learnability.\n\nDynamic tiering is far more valuable as a diagnostic signal generator than a strict forecasting engine. While models cannot reliably predict future tier transitions, they can surface atypical account patterns, signals of risk, and emerging opportunities that support earlier sales intervention and more proactive account planning.\n\n3.2 Models\n\nTo predict future model upgrades and downgrades, we tested the following models:\n\nTable 7. Models Used for Dynamic Prediction\n\n| **Model** | **Strengths** | **Weaknesses** | **When to Use** | | --- | --- | --- | --- | | MLR | Simple; interpretable; fast baseline | Weak on imbalanced data | When transparency and explainability are needed | | Neural Network | Captures nonlinear patterns; stronger recall than MLR | Requires tuning; sensitive to imbalance data | When exploring richer behavioral signals | | CatBoost (baseline, weighted, oversampled) | Strongest overall balance; robust with categorical data; best macro-F1 | Still limited by rarity of tier changes; weighted/oversampled versions risk overfitting | Default diagnostic model for surfacing atypical account patterns | | XGBoost (baseline, weighted) | High performance; scalable; production-ready | Limited by structural imbalance; weighted versions increase false positives | When deploying a stable scoring layer to sales teams |\n\nPerformance was then measured using accuracy, but more importantly, macro recall, precision, and F1, since upgrades and downgrades are much rarer and require balanced evaluation.\n\n3.3 Model Results\n\nAcross all models, overall accuracy appears high (0.95‚Äì0.97), but this metric is dominated by the fact that Tier transitions are extremely rare ‚Äî only 808 of 15,000 cases (5.4%) moved tiers, while 95% stayed unchanged. According to macro metrics such as recall, precision, and F1, every model struggles to reliably detect upgrades and downgrades.\n\nCatBoost and XGBoost deliver the strongest balanced results, achieving the highest macro F1 scores (~0.76). However, even these advanced methods only capture half or fewer of the true upgrade and downgrade events. This reinforces that the challenge is not algorithmic performance, but the underlying business pattern: tier movements are infrequent, policy-driven, and weakly connected to observable account features.\n\nTable 8. Results for Dynamic Prediction\n\n| **Model** | **Accuracy** | **Macro** | | --- | --- | --- | | **Recall** | **Precision** | **F1 Score** | | **MLR** | 0.95 | 0.36 | 0.70 | 0.37 | | **Neural Network** | 0.95 | 0.58 | 0.71 | 0.63 | | **CatBoost** | 0.97 | 0.94 | 0.67 | 0.76 | | **CatBoost (Weighted)** | 0.82 | 0.49 | 0.82 | 0.54 | | **CatBoost (Oversampling)** | 0.69 | 0.42 | 0.75 | 0.42 | | **XGBoost** | 0.97 | 0.93 | 0.67 | 0.76 | | **XGBoost (Weighted)** | 0.97 | 0.85 | 0.70 | 0.76 |\n\n3.4 Dynamic Tiering Implications\n\nBased on the results, our dynamic tiering will have the following implications to Microsoft:\n\n- Tier changes are not reliably forecastable under current rules.\n\nYear-over-year stability is so dominant that even strong ML models cannot surface consistent upgrade or downgrade signals. This suggests that transitions are driven more by sales judgment and tier policy than by measurable account behavior.\n\n- The dynamic model is still valuable: just not as a predictor of future tiers.\n\nRather than serving as a forecasting engine, this pipeline should be viewed as a diagnostic tool that helps identify accounts with unusual patterns, emerging risks, or outlier behavior worth reviewing.\n\n- Dynamic progression complements, rather than replaces, the core segmentation.\n\nIt provides an additional layer of insight alongside clustering and KPI-optimized segmentation, helping Microsoft maintain both structural clarity (static segmentation) and forward-looking awareness (dynamic progression).\n\n###### **4. Optimization in Practice**\n\nTo understand how segmentation could support downstream coverage planning, we developed a small optimization proof-of-concept using Microsoft‚Äôs seller‚Äìtier capacity guidelines (e.g., max accounts per role √ó tier, geo-entity restrictions, in-person vs remote coverage rules).\n\n4.1 What We Explored\n\nUsing our final hybrid segmentation (Method 3), we tested a simplified workflow:\n\n- Formulate a coverage optimization problem\n\n‚óã Assign sellers to accounts under constraints such as:\n\n- - - role √ó tier capacity limits,\n- single-geo assignment,\n- ¬±1 tier movement rules,\n- domain restrictions for Tier C/D.\n\n‚óã This naturally forms a mixed-integer optimization problem (MIP).\n\n- Prototype with standard optimization tools\n\n‚óã Linear and integer programming formulations using Gurobi, OR-Tools, and Pyomo.\n\n‚óã Heuristic solvers (e.g., local search, greedy reallocation, hill climbing) as faster alternatives.\n\n- Simulate coverage scenarios\n\n‚óã Estimate changes in workload balance and whitespace prioritization under different seller‚Äìtier mixes.\n\n‚óã Validate feasibility of the optimization with respect to Microsoft‚Äôs operational rules.\n\n4.2 What We Learned\n\nDue to limited operational metrics (detailed whitespace values, upgrade probabilities, territory boundaries) and time constraints, we did not build a fully deployable engine. However, the PoC confirmed that:\n\n- The segmentation integrates cleanly into a prescriptive segmentation ‚Üí optimization ‚Üí coverage pipeline.\n- A full solver could feasibly allocate sellers under realistic business constraints.\n- Gurobi-style MIP formulations and simulation-based heuristics are both valid paths for future development.\n\nIn short: the optimization layer is technically viable and aligns naturally with our segmentation design, but its full implementation exceeds the scope of this capstone.\n\n###### **5. AI & LLM Integration**\n\nTo make segmentation accessible to a broad set of stakeholders like sales leaders, strategists, and business analysts, we built a conversational tiering assistant powered by LLM-based interpretation of strategic priorities. The assistant allows users to describe their intended segmentation direction in natural language, which the system translates into numerical weights and a refreshed set of tier assignments.\n\n5.1 LLM Workflow Architecture\n\nThe following flowchart demonstrates how the LLM work:\n\n![]()\n\nFig 4. End-to-End LM Workflow\n\n1. Users communicate their goals using intuitive, high-level language (e.g. ‚Äúprioritize runway growth‚Äù, ‚Äúreward high-potential emerging accounts‚Äù). Front end collects the user‚Äôs tiering preference through a chat interface.\n2. The frontend sends this prompt to our cloud FastAPI service on Render.\n3. The LLM interprets the prompt and infers the relative strategic weights and which clustering method to use (KPI-based or Hybrid Approach).\n4. The server applies these weights in the tiering code to generate updated tiers based on the selected approach.\n5. The server returns a refreshed CSV with new tier assignments which can be exported through the chat interface.\n\n5.2 Why LLMs Matter\n\nLLMs enhanced the project in three ways:\n\n1. Interpretation Layer: Helps business users articulate strategy in plain English and convert it to quantifiable modeling inputs.\n2. Explainability Layer: Surfaces cluster drivers, feature differences, and trade-offs across segments in natural language.\n3. Acceleration Layer: Enables real-time exploration of ‚Äúwhat-if‚Äù tiering scenarios without engineering support.\n\nThis integration transforms segmentation from a static analytical artifact into a dynamic, interactive decision-support tool, aligned with how Microsoft teams actually work.\n\n5.3 Backend Architecture and LLM Integration Pipeline\n\nThe conversational tiering system is supported by a cloud-based backend designed to translate natural-language instructions into structured model parameters. The service is deployed on Render and implemented with FastAPI, providing a lightweight, high-performance gateway for managing requests, validating inputs, and coordinating LLM interactions.\n\n- FastAPI as the Orchestration Layer - User instructions are submitted through the chat interface and delivered to a FastAPI endpoint as JSON. FastAPI validates this payload using Pydantic, ensuring the request is well-formed before any processing occurs. The framework manages routing, serialization, and error handling, isolating request management from the downstream LLM and computation layers.\n- LLM Invocation Through the OpenAI API - Once a validated prompt is received, the backend invokes the OpenAI API using a structured system prompt engineered to enforce strict JSON output. The LLM returns four normalized weights reflecting the user‚Äôs strategic intent, along with metadata used to determine whether the user explicitly prefers a KPI-based method or the default Hybrid approach. If no method is specified, the system automatically defaults to Hybrid. Low-temperature decoding is used to minimize stochastic variation and ensure repeatability across identical user prompts. All OpenAI keys are securely stored as Render environment variables.\n- Schema Enforcement and Robust Parsing -To maintain reliability, the backend enforces strict schema validation on LLM responses. The service checks both JSON structure and numeric constraints, ensuring values fall within valid ranges and sum to one. If parsing fails or constraints are violated, the backend automatically reissues a constrained correction prompt. This design prevents malformed outputs and guards against conversational drift.\n- Render Hosting and Operational Considerations - The backend runs in a stateless containerized environment on Render, which handles service orchestration, HTTPS termination, and environment-variable management. Data required for computation is loaded into memory at startup to reduce latency, and the lightweight tiering pipeline ensures that the system remains responsive even under shared compute resources.\n- Response Assembly and Delivery - After LLM interpretation and schema validation, the backend applies the resulting weights and streams the recalculated results back to the user as a downloadable CSV. FastAPI‚Äôs Streaming Response enables direct transmission from memory without temporary filesystem storage, supporting rapid interactive workflows.\n\nTogether, these components form a tightly integrated, cloud-native pipeline: FastAPI handles orchestration, the LLM provides semantic interpretation, Render ensures secure and reliable hosting, and the default Hybrid method ensures consistent behavior unless the user explicitly requests the KPI approach.\n\nDEMO: **** **[Microsoft x UCLA Anderson MSBA - AI-Driven KPI Segmentation Project (LLM demo)](https://youtu.be/5F8M3T-bMwA)**\n\n1. **Conclusion**\n\nOur work delivers a strategic, KPI-driven tiering architecture that resolves the limitations of Microsoft‚Äôs legacy system and sets a scalable foundation for future segmentation and coverage strategy. Across all analyses, five differentiators stand out:\n\n- Clear separation of natural structure vs. business intent: We diagnose where the legacy system diverges from true customer potential and revenue‚Äîestablishing the analytical ground truth Microsoft never previously had.\n- A precise map of strategic trade-offs: By comparing unsupervised, KPI-only, and hybrid approaches, we reveal the operational and business implications behind every tiering philosophy‚Äîmaking the framework decision-ready for leadership.\n- A business-aligned segmentation ready for deployment: Our hybrid KPI-aware model uniquely satisfies KPI lift, distribution stability, ¬±1 movement rules, and interpretability‚Äîproviding a reliable go-forward tiering backbone.\n- A future-proof architecture that extends beyond static tiers: Dynamic progression modeling and optimization PoC show how tiering can evolve into forecasting, prioritization, whitespace planning, and resource optimization.\n- A blueprint for Microsoft‚Äôs next-generation tiering ecosystem: The system integrates data science, business KPIs, optimization, and LLM interpretability into one cohesive workflow‚Äîpositioning Microsoft for an AI-enabled tiering strategy.\n\nIn essence, this work transforms customer tiering into a strategic, explainable, and scalable system‚Äîready to support Microsoft‚Äôs growth ambitions and future AI initiatives.\n\n| **Authors**<br><br><br><br>[Sailing Ni](https://www.linkedin.com/in/sailing-ni-b5ab76180/)\\*, [Joy Yu](https://www.linkedin.com/in/joy-yu-hi/)\\*, [Peng Yang](https://www.linkedin.com/in/yangpeng1014/)\\*, [Richard Sie](https://www.linkedin.com/in/richard-sie/)\\*, [Yifei Wang](https://www.linkedin.com/in/russell-yifeiwang/)\\*<br>*\\*These authors contributed equally.*<br><br><br><br>**Affiliation**<br>Master of Science in Business Analytics (MSBA),<br>UCLA Anderson School of Management,<br>Los Angeles, California 90095, United States<br>*(Conducted December 2025)*<br><br><br><br>**Acknowledgment**<br>This research was conducted as part of a Microsoft-sponsored Capstone Project, led by [Juhi Singh](https://www.linkedin.com/in/singhj73/) and [Bonnie Ao](https://www.linkedin.com/in/bonnie-ao-5360b518b/) from the Microsoft MCAPS AI Transformation Office. | | --- |",
  "Title": "Architecting the Next-Generation Customer Tiering System",
  "FeedLevelAuthor": "rss.livelink.threads-in-node",
  "EnhancedContent": "## An AI-enabled, ML-optimized segmentation architecture aligning statistical structure, business KPIs, and operational rules to power next-generation global tiering\n\n| **Authors**<br><br><br><br>[Sailing Ni](https://www.linkedin.com/in/sailing-ni-b5ab76180/)\\*,¬†[Joy Yu](https://www.linkedin.com/in/joy-yu-hi/)\\*, Peng Yang\\*,¬†[Richard Sie](https://www.linkedin.com/in/richard-sie/)\\*,¬†[Yifei Wang](https://www.linkedin.com/in/russell-yifeiwang/)\\*<br>*\\*These authors contributed equally.*<br><br><br><br>**Affiliation**<br>Master of Science in Business Analytics (MSBA),<br>UCLA Anderson School of Management,<br>Los Angeles, California 90095, United States<br>*(Conducted December 2025)*<br><br><br><br>**Acknowledgment**<br>This research was conducted as part of a Microsoft-sponsored Capstone Project, led by¬†[Juhi Singh](https://www.linkedin.com/in/singhj73/)¬†and¬†[Bonnie Ao](https://www.linkedin.com/in/bonnie-ao-5360b518b/) from the Microsoft MCAPS AI Transformation Office. | | --- |\n\nMicrosoft‚Äôs global B2B software business classifies customers into four tiers to guide coverage, investment, and sales strategy. However, the legacy tiering framework mixes historical rules with manual heuristics, causing several issues:\n\n- Tiers do not consistently reflect customer potential or revenue importance.\n- Statistical coherence and business KPIs (TPA, TCI, SFI) are not optimized or enforced.\n- Tier distributions are imbalanced due to legacy ¬±1 movement and capacity rules.\n- Sales coverage planning depends on a tier structure not grounded in data.\n\nTo address these limitations, we, UCLA Anderson MSBA class of Dec'25, designed a¬†next-generation KPI-driven tiering architecture. Our objective was to move from a heuristic, static system toward a scalable, transparent, and business-aligned framework. Our redesigned tiering system follows five complementary analytical layers, each addressing a specific gap in the legacy process:\n\n- Natural Segmentation (Unsupervised Baseline):¬†Identify the intrinsic structure of the customer base using clustering to understand how customers naturally group\n- Pure KPI-Based Tiering (Upper-Bound Benchmark): Show what tiers would look like if aligned¬†*only*¬†to business KPIs, quantifying the maximum potential lift and exposing trade-offs.\n- Hybrid KPI-Aware Segmentation (Our Contribution): Integrate clustering geometry with KPI optimization and business constraints to produce a realistic, interpretable, and deployable tiering system.\n- Dynamic Tiering (Longitudinal Diagnostics): Analyze historical patterns to understand how companies evolve over time, separating structural tier drift from noise.\n- Optimization & Resource Allocation (Proof of Concept):¬†Demonstrate how the new tiers could feed into downstream coverage and whitespace prioritization through MIP- and heuristic-based approaches.\n\nTogether, these components answer a core strategic question:\n\n‚ÄúHow should Microsoft tier its global customer base so that investment, coverage, and growth strategy directly reflect business value?‚Äù\n\nOur final architecture transforms tiering from a static classification exercise into a KPI-driven, interpretable, and operationally grounded decision framework suitable for Microsoft‚Äôs future AI and data strategy.\n\n###### **Solution Architecture Diagram**\n\nFig 1. Solution Architecture Diagram\n\n###### **1. Success Metrics Definition**\n\nBefore designing any segmentation system, the first step is to establish success metrics that define what ‚Äúgood‚Äù looks like. Without these metrics, models can easily produce clusters that are statistically neat but misaligned with business needs. A clear KPI framework ensures that every model‚Äîregardless of method or complexity‚Äîis evaluated consistently on both analytical quality and real business impact.\n\nWe define success across two complementary dimensions:\n\n1.1 Alignment & Segmentation Quality:\n\nThese metrics evaluate whether the segmentation meaningfully separates customers based on business potential.\n\n1.1.1 Tier Potential Alignment (TPA)\n\nMeasures how well assigned tiers follow the rank order of¬†*PI\\_acct*, our composite indicator of future growth potential. Implemented as a Spearman rank correlation, TPA tests whether higher-potential accounts systematically land in higher tiers.\n\nStep 1 - Formula for PI\\_acct (Potential Index per Account)\n\nStep 2 - Formula for TPA (Tier Potential Alignment)\n\n- ùúå\\_ùë† = Spearman rank correlation\n- Tier Rank = ordinal tier number (Tier A = highest ‚Üí Tier D = lowest)\n\nInterpretation:\n\n- TPA=1 ‚áí Perfect alignment (higher potential ‚Üí higher tier)\n- TPA=0 ‚áí No statistical relationship\n- TPA&lt;0 ‚áí Misalignment (tiers contradict potential)\n\n1.1.2 Tier Compactness Index (TCI)\n\nMeasures how homogeneous each tier is. Low within-tier variance on¬†*PI\\_acct*¬†or Revenue indicates that customers grouped together truly share similar characteristics, improving interpretability and resource planning.\n\n(1) Potential-based Compactness - TCI\\_PI\n\n(2) Revenue-based Compactness - TCI\\_REV\n\n- TCI=1 ‚áí tiers are tight and well-separated\n- TCI=0 ‚áí tiers are random or overlapping\n- TCI&lt;0 ‚áí within-tier variance exceeds total variance (poor grouping)\n\n1.2 Business Impact\n\nThese metrics test whether the segmentation supports strategic goals, not just statistical structure.\n\n1.2.1 Strategic Focus Index (SFI)\n\nQuantifies how much revenue comes from the company‚Äôs most strategically important tiers. High SFI means segmentation helps focus investments‚Äîsales coverage, specialist time, programs‚Äîon the customers that matter most.\n\nUnder the Tier Policy framework, the definition of ‚Äústrategic‚Äù automatically adapts to the number of tiers K - for example, taking the top L tiers (e.g., top 2) or top x % of tiers ranked by mean potential or revenue.\n\n- High SFI: strong emphasis on top strategic segments (potentially efficient but watch concentration risk).\n- Moderate SFI: balanced focus across tiers.\n- Low SFI: diffuse portfolio, limited emphasis on priority segment\n\n1. **Static Segmentation**\n\n2.1 Pure Unsupervised Clustering\n\n2.1.1 Model Conclusions at a Glance\n\nAcross all unsupervised models evaluated‚ÄîWard, Weighted Ward, K-Medoids, K-Means / K-Means++, and HDBSCAN ‚Äî only the Ward model (K=4, Policy v2) provides a segmentation that is simultaneously:\n\n- statistically coherent,\n- business-aligned (high SFI),\n- geometrically stable (clean Silhouette), and\n- operationally interpretable.\n\nAll alternative models either distort cluster geometry, collapse SFI, or produce unstable/illogical tier structures. Final Recommendation**:**¬†Use Ward (K=4, Policy v2) as the natural segmentation baseline.\n\n2.1.2 High-Level Algorithm Comparison\n\nTable 1. Algorithm Comparison\n\n| **Model** | **Algorithm Summary** | **Strengths** | **Weaknesses** | **Business Use** | | --- | --- | --- | --- | --- | | **Ward** | Variance-minimizing hierarchical merges | Best balance of TPA/TCI/SFI; stable geometry | Sensitive to correlated features | Primary model for segmentation | | **Weighted Ward** | Distance reweighted by PI + revenue | Higher TPA | Silhouette collapse; unstable | Not recommended | | **K-Medoids** | Medoid-based dissimilarity minimization | Robust to outliers | Cluster compression; weak SFI | Diagnostic only | | **K-Means / K-Means++** | Squared-distance minimization | Fast baseline | SFI collapse; over-tight clusters | Numeric benchmark only | | **HDBSCAN** | Density-based clustering with noise | Good for anomaly detection | TPA collapse; noisy tiers; broken PI ordering | Not suitable for tiering |\n\n2.1.3 Modeling Results\n\nTable 2. Unsupervised Clustering Model Results\n\n| Metric | FY26 Baseline (Legacy A+B) | Ward K=4 (Policy v2) | Weighted Ward2-B (Œ±=4, Œ≤=0.8, s=0.7, K=5) | Unweighted Ward (Policy v2, K=4) | Unweighted Ward (Policy v2, K=3) | K-Medoids B4 Behavior-only (K=3) | K-means K=4 (Policy v2) | K-means++ K=4 (Policy v2) | HDBSCAN (baseline settings) | | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | | **TPA** | 0.260 | 0.260 | 0.860 | 0.260 | 0.300 | 0.520 | 0.310 | 0.310 | 0.040 | | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | | **TCI\\_PI** | 0.222 | 0.461 | 0.772 | 0.461 | 0.405 | 0.173 | 0.476 | 0.476 | 0.004 | | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | | **TCI\\_REV** | 0.469 | 0.801 | 0.640 | 0.801 | 0.672 | 0.002 | 0.831 | 0.831 | 0.062 | | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | | **SFI** | 0.807 | 0.868 | 0.817 | 0.868 | 0.960 | 0.656 | 0.332 | 0.332 | 0.719 | | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | | **Silhouette** | nan | 0.560 | 0.145 | 0.560 | 0.604 | 0.466 | 0.523 | 0.523 | 0.186 | | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n\n- Ward (K=4, Policy v2) remains the strongest performer: SFI ‚âà 0.87, Silhouette ‚âà 0.56, stable geometric structure.\n- Weighted Ward raises TPA/PI slightly but Silhouette collapses (~0.15) ‚Üí structural instability ‚Üí not viable.\n- K-Medoids consistently compresses clusters; TPA/TCI gain is offset by TCI\\_REV collapse and low SFI.\n- K-Means / K-Means++ tighten numeric clusters but SFI drops to ~0.33 ‚Üí tiers lose strategic meaning.\n- HDBSCAN generates large noisy segments; TPA = 0.044, TCI\\_PI = 0.004, Silhouette = 0.186, and Tier A/B contain negative PI ‚Üí fundamentally unsuitable.\n\nConclusion: Only Ward (K=4) produces segmentation with both statistical integrity and business relevance.\n\n2.1.4 Implications, Limitations, Next Steps\n\nImplications\n\nOur current unsupervised segmentation delivers statistically coherent and operationally usable tiers, but several structural findings emerged:\n\n1. Unsupervised methods reveal the data‚Äôs natural shape, not business priorities.\n2. Ward/K-means/HDBSCAN can discover separations in the feature space but cannot move clusters toward preferred PI or revenue patterns.\n3. Cluster outcomes cannot guarantee business-desired constraints.\n- If Tier A‚Äôs PI mean is too low, the model cannot raise it.\n- If Tier C becomes too large, clustering cannot rebalance it.\n- If the business wants stronger SFI, clustering alone cannot optimize that objective.\n4. For example:\n5. Some business-critical metrics are only evaluated¬†*after*¬†clustering, not optimized¬†*within*¬†clustering.\n6. Tier size distributions, average PI per tier, and revenue share are structurally important but not part of the unsupervised objective.\n\nHence,\n\nUnsupervised clustering provides a statistically coherent view of the data‚Äôs natural structure, but it cannot guarantee business-preferred tier outcomes. The models cannot enforce hard constraints (e.g., desired A/B/C distribution, monotonic PI means, revenue share targets), nor can they adjust tiers when PI is too low or clusters become imbalanced. Additionally, key tier-level KPIs‚Äîsuch as average PI per tier, tier size stability, and revenue distribution‚Äîare only evaluated¬†*after*¬†clustering rather than optimized during it, limiting their influence on the final tier design.\n\nTo overcome these structural limitations, the next stage of the system must incorporate semi-supervised guidance and policy-based optimization, where business KPIs directly shape tier boundaries and ranking. Future iterations will expand the policy beyond PI and revenue to include behavioral and market signals and bring tier-level metrics into the objective function to better align the segmentation with real-world operational priorities.\n\n2.2 Semi-supervised KPI-Driven Learning\n\nComposite Score ‚Äî KPI-Driven Objective for Tiering\n\nTo guide our semi-supervised and hybrid methods, we define a Composite Score that unifies Microsoft‚Äôs key business KPIs into a single optimization target. It ensures that all modeling layers‚ÄîPure KPI-Based Tiering and Hybrid KPI-Aware Segmentation‚Äîoptimize toward the same business priorities. Unsupervised clustering cannot optimize business outcomes. A composite objective is needed to consistently evaluate and improve tiering performance across:\n\n- Potential uplift (TPA)\n- Stability of tier structure (SFI)\n- Within-tier improvement (TCI\\_PI)\n- Revenue scale (TCI\\_REV)\n\nTo align tiering with business priorities, we summarize four key KPIs‚ÄîTPA, SFI, TCI\\_PI, and TCI\\_REV‚Äîinto one normalized measure:\n\nComposite Score = 0.35√óTPA + 0.35√óSFI + 0.30√ó(TCI\\_PI + TCI\\_REV)\n\nThis score provides a single benchmark for comparing methods and serves as the optimization target in our semi-supervised and hybrid approaches.\n\nHow It Is Used\n\n- Benchmarking: Compare all methods on a unified scale.\n- Optimization: Serves as the objective in constrained local search (Method 3).\n- Rule Learning: Guides the decision-tree logic extracted after optimization.\n\nWhy It Matters\n\nThe Composite Score centers the analysis around a single question: ‚ÄúWhich tiering structure creates the strongest balance of growth potential, stability, and revenue impact?‚Äù\n\n2.3 Pure KPI-Based Tiering\n\n2.3.1 Model Conclusions at a Glance\n\nPure KPI-based tiering shows what the tiers would look like if Microsoft prioritized business KPIs above all else. It achieves the¬†largest KPI improvements, but causes major distribution shifts and violates movement rules, making it operationally unrealistic.\n\nFinal takeaway: Pure KPI tiering is a valuable benchmark for understanding KPI potential, but cannot be operationalized.\n\n2.3.2 High-Level Algorithm Summary\n\nTable 3. Methods of KPI-Based Tiering\n\n| Method | Algorithm Summary | Strengths | Weaknesses | Business Use | | --- | --- | --- | --- | --- | | **New\\_Tier\\_Direct**(PI ranking only) | Rank accounts by PI/KPI score and assign tiers directly | **Highest KPI gains**; preserves overall tier distribution | Moves¬†**~20‚Äì40%**companies; violates ¬±1 rule; disrupts continuity | KPI upper-bound benchmark | | --- | --- | --- | --- | --- | | **Tier\\_PI\\_Constrained**(PI ranking + ¬±1 rule) | Same as above but restrict movement to adjacent tiers | KPI lift + respects movement constraint | Still moves¬†**~20‚Äì40%;**¬†breaks tier distribution (Tier C inflation) | Diagnostic only | | --- | --- | --- | --- | --- |\n\n2.3.3 Modeling Results\n\nTable 4. Modeling Results for KPI-Based Tiering\n\n| KPI | FY26 Baseline | New\\_Tier\\_Direct | Tier\\_PI\\_Constrained | | --- | --- | --- | --- | | Composite Score | 0.5804 | 0.8105 | 0.763 | | TPA | 0.2590 | 0.8300 | 0.721 | | TCI\\_PI | 0.2220 | 0.5360 | 0.492 | | TCI\\_REV | 0.4690 | 0.3970 | 0.452 | | SFI | 0.8070 | 0.6860 | 0.650 |\n\nNew\\_Tier\\_Direct\n\n- Composite Score: 0.5804 ‚Üí 0.8105\n- TPA increases sharply (0.259 ‚Üí 0.830)\n- Violates ¬±1 rule; major reassignments (~20%‚Äì40%)\n\nTier\\_PI\\_Constrained\n\n- Respects ¬±1 movement\n- KPI still improves (Composite 0.763)\n- But tier distribution collapses (Tier C over-expands)\n- Still ~20‚Äì40% movement ‚Üí not feasible\n\nHence:¬†No PI-only method balances KPI lift with operational feasibility.\n\n2.3.4 Limitations & Next Steps\n\nPure KPI tiering cannot simultaneously:\n\n- preserve tier distribution,\n- respect ¬±1 movement rule, and\n- deliver consistent KPI improvements.\n\nThis creates the need for a hybrid model that combines clustering structure with KPI-aligned tier ordering.\n\n2.4 Hybrid KPI-Aware Segmentation (Our Contribution)\n\n2.4.1 Model Conclusions at a Glance\n\nOur hybrid method blends clustering geometry with KPI-driven optimization, achieving a practical balance between:\n\n- statistical structure,\n- business constraints, and\n- KPI improvement.\n\nFinal Recommendation: This is the segmentation framework we recommend Microsoft to adopt.\n\n‚ûî¬†¬†¬† It produces the most deployable segmentation by balancing KPI lift with stability and interpretability.\n\n‚ûî¬†¬†¬† Delivers meaningful KPI improvement while changing only ~5% of accounts, compared to Model B‚Äôs 20‚Äì40%.\n\n2.4.2 High-Level Algorithm Summary\n\nTable 5. Algorithm Comparison\n\n| **Component** | **Purpose** | **Strengths** | **Notes** | | --- | --- | --- | --- | | **Constrained Local Search** | Optimize composite KPI score starting from FY26 tiers | KPI uplift with strict constraints | Only small movements allowed (~5%) | | **Tier Movement Constraint (+1/‚Äì1)** | Ensure realistic transitions | Guarantees business rules; keeps structure stable | Limits improvement ceiling | | **Decision Tree** | Learn interpretable rules from optimized tiers | Deployable, explainable, reusable | Accuracy ~80%; tunable with weighting | | **Closed Loop Optimization** | Improve both rules and allocation iteratively | Stable + interpretable | Future extension |\n\n2.4.3 Modeling Results\n\nTable 6. Modeling Results for Hybrid Segmentation\n\n| KPI | FY26 Baseline | New\\_Tier\\_Direct | Tier\\_PI\\_Constrained | ImprovedTier | | --- | --- | --- | --- | --- | | Composite Score | 0.5804 | 0.8105 | 0.763 | 0.6512 | | TPA | 0.2590 | 0.8300 | 0.721 | 0.2990 | | TCI\\_PI | 0.2220 | 0.5360 | 0.492 | 0.3450 | | TCI\\_REV | 0.4690 | 0.3970 | 0.452 | 0.5250 | | SFI | 0.8070 | 0.6860 | 0.650 | 0.8160 |\n\nFig 2. Visualization of Decision Tree\n\nFig 3. Explanation of Decision Tree\n\nInterpretation of Hybrid Model (Improved Tier)\n\n- Composite Score: 0.5804 ‚Üí 0.6512\n- TPA improvement (0.259 ‚Üí 0.299)\n- TCI\\_PI and TCI\\_REV both rise\n- SFI improves compared to constrained PI method\n- Only ~5% of companies move tiers, versus Method 2‚Äôs 20‚Äì40%\n\nThis makes Method 3 the only method that simultaneously satisfies:\n\n- KPI improvement\n- original tier distribution\n- ¬±1 movement rule\n- low operational disruption\n- interpretability (via decision tree)\n\n2.4.4 Conclusion\n\nModel C offers a pragmatic middle ground:¬†KPI lift close to pure PI tiering, operational impact close to clustering, and full interpretability.\n\nFor Microsoft, this hybrid framework is the most realistic and sustainable segmentation approach\n\n###### **3. Dynamic Tier Progression**\n\n3.1 Model Conclusions at a Glance\n\nOur benchmarking shows that CatBoost and XGBoost consistently deliver the strongest overall performance, achieving the highest macro-F1 (~0.76) across all tested methods. However, despite these gains, the underlying business pattern remains dominant: tier changes are extremely rare (‚âà5.4%), and Microsoft‚Äôs one-step movement rule severely limits model learnability.\n\nDynamic tiering is far more valuable as a diagnostic signal generator than a strict forecasting engine. While models cannot reliably predict future tier transitions, they can surface atypical account patterns, signals of risk, and emerging opportunities that support earlier sales intervention and more proactive account planning.\n\n3.2 Models\n\nTo predict future model upgrades and downgrades, we tested the following models:\n\nTable 7. Models Used for Dynamic Prediction\n\n| **Model** | **Strengths** | **Weaknesses** | **When to Use** | | --- | --- | --- | --- | | MLR | Simple; interpretable; fast baseline | Weak on imbalanced data | When transparency and explainability are needed | | Neural Network | Captures nonlinear patterns; stronger recall than MLR | Requires tuning; sensitive to imbalance data | When exploring richer behavioral signals | | CatBoost (baseline, weighted, oversampled) | Strongest overall balance; robust with categorical data; best macro-F1 | Still limited by rarity of tier changes; weighted/oversampled versions risk overfitting | Default diagnostic model for surfacing atypical account patterns | | XGBoost (baseline, weighted) | High performance; scalable; production-ready | Limited by structural imbalance; weighted versions increase false positives | When deploying a stable scoring layer to sales teams |\n\nPerformance was then measured using accuracy, but more importantly, macro recall, precision, and F1, since upgrades and downgrades are much rarer and require balanced evaluation.\n\n3.3 Model Results\n\nAcross all models, overall accuracy appears high (0.95‚Äì0.97), but this metric is dominated by the fact that Tier transitions are extremely rare ‚Äî only 808 of 15,000 cases (5.4%) moved tiers, while 95% stayed unchanged. According to macro metrics such as recall, precision, and F1, every model struggles to reliably detect upgrades and downgrades.\n\nCatBoost and XGBoost deliver the strongest balanced results, achieving the highest macro F1 scores (~0.76). However, even these advanced methods only capture half or fewer of the true upgrade and downgrade events. This reinforces that the challenge is not algorithmic performance, but the underlying business pattern: tier movements are infrequent, policy-driven, and weakly connected to observable account features.\n\nTable 8. Results for Dynamic Prediction\n\n| **Model** | **Accuracy** | **Macro** | | --- | --- | --- | | **Recall** | **Precision** | **F1 Score** | | **MLR** | 0.95 | 0.36 | 0.70 | 0.37 | | **Neural Network** | 0.95 | 0.58 | 0.71 | 0.63 | | **CatBoost** | 0.97 | 0.94 | 0.67 | 0.76 | | **CatBoost (Weighted)** | 0.82 | 0.49 | 0.82 | 0.54 | | **CatBoost (Oversampling)** | 0.69 | 0.42 | 0.75 | 0.42 | | **XGBoost** | 0.97 | 0.93 | 0.67 | 0.76 | | **XGBoost (Weighted)** | 0.97 | 0.85 | 0.70 | 0.76 |\n\n3.4 Dynamic Tiering Implications\n\nBased on the results, our dynamic tiering will have the following implications to Microsoft:\n\n- Tier changes are not reliably forecastable under current rules.\n\nYear-over-year stability is so dominant that even strong ML models cannot surface consistent upgrade or downgrade signals. This suggests that transitions are driven more by sales judgment and tier policy than by measurable account behavior.\n\n- The dynamic model is still valuable: just not as a predictor of future tiers.\n\nRather than serving as a forecasting engine, this pipeline should be viewed as a diagnostic tool that helps identify accounts with unusual patterns, emerging risks, or outlier behavior worth reviewing.\n\n- Dynamic progression complements, rather than replaces, the core segmentation.\n\nIt provides an additional layer of insight alongside clustering and KPI-optimized segmentation, helping Microsoft maintain both structural clarity (static segmentation) and forward-looking awareness (dynamic progression).\n\n###### **4. Optimization in Practice**\n\nTo understand how segmentation could support downstream coverage planning, we developed a small optimization proof-of-concept using Microsoft‚Äôs seller‚Äìtier capacity guidelines (e.g., max accounts per role √ó tier, geo-entity restrictions, in-person vs remote coverage rules).\n\n4.1 What We Explored\n\nUsing our final hybrid segmentation (Method 3), we tested a simplified workflow:\n\n- Formulate a coverage optimization problem\n\n‚óã¬†¬†¬†¬†¬† Assign sellers to accounts under constraints such as:\n\n- - - role √ó tier capacity limits,\n- single-geo assignment,\n- ¬±1 tier movement rules,\n- domain restrictions for Tier C/D.\n\n‚óã¬†¬†¬†¬†¬† This naturally forms a mixed-integer optimization problem (MIP).\n\n- Prototype with standard optimization tools\n\n‚óã¬†¬†¬†¬†¬† Linear and integer programming formulations using Gurobi, OR-Tools, and Pyomo.\n\n‚óã¬†¬†¬†¬†¬† Heuristic solvers (e.g., local search, greedy reallocation, hill climbing) as faster alternatives.\n\n- Simulate coverage scenarios\n\n‚óã¬†¬†¬†¬†¬† Estimate changes in workload balance and whitespace prioritization under different seller‚Äìtier mixes.\n\n‚óã¬†¬†¬†¬†¬† Validate feasibility of the optimization with respect to Microsoft‚Äôs operational rules.\n\n4.2 What We Learned\n\nDue to limited operational metrics (detailed whitespace values, upgrade probabilities, territory boundaries) and time constraints, we did not build a fully deployable engine. However, the PoC confirmed that:\n\n- The segmentation integrates cleanly into a prescriptive segmentation ‚Üí optimization ‚Üí coverage pipeline.\n- A full solver could feasibly allocate sellers under realistic business constraints.\n- Gurobi-style MIP formulations and simulation-based heuristics are both valid paths for future development.\n\nIn short: the optimization layer is technically viable and aligns naturally with our segmentation design, but its full implementation exceeds the scope of this capstone.\n\n###### **5. AI & LLM Integration**\n\nTo make segmentation accessible to a broad set of stakeholders like sales leaders, strategists, and business analysts, we built a conversational tiering assistant powered by LLM-based interpretation of strategic priorities. The assistant allows users to describe their intended segmentation direction in natural language, which the system translates into numerical weights and a refreshed set of tier assignments.\n\n5.1 LLM Workflow Architecture\n\nThe following flowchart demonstrates how the LLM work:\n\nFig 4. End-to-End LM Workflow\n\n1. Users communicate their goals using intuitive, high-level language (e.g. ‚Äúprioritize runway growth‚Äù, ‚Äúreward high-potential emerging accounts‚Äù). Front end collects the user‚Äôs tiering preference through a chat interface.\n2. The frontend sends this prompt to our cloud FastAPI service on Render.\n3. The LLM interprets the prompt and infers the relative strategic weights and which clustering method to use (KPI-based or Hybrid Approach).\n4. The server applies these weights in the tiering code to generate updated tiers based on the selected approach.\n5. The server returns a refreshed CSV with new tier assignments which can be exported through the chat interface.\n\n5.2 Why LLMs Matter\n\nLLMs enhanced the project in three ways:\n\n1. Interpretation Layer: Helps business users articulate strategy in plain English and convert it to quantifiable modeling inputs.\n2. Explainability Layer: Surfaces cluster drivers, feature differences, and trade-offs across segments in natural language.\n3. Acceleration Layer: Enables real-time exploration of ‚Äúwhat-if‚Äù tiering scenarios without engineering support.\n\nThis integration transforms segmentation from a static analytical artifact into a dynamic, interactive decision-support tool, aligned with how Microsoft teams actually work.\n\n5.3 Backend Architecture and LLM Integration Pipeline\n\nThe conversational tiering system is supported by a cloud-based backend designed to translate natural-language instructions into structured model parameters. The service is deployed on Render and implemented with FastAPI, providing a lightweight, high-performance gateway for managing requests, validating inputs, and coordinating LLM interactions.\n\n- FastAPI as the Orchestration Layer - User instructions are submitted through the chat interface and delivered to a FastAPI endpoint as JSON. FastAPI validates this payload using Pydantic, ensuring the request is well-formed before any processing occurs. The framework manages routing, serialization, and error handling, isolating request management from the downstream LLM and computation layers.\n- LLM Invocation Through the OpenAI API - Once a validated prompt is received, the backend invokes the OpenAI API using a structured system prompt engineered to enforce strict JSON output. The LLM returns four normalized weights reflecting the user‚Äôs strategic intent, along with metadata used to determine whether the user explicitly prefers a KPI-based method or the default Hybrid approach. If no method is specified, the system automatically defaults to Hybrid. Low-temperature decoding is used to minimize stochastic variation and ensure repeatability across identical user prompts. All OpenAI keys are securely stored as Render environment variables.\n- Schema Enforcement and Robust Parsing -To maintain reliability, the backend enforces strict schema validation on LLM responses. The service checks both JSON structure and numeric constraints, ensuring values fall within valid ranges and sum to one. If parsing fails or constraints are violated, the backend automatically reissues a constrained correction prompt. This design prevents malformed outputs and guards against conversational drift.\n- Render Hosting and Operational Considerations - The backend runs in a stateless containerized environment on Render, which handles service orchestration, HTTPS termination, and environment-variable management. Data required for computation is loaded into memory at startup to reduce latency, and the lightweight tiering pipeline ensures that the system remains responsive even under shared compute resources.\n- Response Assembly and Delivery - After LLM interpretation and schema validation, the backend applies the resulting weights and streams the recalculated results back to the user as a downloadable CSV. FastAPI‚Äôs Streaming Response enables direct transmission from memory without temporary filesystem storage, supporting rapid interactive workflows.\n\nTogether, these components form a tightly integrated, cloud-native pipeline: FastAPI handles orchestration, the LLM provides semantic interpretation, Render ensures secure and reliable hosting, and the default Hybrid method ensures consistent behavior unless the user explicitly requests the KPI approach.\n\nDEMO:**** **[Microsoft x UCLA Anderson MSBA - AI-Driven KPI Segmentation Project (LLM demo)](https://youtu.be/5F8M3T-bMwA)**\n\n1. **Conclusion**\n\nOur work delivers a strategic, KPI-driven tiering architecture that resolves the limitations of Microsoft‚Äôs legacy system and sets a scalable foundation for future segmentation and coverage strategy. Across all analyses, five differentiators stand out:\n\n- Clear separation of natural structure vs. business intent: We diagnose where the legacy system diverges from true customer potential and revenue‚Äîestablishing the analytical ground truth Microsoft never previously had.\n- A precise map of strategic trade-offs: By comparing unsupervised, KPI-only, and hybrid approaches, we reveal the operational and business implications behind every tiering philosophy‚Äîmaking the framework decision-ready for leadership.\n- A business-aligned segmentation ready for deployment: Our hybrid KPI-aware model uniquely satisfies KPI lift, distribution stability, ¬±1 movement rules, and interpretability‚Äîproviding a reliable go-forward tiering backbone.\n- A future-proof architecture that extends beyond static tiers: Dynamic progression modeling and optimization PoC show how tiering can evolve into forecasting, prioritization, whitespace planning, and resource optimization.\n- A blueprint for Microsoft‚Äôs next-generation tiering ecosystem: The system integrates data science, business KPIs, optimization, and LLM interpretability into one cohesive workflow‚Äîpositioning Microsoft for an AI-enabled tiering strategy.\n\nIn essence, this work transforms customer tiering into a strategic, explainable, and scalable system‚Äîready to support Microsoft‚Äôs growth ambitions and future AI initiatives.\n\n| **Authors**<br><br><br><br>[Sailing Ni](https://www.linkedin.com/in/sailing-ni-b5ab76180/)\\*,¬†[Joy Yu](https://www.linkedin.com/in/joy-yu-hi/)\\*, [Peng Yang](https://www.linkedin.com/in/yangpeng1014/)\\*,¬†[Richard Sie](https://www.linkedin.com/in/richard-sie/)\\*,¬†[Yifei Wang](https://www.linkedin.com/in/russell-yifeiwang/)\\*<br>*\\*These authors contributed equally.*<br><br><br><br>**Affiliation**<br>Master of Science in Business Analytics (MSBA),<br>UCLA Anderson School of Management,<br>Los Angeles, California 90095, United States<br>*(Conducted December 2025)*<br><br><br><br>**Acknowledgment**<br>This research was conducted as part of a Microsoft-sponsored Capstone Project, led by¬†[Juhi Singh](https://www.linkedin.com/in/singhj73/)¬†and¬†[Bonnie Ao](https://www.linkedin.com/in/bonnie-ao-5360b518b/) from the Microsoft MCAPS AI Transformation Office. | | --- |\n\nUpdated Dec 04, 2025\n\nVersion 2.0\n\n[analytics](/tag/analytics?nodeId=board%3AAnalyticsonAzure)\n\n[azure](/tag/azure?nodeId=board%3AAnalyticsonAzure)\n\n[azure stream analytics](/tag/azure%20stream%20analytics?nodeId=board%3AAnalyticsonAzure)\n\n[azure synapse analytics](/tag/azure%20synapse%20analytics?nodeId=board%3AAnalyticsonAzure)\n\n[machine learning](/tag/machine%20learning?nodeId=board%3AAnalyticsonAzure)\n\n[MlFlow](/tag/MlFlow?nodeId=board%3AAnalyticsonAzure)\n\n[!\\[BonnieAo&#x27;s avatar\\](https://techcommunity.microsoft.com/t5/s/gxcuf89792/m_assets/avatars/default/avatar-9.svg?image-dimensions=50x50)](/users/bonnieao/2992358) [BonnieAo](/users/bonnieao/2992358) ![Icon for Microsoft rank](https://techcommunity.microsoft.com/t5/s/gxcuf89792/images/cmstNC05WEo0blc?image-dimensions=100x16&amp;constrain-image=true)Microsoft\n\nJoined April 10, 2025\n\n[View Profile](/users/bonnieao/2992358)\n\n/category/azure/blog/analyticsonazure [Analytics on Azure Blog](/category/azure/blog/analyticsonazure) Follow this blog board to get notified when there's new activity",
  "FeedName": "Microsoft Tech Community",
  "FeedUrl": "https://techcommunity.microsoft.com/t5/s/gxcuf89792/rss/Category?category.id=Azure",
  "PubDate": "2025-12-04T21:00:36+00:00"
}
