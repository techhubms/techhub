{
  "Link": "https://techcommunity.microsoft.com/t5/apps-on-azure-blog/low-light-image-enhancer-python-opencv-on-azure-app-service/ba-p/4466837",
  "OutputDir": "_community",
  "ProcessedDate": "2025-11-04 08:04:56",
  "FeedName": "Microsoft Tech Community",
  "PubDate": "2025-11-04T07:33:04+00:00",
  "Tags": [],
  "Title": "Low-Light Image Enhancer (Python + OpenCV) on Azure App Service",
  "FeedLevelAuthor": "rss.livelink.threads-in-node",
  "EnhancedContent": "Low-light photos are everywhere: indoor team shots, dim restaurant pics, grainy docs. This post shows a tiny Python app (Flask + OpenCV) that fixes them with explainable image processing—not a heavyweight model. We’ll walk the code that does the real work (CLAHE → gamma → brightness → subtle saturation) and deploy it to **Azure App Service for Linux**.\n\n#### What you’ll build\n\nA Flask web app that accepts an image upload, runs a fast enhancement pipeline (CLAHE → gamma → brightness → subtle saturation), and returns **base64 data URIs** for an instant before/after view in the browser—no storage required for the basic demo.\n\n#### Architecture at a glance\n\n1. **Browser → /enhance** (multipart form): sends an image + optional tunables (clip\\_limit, gamma, brightness).\n2. **Flask → Enhancer**: converts the upload to a NumPy RGB array and calls LowLightEnhancer.enhance\\_image(...).\n3. **Response**: returns JSON with original and enhanced images as base64 PNG data URIs for immediate rendering.\n\n#### Prerequisites\n\n- An Azure subscription\n- [**Azure Developer CLI (azd)**](https://aka.ms/azd) installed\n- (Optional) Python 3.9+ on your dev box for reading the code or extending it\n\n#### Deploy with azd\n\n``` git clone https://github.com/Azure-Samples/appservice-ai-samples.git cd appservice-ai-samples/lowlight-enhancer azd init azd up ```\n\nWhen *azd up* finishes, open the printed URL, upload a low-light photo, and compare the result side-by-side.\n\n#### Code walkthrough (the parts that matter)\n\n##### 1) Flask surface area (**app.py**)\n\n- **File size guard**:\n\n``` app = Flask(__name__) app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024 # 16 MB ```\n\n- **Two routes**:\n- *GET /* - renders the simple UI\n- *POST /enhance* - the JSON API the UI calls via XHR/fetch\n\n- **Parameter handling with sane defaults**:\n\n``` clip_limit = float(request.form.get('clip_limit', 2.0)) gamma = float(request.form.get('gamma', 1.2)) brightness = float(request.form.get('brightness', 1.1)) ```\n\n##### 2) Zero-temp-file processing + data-URI response (**app.py**)\n\n*process\\_uploaded\\_image* keeps the hot path tight: convert to RGB → enhance → convert both versions to **base64 PNG** and return them inline.\n\n``` def process_uploaded_image(file_storage, clip_limit=2.0, gamma=1.2, brightness=1.1):\n# PIL → NumPy (RGB)\nimg_pil = Image.open(file_storage) if img_pil.mode != 'RGB': img_pil = img_pil.convert('RGB') img_array = np.array(img_pil)\n\n# Enhance\nenhanced = LowLightEnhancer().enhance_image( img_array, clip_limit=clip_limit, gamma=gamma, brightness_boost=brightness )\n\n# Back to base64 data URIs for instant display\ndef pil_to_base64(pil_img): buf = io.BytesIO(); pil_img.save(buf, format='PNG') return base64.b64encode(buf.getvalue()).decode('utf-8')\n\nenhanced_pil = Image.fromarray(enhanced) return { 'original': f'data:image/png;base64,{pil_to_base64(img_pil)}', 'enhanced': f'data:image/png;base64,{pil_to_base64(enhanced_pil)}' }\n\n```\n\n##### 3) The enhancement core (**enhancer.py**)\n\n*LowLightEnhancer* implements a classic pipeline that runs great on CPU:\n\n``` class LowLightEnhancer: def __init__(self): self.clip_limit = 2.0 self.tile_grid_size = (8, 8)\n\ndef enhance_image(self, image, clip_limit=2.0, gamma=1.2, brightness_boost=1.1):\n# Normalize to RGB if the input came in as OpenCV BGR\nis_bgr = self._detect_bgr(image) rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) if is_bgr else image\n\n# 1) CLAHE on L-channel (LAB) for local contrast without color blowout\nlab = cv2.cvtColor(rgb, cv2.COLOR_RGB2LAB) l, a, b = cv2.split(lab) clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=self.tile_grid_size) l = clahe.apply(l)\n\n# 2) Gamma correction (perceptual brightness curve)\nl = self._apply_gamma_correction(l, gamma)\n\n# 3) Gentle overall lift\nl = np.clip(l * brightness_boost, 0, 255).astype(np.uint8)\n\n# Recombine + small saturation nudge for a natural look\nenhanced = cv2.cvtColor(cv2.merge([l, a, b]), cv2.COLOR_LAB2RGB) enhanced = self._boost_saturation(enhanced, factor=1.1) return cv2.cvtColor(enhanced, cv2.COLOR_RGB2BGR) if is_bgr else enhanced ```\n\n- **CLAHE on L** (not RGB) avoids the “oversaturated neon” artifact common with naive histogram equalization.\n- **Gamma via LUT** (below) is fast and lets you brighten mid-tones without crushing highlights.\n- A tiny **brightness multiplier** brings the image up just a bit after contrast/curve changes.\n- A **+10% saturation** helps counter the desaturation that often follows brightening.\n\n##### 4) Fast gamma with a lookup table (**enhancer.py**)\n\n``` def _apply_gamma_correction(self, image, gamma: float) -> np.ndarray: inv_gamma = 1.0 / gamma table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in range(256)], dtype=np.uint8) return cv2.LUT(image, table) ```\n\nNotes:\n\n- With gamma = 1.2, inv\\_gamma ≈ 0.833 → curve brightens mid-tones (exponent &lt; 1).\n- cv2.LUT applies the 256-entry mapping efficiently across the image.\n\n##### 5) Bounded color pop: subtle saturation boost (**enhancer.py**)\n\n``` def _boost_saturation(self, image: np.ndarray, factor: float) -> np.ndarray: hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV).astype(np.float32) hsv[:, :, 1] = np.clip(hsv[:, :, 1] * factor, 0, 255) return cv2.cvtColor(hsv.astype(np.uint8), cv2.COLOR_HSV2RGB) ```\n\nNotes:\n\n- Working in **HSV** keeps hue and brightness stable while gently lifting color.\n- The clip to [0, 255] prevents out-of-gamut surprises.\n\n#### Tuning cheatsheet (which knob to turn, and when)\n\n- **Too flat / muddy** → raise clip\\_limit from **2.0 → 3.0–4.0** (more local contrast).\n- **Still too dark** → raise gamma from **1.2 → 1.4–1.6** (brightens mid-tones).\n- **Harsh or “crunchy”** → lower clip\\_limit, or drop brightness\\_boost to **1.05–1.1**.\n- **Colors feel washed out** → increase saturation factor a touch (e.g., **1.1 → 1.15**).\n\n#### What to try next\n\n- Expose more controls in the UI (e.g., tile grid size, saturation factor).\n- Persist originals/results to **Azure Blob Storage** and add shareable links.\n- Add a background job for **batch processing** using the CLI helper.\n\n#### Conclusion\n\nThe complete sample code and deployment templates are available in the [appservice-ai-samples repository](https://github.com/Azure-Samples/appservice-ai-samples/)\n\nReady to build your own AI chat app? Clone the repo and run azd up to get started in minutes!\n\nFor more Azure App Service AI samples and best practices, check out the [Azure App Service AI integration documentation](https://learn.microsoft.com/azure/app-service/overview-ai-integration)\n\nPublished Nov 04, 2025\n\nVersion 1.0\n\n[azure app service](/tag/azure%20app%20service?nodeId=board%3AAppsonAzureBlog)\n\n[python](/tag/python?nodeId=board%3AAppsonAzureBlog)\n\n[!\\[TulikaC&#x27;s avatar\\](https://techcommunity.microsoft.com/t5/s/gxcuf89792/m_assets/avatars/default/avatar-1.svg?image-dimensions=50x50)](/users/tulikac/1661700) [TulikaC](/users/tulikac/1661700) ![Icon for Microsoft rank](https://techcommunity.microsoft.com/t5/s/gxcuf89792/images/cmstNC05WEo0blc?image-dimensions=100x16&amp;constrain-image=true)Microsoft\n\nJoined December 21, 2022\n\n[View Profile](/users/tulikac/1661700)\n\n/category/azure/blog/appsonazureblog [Apps on Azure Blog](/category/azure/blog/appsonazureblog) Follow this blog board to get notified when there's new activity",
  "Author": "TulikaC",
  "FeedUrl": "https://techcommunity.microsoft.com/t5/s/gxcuf89792/rss/Category?category.id=Azure",
  "Description": "Low-light photos are everywhere: indoor team shots, dim restaurant pics, grainy docs. This post shows a tiny Python app (Flask + OpenCV) that fixes them with explainable image processing—not a heavyweight model. We’ll walk the code that does the real work (CLAHE → gamma → brightness → subtle saturation) and deploy it to **Azure App Service for Linux**.\n\n#### What you’ll build\n\nA Flask web app that accepts an image upload, runs a fast enhancement pipeline (CLAHE → gamma → brightness → subtle saturation), and returns **base64 data URIs** for an instant before/after view in the browser—no storage required for the basic demo.\n\n#### Architecture at a glance\n\n1. **Browser → /enhance** (multipart form): sends an image + optional tunables (clip\\_limit, gamma, brightness).\n2. **Flask → Enhancer**: converts the upload to a NumPy RGB array and calls LowLightEnhancer.enhance\\_image(...).\n3. **Response**: returns JSON with original and enhanced images as base64 PNG data URIs for immediate rendering.\n\n#### Prerequisites\n\n- An Azure subscription\n- [**Azure Developer CLI (azd)**](https://aka.ms/azd) installed\n- (Optional) Python 3.9+ on your dev box for reading the code or extending it\n\n#### Deploy with azd\n\n- git clone https://github.com/Azure-Samples/appservice-ai-samples.git\ncd appservice-ai-samples/lowlight-enhancer azd init azd up\n\nWhen *azd up* finishes, open the printed URL, upload a low-light photo, and compare the result side-by-side.\n\n#### Code walkthrough (the parts that matter)\n\n##### 1) Flask surface area (**app.py**)\n\n- **File size guard**:\n- app = Flask(\\_\\_name\\_\\_)\napp.config['MAX\\_CONTENT\\_LENGTH'] = 16 \\* 1024 \\* 1024 # 16 MB\n\n- **Two routes**:\n- *GET /* - renders the simple UI\n- *POST /enhance* - the JSON API the UI calls via XHR/fetch\n\n- **Parameter handling with sane defaults**:\n- clip\\_limit = float(request.form.get('clip\\_limit', 2.0))\ngamma = float(request.form.get('gamma', 1.2)) brightness = float(request.form.get('brightness', 1.1))\n\n##### 2) Zero-temp-file processing + data-URI response (**app.py**)\n\n*process\\_uploaded\\_image* keeps the hot path tight: convert to RGB → enhance → convert both versions to **base64 PNG** and return them inline.\n- def process\\_uploaded\\_image(file\\_storage, clip\\_limit=2.0, gamma=1.2, brightness=1.1):\n# PIL → NumPy (RGB)\nimg\\_pil = Image.open(file\\_storage) if img\\_pil.mode != 'RGB': img\\_pil = img\\_pil.convert('RGB') img\\_array = np.array(img\\_pil)\n\n# Enhance\nenhanced = LowLightEnhancer().enhance\\_image( img\\_array, clip\\_limit=clip\\_limit, gamma=gamma, brightness\\_boost=brightness )\n\n# Back to base64 data URIs for instant display\ndef pil\\_to\\_base64(pil\\_img): buf = io.BytesIO(); pil\\_img.save(buf, format='PNG') return base64.b64encode(buf.getvalue()).decode('utf-8')\n\nenhanced\\_pil = Image.fromarray(enhanced) return { 'original': f'data:image/png;base64,{pil\\_to\\_base64(img\\_pil)}', 'enhanced': f'data:image/png;base64,{pil\\_to\\_base64(enhanced\\_pil)}' }\n\n##### 3) The enhancement core (**enhancer.py**)\n\n*LowLightEnhancer* implements a classic pipeline that runs great on CPU:\n- class LowLightEnhancer:\ndef \\_\\_init\\_\\_(self): self.clip\\_limit = 2.0 self.tile\\_grid\\_size = (8, 8)\n\ndef enhance\\_image(self, image, clip\\_limit=2.0, gamma=1.2, brightness\\_boost=1.1):\n# Normalize to RGB if the input came in as OpenCV BGR\nis\\_bgr = self.\\_detect\\_bgr(image) rgb = cv2.cvtColor(image, cv2.COLOR\\_BGR2RGB) if is\\_bgr else image\n\n# 1) CLAHE on L-channel (LAB) for local contrast without color blowout\nlab = cv2.cvtColor(rgb, cv2.COLOR\\_RGB2LAB) l, a, b = cv2.split(lab) clahe = cv2.createCLAHE(clipLimit=clip\\_limit, tileGridSize=self.tile\\_grid\\_size) l = clahe.apply(l)\n\n# 2) Gamma correction (perceptual brightness curve)\nl = self.\\_apply\\_gamma\\_correction(l, gamma)\n\n# 3) Gentle overall lift\nl = np.clip(l \\* brightness\\_boost, 0, 255).astype(np.uint8)\n\n# Recombine + small saturation nudge for a natural look\nenhanced = cv2.cvtColor(cv2.merge([l, a, b]), cv2.COLOR\\_LAB2RGB) enhanced = self.\\_boost\\_saturation(enhanced, factor=1.1) return cv2.cvtColor(enhanced, cv2.COLOR\\_RGB2BGR) if is\\_bgr else enhanced\n- **CLAHE on L** (not RGB) avoids the “oversaturated neon” artifact common with naive histogram equalization.\n- **Gamma via LUT** (below) is fast and lets you brighten mid-tones without crushing highlights.\n- A tiny **brightness multiplier** brings the image up just a bit after contrast/curve changes.\n- A **+10% saturation** helps counter the desaturation that often follows brightening.\n\n##### 4) Fast gamma with a lookup table (**enhancer.py**)\n- def \\_apply\\_gamma\\_correction(self, image, gamma: float) -> np.ndarray:\ninv\\_gamma = 1.0 / gamma table = np.array([((i / 255.0) \\*\\* inv\\_gamma) \\* 255 for i in range(256)], dtype=np.uint8) return cv2.LUT(image, table)\n\nNotes:\n\n- With gamma = 1.2, inv\\_gamma ≈ 0.833 → curve brightens mid-tones (exponent\n- cv2.LUT applies the 256-entry mapping efficiently across the image.\n\n##### 5) Bounded color pop: subtle saturation boost (**enhancer.py**)\n- def \\_boost\\_saturation(self, image: np.ndarray, factor: float) -> np.ndarray:\nhsv = cv2.cvtColor(image, cv2.COLOR\\_RGB2HSV).astype(np.float32) hsv[:, :, 1] = np.clip(hsv[:, :, 1] \\* factor, 0, 255) return cv2.cvtColor(hsv.astype(np.uint8), cv2.COLOR\\_HSV2RGB)\n\nNotes:\n\n- Working in **HSV** keeps hue and brightness stable while gently lifting color.\n- The clip to [0, 255] prevents out-of-gamut surprises.\n\n#### Tuning cheatsheet (which knob to turn, and when)\n\n- **Too flat / muddy** → raise clip\\_limit from **2.0 → 3.0–4.0** (more local contrast).\n- **Still too dark** → raise gamma from **1.2 → 1.4–1.6** (brightens mid-tones).\n- **Harsh or “crunchy”** → lower clip\\_limit, or drop brightness\\_boost to **1.05–1.1**.\n- **Colors feel washed out** → increase saturation factor a touch (e.g., **1.1 → 1.15**).\n\n#### What to try next\n\n- Expose more controls in the UI (e.g., tile grid size, saturation factor).\n- Persist originals/results to **Azure Blob Storage** and add shareable links.\n- Add a background job for **batch processing** using the CLI helper.\n\n#### Conclusion\n\nThe complete sample code and deployment templates are available in the [appservice-ai-samples repository](https://github.com/Azure-Samples/appservice-ai-samples/)\n\nReady to build your own AI chat app? Clone the repo and run azd up to get started in minutes!\n\nFor more Azure App Service AI samples and best practices, check out the [Azure App Service AI integration documentation](https://learn.microsoft.com/azure/app-service/overview-ai-integration)"
}
