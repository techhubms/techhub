{
  "EnhancedContent": "## Enterprise workflows are getting more complex—spanning multiple systems, demanding real-time decisions, and enforcing strict compliance. Monolithic AI can’t keep up. The future? Specialized AI agents working together.\n\nMulti‑agent systems turn complex, cross‑department processes into reliable, scalable AI workflows. Here’s a practical guide to designing, wiring, and shipping them with Azure AI Foundry—plus three real‑world scenarios you can take to production.\n\n**Why multi‑agent—and why now?**\n\nModern business workflows rarely fit a single prompt. They span data retrieval, policy checks, approvals, and human sign‑off. Azure AI Foundry brings an **Agent Service**, **connected agents**, and **multi‑agent workflows** that let specialized agents collaborate, with enterprise‑grade security, observability, and open standards (A2A, MCP) baked in. In short: you get faster time‑to‑value without home‑grown orchestration and glue code.\n\n**What you can build today with Foundry**\n\n- **Agent Service**: Define goal‑directed agents, attach tools (Azure AI Search, OpenAPI plugins, Logic Apps, Functions), and deploy with enterprise policies.\n- **Connected agents (A2A)**: Register agents as each other’s “tools” so the **orchestrator** can delegate tasks to **specialists** via natural language—no custom routing required.\n- **Multi‑agent workflows**: Add a **stateful layer** for context, retries, compensation, and long‑running steps—ideal for approvals, fulfilment, and back‑office flows.\n- **Interoperability**: MCP for shared context; A2A for agent‑to‑agent message exchange—across Azure and other clouds.\n- **Observability & trust**: Tracing, metrics, evaluations, and content safety guardrails to measure quality and keep humans in the loop when it matters.\n\n## Reference architecture (mental model)\n\n**User / System trigger** ⟶ **Orchestrator Agent** → delegates to:\n\n1. **Retrieval Agent** (Azure AI Search, Fabric/OneLake)\n2. **Analysis Agent** (reasoning, code execution for calculations)\n3. **Policy Agent** (entitlements, RAI checks, approvals)\n4. **Action Agent** (OpenAPI/Logic Apps/Functions to update systems)\nResults consolidated by **Orchestrator** → **Human‑in‑the‑loop** (if required) → **Audit & telemetry** (Foundry observability)\n\n## Three real‑world scenarios you can ship\n\n### 1) Customer support autopilot (triage → resolution → summary)\n\n- **Flow**: Orchestrator receives a ticket → classifies (Priority/Intent) → Retrieval Agent pulls KB + case history → Analysis Agent drafts fix → Policy Agent checks entitlement/SLAs → Action Agent updates CRM & sends response.\n- **Why multi‑agent**: Clear separation of concerns improves reliability and speeds root‑cause when something breaks.\n\n### 2) Financial approvals (policy‑aware, multi‑step)\n\n- **Flow**: Orchestrator parses invoice → Extraction Agent pulls vendor/PO data → Risk Agent screens anomalies/fraud → Policy Agent checks limits & compliance → Human approval gate → Action Agent posts to ERP.\n- **Why multi‑agent**: Stateful workflows with retries, compensations, and gated actions map cleanly to approvals.\n\n### 3) Supply‑chain exceptions (sense → reason → act)\n\n- **Flow**: Orchestrator ingests an exception → Forecast Agent estimates impact → Vendor Agent queries lead times via OpenAPI → Plan Agent proposes mitigation → Policy Agent validates → Action Agent places change orders.\n- **Why multi‑agent**: Parallel specialization lowers latency and keeps the orchestrator simple.\n\n## Build your first connected‑agent workflow (conceptual walk‑through)\n\nYou can do this in the **Azure AI Foundry portal** or via the **Foundry SDK**. The high‑level steps mirror the official “Connected agents” how‑to.\n\n### 1) Create a Foundry project & deployments\n\n- Provision your model deployments (for example, a reasoning model for the Orchestrator, a cost‑optimized model for specialists).\n- Connect data sources (Azure AI Search index; Fabric/OneLake; SharePoint) and register tools (OpenAPI, Logic Apps/Functions).\n\n### 2) Define agent roles\n\n- **Orchestrator**: understands goals, delegates, composes answers.\n- **Retrieval**: authoritative grounding from enterprise content.\n- **Analysis**: calculations, code execution for tabular or numeric tasks.\n- **Policy**: entitlements, data‑loss checks, approval thresholds.\n- **Action**: calls systems of record with auditable side‑effects.\n\n### 3) Register connected agents (A2A)\n\nIn the portal, add each specialist as a **tool** to the Orchestrator; in code, you’d associate child agent IDs as callable tools.\n\n> >\n> # Conceptual snippet (simplified). Refer to docs for exact SDK classes.\n> orchestrator = agents.create(\n>     name=\"orchestrator\",\n>     instructions=\"You coordinate specialists. Delegate, verify, and compile final answers.\"\n> )\n> > >\n> retrieval = agents.create(name=\"retrieval\", tools=[\"azure\\_ai\\_search:kb\\_index\"])\n> analysis  = agents.create(name=\"analysis\",  tools=[\"code\\_interpreter\"])\n> policy    = agents.create(name=\"policy\",    tools=[\"policy\\_rules:mcp\"])\n> action    = agents.create(name=\"action\",    tools=[\"openapi:erp\",\"logicapp:notify\"])\n> > >\n> # Connect specialists as 'tools' on the orchestrator (A2A)\n> agents.connect(parent=orchestrator.id, children=[retrieval.id, analysis.id, policy.id, action.id])\n> >\n\n### 4) Orchestrate as a workflow (state, retries, HIL)\n\nAdd a workflow definition that persists state, sets retry/backoff policies, and inserts **human‑in‑the‑loop** gates for sensitive steps (for example, spend over a threshold).\n\n> >\n> # Pseudocode: workflow policy\n> steps:\n>   - delegate: retrieval\n>     retry: {max: 2, backoff: expo}\n>   - parallel:\n>       - analysis\n>       - policy\n>   - gate:\n>       type: human\\_approval\n>       condition: \"${policy.limit\\_exceeded == true}\"\n>   - delegate: action\n> audit:\n>   trace: enabled\n>   pii\\_redaction: strict\n> >\n\n### 5) Observe, evaluate, and iterate\n\nUse Foundry **traces**, **scores**, and **evaluations** to compare prompts, tools, and model mix; add cost/latency budgets per step and enable content safety filters.\n\n## Design tips from the field\n\n- **Start small**: two agents (Orchestrator + specialist) are enough to prove value. Add more only when clarity or latency improves.\n- **Isolate responsibilities**: retrieval should never mutate systems; action agents shouldn’t reason about policy.\n- **Make steps idempotent**: so retries are safe. Leverage correlation IDs in action agents.\n- **Guardrails &gt; guesswork**: define **gated actions** for irreversible operations; log every action payload for audits.\n- **Cost & latency budgets**: use cheaper models for retrieval/formatting; reserve premium reasoning where it moves the KPI.\n- **Humans in the loop**: approvals, exceptions, and SLA breaches should route to people—with crisp, linked evidence packs.\n\n## Resources to go deeper\n\n- **Azure AI Foundry: AI app & agent factory (multi‑agent overview, A2A, MCP, workflows)**\n- **How‑to: Build “connected agents” (step‑by‑step)**\n- **Architecture Center: AI agent orchestration patterns**\n- **Multi‑agent systems & MCP tools (TechCommunity explainer + Learn modules)**\n\nUpdated Aug 31, 2025\n\nVersion 1.0\n\n[!\\[lakshaymalik&#x27;s avatar\\](https://techcommunity.microsoft.com/t5/s/gxcuf89792/m_assets/avatars/default/avatar-8.svg?image-dimensions=50x50)](/users/lakshaymalik/2973662) [lakshaymalik](/users/lakshaymalik/2973662) ![Icon for Microsoft rank](https://techcommunity.microsoft.com/t5/s/gxcuf89792/images/cmstNC05WEo0blc?image-dimensions=100x16&amp;constrain-image=true)Microsoft\n\nJoined March 28, 2025\n\n[View Profile](/users/lakshaymalik/2973662)\n\n/category/azure/blog/azureinfrastructureblog [Azure Infrastructure Blog](/category/azure/blog/azureinfrastructureblog) Follow this blog board to get notified when there's new activity",
  "Link": "https://techcommunity.microsoft.com/t5/azure-infrastructure-blog/multi-agent-orchestration-with-azure-ai-foundry-from-idea-to/ba-p/4449925",
  "Tags": [],
  "Author": "lakshaymalik",
  "FeedUrl": "https://techcommunity.microsoft.com/t5/s/gxcuf89792/rss/Category?category.id=Azure",
  "FeedLevelAuthor": "rss.livelink.threads-in-node",
  "Title": "Multi‑Agent Orchestration with Azure AI Foundry: From Idea to Production",
  "FeedName": "Microsoft Tech Community",
  "OutputDir": "_community",
  "ProcessedDate": "2025-08-31 15:11:28",
  "Description": "Multi‑agent systems turn complex, cross‑department processes into reliable, scalable AI workflows. Here’s a practical guide to designing, wiring, and shipping them with Azure AI Foundry—plus three real‑world scenarios you can take to production.\n\n**Why multi‑agent—and why now?**\n\nModern business workflows rarely fit a single prompt. They span data retrieval, policy checks, approvals, and human sign‑off. Azure AI Foundry brings an **Agent Service**, **connected agents**, and **multi‑agent workflows** that let specialized agents collaborate, with enterprise‑grade security, observability, and open standards (A2A, MCP) baked in. In short: you get faster time‑to‑value without home‑grown orchestration and glue code.\n\n**What you can build today with Foundry**\n\n- **Agent Service**: Define goal‑directed agents, attach tools (Azure AI Search, OpenAPI plugins, Logic Apps, Functions), and deploy with enterprise policies.\n- **Connected agents (A2A)**: Register agents as each other’s “tools” so the **orchestrator** can delegate tasks to **specialists** via natural language—no custom routing required.\n- **Multi‑agent workflows**: Add a **stateful layer** for context, retries, compensation, and long‑running steps—ideal for approvals, fulfilment, and back‑office flows.\n- **Interoperability**: MCP for shared context; A2A for agent‑to‑agent message exchange—across Azure and other clouds.\n- **Observability & trust**: Tracing, metrics, evaluations, and content safety guardrails to measure quality and keep humans in the loop when it matters.\n\n## Reference architecture (mental model)\n\n**User / System trigger** ⟶ **Orchestrator Agent** → delegates to:\n\n1. **Retrieval Agent** (Azure AI Search, Fabric/OneLake)\n2. **Analysis Agent** (reasoning, code execution for calculations)\n3. **Policy Agent** (entitlements, RAI checks, approvals)\n4. **Action Agent** (OpenAPI/Logic Apps/Functions to update systems)\nResults consolidated by **Orchestrator** → **Human‑in‑the‑loop** (if required) → **Audit & telemetry** (Foundry observability)\n\n## Three real‑world scenarios you can ship\n\n### 1) Customer support autopilot (triage → resolution → summary)\n\n- **Flow**: Orchestrator receives a ticket → classifies (Priority/Intent) → Retrieval Agent pulls KB + case history → Analysis Agent drafts fix → Policy Agent checks entitlement/SLAs → Action Agent updates CRM & sends response.\n- **Why multi‑agent**: Clear separation of concerns improves reliability and speeds root‑cause when something breaks.\n\n### 2) Financial approvals (policy‑aware, multi‑step)\n\n- **Flow**: Orchestrator parses invoice → Extraction Agent pulls vendor/PO data → Risk Agent screens anomalies/fraud → Policy Agent checks limits & compliance → Human approval gate → Action Agent posts to ERP.\n- **Why multi‑agent**: Stateful workflows with retries, compensations, and gated actions map cleanly to approvals.\n\n### 3) Supply‑chain exceptions (sense → reason → act)\n\n- **Flow**: Orchestrator ingests an exception → Forecast Agent estimates impact → Vendor Agent queries lead times via OpenAPI → Plan Agent proposes mitigation → Policy Agent validates → Action Agent places change orders.\n- **Why multi‑agent**: Parallel specialization lowers latency and keeps the orchestrator simple.\n\n## Build your first connected‑agent workflow (conceptual walk‑through)\n\nYou can do this in the **Azure AI Foundry portal** or via the **Foundry SDK**. The high‑level steps mirror the official “Connected agents” how‑to.\n\n### 1) Create a Foundry project & deployments\n\n- Provision your model deployments (for example, a reasoning model for the Orchestrator, a cost‑optimized model for specialists).\n- Connect data sources (Azure AI Search index; Fabric/OneLake; SharePoint) and register tools (OpenAPI, Logic Apps/Functions).\n\n### 2) Define agent roles\n\n- **Orchestrator**: understands goals, delegates, composes answers.\n- **Retrieval**: authoritative grounding from enterprise content.\n- **Analysis**: calculations, code execution for tabular or numeric tasks.\n- **Policy**: entitlements, data‑loss checks, approval thresholds.\n- **Action**: calls systems of record with auditable side‑effects.\n\n### 3) Register connected agents (A2A)\n\nIn the portal, add each specialist as a **tool** to the Orchestrator; in code, you’d associate child agent IDs as callable tools.\n\n> >\n> # Conceptual snippet (simplified). Refer to docs for exact SDK classes.\n> orchestrator = agents.create(\n> name=\"orchestrator\",\n> instructions=\"You coordinate specialists. Delegate, verify, and compile final answers.\"\n> )\n> > >\n> retrieval = agents.create(name=\"retrieval\", tools=[\"azure\\_ai\\_search:kb\\_index\"])\n> analysis = agents.create(name=\"analysis\", tools=[\"code\\_interpreter\"])\n> policy = agents.create(name=\"policy\", tools=[\"policy\\_rules:mcp\"])\n> action = agents.create(name=\"action\", tools=[\"openapi:erp\",\"logicapp:notify\"])\n> > >\n> # Connect specialists as 'tools' on the orchestrator (A2A)\n> agents.connect(parent=orchestrator.id, children=[retrieval.id, analysis.id, policy.id, action.id])\n> >\n\n### 4) Orchestrate as a workflow (state, retries, HIL)\n\nAdd a workflow definition that persists state, sets retry/backoff policies, and inserts **human‑in‑the‑loop** gates for sensitive steps (for example, spend over a threshold).\n\n> >\n> # Pseudocode: workflow policy\n> steps:\n> - delegate: retrieval\n> retry: {max: 2, backoff: expo}\n> - parallel:\n> - analysis\n> - policy\n> - gate:\n> type: human\\_approval\n> condition: \"${policy.limit\\_exceeded == true}\"\n> - delegate: action\n> audit:\n> trace: enabled\n> pii\\_redaction: strict\n> >\n\n### 5) Observe, evaluate, and iterate\n\nUse Foundry **traces**, **scores**, and **evaluations** to compare prompts, tools, and model mix; add cost/latency budgets per step and enable content safety filters.\n\n## Design tips from the field\n\n- **Start small**: two agents (Orchestrator + specialist) are enough to prove value. Add more only when clarity or latency improves.\n- **Isolate responsibilities**: retrieval should never mutate systems; action agents shouldn’t reason about policy.\n- **Make steps idempotent**: so retries are safe. Leverage correlation IDs in action agents.\n- **Guardrails > guesswork**: define **gated actions** for irreversible operations; log every action payload for audits.\n- **Cost & latency budgets**: use cheaper models for retrieval/formatting; reserve premium reasoning where it moves the KPI.\n- **Humans in the loop**: approvals, exceptions, and SLA breaches should route to people—with crisp, linked evidence packs.\n\n## Resources to go deeper\n\n- **Azure AI Foundry: AI app & agent factory (multi‑agent overview, A2A, MCP, workflows)**\n- **How‑to: Build “connected agents” (step‑by‑step)**\n- **Architecture Center: AI agent orchestration patterns**\n- **Multi‑agent systems & MCP tools (TechCommunity explainer + Learn modules)**",
  "PubDate": "2025-08-31T14:59:26+00:00"
}
