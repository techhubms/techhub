{
  "PubDate": "2025-08-22T16:38:59+00:00",
  "FeedUrl": "https://techcommunity.microsoft.com/t5/s/gxcuf89792/rss/Category?category.id=Azure",
  "Link": "https://techcommunity.microsoft.com/t5/linux-and-open-source-blog/troubleshooting-network-issues-with-retina/ba-p/4446071",
  "EnhancedContent": "The Kubernetes environment comes with its own unique challenges, particularly at enterprise level scale. Hundreds or thousands of pods may exist at any given point in time and are continuously being created, deleted, restarted, reallocated etc. On top of that, these pods are also distributed amongst tens, hundreds, or even thousands of nodes.\n\nIf you need to troubleshoot connectivity issues within your microservices on such a cluster, manually executing tcpdump against individual containers will be an extremely slow and tedious process. This would typically require you to identify the node where the relevant pod is running, run tcpdump (installing it if needed) and then transfer the .pcap files away for analysis. Rinse and repeat for multiple pods as required.\n\nInstalling tools can be restricted in many environments, and the ephemeral nature of pods makes pod-based captures unreliable and difficult to manage.\n\nEnter Retina.\n\n## What is Retina?\n\nRetina is a cloud-agnostic, open-source Kubernetes network observability platform that leverages the power of eBPF for observability and deep network insights.\n\nThis post will discuss how Retina solves key challenges of performing packet captures in a Kubernetes environment, and additional debug tools which are provided within the Retina Shell.\n\nTo learn more about Retina, refer to the following blog post: [Retina: Bridging Kubernetes Observability and eBPF Across the Clouds](https://techcommunity.microsoft.com/blog/linuxandopensourceblog/ebpf-powered-observability-beyond-azure-a-multi-cloud-perspective-with-retina/4403361), or visit the documentation directly at [retina.sh](https://retina.sh/).\n\n## Packet Captures with Retina\n\nRetina captures allow users to perform distributed packet captures across the cluster, based on specified Nodes/Pods and other supported filters. This eliminates the manual toil of installing tools and running captures on individual targets.\n\nThe captures are performed on demand, either via the CLI or a CRD, and can be output to persistent storage options which include the host filesystem, PVC or a storage blob. Whenever a capture is initiated, a Kubernetes job is created on each relevant Node. The job’s worker Pod runs for the specified duration, performs the capture, and wraps the network information into a tarball. The tarball is then copied to the appropriate output location(s).\n\nThe names of the created jobs are appended with a random hash to uniquely identify them. For example, a capture named '*hello-world'* might end up with a name '*hello-world-bkfzp*'.\n\nThe names of the tarballs include the capture name, the host name, and a UTC time stamp - e.g. '*hello-world-aks-agentpool-13097696-vmss000000-20250813182832UTC.tar.gz'.*\n\nRetina CLI - performing a packet capture and downloading the output\n\nThe result of the capture contains more than just a .pcap file. Retina also captures a number of networking metadata such as iptables rules, socket statistics, kernel network information from */proc/net*, and more. Refer to the documentation for the exhaustive list - [Tarball Contents](https://retina.sh/docs/Captures/cli#file-and-directory-structure-inside-the-tarball).\n\nTo learn more about Retina captures, check out the documentation:\n\n- [Capture with CLI](https://retina.sh/docs/Captures/cli)\n\n- [Capture with CRD](https://retina.sh/docs/Captures/crd)\n\n### Quick Start\n\n```\n# install Retina CLI\nkubectl krew install retina\n\n# create a packet capture\nkubectl retina capture create\n\n# observe captures until they are done\nkubectl retina capture list\n\n# download the result of the capture\nkubectl retina capture download --name retina-capture\n\n# extract the contents of the downloaded tarball\ntar -xvf <name.tar.gz> ```\n\n### Common Scenarios\n\nExample 1: Capture traffic from a single deployment, e.g. coredns\n\n``` kubectl retina capture create \\ --name coredns \\ --pod-selectors \"k8s-app=kube-dns\" \\ --namespace-selectors=\"kubernetes.io/metadata.name=kube-system\" ```\n\nExample 2: Capture traffic from a single deployment with specific traffic filters\n\n``` kubectl retina capture create \\ --name coredns \\ --pod-selectors \"k8s-app=kube-dns\" \\ --namespace-selectors=\"kubernetes.io/metadata.name=kube-system\" \\ --tcpdump-filter \"tcp and port 53\" ```\n\nExample 3: Capture all traffic on a specific node\n\n``` kubectl retina capture create \\ --name node-full \\ --node-selectors \"kubernetes.io/hostname=aks-nodepool1-21861315-vmss000003\" ```\n\nExample 4: Capture all HTTPS traffic on all Linux nodes and upload to blob storage\n\n``` kubectl retina capture create \\ --name all-linux-node-443 \\ --node-selectors \"kubernetes.io/os=linux\" \\ --tcpdump-filter \"tcp and port 443\" \\ --blob-upload <SAS URL> ```\n\n## Advanced Debugging with Retina Shell\n\nThe [Retina Shell](https://retina.sh/docs/Troubleshooting/shell) is still considered to be an experimental feature; however, it has already proven to be extremely useful for troubleshooting different networking scenarios.\n\n> >\n> Note: As of v1.0.0-rc2, Retina Shell only supports Linux based Nodes / Pods.\n> >\n\nBy running the '*retina shell'* command you can start an interactive shell on a Kubernetes Node or Pod. This runs a container image which contains many networking tools such as curl, ping, nslookup, iptables and more.\n\nIn the latest Retina release (v0.0.36) both pwru and bpftool have been added to the suite. Inspektor Gadget has been added within the pre-release v1.0.0-rc2.\n\nRetina CLI - using retina shell to connect to a node to troubleshoot with bpftool and pwru\n\nTo learn more about Retina Shell, check out the documentation:\n\n- [Retina Shell](https://retina.sh/docs/Troubleshooting/shell)\n\n### Quick Start\n\n```\n# different ways of invoking the Retina Shell\nkubectl retina shell <node-name> kubectl retina shell -n <namespace> pods/<pod-name> kubectl retina shell <node-name> --mount-host-filesystem kubectl retina shell <node-name> --capabilities=<CAPABILITIES,COMMA,SEPARATED> ```\n\n### [pwru](https://github.com/cilium/pwru)\n\nAn eBPF-based tool for tracing network packets in the Linux kernel with advanced filtering capabilities. It allows fine-grained introspection of the kernel state to facilitate debugging network connectivity issues.\n\nExample: Debugging HTTP Traffic Between Microservices\n\n``` pwru \"tcp and (src port 8080 or dst port 8080)\" ```\n\n### [bpftool](https://github.com/libbpf/bpftool)\n\nAllows users to list, dump, load BPF programs and more. It is a reference utility to quickly inspect and manage BPF objects on your system, to manipulate BPF object files, or to perform various other BPF-related tasks.\n\nExample 1: List and Inspect Loaded BPF Programs\n\n``` bpftool prog show ```\n\nExample 2: Dump BPF Maps to Debug Connection Tracking\n\n``` bpftool map dump id <map_id> ```\n\n### [Inspektor Gadget](https://github.com/inspektor-gadget/inspektor-gadget)\n\nA set of tools and framework for data collection and system inspection on Kubernetes clusters and Linux hosts using eBPF.\n\nExample 1: Trace DNS Queries and Responses\n\n``` ig run trace_dns:latest -n <namespace> -p <pod> ```\n\nExample 2: Trace OOM Kill Events\n\n``` ig run trace_oomkill:latest --namespace <namespace> ```\n\n## Conclusion\n\nThe best network issues are the ones that never happen. Unfortunately, this is not the reality for most services and when things inevitably go bad you need to be able to count on your tools to help you.\n\nRetina solves many of the challenges of debugging connectivity issues in a Kubernetes environment by providing a streamlined experience out-of-the-box, eliminating the manual toil and operational overhead. Whether you need to run a distributed packet capture across your cluster or connect to a Node and dig deeper with specialized tooling, Retina has you covered.\n\nTo keep up with the development and new releases, star the repository on GitHub - [microsoft/retina](https://github.com/microsoft/retina), or contribute to the project yourself by following the [development guide](https://retina.sh/docs/Contributing/development/)!\n\nUpdated Aug 22, 2025\n\nVersion 1.0\n\n[ebpf](/tag/ebpf?nodeId=board%3ALinuxandOpenSourceBlog)\n\n[inspektor gadget](/tag/inspektor%20gadget?nodeId=board%3ALinuxandOpenSourceBlog)\n\n[monitoring](/tag/monitoring?nodeId=board%3ALinuxandOpenSourceBlog)\n\n[observability](/tag/observability?nodeId=board%3ALinuxandOpenSourceBlog)\n\n[troubleshooting](/tag/troubleshooting?nodeId=board%3ALinuxandOpenSourceBlog)\n\n[!\\[kamilp&#x27;s avatar\\](https://techcommunity.microsoft.com/t5/s/gxcuf89792/images/dS0zMDAxODE0LWhzV0xzQw?image-coordinates=58%2C206%2C940%2C1089&amp;image-dimensions=50x50)](/users/kamilp/3001814) [kamilp](/users/kamilp/3001814) ![Icon for Microsoft rank](https://techcommunity.microsoft.com/t5/s/gxcuf89792/images/cmstNC05WEo0blc?image-dimensions=100x16&amp;constrain-image=true)Microsoft\n\nJoined April 18, 2025\n\n[View Profile](/users/kamilp/3001814)\n\n/category/azure/blog/linuxandopensourceblog [Linux and Open Source Blog](/category/azure/blog/linuxandopensourceblog) Follow this blog board to get notified when there's new activity",
  "OutputDir": "_community",
  "FeedName": "Microsoft Tech Community",
  "Description": "The Kubernetes environment comes with its own unique challenges, particularly at enterprise level scale. Hundreds or thousands of pods may exist at any given point in time and are continuously being created, deleted, restarted, reallocated etc. On top of that, these pods are also distributed amongst tens, hundreds, or even thousands of nodes.\n\nIf you need to troubleshoot connectivity issues within your microservices on such a cluster, manually executing tcpdump against individual containers will be an extremely slow and tedious process. This would typically require you to identify the node where the relevant pod is running, run tcpdump (installing it if needed) and then transfer the .pcap files away for analysis. Rinse and repeat for multiple pods as required.\n\nInstalling tools can be restricted in many environments, and the ephemeral nature of pods makes pod-based captures unreliable and difficult to manage.\n\nEnter Retina.\n\n## What is Retina?\n\nRetina is a cloud-agnostic, open-source Kubernetes network observability platform that leverages the power of eBPF for observability and deep network insights.\n\nThis post will discuss how Retina solves key challenges of performing packet captures in a Kubernetes environment, and additional debug tools which are provided within the Retina Shell.\n\nTo learn more about Retina, refer to the following blog post: [Retina: Bridging Kubernetes Observability and eBPF Across the Clouds](https://techcommunity.microsoft.com/blog/linuxandopensourceblog/ebpf-powered-observability-beyond-azure-a-multi-cloud-perspective-with-retina/4403361), or visit the documentation directly at [retina.sh](https://retina.sh/).\n\n## Packet Captures with Retina\n\nRetina captures allow users to perform distributed packet captures across the cluster, based on specified Nodes/Pods and other supported filters. This eliminates the manual toil of installing tools and running captures on individual targets.\n\nThe captures are performed on demand, either via the CLI or a CRD, and can be output to persistent storage options which include the host filesystem, PVC or a storage blob. Whenever a capture is initiated, a Kubernetes job is created on each relevant Node. The job’s worker Pod runs for the specified duration, performs the capture, and wraps the network information into a tarball. The tarball is then copied to the appropriate output location(s).\n\nThe names of the created jobs are appended with a random hash to uniquely identify them. For example, a capture named '*hello-world'* might end up with a name '*hello-world-bkfzp*'.\n\nThe names of the tarballs include the capture name, the host name, and a UTC time stamp - e.g. '*hello-world-aks-agentpool-13097696-vmss000000-20250813182832UTC.tar.gz'.*\n\n![]()Retina CLI - performing a packet capture and downloading the output\n\nThe result of the capture contains more than just a .pcap file. Retina also captures a number of networking metadata such as iptables rules, socket statistics, kernel network information from */proc/net*, and more. Refer to the documentation for the exhaustive list - [Tarball Contents](https://retina.sh/docs/Captures/cli#file-and-directory-structure-inside-the-tarball).\n\nTo learn more about Retina captures, check out the documentation:\n\n- [Capture with CLI](https://retina.sh/docs/Captures/cli)\n\n- [Capture with CRD](https://retina.sh/docs/Captures/crd)\n\n### Quick Start\n\n- # install Retina CLI\nkubectl krew install retina\n\n# create a packet capture\nkubectl retina capture create\n\n# observe captures until they are done\nkubectl retina capture list\n\n# download the result of the capture\nkubectl retina capture download --name retina-capture\n\n# extract the contents of the downloaded tarball\ntar -xvf\n\n### Common Scenarios\n\nExample 1: Capture traffic from a single deployment, e.g. coredns\n- kubectl retina capture create \\\n--name coredns \\ --pod-selectors \"k8s-app=kube-dns\" \\ --namespace-selectors=\"kubernetes.io/metadata.name=kube-system\"\n\nExample 2: Capture traffic from a single deployment with specific traffic filters\n- kubectl retina capture create \\\n--name coredns \\ --pod-selectors \"k8s-app=kube-dns\" \\ --namespace-selectors=\"kubernetes.io/metadata.name=kube-system\" \\ --tcpdump-filter \"tcp and port 53\"\n\nExample 3: Capture all traffic on a specific node\n- kubectl retina capture create \\\n--name node-full \\ --node-selectors \"kubernetes.io/hostname=aks-nodepool1-21861315-vmss000003\"\n\nExample 4: Capture all HTTPS traffic on all Linux nodes and upload to blob storage\n- kubectl retina capture create \\\n--name all-linux-node-443 \\ --node-selectors \"kubernetes.io/os=linux\" \\ --tcpdump-filter \"tcp and port 443\" \\ --blob-upload\n\n## Advanced Debugging with Retina Shell\n\nThe [Retina Shell](https://retina.sh/docs/Troubleshooting/shell) is still considered to be an experimental feature; however, it has already proven to be extremely useful for troubleshooting different networking scenarios.\n\n> >\n> Note: As of v1.0.0-rc2, Retina Shell only supports Linux based Nodes / Pods.\n> >\n\nBy running the '*retina shell'* command you can start an interactive shell on a Kubernetes Node or Pod. This runs a container image which contains many networking tools such as curl, ping, nslookup, iptables and more.\n\nIn the latest Retina release (v0.0.36) both pwru and bpftool have been added to the suite. Inspektor Gadget has been added within the pre-release v1.0.0-rc2.\n\n![]()Retina CLI - using retina shell to connect to a node to troubleshoot with bpftool and pwru\n\nTo learn more about Retina Shell, check out the documentation:\n\n- [Retina Shell](https://retina.sh/docs/Troubleshooting/shell)\n\n### Quick Start\n- # different ways of invoking the Retina Shell\nkubectl retina shell kubectl retina shell -n pods/ kubectl retina shell --mount-host-filesystem kubectl retina shell --capabilities=\n\n### [pwru](https://github.com/cilium/pwru)\n\nAn eBPF-based tool for tracing network packets in the Linux kernel with advanced filtering capabilities. It allows fine-grained introspection of the kernel state to facilitate debugging network connectivity issues.\n\nExample: Debugging HTTP Traffic Between Microservices\n- pwru \"tcp and (src port 8080 or dst port 8080)\"\n\n### [bpftool](https://github.com/libbpf/bpftool)\n\nAllows users to list, dump, load BPF programs and more. It is a reference utility to quickly inspect and manage BPF objects on your system, to manipulate BPF object files, or to perform various other BPF-related tasks.\n\nExample 1: List and Inspect Loaded BPF Programs\n- bpftool prog show\n\nExample 2: Dump BPF Maps to Debug Connection Tracking\n- bpftool map dump id\n\n### [Inspektor Gadget](https://github.com/inspektor-gadget/inspektor-gadget)\n\nA set of tools and framework for data collection and system inspection on Kubernetes clusters and Linux hosts using eBPF.\n\nExample 1: Trace DNS Queries and Responses\n- ig run trace\\_dns:latest -n -p\n\nExample 2: Trace OOM Kill Events\n- ig run trace\\_oomkill:latest --namespace\n\n## Conclusion\n\nThe best network issues are the ones that never happen. Unfortunately, this is not the reality for most services and when things inevitably go bad you need to be able to count on your tools to help you.\n\nRetina solves many of the challenges of debugging connectivity issues in a Kubernetes environment by providing a streamlined experience out-of-the-box, eliminating the manual toil and operational overhead. Whether you need to run a distributed packet capture across your cluster or connect to a Node and dig deeper with specialized tooling, Retina has you covered.\n\nTo keep up with the development and new releases, star the repository on GitHub - [microsoft/retina](https://github.com/microsoft/retina), or contribute to the project yourself by following the [development guide](https://retina.sh/docs/Contributing/development/)!",
  "ProcessedDate": "2025-08-22 17:11:09",
  "FeedLevelAuthor": "rss.livelink.threads-in-node",
  "Title": "Troubleshooting Network Issues with Retina",
  "Tags": [],
  "Author": "kamilp"
}
