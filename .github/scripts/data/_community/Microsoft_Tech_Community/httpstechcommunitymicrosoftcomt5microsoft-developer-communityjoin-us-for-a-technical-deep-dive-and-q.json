{
  "Title": "Join Us for a Technical Deep Dive and Q&A on Foundry Local - LLMs on device",
  "ProcessedDate": "2025-09-19 07:12:42",
  "Description": "**Join us for an Ask Me Anything with the Foundry Local team on September 29th, 2025!**\n\nDiscover how Foundry Local is redefining edge AI with powerful features like **on-device inference**, enabling you to run models directly on your hardware, cutting costs and keeping your data secure. Whether you're customizing models to fit unique use cases or integrating seamlessly via SDKs, APIs, or CLI, Foundry Local offers scalable pathways to Azure AI Foundry as your needs evolve. It's the perfect solution for environments with limited connectivity, sensitive data requirements, low-latency demands, or early-stage experimentation before cloud deployment. If you're building smarter, leaner, and more private AI workflows, this AMA is your chance to dive deep with the team behind it all.\n\n### **What is Foundry Local?**\n\n[Foundry Local](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/) is a set of development tools designed to help you build and evaluate LLM applications on your local machine. It provides a curated collection of production-quality tools, including evaluation and prompt engineering capabilities, that are fully compatible with Azure AI. This allows for a seamless transition of your work from your local environment to the cloud. Don't miss this opportunity to connect with our experts and enhance your understanding of local LLM development.\n\n![]()\n\nFoundry Local is an on-device AI inference solution offering performance, privacy, customization, and cost advantages. It integrates seamlessly into your existing workflows and applications through an intuitive CLI, SDK, and REST API.\n\n## Key features\n\n- **On-Device Inference**: Run models locally on your own hardware, reducing your costs while keeping all your data on your device.\n- **Model Customization**: Select from preset models or use your own to meet specific requirements and use cases.\n- **Cost Efficiency**: Eliminate recurring cloud service costs by using your existing hardware, making AI more accessible.\n- **Seamless Integration**: Connect with your applications through an SDK, API endpoints, or the CLI, with easy scaling to Azure AI Foundry as your needs grow.\n\n### **How to Join:**\n\n[Register to Join the Azure AI Foundry Discord Community Event](https://discord.gg/azureaifoundry?event=1418186096830972056) 29th Sept 2025 9am Pacific Time UTC−08:00\n\n### **Unlock Accelerated Local LLM Development**\n\nDiscover how Foundry Local can enhance your development process and explore the possibilities for building robust LLM applications. Whether you're a seasoned AI developer or just getting started, this session is your chance to get hands-on insights into the innovative world of Azure AI Foundry.\n\n### **Event Highlights:**\n\n- An in-depth overview of the Foundry Local CLI and SDK.\n- Interactive demo with step-by-step examples.\n- Best practices for local AI Inference and models\n- Transitioning your local development to cloud solutions or vice-versa\n\n### **Why Attend?**\n\n- Gain expert insights into Foundry Local, and ask questions about using Foundry Local\n- Network with fellow AI professionals and developers.\n- Enhance your AI development skills with practical examples.\n- Stay at the forefront of LLM application development.\n\n### **Speakers**\n\n![]()Maanav Dalah Product Manager Foundry Local\n\n**Maanav Dalal**\n\nProduct Manager |Foundry Local [Microsoft](https://build.microsoft.com/en-US/speakers?filter=company%3EMicrosoft)\n\nMaanav Dalal is a PM on the AI Frameworks team. He's super inquisitive about the ways you use AI in daily life, so be encouraged to strike up a conversation with him about that.\n\n[LinkedIn Profile](https://www.linkedin.com/in/maanavdalal/)",
  "FeedUrl": "https://techcommunity.microsoft.com/t5/s/gxcuf89792/rss/Category?category.id=Azure",
  "Link": "https://techcommunity.microsoft.com/t5/microsoft-developer-community/join-us-for-a-technical-deep-dive-and-q-a-on-foundry-local-llms/ba-p/4455060",
  "EnhancedContent": "## Join us for an Ask Me Anything with the Foundry Local team on September 29th, 2025! Discover how Foundry Local is redefining edge AI with powerful features like on-device inference, enabling you to run models directly on your hardware.\n\n**Join us for an Ask Me Anything with the Foundry Local team on September 29th, 2025!**\n\nDiscover how Foundry Local is redefining edge AI with powerful features like **on-device inference**, enabling you to run models directly on your hardware, cutting costs and keeping your data secure. Whether you're customizing models to fit unique use cases or integrating seamlessly via SDKs, APIs, or CLI, Foundry Local offers scalable pathways to Azure AI Foundry as your needs evolve. It's the perfect solution for environments with limited connectivity, sensitive data requirements, low-latency demands, or early-stage experimentation before cloud deployment. If you're building smarter, leaner, and more private AI workflows, this AMA is your chance to dive deep with the team behind it all.\n\n### **What is Foundry Local?**\n\n[Foundry Local](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/) is a set of development tools designed to help you build and evaluate LLM applications on your local machine. It provides a curated collection of production-quality tools, including evaluation and prompt engineering capabilities, that are fully compatible with Azure AI. This allows for a seamless transition of your work from your local environment to the cloud. Don't miss this opportunity to connect with our experts and enhance your understanding of local LLM development.\n\nFoundry Local is an on-device AI inference solution offering performance, privacy, customization, and cost advantages. It integrates seamlessly into your existing workflows and applications through an intuitive CLI, SDK, and REST API.\n\n## Key features\n\n- **On-Device Inference**: Run models locally on your own hardware, reducing your costs while keeping all your data on your device.\n- **Model Customization**: Select from preset models or use your own to meet specific requirements and use cases.\n- **Cost Efficiency**: Eliminate recurring cloud service costs by using your existing hardware, making AI more accessible.\n- **Seamless Integration**: Connect with your applications through an SDK, API endpoints, or the CLI, with easy scaling to Azure AI Foundry as your needs grow.\n\n### **How to Join:**\n\n[Register to Join the Azure AI Foundry Discord Community Event](https://discord.gg/azureaifoundry?event=1418186096830972056) 29th Sept 2025 9am Pacific Time UTC−08:00\n\n### **Unlock Accelerated Local LLM Development**\n\nDiscover how Foundry Local can enhance your development process and explore the possibilities for building robust LLM applications. Whether you're a seasoned AI developer or just getting started, this session is your chance to get hands-on insights into the innovative world of Azure AI Foundry.\n\n### **Event Highlights:**\n\n- An in-depth overview of the Foundry Local CLI and SDK.\n- Interactive demo with step-by-step examples.\n- Best practices for local AI Inference and models\n- Transitioning your local development to cloud solutions or vice-versa\n\n### **Why Attend?**\n\n- Gain expert insights into Foundry Local, and ask questions about using Foundry Local\n- Network with fellow AI professionals and developers.\n- Enhance your AI development skills with practical examples.\n- Stay at the forefront of LLM application development.\n\n### **Speakers**\n\nMaanav Dalah Product Manager Foundry Local\n\n**Maanav Dalal**\n\nProduct Manager |Foundry Local [Microsoft](https://build.microsoft.com/en-US/speakers?filter=company%3EMicrosoft)\n\nMaanav Dalal is a PM on the AI Frameworks team. He's super inquisitive about the ways you use AI in daily life, so be encouraged to strike up a conversation with him about that.\n\n[LinkedIn Profile](https://www.linkedin.com/in/maanavdalal/)\n\nPublished Sep 19, 2025\n\nVersion 1.0\n\n[ai](/tag/ai?nodeId=board%3AAzureDevCommunityBlog)\n\n[ai foundry](/tag/ai%20foundry?nodeId=board%3AAzureDevCommunityBlog)\n\n[azure ai foundry](/tag/azure%20ai%20foundry?nodeId=board%3AAzureDevCommunityBlog)\n\n[foundry local](/tag/foundry%20local?nodeId=board%3AAzureDevCommunityBlog)\n\n[genai](/tag/genai?nodeId=board%3AAzureDevCommunityBlog)\n\n[get started](/tag/get%20started?nodeId=board%3AAzureDevCommunityBlog)\n\n[Hugging Face](/tag/Hugging%20Face?nodeId=board%3AAzureDevCommunityBlog)\n\n[learning](/tag/learning?nodeId=board%3AAzureDevCommunityBlog)\n\n[llm](/tag/llm?nodeId=board%3AAzureDevCommunityBlog)\n\n[phi-3](/tag/phi-3?nodeId=board%3AAzureDevCommunityBlog)\n\n[!\\[Lee_Stott&#x27;s avatar\\](https://techcommunity.microsoft.com/t5/s/gxcuf89792/images/dS0yMTA1NDYtODM5MjVpMDI2ODNGQTMwMzAwNDFGQQ?image-dimensions=50x50)](/users/lee_stott/210546) [Lee_Stott](/users/lee_stott/210546) ![Icon for Microsoft rank](https://techcommunity.microsoft.com/t5/s/gxcuf89792/images/cmstNC05WEo0blc?image-dimensions=100x16&amp;constrain-image=true)Microsoft\n\nJoined September 25, 2018\n\n[View Profile](/users/lee_stott/210546)\n\n/category/azure/blog/azuredevcommunityblog [Microsoft Developer Community Blog](/category/azure/blog/azuredevcommunityblog) Follow this blog board to get notified when there's new activity",
  "FeedLevelAuthor": "rss.livelink.threads-in-node",
  "PubDate": "2025-09-19T07:00:00+00:00",
  "FeedName": "Microsoft Tech Community",
  "Author": "Lee_Stott",
  "Tags": [],
  "OutputDir": "_community"
}
