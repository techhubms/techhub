{
  "FeedName": "Microsoft Tech Community",
  "FeedUrl": "https://techcommunity.microsoft.com/t5/s/gxcuf89792/rss/Category?category.id=Azure",
  "Link": "https://techcommunity.microsoft.com/t5/azure-architecture-blog/validating-scalable-eda-storage-performance-azure-netapp-files/ba-p/4459517",
  "EnhancedContent": "## Electronic Design Automation (EDA) workloads drive innovation across the semiconductor industry, demanding robust, scalable, and high-performance cloud solutions to accelerate time-to-market and maximize business outcomes. Azure NetApp Files empowers engineering teams to run complex simulations, manage vast datasets, and optimize workflows by delivering industry-leading performance, flexibility, and simplified deployment—eliminating the need for costly infrastructure overprovisioning or disruptive workflow changes. This leads to faster product development cycles, reduced risk of project delays, and the ability to capitalize on new opportunities in a highly competitive market. In a historic milestone, Microsoft has been independently validated Azure NetApp Files for EDA workloads through the publication of the SPECstorage® Solution 2020 EDA\\_BLENDED benchmark, providing objective proof of its readiness to meet the most demanding enterprise requirements, now and in the future.\n\n# Table of Contents\n\nAbstract\n\nFrom silicon to speed: How Azure NetApp Files powers EDA's future today\n\nThe Reason: Why Azure NetApp Files for EDA workloads\n\nUnmatched Performance and Scale for EDA\n\nCost and Performance Optimization with Azure NetApp Files\n\nGlobal Collaboration and 24×7 Productivity\n\nOperational Simplicity and Enterprise Reliability\n\nKey Azure NetApp Files Capabilities & Benefits for EDA at a Glance\n\nThe Proof: Azure NetApp Files delivers at scale\n\nUnderstanding and Simulating EDA Workloads\n\nResults at a glance\n\nFor Starters: Single Large Volume Performance\n\nResults in detail\n\nAzure NetApp Files large volume – the starting point\n\nAzure NetApp Files large volume scale – horizontal scaling\n\nFor Scalers: Large Volumes Performance and Scalability\n\nThe Method: SPECstorage® Solution 2020 Methodology\n\nBenchmark Testbeds: Configuration and Environment\n\nArchitecture\n\nAzure NetApp Files large volume\n\nAzure NetApp Files large volume scale\n\nPublished Benchmark Results\n\nBenchmarking and Real-World Relevance\n\nConclusion\n\nLearn more\n\n# Abstract\n\nElectronic Design Automation (EDA) workloads drive innovation across the semiconductor industry, demanding robust, scalable, and high-performance cloud solutions to accelerate time-to-market and maximize business outcomes. Azure NetApp Files empowers engineering teams to run complex simulations, manage vast datasets, and optimize workflows by delivering industry-leading performance, flexibility, and simplified deployment—eliminating the need for costly infrastructure overprovisioning or disruptive workflow changes. This leads to faster product development cycles, reduced risk of project delays, and the ability to capitalize on new opportunities in a highly competitive market. In a historic milestone, Microsoft has been independently validated Azure NetApp Files for EDA workloads through the publication of the SPECstorage® Solution 2020 EDA\\_BLENDED benchmark, providing objective proof of its readiness to meet the most demanding enterprise requirements, now and in the future.\n\nCo-authors:\n\n- [Ranga Sankar](https://www.linkedin.com/in/ranga-sankar-2594401/), Azure NetApp Files Technical Marketing Engineer\n- [George Strother](https://www.linkedin.com/in/gstrother/), Senior Cloud Solutions Architect, NetApp\n- [Chad Morgenstern](https://www.linkedin.com/in/chadmorgenstern/), Director of Engineering (Performance), NetApp\n- [Andy Chan](https://www.linkedin.com/in/andy-chan-3720418/), Principal Product Manager – Azure NetApp Files HPC/EDA\n- [Srinivasan Malayala](https://www.linkedin.com/in/malayala/), Product, Program & Engineering Management, Microsoft\n\n# From silicon to speed: How Azure NetApp Files powers EDA's future today\n\nSemiconductor innovation is accelerating as high-performance computing workloads shift from on-premises to the cloud. Electronic Design Automation demands massive compute and scalable storage to manage petabytes of data. With chip design projects costing hundreds of millions, delays can mean missing market windows and real financial loss. To stay ahead, engineering teams must run more simulations faster.\n\nEDA workloads push infrastructure to its limits – often requiring tens of thousands of cores and parallel access to large datasets. Storage must deliver consistent throughput and low latency to keep workflows moving. Design and simulation tasks generate enormous volumes of data, and bottlenecks in reading or writing those datasets can stall progress across distributed environments.\n\nTo validate its readiness for these demands, Microsoft submitted Azure NetApp Files to the SPECstorage® Solution 2020 EDA\\_BLENDED benchmark – the industry’s most rigorous test for storage performance in silicon design. This marks the first time Azure NetApp Files has been independently benchmarked for EDA workloads.\n\nAzure NetApp Files meets these demands with proven performance and scale. Trusted by leading semiconductor and HPC teams, it supports parallel access, sustained throughput, and low-latency responsiveness for complex silicon design workflows. These published results confirm Azure NetApp Files as a high-performance option for cloud-based EDA – and signal Microsoft’s commitment to transparency, readiness, and the future of semiconductor design.\n\n# The Reason: Why Azure NetApp Files for EDA workloads\n\nAzure NetApp Files is an Azure native, 1st -party, enterprise-grade file storage service built for the demands of Electronic Design Automation. It delivers on-premises level throughput and latency in the cloud, with scalability, global availability, and ease of use required by modern semiconductor workflows. In fact, Azure NetApp Files is used by top chipmakers – such as [AMD](https://www.microsoft.com/en/customers/story/1609171555313020501-amd-manufacturing-azure-netapp-files) – and even [Microsoft’s own silicon design teams](https://azure.microsoft.com/blog/azure-netapp-files-revolutionizing-silicon-design-for-high-performance-computing/). Azure NetApp Files is [recommended as high performance file storage with Microsoft Discovery](https://techcommunity.microsoft.com/blog/azurehighperformancecomputingblog/microsoft-discovery-the-path-to-an-agentic-eda-environment/4425992), making it the go-to choice for EDA workloads in Azure.\n\n**Source**: [https://azure.microsoft.com/blog/azure-netapp-files-revolutionizing-silicon-design-for-high-performance-computing/](https://azure.microsoft.com/blog/azure-netapp-files-revolutionizing-silicon-design-for-high-performance-computing/)\n\n## Unmatched Performance and Scale for EDA\n\nIn Electronic Design Automation, storage performance directly affects simulation speed and resource utilization. Azure NetApp Files ensures storage keeps pace with compute, so design teams can run large jobs without bottlenecks. For simplicity, a single Azure NetApp Files large volume delivers close to 12 GiB/s of EDA Blended throughput and hundreds of thousands of operations per second at sub-millisecond latency. Multiple volumes can be mounted in parallel to feed tens of thousands of cores, keeping simulation clusters fully utilized, significantly reducing job runtimes.\n\nEngineers can start with a single high-performance volume and scale up and out to support larger projects or more parallel jobs. Each large volume supports up to 2 PiB of data in a single namespace, simplifying access to massive design datasets.\n\nAzure NetApp Files’ ease of deployment, rich performance and scalability translate directly into faster time to market and real cost savings. Azure NetApp Files lets engineers run *more* experiments and validations in *less* time, hitting tape out deadlines and launch targets without risk.\n\n## Cost and Performance Optimization with Azure NetApp Files\n\nAzure NetApp Files offers a range of service levels – [Flexible, Standard, Premium, and Ultra](https://learn.microsoft.com/azure/azure-netapp-files/azure-netapp-files-service-levels) – designed to align storage performance and cost with the specific needs of EDA workloads. This flexibility allows engineering teams to optimize spending without compromising performance, especially during fluctuating simulation cycles. Most significant Azure NetApp Files attributes for EDA workloads are:\n\n- **Flexible Service Level (FSL)**: Decouples storage capacity and bandwidth, enabling [precise tuning for workloads](https://learn.microsoft.com/azure/azure-netapp-files/azure-netapp-files-service-levels#flexible-service-level-throughput-examples) that are either throughput-sensitive or capacity-heavy. You can scale bandwidth independently of volume size, which is ideal for bursty EDA workloads or when transitioning between active and dormant phases.\n- **Storage with** **cool access**: Automatically [moves infrequently accessed data to lower-cost Azure storage](https://learn.microsoft.com/azure/azure-netapp-files/cool-access-introduction), reducing total cost of ownership by over 60% for cold data. This is especially valuable for EDA environments where large datasets may be archived between tape-out cycles or reused across projects.\n- **Dynamic Scalability**: Azure NetApp Files [volumes can be resized](https://learn.microsoft.com/azure/azure-netapp-files/azure-netapp-files-resize-capacity-pools-or-volumes) or [changed between most service levels non-disruptively](https://learn.microsoft.com/azure/azure-netapp-files/dynamic-change-volume-service-level), allowing teams to scale up during peak simulation periods and scale down when workloads are idle. This elasticity ensures that storage costs reflect actual usage, not overprovisioned capacity.\n- **Extreme Metadata Operations Capability**: EDA workloads are [notoriously metadata-intensive, with millions of small files accessed randomly](https://learn.microsoft.com/azure/azure-netapp-files/solutions-benefits-azure-netapp-files-electronic-design-automation). Azure NetApp Files architecture is optimized for this pattern, delivering high IOPS and low latency even under heavy metadata loads – ensuring that frontend design tools and version control systems perform smoothly.\n\nThese capabilities make Azure NetApp Files not just a high-performance solution, but a cost-efficient and operationally agile platform for semiconductor design teams.\n\n## Global Collaboration and 24×7 Productivity\n\nIn today’s semiconductor industry, success hinges not only on performance and scale, but also on the ability to access critical design data anywhere, at any time. Azure NetApp Files’ worldwide availability – spanning over 45 Azure regions – empowers engineering teams to run localized simulations and instantly access resulting data from anywhere on the globe. This global reach ensures that whether engineers are in Tokyo, Amsterdam, or Silicon Valley, they can seamlessly collaborate and pick up where others left off, supporting true 24/7 “follow-the-sun” workflows. Features like cross-region replication and Global VNet Peering make it possible to maintain business continuity, ensuring design progress continues uninterrupted even if a regional disruption occurs. With Azure NetApp Files on Azure, EDA teams stay connected and productive, wherever innovation happens.\n\n## Operational Simplicity and Enterprise Reliability\n\nAzure NetApp Files not only meets performance needs; it does so through a fully managed, enterprise-proven platform that simplifies operation. Being an Azure first-party service, Azure NetApp Files is managed just like any other cloud resource – with unified billing, monitoring, and role-based access control through the Azure portal. Deploying storage is no longer a lengthy IT project: an engineer can provision a high-performance Azure NetApp Files volume in a few clicks (or via Terraform/CLI for automation) and have it ready for use in minutes. There’s no need for specialized storage admins to tune RAID groups or cache settings; Azure NetApp Files handles the backend optimizations for you. This ease of deployment and scaling lets your organization quickly spin up the infrastructure needed for peak tape-out crunch times, then scale back, aligning costs with actual demand – something on-premises NAS can’t easily match. Agentic AI workflows powered by Microsoft Discovery all make this even more frictionless.\n\nAzure NetApp Files is backed by battle-tested NetApp® ONTAP® technology under the hood, and as a Volumes as a Service is easy to consume – with features like instantaneous snapshots and clones, replication (for backups or geo-redundancy), and on-disk encryption – all transparent to users. Azure NetApp Files carries a 99.99% availability SLA, so engineers don’t worry about unplanned outages disrupting their work. Azure NetApp Files provides security and access controls that meet enterprise requirements by supporting standard directory services such as FreeIPA and OpenLDAP – using NFSv3 POSIX permissions – to help safeguard sensitive design intellectual property.\n\n##  Key Azure NetApp Files Capabilities & Benefits for EDA at a Glance\n\n| **Azure NetApp Files Capability** | **Benefit to EDA Teams** | | --- | --- | | **Azure Volumes as a Service with on-demand provisioning, scaling and deprovisioning. No upfront license cost or long-term commitments.** | **Agile provisioning and on-demand consumption**: This agility allows engineering teams to quickly adapt storage to project needs, only pay for what they use – when they use, and accelerate chip design cycles without upfront commitments. | | **On-Demand Extreme Performance – In-Azure bare-metal storage delivering up to 12.5 GB/s throughput and 800K+ IOPS per volume, with &lt;1 ms typical latency until the very edge.** | **No Storage Bottlenecks:** Run massive simulations at full speed. Even I/O-intensive EDA tasks (front-end random IO or back-end streaming IO) complete faster, boosting engineer productivity and maximizing expensive EDA license use. | | **Massive Single-Volume Capacity – Each Azure NetApp Files large volume supports 1 PiB (2 PiB by request) in a single mount, with support for ~16 billion files.** | **Simplified Data Management at Scale:** House enormous chip design datasets in one place for easy access and management. | | **Linear Scale-Out – Create multiple volumes for virtually unlimited aggregate performance.** | **“Grow-as-you-go” Flexibility:** Easily scale storage to match any size of HPC cluster or project. | | **Global Deployment & Replication – Available across 45+ Azure regions, with cross-region and cross-zone replication.** | **Global Collaboration & Resilience:** Enable teams in different geographies to work on the same design data locally, with disaster recovery built-in. | | **Fully Managed Service – Azure-native, with unified billing, monitoring, and role-based access control.** | **Lower Ops Burden & Faster Setup:** No hardware to manage; provision volumes in minutes. | | **Standard Protocols (NFS, SMB, Object REST API) – Supports NFSv3, NFSv4.1, SMB, and dual-protocol access.** | **Easy Migration & Integration:** Lift-and-shift existing workflows with zero code changes. | | **Enterprise Data Management – Snapshots, clones, backups, encryption, and access controls.** | **Safe and Efficient Operations:** Protect critical design data with minimal effort. | | **Multiple Service Levels (Flexible, Standard, Premium, Ultra)** | **Cost-Performance Alignment:** Choose the right tier for each workload phase – burst, steady-state, or archive. | | **Cool Access– Automatically moves cold data to lower-cost storage.** | **Lower TCO for Archived Data:** Save up to 76% on infrequently accessed datasets. | | **Dynamic Scalability – Resize volumes and adjust performance tiers non-disruptively.** | **Elastic Cost Control:** Scale up during peak demand, scale down when idle. | | **Extreme Metadata Operations Capability – Optimized for millions of small file accesses, even with cool access enabled.** | **Frontend Tool Responsiveness**: Keep design tools and version control systems fast and reliable. |\n\nAzure NetApp Files offers the performance of specialized on-prem storage without the administrative overhead – your teams can focus on chip design, not on babysitting storage systems.\n\n# The Proof: Azure NetApp Files delivers at scale\n\nOf course, all the features and advantages detailed above would be merely theoretical without concrete evidence of performance to back them up. Recognizing the importance of substantiating these claims, Microsoft chose to submit two Azure NetApp Files benchmark tests: one focused on a single large volume’s capabilities, and another designed to demonstrate linear scalability across multiple volumes.\n\n## Understanding and Simulating EDA Workloads\n\nIn the world of high-performance computing, consistency, and credibility matter. That’s why the tech industry relies on vendor-neutral groups such as [Standard Performance Evaluation Corporation (SPEC)](https://www.spec.org/spec/) to create standardized benchmarks. SPEC’s Storage committee developed SPECstorage® Solution 2020 which contains the EDA\\_BLENDED workload profile. Each EDA\\_BLENDED “job” mixes both front end and backend application input/output profiles:\n\n- Three EDA\\_FRONTEND processes each performing 60% Metadata operations, 7% file reads, 7% file writes, 8% random reads and 15% random writes.\n- Two EDA\\_BACKEND threads performing 50% sequential reads and 50% sequential writes.\n\nMore details on the workload can be found in the user guide: [https://www.spec.org/storage2020/docs/usersguide.pdf#page=30](https://www.spec.org/storage2020/docs/usersguide.pdf#page=30)\n\nThe SPECstorage® Solution 2020 EDA\\_BLENDED benchmark was strategically selected and utilized as an industry-standard method to validate the performance capabilities of Azure NetApp Files.\n\n## Results at a glance\n\nThis section outlines the high-level outcomes for these SPECstorage® Solution 2020 EDA\\_BLENDED benchmarks, providing real-world validation of Azure NetApp Files’ performance and scalability:\n\n- **Linear Scalability**\nPerformance scaled linearly with additional volumes. Scaling the test horizontally to 6 volumes yielded about 6× the throughput and 6× the SPECstorage® Solution 2020\\_EDA\\_BLENDED JOBS.\n- **Ultra-Low Latency**Both single volume and scale tests performed with a consistently low Overall Response Time (ORT) of well below one millisecond.\n- **Cloud Performance at Scale**Performance increased in direct proportion to the number of volumes added. This means Azure NetApp Files can handle large chip design projects with ease, giving semiconductor companies confidence to migrate their most intensive workloads to the cloud, and provide scalability as long as resources are available.\n\n## For Starters: Single Large Volume Performance\n\nAzure NetApp Files supports a phased deployment approach. Teams can begin with a single high-performance large volume to support mid-sized environments or isolated workflows, then expand vertically or horizontally as project demands grow. This flexibility allows organizations to align infrastructure with workload intensity from day one, without overprovisioning or rearchitecting.\n\nThe linear scaling observed also indicates that performance remains consistent as the environment expands. This is a crucial advantage as projects and datasets become larger and more complex over time, ensuring that performance does not degrade with scale.\n\n## Results in detail\n\nThis paragraph provides a more detailed breakdown of both the Azure NetApp Files large volume and large volume scale submissions. By outlining the configuration, performance results, and comparative benchmarks for each scenario, you gain clear insight into the outcomes and the scalability and throughput achieved. This approach ensures a deeper understanding of the results and the real-world impact of these solutions.\n\n### Azure NetApp Files large volume – the starting point\n\nIn the first scenario, the test used **one Azure NetApp Files large volume**. Ten client VMs generated simultaneous load.\n\n| **The results:**<br><br><br><br>The Azure NetApp Files large volume configuration reached **1760** SPECstorage® Solution 2020\\_EDA\\_BLENDED JOBS with an overall response time of **0.48 ms**. | | --- |\n\nA single Azure NetApp Files large volume delivered **12,780 MiB/s** (12,481 MiB/s) of throughput and **792,046 operations per second** at peak. Throughout the iterations, sub-millisecond latency was observed with latency only breaching 1 ms at the very peak. For many EDA workflows, a single 50 TiB volume offers substantial performance headroom, making it a strong fit for demanding HPC I/O requirements.\n\n### Azure NetApp Files large volume scale – horizontal scaling\n\nIn this scenario, the test deployed **six large Azure NetApp Files large volumes**, each configured with 50 TiB capacity and a QoS setting of 12,800 MiB/s under the Flexible service level. Each volume was presented through a unique storage endpoint, totaling six IP addresses. For resource availability reasons, the volumes were distributed across multiple Azure regions and availability zones, though this is not a requirement. Deployments can use any number of volumes, and regional distribution is optional – only necessary when targeting specific availability or resilience goals. Sixty client VMs (ten per volume) generated simultaneous load across all six volumes.\n\n| **The results:**<br><br><br><br>****The Azure NetApp Files large volume scale configuration reached **10,560** SPECstorage® Solution 2020\\_EDA\\_BLENDED JOBS with an overall response time of **0.64 ms**. | | --- |\n\nAt this scale, the aggregate throughput was **76,487 MB/s** (74,695 MiB/s), with **4,745,453 operations per second** on the benchmark. Again, throughout the iterations, sub-millisecond latency was observed with latency only breaching 1 ms at the peak.\n\n## For Scalers: Large Volumes Performance and Scalability\n\nThe results demonstrate that Azure NetApp Files scaled horizontally across all critical benchmark metrics – Job Sets, Throughput, and Operations per second – with only a minimal increase in Overall Response Times (ORT), reflecting slight variation between the environments. This confirms that performance scaled linearly without significantly compromising latency as additional volumes were added.\n\n| **EDA\\_BLENDED Metric** | **Large volume** | **Large volume scale** | **Factor** | | --- | --- | --- | --- | | **Job Sets** | 1,760 | 10,560 | 6.00 | | **Throughput (MB/s)** | 12,780 | 76,487 | 5.98 | | **Operations/second** | 792,046 | 4,745,453 | 5.99 | | **ORT (ms)** | 0.48 | 0.64 | 1.33 |\n\nThe following diagrams further illustrate these performance characteristics.\n\n# The Method: SPECstorage® Solution 2020 Methodology\n\nConsistency and credibility are essential in high-performance computing, where organizations like SPEC set standard benchmarks. This chapter focuses on the benchmark details.\n\n## Benchmark Testbeds: Configuration and Environment\n\nTo understand the SPECstorage® Solution 2020 EDA\\_BLENDED results, it’s essential to examine the test architecture that enabled them. The following section outlines the configuration used – providing transparency and a foundation for reproducibility or future scaling.\n\n## Architecture\n\n### Azure NetApp Files large volume\n\nThe test setup utilized ten RHEL 9.5 workload clients – each with a maximum network bandwidth of 16 Gbps – connected to a single Azure NetApp Files large volume of 50 TiB (with Flexible service level and QoS of 12,800 MiB/s).\n\nThe configuration diagram below illustrates the data flow and network topology, showing all clients accessing the Azure NetApp Files volume over a single Azure Virtual Network (VNet).\n\n### Azure NetApp Files large volume scale\n\nFor large volume scale test, the same configuration was replicated in six Azure availability zones, spread across four Azure regions – in this case Canada Central, Germany West Central, South Africa North, and Qatar Central. Each zone was identically configured with ten virtual machines and one large volume each co-located in one availability zone. Azure’s Virtual Network peering connected the virtual networks across the regions/zones so we could execute a single benchmark run that spanned all the clients simultaneously.\n\nThis multi-region/zone configuration was selected for resource availability reasons. This configuration is not a requirement – deployments can use any number of volumes (not limited to six), and volumes do not need to be distributed across different regions or zones unless desired for specific availability or resilience needs. Sixty RHEL 9.5 workload clients (10 per volume) – each with a maximum network bandwidth of 16 Gbps – generated load to push all volumes simultaneously.\n\nFull details of the benchmark tests executed can be found in this article: [Benefits of using Azure NetApp Files for Electronic Design Automation (EDA)](https://learn.microsoft.com/azure/azure-netapp-files/solutions-benefits-azure-netapp-files-electronic-design-automation).\n\n## Published Benchmark Results\n\nFor those seeking in-depth insights and further validation of the Azure NetApp Files benchmark performance, the complete, officially published benchmark reports offer a comprehensive look into the methodology, results, and detailed configurations used in the tests. These resources provide transparency and allow readers to fully understand the rigorous processes behind the results, supporting both technical due diligence and reproducibility for organizations considering similar deployments. Whether you are interested in the architectural nuances, performance metrics, or scalability observations, these reports are essential references for anyone evaluating storage solutions for demanding EDA workloads in the cloud.\n\nAccess the detailed reports here:\n\n- [Azure NetApp Files large volume](https://www.spec.org/storage2020/results/res2025q4/storage2020-20250929-00143.html)This report covers the single large volume benchmark tests, showcasing how a single Azure NetApp Files large volume performs under the EDA\\_BLENDED workload, including specifics on throughput, response times, and system configuration.\n- [Azure NetApp Files large volume scale](https://www.spec.org/storage2020/results/res2025q4/storage2020-20250929-00142.html)This report provides an in-depth view of scaling performance across multiple Azure regions and availability zones, demonstrating the linear scalability and global reach of Azure NetApp Files for high-performance, distributed EDA workloads.\n\nThese published reports serve as valuable resources for IT architects, engineering teams, and decision-makers looking to leverage Azure NetApp Files for their most demanding semiconductor design and EDA applications.\n\n## Benchmarking and Real-World Relevance\n\nThe benchmark methodology was designed not only for performance measurement, but also for reproducibility and real-world relevance. To achieve this, Azure NetApp Files volumes were deployed across multiple availability zones and regions, ensuring that our results were not tied to a single zone’s infrastructure or transient conditions.\n\nThe selection of the large volume scale configuration was strategically driven by the availability of compute and storage resources within individual availability zones, ensuring optimal performance and minimal latency. Importantly, the demonstration with six volumes was not intended to represent a hard limit or maximum system capacity. In reality, this configuration serves as a proof point for scalability – should additional compute and storage resources become available in co-located setups, the architecture can seamlessly expand to accommodate [significantly more volumes](https://learn.microsoft.com/azure/azure-netapp-files/azure-netapp-files-resource-limits#resource-limits).\n\nThis inherent flexibility means organizations are not constrained by the initial deployment size; rather, they can confidently scale their EDA and Azure NetApp Files environment to meet evolving workload demands and infrastructure growth. The system’s design empowers enterprises to dynamically adjust resources, supporting everything from routine EDA operations to the most demanding, high-volume tape-out events, all without hitting storage bottlenecks. This approach mirrors how leading semiconductor firms and EDA teams operate today:\n\n**Global Collaboration:** Scale-out volume deployment enables engineering teams in different regions to access localized datasets with minimal latency, enabling global collaboration, 24/7 development cycles, and rapid iteration.\n\n**Scalable Production Workloads:** Firms routinely roll out volumes across regions and zones to balance load, optimize resource utilization, make use of available storage and compute resources where they are available and as such support large-scale tape-out events or peak simulation periods.\n\n# Conclusion\n\nThe future of semiconductor design is entering a new era, and it’s powered by Azure NetApp Files and validated by industry-leading SPEC benchmarks. With Azure NetApp Files, engineering teams are no longer constrained by infrastructure limitations – they can accelerate time-to-market, scale effortlessly across multiple regions and availability zones, and collaborate globally with minimal latency.\n\nThis platform’s ability to deliver unwavering throughput, lightning-fast responsiveness, and seamless scalability empowers organizations to tackle even the most demanding EDA workloads, from routine design iterations to large-scale tape-out events. Proven by rigorous, reproducible benchmarking and trusted by top semiconductor firms worldwide, Azure NetApp Files provides the performance, flexibility, and reliability required to transform the way chips are designed and brought to market.\n\nAs the pace of innovation intensifies and global collaboration becomes the standard, Azure NetApp Files stands out as the storage solution that enables teams to unlock new possibilities, drive faster development cycles, and maintain a critical competitive edge in a rapidly evolving industry.\n\n#  Learn more\n\n- [What is Azure NetApp Files](https://learn.microsoft.com/en-us/azure/azure-netapp-files/azure-netapp-files-introduction)\n- [SPECstorage® Solution 2020](https://www.spec.org/storage2020/)\n- [All Published SPECstorage® Solution 2020_eda_blended Results](https://www.spec.org/storage2020/results/eda_blended/)\n- [Benefits of using Azure NetApp Files for Electronic Design Automation (EDA)](https://learn.microsoft.com/azure/azure-netapp-files/solutions-benefits-azure-netapp-files-electronic-design-automation)\n- [Azure NetApp Files: Revolutionizing silicon design for high-performance computing](https://azure.microsoft.com/blog/azure-netapp-files-revolutionizing-silicon-design-for-high-performance-computing/)\n- [Solution architectures using Azure NetApp Files | Electronic design automation (EDA)](https://learn.microsoft.com/azure/azure-netapp-files/azure-netapp-files-solution-architectures#electronic-design-automation-eda)\n- [Microsoft Discovery: The path to an agentic EDA environment](https://techcommunity.microsoft.com/blog/azurehighperformancecomputingblog/microsoft-discovery-the-path-to-an-agentic-eda-environment/4425992)\n\nUpdated Oct 14, 2025\n\nVersion 3.0\n\n[advance analytics](/tag/advance%20analytics?nodeId=board%3AAzureArchitectureBlog)\n\n[application](/tag/application?nodeId=board%3AAzureArchitectureBlog)\n\n[artificial intelligence](/tag/artificial%20intelligence?nodeId=board%3AAzureArchitectureBlog)\n\n[data platform](/tag/data%20platform?nodeId=board%3AAzureArchitectureBlog)\n\n[infrastructure](/tag/infrastructure?nodeId=board%3AAzureArchitectureBlog)\n\n[well architected](/tag/well%20architected?nodeId=board%3AAzureArchitectureBlog)\n\n[!\\[GeertVanTeylingen&#x27;s avatar\\](https://techcommunity.microsoft.com/t5/s/gxcuf89792/images/dS0yMjI4NTMtMzI1MjMwaTVERUE2NzdCRkJBNjkxQzg?image-dimensions=50x50)](/users/geertvanteylingen/222853) [GeertVanTeylingen](/users/geertvanteylingen/222853) ![Icon for Microsoft rank](https://techcommunity.microsoft.com/t5/s/gxcuf89792/images/cmstNC05WEo0blc?image-dimensions=100x16&amp;constrain-image=true)Microsoft\n\nJoined October 04, 2018\n\n[View Profile](/users/geertvanteylingen/222853)\n\n/category/azure/blog/azurearchitectureblog [Azure Architecture Blog](/category/azure/blog/azurearchitectureblog) Follow this blog board to get notified when there's new activity",
  "Author": "GeertVanTeylingen",
  "Description": "![]()\n\n# Table of Contents\n\nAbstract\n\nFrom silicon to speed: How Azure NetApp Files powers EDA's future today\n\nThe Reason: Why Azure NetApp Files for EDA workloads\n\nUnmatched Performance and Scale for EDA\n\nCost and Performance Optimization with Azure NetApp Files\n\nGlobal Collaboration and 24×7 Productivity\n\nOperational Simplicity and Enterprise Reliability\n\nKey Azure NetApp Files Capabilities & Benefits for EDA at a Glance\n\nThe Proof: Azure NetApp Files delivers at scale\n\nUnderstanding and Simulating EDA Workloads\n\nResults at a glance\n\nFor Starters: Single Large Volume Performance\n\nResults in detail\n\nAzure NetApp Files large volume – the starting point\n\nAzure NetApp Files large volume scale – horizontal scaling\n\nFor Scalers: Large Volumes Performance and Scalability\n\nThe Method: SPECstorage® Solution 2020 Methodology\n\nBenchmark Testbeds: Configuration and Environment\n\nArchitecture\n\nAzure NetApp Files large volume\n\nAzure NetApp Files large volume scale\n\nPublished Benchmark Results\n\nBenchmarking and Real-World Relevance\n\nConclusion\n\nLearn more\n\n# Abstract\n\nElectronic Design Automation (EDA) workloads drive innovation across the semiconductor industry, demanding robust, scalable, and high-performance cloud solutions to accelerate time-to-market and maximize business outcomes. Azure NetApp Files empowers engineering teams to run complex simulations, manage vast datasets, and optimize workflows by delivering industry-leading performance, flexibility, and simplified deployment—eliminating the need for costly infrastructure overprovisioning or disruptive workflow changes. This leads to faster product development cycles, reduced risk of project delays, and the ability to capitalize on new opportunities in a highly competitive market. In a historic milestone, Microsoft has been independently validated Azure NetApp Files for EDA workloads through the publication of the SPECstorage® Solution 2020 EDA\\_BLENDED benchmark, providing objective proof of its readiness to meet the most demanding enterprise requirements, now and in the future.\n\nCo-authors:\n\n- [Ranga Sankar](https://www.linkedin.com/in/ranga-sankar-2594401/), Azure NetApp Files Technical Marketing Engineer\n- [George Strother](https://www.linkedin.com/in/gstrother/), Senior Cloud Solutions Architect, NetApp\n- [Chad Morgenstern](https://www.linkedin.com/in/chadmorgenstern/), Director of Engineering (Performance), NetApp\n- [Andy Chan](https://www.linkedin.com/in/andy-chan-3720418/), Principal Product Manager – Azure NetApp Files HPC/EDA\n- [Srinivasan Malayala](https://www.linkedin.com/in/malayala/), Product, Program & Engineering Management, Microsoft\n\n# From silicon to speed: How Azure NetApp Files powers EDA's future today\n\nSemiconductor innovation is accelerating as high-performance computing workloads shift from on-premises to the cloud. Electronic Design Automation demands massive compute and scalable storage to manage petabytes of data. With chip design projects costing hundreds of millions, delays can mean missing market windows and real financial loss. To stay ahead, engineering teams must run more simulations faster.\n\nEDA workloads push infrastructure to its limits – often requiring tens of thousands of cores and parallel access to large datasets. Storage must deliver consistent throughput and low latency to keep workflows moving. Design and simulation tasks generate enormous volumes of data, and bottlenecks in reading or writing those datasets can stall progress across distributed environments.\n\nTo validate its readiness for these demands, Microsoft submitted Azure NetApp Files to the SPECstorage® Solution 2020 EDA\\_BLENDED benchmark – the industry’s most rigorous test for storage performance in silicon design. This marks the first time Azure NetApp Files has been independently benchmarked for EDA workloads.\n\nAzure NetApp Files meets these demands with proven performance and scale. Trusted by leading semiconductor and HPC teams, it supports parallel access, sustained throughput, and low-latency responsiveness for complex silicon design workflows. These published results confirm Azure NetApp Files as a high-performance option for cloud-based EDA – and signal Microsoft’s commitment to transparency, readiness, and the future of semiconductor design.\n\n# The Reason: Why Azure NetApp Files for EDA workloads\n\nAzure NetApp Files is an Azure native, 1st -party, enterprise-grade file storage service built for the demands of Electronic Design Automation. It delivers on-premises level throughput and latency in the cloud, with scalability, global availability, and ease of use required by modern semiconductor workflows. In fact, Azure NetApp Files is used by top chipmakers – such as [AMD](https://www.microsoft.com/en/customers/story/1609171555313020501-amd-manufacturing-azure-netapp-files) – and even [Microsoft’s own silicon design teams](https://azure.microsoft.com/blog/azure-netapp-files-revolutionizing-silicon-design-for-high-performance-computing/). Azure NetApp Files is [recommended as high performance file storage with Microsoft Discovery](https://techcommunity.microsoft.com/blog/azurehighperformancecomputingblog/microsoft-discovery-the-path-to-an-agentic-eda-environment/4425992), making it the go-to choice for EDA workloads in Azure.\n\n![]()**Source**: [https://azure.microsoft.com/blog/azure-netapp-files-revolutionizing-silicon-design-for-high-performance-computing/](https://azure.microsoft.com/blog/azure-netapp-files-revolutionizing-silicon-design-for-high-performance-computing/)\n\n## Unmatched Performance and Scale for EDA\n\nIn Electronic Design Automation, storage performance directly affects simulation speed and resource utilization. Azure NetApp Files ensures storage keeps pace with compute, so design teams can run large jobs without bottlenecks. For simplicity, a single Azure NetApp Files large volume delivers close to 12 GiB/s of EDA Blended throughput and hundreds of thousands of operations per second at sub-millisecond latency. Multiple volumes can be mounted in parallel to feed tens of thousands of cores, keeping simulation clusters fully utilized, significantly reducing job runtimes.\n\nEngineers can start with a single high-performance volume and scale up and out to support larger projects or more parallel jobs. Each large volume supports up to 2 PiB of data in a single namespace, simplifying access to massive design datasets.\n\nAzure NetApp Files’ ease of deployment, rich performance and scalability translate directly into faster time to market and real cost savings. Azure NetApp Files lets engineers run *more* experiments and validations in *less* time, hitting tape out deadlines and launch targets without risk.\n\n## Cost and Performance Optimization with Azure NetApp Files\n\nAzure NetApp Files offers a range of service levels – [Flexible, Standard, Premium, and Ultra](https://learn.microsoft.com/azure/azure-netapp-files/azure-netapp-files-service-levels) – designed to align storage performance and cost with the specific needs of EDA workloads. This flexibility allows engineering teams to optimize spending without compromising performance, especially during fluctuating simulation cycles. Most significant Azure NetApp Files attributes for EDA workloads are:\n\n- **Flexible Service Level (FSL)**: Decouples storage capacity and bandwidth, enabling [precise tuning for workloads](https://learn.microsoft.com/azure/azure-netapp-files/azure-netapp-files-service-levels#flexible-service-level-throughput-examples) that are either throughput-sensitive or capacity-heavy. You can scale bandwidth independently of volume size, which is ideal for bursty EDA workloads or when transitioning between active and dormant phases.\n- **Storage with** **cool access**: Automatically [moves infrequently accessed data to lower-cost Azure storage](https://learn.microsoft.com/azure/azure-netapp-files/cool-access-introduction), reducing total cost of ownership by over 60% for cold data. This is especially valuable for EDA environments where large datasets may be archived between tape-out cycles or reused across projects.\n- **Dynamic Scalability**: Azure NetApp Files [volumes can be resized](https://learn.microsoft.com/azure/azure-netapp-files/azure-netapp-files-resize-capacity-pools-or-volumes) or [changed between most service levels non-disruptively](https://learn.microsoft.com/azure/azure-netapp-files/dynamic-change-volume-service-level), allowing teams to scale up during peak simulation periods and scale down when workloads are idle. This elasticity ensures that storage costs reflect actual usage, not overprovisioned capacity.\n- **Extreme Metadata Operations Capability**: EDA workloads are [notoriously metadata-intensive, with millions of small files accessed randomly](https://learn.microsoft.com/azure/azure-netapp-files/solutions-benefits-azure-netapp-files-electronic-design-automation). Azure NetApp Files architecture is optimized for this pattern, delivering high IOPS and low latency even under heavy metadata loads – ensuring that frontend design tools and version control systems perform smoothly.\n\nThese capabilities make Azure NetApp Files not just a high-performance solution, but a cost-efficient and operationally agile platform for semiconductor design teams.\n\n## Global Collaboration and 24×7 Productivity\n\nIn today’s semiconductor industry, success hinges not only on performance and scale, but also on the ability to access critical design data anywhere, at any time. Azure NetApp Files’ worldwide availability – spanning over 45 Azure regions – empowers engineering teams to run localized simulations and instantly access resulting data from anywhere on the globe. This global reach ensures that whether engineers are in Tokyo, Amsterdam, or Silicon Valley, they can seamlessly collaborate and pick up where others left off, supporting true 24/7 “follow-the-sun” workflows. Features like cross-region replication and Global VNet Peering make it possible to maintain business continuity, ensuring design progress continues uninterrupted even if a regional disruption occurs. With Azure NetApp Files on Azure, EDA teams stay connected and productive, wherever innovation happens.\n\n## Operational Simplicity and Enterprise Reliability\n\nAzure NetApp Files not only meets performance needs; it does so through a fully managed, enterprise-proven platform that simplifies operation. Being an Azure first-party service, Azure NetApp Files is managed just like any other cloud resource – with unified billing, monitoring, and role-based access control through the Azure portal. Deploying storage is no longer a lengthy IT project: an engineer can provision a high-performance Azure NetApp Files volume in a few clicks (or via Terraform/CLI for automation) and have it ready for use in minutes. There’s no need for specialized storage admins to tune RAID groups or cache settings; Azure NetApp Files handles the backend optimizations for you. This ease of deployment and scaling lets your organization quickly spin up the infrastructure needed for peak tape-out crunch times, then scale back, aligning costs with actual demand – something on-premises NAS can’t easily match. Agentic AI workflows powered by Microsoft Discovery all make this even more frictionless.\n\nAzure NetApp Files is backed by battle-tested NetApp® ONTAP® technology under the hood, and as a Volumes as a Service is easy to consume – with features like instantaneous snapshots and clones, replication (for backups or geo-redundancy), and on-disk encryption – all transparent to users. Azure NetApp Files carries a 99.99% availability SLA, so engineers don’t worry about unplanned outages disrupting their work. Azure NetApp Files provides security and access controls that meet enterprise requirements by supporting standard directory services such as FreeIPA and OpenLDAP – using NFSv3 POSIX permissions – to help safeguard sensitive design intellectual property.\n\n## Key Azure NetApp Files Capabilities & Benefits for EDA at a Glance\n\n| **Azure NetApp Files Capability** | **Benefit to EDA Teams** | | --- | --- | | **Azure Volumes as a Service with on-demand provisioning, scaling and deprovisioning. No upfront license cost or long-term commitments.** | **Agile provisioning and on-demand consumption**: This agility allows engineering teams to quickly adapt storage to project needs, only pay for what they use – when they use, and accelerate chip design cycles without upfront commitments. | | **On-Demand Extreme Performance – In-Azure bare-metal storage delivering up to 12.5 GB/s throughput and 800K+ IOPS per volume, with** | **No Storage Bottlenecks:** Run massive simulations at full speed. Even I/O-intensive EDA tasks (front-end random IO or back-end streaming IO) complete faster, boosting engineer productivity and maximizing expensive EDA license use. | | **Massive Single-Volume Capacity – Each Azure NetApp Files large volume supports 1 PiB (2 PiB by request) in a single mount, with support for ~16 billion files.** | **Simplified Data Management at Scale:** House enormous chip design datasets in one place for easy access and management. | | **Linear Scale-Out – Create multiple volumes for virtually unlimited aggregate performance.** | **“Grow-as-you-go” Flexibility:** Easily scale storage to match any size of HPC cluster or project. | | **Global Deployment & Replication – Available across 45+ Azure regions, with cross-region and cross-zone replication.** | **Global Collaboration & Resilience:** Enable teams in different geographies to work on the same design data locally, with disaster recovery built-in. | | **Fully Managed Service – Azure-native, with unified billing, monitoring, and role-based access control.** | **Lower Ops Burden & Faster Setup:** No hardware to manage; provision volumes in minutes. | | **Standard Protocols (NFS, SMB, Object REST API) – Supports NFSv3, NFSv4.1, SMB, and dual-protocol access.** | **Easy Migration & Integration:** Lift-and-shift existing workflows with zero code changes. | | **Enterprise Data Management – Snapshots, clones, backups, encryption, and access controls.** | **Safe and Efficient Operations:** Protect critical design data with minimal effort. | | **Multiple Service Levels (Flexible, Standard, Premium, Ultra)** | **Cost-Performance Alignment:** Choose the right tier for each workload phase – burst, steady-state, or archive. | | **Cool Access– Automatically moves cold data to lower-cost storage.** | **Lower TCO for Archived Data:** Save up to 76% on infrequently accessed datasets. | | **Dynamic Scalability – Resize volumes and adjust performance tiers non-disruptively.** | **Elastic Cost Control:** Scale up during peak demand, scale down when idle. | | **Extreme Metadata Operations Capability – Optimized for millions of small file accesses, even with cool access enabled.** | **Frontend Tool Responsiveness**: Keep design tools and version control systems fast and reliable. |\n\nAzure NetApp Files offers the performance of specialized on-prem storage without the administrative overhead – your teams can focus on chip design, not on babysitting storage systems.\n\n# The Proof: Azure NetApp Files delivers at scale\n\nOf course, all the features and advantages detailed above would be merely theoretical without concrete evidence of performance to back them up. Recognizing the importance of substantiating these claims, Microsoft chose to submit two Azure NetApp Files benchmark tests: one focused on a single large volume’s capabilities, and another designed to demonstrate linear scalability across multiple volumes.\n\n## Understanding and Simulating EDA Workloads\n\nIn the world of high-performance computing, consistency, and credibility matter. That’s why the tech industry relies on vendor-neutral groups such as [Standard Performance Evaluation Corporation (SPEC)](https://www.spec.org/spec/) to create standardized benchmarks. SPEC’s Storage committee developed SPECstorage® Solution 2020 which contains the EDA\\_BLENDED workload profile. Each EDA\\_BLENDED “job” mixes both front end and backend application input/output profiles:\n\n- Three EDA\\_FRONTEND processes each performing 60% Metadata operations, 7% file reads, 7% file writes, 8% random reads and 15% random writes.\n- Two EDA\\_BACKEND threads performing 50% sequential reads and 50% sequential writes.\n\nMore details on the workload can be found in the user guide: [https://www.spec.org/storage2020/docs/usersguide.pdf#page=30](https://www.spec.org/storage2020/docs/usersguide.pdf#page=30)\n\nThe SPECstorage® Solution 2020 EDA\\_BLENDED benchmark was strategically selected and utilized as an industry-standard method to validate the performance capabilities of Azure NetApp Files.\n\n## Results at a glance\n\nThis section outlines the high-level outcomes for these SPECstorage® Solution 2020 EDA\\_BLENDED benchmarks, providing real-world validation of Azure NetApp Files’ performance and scalability:\n\n- **Linear Scalability**\nPerformance scaled linearly with additional volumes. Scaling the test horizontally to 6 volumes yielded about 6× the throughput and 6× the SPECstorage® Solution 2020\\_EDA\\_BLENDED JOBS.\n- **Ultra-Low Latency**Both single volume and scale tests performed with a consistently low Overall Response Time (ORT) of well below one millisecond.\n- **Cloud Performance at Scale**Performance increased in direct proportion to the number of volumes added. This means Azure NetApp Files can handle large chip design projects with ease, giving semiconductor companies confidence to migrate their most intensive workloads to the cloud, and provide scalability as long as resources are available.\n\n## For Starters: Single Large Volume Performance\n\nAzure NetApp Files supports a phased deployment approach. Teams can begin with a single high-performance large volume to support mid-sized environments or isolated workflows, then expand vertically or horizontally as project demands grow. This flexibility allows organizations to align infrastructure with workload intensity from day one, without overprovisioning or rearchitecting.\n\nThe linear scaling observed also indicates that performance remains consistent as the environment expands. This is a crucial advantage as projects and datasets become larger and more complex over time, ensuring that performance does not degrade with scale.\n\n## Results in detail\n\nThis paragraph provides a more detailed breakdown of both the Azure NetApp Files large volume and large volume scale submissions. By outlining the configuration, performance results, and comparative benchmarks for each scenario, you gain clear insight into the outcomes and the scalability and throughput achieved. This approach ensures a deeper understanding of the results and the real-world impact of these solutions.\n\n### Azure NetApp Files large volume – the starting point\n\nIn the first scenario, the test used **one Azure NetApp Files large volume**. Ten client VMs generated simultaneous load.\n\n| **The results:**<br><br><br><br>The Azure NetApp Files large volume configuration reached **1760** SPECstorage® Solution 2020\\_EDA\\_BLENDED JOBS with an overall response time of **0.48 ms**. | | --- |\n\n![]()\n\nA single Azure NetApp Files large volume delivered **12,780 MiB/s** (12,481 MiB/s) of throughput and **792,046 operations per second** at peak. Throughout the iterations, sub-millisecond latency was observed with latency only breaching 1 ms at the very peak. For many EDA workflows, a single 50 TiB volume offers substantial performance headroom, making it a strong fit for demanding HPC I/O requirements.\n\n### Azure NetApp Files large volume scale – horizontal scaling\n\nIn this scenario, the test deployed **six large Azure NetApp Files large volumes**, each configured with 50 TiB capacity and a QoS setting of 12,800 MiB/s under the Flexible service level. Each volume was presented through a unique storage endpoint, totaling six IP addresses. For resource availability reasons, the volumes were distributed across multiple Azure regions and availability zones, though this is not a requirement. Deployments can use any number of volumes, and regional distribution is optional – only necessary when targeting specific availability or resilience goals. Sixty client VMs (ten per volume) generated simultaneous load across all six volumes.\n\n| **The results:**<br><br><br><br> **** The Azure NetApp Files large volume scale configuration reached **10,560** SPECstorage® Solution 2020\\_EDA\\_BLENDED JOBS with an overall response time of **0.64 ms**. | | --- |\n\n![]()\n\nAt this scale, the aggregate throughput was **76,487 MB/s** (74,695 MiB/s), with **4,745,453 operations per second** on the benchmark. Again, throughout the iterations, sub-millisecond latency was observed with latency only breaching 1 ms at the peak.\n\n## For Scalers: Large Volumes Performance and Scalability\n\nThe results demonstrate that Azure NetApp Files scaled horizontally across all critical benchmark metrics – Job Sets, Throughput, and Operations per second – with only a minimal increase in Overall Response Times (ORT), reflecting slight variation between the environments. This confirms that performance scaled linearly without significantly compromising latency as additional volumes were added.\n\n| **EDA\\_BLENDED Metric** | **Large volume** | **Large volume scale** | **Factor** | | --- | --- | --- | --- | | **Job Sets** | 1,760 | 10,560 | 6.00 | | **Throughput (MB/s)** | 12,780 | 76,487 | 5.98 | | **Operations/second** | 792,046 | 4,745,453 | 5.99 | | **ORT (ms)** | 0.48 | 0.64 | 1.33 |\n\nThe following diagrams further illustrate these performance characteristics.\n\n![]()![]()\n\n# The Method: SPECstorage® Solution 2020 Methodology\n\nConsistency and credibility are essential in high-performance computing, where organizations like SPEC set standard benchmarks. This chapter focuses on the benchmark details.\n\n## Benchmark Testbeds: Configuration and Environment\n\nTo understand the SPECstorage® Solution 2020 EDA\\_BLENDED results, it’s essential to examine the test architecture that enabled them. The following section outlines the configuration used – providing transparency and a foundation for reproducibility or future scaling.\n\n## Architecture\n\n### Azure NetApp Files large volume\n\nThe test setup utilized ten RHEL 9.5 workload clients – each with a maximum network bandwidth of 16 Gbps – connected to a single Azure NetApp Files large volume of 50 TiB (with Flexible service level and QoS of 12,800 MiB/s).\n\nThe configuration diagram below illustrates the data flow and network topology, showing all clients accessing the Azure NetApp Files volume over a single Azure Virtual Network (VNet).\n\n![]()\n\n### Azure NetApp Files large volume scale\n\nFor large volume scale test, the same configuration was replicated in six Azure availability zones, spread across four Azure regions – in this case Canada Central, Germany West Central, South Africa North, and Qatar Central. Each zone was identically configured with ten virtual machines and one large volume each co-located in one availability zone. Azure’s Virtual Network peering connected the virtual networks across the regions/zones so we could execute a single benchmark run that spanned all the clients simultaneously.\n\nThis multi-region/zone configuration was selected for resource availability reasons. This configuration is not a requirement – deployments can use any number of volumes (not limited to six), and volumes do not need to be distributed across different regions or zones unless desired for specific availability or resilience needs. Sixty RHEL 9.5 workload clients (10 per volume) – each with a maximum network bandwidth of 16 Gbps – generated load to push all volumes simultaneously.\n\n![]()\n\nFull details of the benchmark tests executed can be found in this article: [Benefits of using Azure NetApp Files for Electronic Design Automation (EDA)](https://learn.microsoft.com/azure/azure-netapp-files/solutions-benefits-azure-netapp-files-electronic-design-automation).\n\n## Published Benchmark Results\n\nFor those seeking in-depth insights and further validation of the Azure NetApp Files benchmark performance, the complete, officially published benchmark reports offer a comprehensive look into the methodology, results, and detailed configurations used in the tests. These resources provide transparency and allow readers to fully understand the rigorous processes behind the results, supporting both technical due diligence and reproducibility for organizations considering similar deployments. Whether you are interested in the architectural nuances, performance metrics, or scalability observations, these reports are essential references for anyone evaluating storage solutions for demanding EDA workloads in the cloud.\n\nAccess the detailed reports here:\n\n- [Azure NetApp Files large volume](https://www.spec.org/storage2020/results/res2025q4/storage2020-20250929-00143.html)This report covers the single large volume benchmark tests, showcasing how a single Azure NetApp Files large volume performs under the EDA\\_BLENDED workload, including specifics on throughput, response times, and system configuration.\n- [Azure NetApp Files large volume scale](https://www.spec.org/storage2020/results/res2025q4/storage2020-20250929-00142.html)This report provides an in-depth view of scaling performance across multiple Azure regions and availability zones, demonstrating the linear scalability and global reach of Azure NetApp Files for high-performance, distributed EDA workloads.\n\nThese published reports serve as valuable resources for IT architects, engineering teams, and decision-makers looking to leverage Azure NetApp Files for their most demanding semiconductor design and EDA applications.\n\n## Benchmarking and Real-World Relevance\n\nThe benchmark methodology was designed not only for performance measurement, but also for reproducibility and real-world relevance. To achieve this, Azure NetApp Files volumes were deployed across multiple availability zones and regions, ensuring that our results were not tied to a single zone’s infrastructure or transient conditions.\n\nThe selection of the large volume scale configuration was strategically driven by the availability of compute and storage resources within individual availability zones, ensuring optimal performance and minimal latency. Importantly, the demonstration with six volumes was not intended to represent a hard limit or maximum system capacity. In reality, this configuration serves as a proof point for scalability – should additional compute and storage resources become available in co-located setups, the architecture can seamlessly expand to accommodate [significantly more volumes](https://learn.microsoft.com/azure/azure-netapp-files/azure-netapp-files-resource-limits#resource-limits).\n\nThis inherent flexibility means organizations are not constrained by the initial deployment size; rather, they can confidently scale their EDA and Azure NetApp Files environment to meet evolving workload demands and infrastructure growth. The system’s design empowers enterprises to dynamically adjust resources, supporting everything from routine EDA operations to the most demanding, high-volume tape-out events, all without hitting storage bottlenecks. This approach mirrors how leading semiconductor firms and EDA teams operate today:\n\n**Global Collaboration:** Scale-out volume deployment enables engineering teams in different regions to access localized datasets with minimal latency, enabling global collaboration, 24/7 development cycles, and rapid iteration.\n\n**Scalable Production Workloads:** Firms routinely roll out volumes across regions and zones to balance load, optimize resource utilization, make use of available storage and compute resources where they are available and as such support large-scale tape-out events or peak simulation periods.\n\n# Conclusion\n\nThe future of semiconductor design is entering a new era, and it’s powered by Azure NetApp Files and validated by industry-leading SPEC benchmarks. With Azure NetApp Files, engineering teams are no longer constrained by infrastructure limitations – they can accelerate time-to-market, scale effortlessly across multiple regions and availability zones, and collaborate globally with minimal latency.\n\nThis platform’s ability to deliver unwavering throughput, lightning-fast responsiveness, and seamless scalability empowers organizations to tackle even the most demanding EDA workloads, from routine design iterations to large-scale tape-out events. Proven by rigorous, reproducible benchmarking and trusted by top semiconductor firms worldwide, Azure NetApp Files provides the performance, flexibility, and reliability required to transform the way chips are designed and brought to market.\n\nAs the pace of innovation intensifies and global collaboration becomes the standard, Azure NetApp Files stands out as the storage solution that enables teams to unlock new possibilities, drive faster development cycles, and maintain a critical competitive edge in a rapidly evolving industry.\n\n# Learn more\n\n- [What is Azure NetApp Files](https://learn.microsoft.com/en-us/azure/azure-netapp-files/azure-netapp-files-introduction)\n- [SPECstorage® Solution 2020](https://www.spec.org/storage2020/)\n- [All Published SPECstorage® Solution 2020_eda_blended Results](https://www.spec.org/storage2020/results/eda_blended/)\n- [Benefits of using Azure NetApp Files for Electronic Design Automation (EDA)](https://learn.microsoft.com/azure/azure-netapp-files/solutions-benefits-azure-netapp-files-electronic-design-automation)\n- [Azure NetApp Files: Revolutionizing silicon design for high-performance computing](https://azure.microsoft.com/blog/azure-netapp-files-revolutionizing-silicon-design-for-high-performance-computing/)\n- [Solution architectures using Azure NetApp Files | Electronic design automation (EDA)](https://learn.microsoft.com/azure/azure-netapp-files/azure-netapp-files-solution-architectures#electronic-design-automation-eda)\n- [Microsoft Discovery: The path to an agentic EDA environment](https://techcommunity.microsoft.com/blog/azurehighperformancecomputingblog/microsoft-discovery-the-path-to-an-agentic-eda-environment/4425992)",
  "Tags": [],
  "Title": "Validating Scalable EDA Storage Performance: Azure NetApp Files and SPECstorage Solution 2020",
  "ProcessedDate": "2025-10-14 02:29:26",
  "OutputDir": "_community",
  "FeedLevelAuthor": "rss.livelink.threads-in-node",
  "PubDate": "2025-10-14T01:37:14+00:00"
}
