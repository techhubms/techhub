{
  "Title": "Staying in the flow: SleekFlow and Azure turn customer conversations into conversions",
  "EnhancedContent": "## This article was authored by Leo Choi, Director of Engineering, SleekFlow\n\nA customer adds three items to their cart but never checks out. Another asks about shipping, gets stuck waiting eight minutes, only to drop the call. A lead responds to an offer but is never followed up with in time. Each of these moments represents lost revenue, and they happen to businesses every day.\n\nSleekFlow was founded in 2019 to help companies turn those almost-lost-customer moments into connection, retention, and growth. Today we serve more than 2,000 mid-market and enterprise organizations across industries including retail and e-commerce, financial services, healthcare, travel and hospitality, telecommunications, real estate, and professional services. In total, those customers rely on SleekFlow to orchestrate more than 600,000 daily customer interactions across WhatsApp, Instagram, web chat, email, and more.\n\nOur name reflects what makes us different. *Sleek* is about unified, polished experiences—consolidating conversations into one intelligent, enterprise-ready platform. *Flow* is about orchestration—AI and human agents working together to move each conversation forward, from first inquiry to purchase to renewal.\n\n# The drive for enterprise-ready agentic AI\n\nEnterprises today expect always-on, intelligent conversations—but delivering that at scale proved daunting. When we set out to build AgentFlow, our agentic AI platform, we quickly ran into familiar roadblocks: downtime that disrupted peak-hour interactions, vector search delays that hurt accuracy, and costs that ballooned under multi-tenant workloads. Development slowed from limited compatibility with other technologies, while customer onboarding stalled without clear compliance assurances.\n\nTo move past these barriers, we needed a foundation that could deliver the performance, trust, and global scale enterprises demand.\n\n# The platform behind the flow: How Azure powers AgentFlow\n\nWe chose Azure because building AgentFlow required more than raw compute power. Chatbots built on a single-agent model often stall out. They struggle to retrieve the right context, they miss critical handoffs, and they return answers too slowly to keep a customer engaged. To fix that, we needed an ecosystem capable of supporting a team of specialized AI agents working together at enterprise scale.\n\n[Azure Cosmos DB](https://azure.microsoft.com/en-us/products/cosmos-db) provides the backbone for memory and context, managing short-term interactions, long-term histories, and vector embeddings in containers that respond in 15–20 milliseconds. Powered by Azure AI Foundry, our agents use [Azure OpenAI models within Azure AI Foundry](https://azure.microsoft.com/en-us/products/ai-foundry/models/openai) to understand and generate responses natively in multiple languages. Whether in English, Chinese, or Portuguese, the responses feel natural and aligned with the brand. [Semantic Kernel](https://learn.microsoft.com/en-us/semantic-kernel/overview/) acts as the conductor, orchestrating multiple agents, each of which retrieves the necessary knowledge and context, including chat histories, transactional data, and vector embeddings, directly from Azure Cosmos DB. For example, one agent could be retrieving pricing data, another summarizing it, and a third preparing it for a human handoff.\n\nThe result is not just responsiveness but accuracy. A telecom provider can resolve a billing question while surfacing an upsell opportunity in the same dialogue. A financial advisor can walk into a call with a complete dossier prepared in seconds rather than hours. A retailer can save a purchase by offering an in-stock substitute before the shopper abandons the cart.\n\nEach of these conversations is different, yet the foundation is consistent on AgentFlow.\n\n# Fast, fluent, and focused: Azure keeps conversations moving\n\nSpeed is the heartbeat of a good conversation. A delayed answer feels like a dropped call, and an irrelevant one breaks trust. For AgentFlow to keep customers engaged, every operation behind the scenes has to happen in milliseconds.\n\nA single interaction can involve dozens of steps. One agent pulls product information from embeddings, another checks it against structured policy data, and a third generates a concise, brand-aligned response. If any of these steps lag, the dialogue falters.\n\nOn Azure, they don’t. Azure Cosmos DB manages conversational memory and agent state across dedicated containers for short-term exchanges, long-term history, and vector search. Sharded [DiskANN](https://devblogs.microsoft.com/cosmosdb/diskann-for-azure-cosmos-db-now-in-open-public-preview/) indexing powers semantic lookups that resolve in the 15–20 millisecond range—fast enough that the customer never feels a pause. Microsoft Phi’s model Phi-4 as well as Azure OpenAI in Foundry Models like o3-mini and o4-mini, provide the reasoning, and [Azure Container Apps](https://learn.microsoft.com/en-us/azure/container-apps/overview) scale elastically, so performance holds steady during event-driven bursts, such as campaign broadcasts that can push the platform from a few to thousands of conversations per minute, and during daily peak-hour surges.\n\nTo support that level of responsiveness, we run Azure Container Apps on the Pay-As-You-Go consumption plan, using KEDA-based autoscaling to expand from five idle containers to more than 160 within seconds. Meanwhile, Microsoft Orleans coordinates lightweight in-memory clustering to keep conversations sleek and flowing.\n\nThe results are tangible. Retrieval-augmented generation recall improved from 50 to 70 percent. Execution speed is about 50 percent faster. For SleekFlow’s customers, that means carts are recovered before they’re abandoned, leads are qualified in real time, and support inquiries move forward instead of stalling out.\n\nWith Azure handling the complexity under the hood, conversations flow naturally on the surface—and that’s what keeps customers engaged.\n\n# Secure enough for enterprises, human enough for customers\n\nAgentFlow was built with security-by-design as a first principle, giving businesses confidence that every interaction is private, compliant, and reliable.\n\nOn Azure, every AI agent operates inside guardrails enterprises can depend on. Azure Cosmos DB enforces strict per-tenant isolation through logical partitioning, encryption, and role-based access control, ensuring chat histories, knowledge bases, and embeddings remain auditable and contained.  Models deployed through Azure AI Foundry, including Azure OpenAI and Microsoft Phi, process data entirely within SleekFlow’s Azure environment and guarantees it is never used to train public models, with activity logged for transparency. And Azure’s certifications—including ISO 27001, SOC 2, and GDPR—are backed by continuous monitoring and regional data residency options, proving compliance at a global scale.\n\nBut trust is more than a checklist of certifications. AgentFlow brings human-like fluency and empathy to every interaction, powered by Azure OpenAI running with high token-per-second throughput so responses feel natural in real time. Quality control isn’t left to chance. Human override workflows are orchestrated through Azure Container Apps and Azure App Service, ensuring AI agents can carry conversations confidently until they’re ready for human agents.\n\nEnterprises gain the confidence to let AI handle revenue-critical moments, knowing Azure provides the foundation and SleekFlow provides the human-centered design.\n\n# Shaping the next era of conversational AI on Azure\n\nThe benefits of Azure show up not only in customer conversations but also in the way our own teams work. Faster processing speeds and high token-per-second throughput reduce latency, so we spend less time debugging and more time building. Stable infrastructure minimizes downtime and troubleshooting, lowering operational costs.\n\nThat same reliability and scalability have transformed the way we engineer AgentFlow.\n\nAgentFlow started as part of our monolithic system. Shipping new features used to take about a month of development and another week of heavy testing to make sure everything held together. After moving AgentFlow to a microservices architecture on Azure Container Apps, we can now deploy updates almost daily with no down time or customer impact. And this is all thanks to native support for rolling updates and blue-green deployments.\n\nThis agility is what excites us most about what's ahead. With Azure as our foundation, SleekFlow is not simply keeping pace with the evolution of conversational AI—we are shaping what comes next. Every interaction we refine, every second we save, and every workflow we streamline brings us closer to our mission: keeping conversations sleek, flowing, and valuable for enterprises everywhere.\n\nUpdated Nov 10, 2025\n\nVersion 1.0\n\n[azure](/tag/azure?nodeId=board%3Aazure-customer-innovation-blog)\n\n[azure ai foundry](/tag/azure%20ai%20foundry?nodeId=board%3Aazure-customer-innovation-blog)\n\n[azure container apps](/tag/azure%20container%20apps?nodeId=board%3Aazure-customer-innovation-blog)\n\n[azure cosmos db](/tag/azure%20cosmos%20db?nodeId=board%3Aazure-customer-innovation-blog)\n\n[azure openai](/tag/azure%20openai?nodeId=board%3Aazure-customer-innovation-blog)\n\n[DiskANN](/tag/DiskANN?nodeId=board%3Aazure-customer-innovation-blog)\n\n[PHI](/tag/PHI?nodeId=board%3Aazure-customer-innovation-blog)\n\n[rag](/tag/rag?nodeId=board%3Aazure-customer-innovation-blog)\n\n[semantic kernel](/tag/semantic%20kernel?nodeId=board%3Aazure-customer-innovation-blog)\n\n[!\\[mtoiba&#x27;s avatar\\](https://techcommunity.microsoft.com/t5/s/gxcuf89792/images/dS0xNzc3MjY0LTU2MDg4M2k3MkYyM0QwRUI4MDQzOEFG?image-dimensions=50x50)](/users/mtoiba/1777264) [mtoiba](/users/mtoiba/1777264) ![Icon for Microsoft rank](https://techcommunity.microsoft.com/t5/s/gxcuf89792/images/cmstNC05WEo0blc?image-dimensions=100x16&amp;constrain-image=true)Microsoft\n\nJoined March 14, 2023\n\n[View Profile](/users/mtoiba/1777264)\n\n/category/azure/blog/azure-customer-innovation-blog [Azure Customer Innovation Blog](/category/azure/blog/azure-customer-innovation-blog) Follow this blog board to get notified when there's new activity",
  "Link": "https://techcommunity.microsoft.com/t5/azure-customer-innovation-blog/staying-in-the-flow-sleekflow-and-azure-turn-customer/ba-p/4467945",
  "FeedUrl": "https://techcommunity.microsoft.com/t5/s/gxcuf89792/rss/Category?category.id=Azure",
  "ProcessedDate": "2025-11-10 18:06:27",
  "FeedName": "Microsoft Tech Community",
  "Tags": [],
  "Description": "A customer adds three items to their cart but never checks out. Another asks about shipping, gets stuck waiting eight minutes, only to drop the call. A lead responds to an offer but is never followed up with in time. Each of these moments represents lost revenue, and they happen to businesses every day.\n\nSleekFlow was founded in 2019 to help companies turn those almost-lost-customer moments into connection, retention, and growth. Today we serve more than 2,000 mid-market and enterprise organizations across industries including retail and e-commerce, financial services, healthcare, travel and hospitality, telecommunications, real estate, and professional services. In total, those customers rely on SleekFlow to orchestrate more than 600,000 daily customer interactions across WhatsApp, Instagram, web chat, email, and more.\n\nOur name reflects what makes us different. *Sleek* is about unified, polished experiences—consolidating conversations into one intelligent, enterprise-ready platform. *Flow* is about orchestration—AI and human agents working together to move each conversation forward, from first inquiry to purchase to renewal.\n\n# The drive for enterprise-ready agentic AI\n\nEnterprises today expect always-on, intelligent conversations—but delivering that at scale proved daunting. When we set out to build AgentFlow, our agentic AI platform, we quickly ran into familiar roadblocks: downtime that disrupted peak-hour interactions, vector search delays that hurt accuracy, and costs that ballooned under multi-tenant workloads. Development slowed from limited compatibility with other technologies, while customer onboarding stalled without clear compliance assurances.\n\nTo move past these barriers, we needed a foundation that could deliver the performance, trust, and global scale enterprises demand.\n\n# The platform behind the flow: How Azure powers AgentFlow\n\nWe chose Azure because building AgentFlow required more than raw compute power. Chatbots built on a single-agent model often stall out. They struggle to retrieve the right context, they miss critical handoffs, and they return answers too slowly to keep a customer engaged. To fix that, we needed an ecosystem capable of supporting a team of specialized AI agents working together at enterprise scale.\n\n[Azure Cosmos DB](https://azure.microsoft.com/en-us/products/cosmos-db) provides the backbone for memory and context, managing short-term interactions, long-term histories, and vector embeddings in containers that respond in 15–20 milliseconds. Powered by Azure AI Foundry, our agents use [Azure OpenAI models within Azure AI Foundry](https://azure.microsoft.com/en-us/products/ai-foundry/models/openai) to understand and generate responses natively in multiple languages. Whether in English, Chinese, or Portuguese, the responses feel natural and aligned with the brand. [Semantic Kernel](https://learn.microsoft.com/en-us/semantic-kernel/overview/) acts as the conductor, orchestrating multiple agents, each of which retrieves the necessary knowledge and context, including chat histories, transactional data, and vector embeddings, directly from Azure Cosmos DB. For example, one agent could be retrieving pricing data, another summarizing it, and a third preparing it for a human handoff.\n\nThe result is not just responsiveness but accuracy. A telecom provider can resolve a billing question while surfacing an upsell opportunity in the same dialogue. A financial advisor can walk into a call with a complete dossier prepared in seconds rather than hours. A retailer can save a purchase by offering an in-stock substitute before the shopper abandons the cart.\n\nEach of these conversations is different, yet the foundation is consistent on AgentFlow.\n\n# Fast, fluent, and focused: Azure keeps conversations moving\n\nSpeed is the heartbeat of a good conversation. A delayed answer feels like a dropped call, and an irrelevant one breaks trust. For AgentFlow to keep customers engaged, every operation behind the scenes has to happen in milliseconds.\n\nA single interaction can involve dozens of steps. One agent pulls product information from embeddings, another checks it against structured policy data, and a third generates a concise, brand-aligned response. If any of these steps lag, the dialogue falters.\n\nOn Azure, they don’t. Azure Cosmos DB manages conversational memory and agent state across dedicated containers for short-term exchanges, long-term history, and vector search. Sharded [DiskANN](https://devblogs.microsoft.com/cosmosdb/diskann-for-azure-cosmos-db-now-in-open-public-preview/) indexing powers semantic lookups that resolve in the 15–20 millisecond range—fast enough that the customer never feels a pause. Microsoft Phi’s model Phi-4 as well as Azure OpenAI in Foundry Models like o3-mini and o4-mini, provide the reasoning, and [Azure Container Apps](https://learn.microsoft.com/en-us/azure/container-apps/overview) scale elastically, so performance holds steady during event-driven bursts, such as campaign broadcasts that can push the platform from a few to thousands of conversations per minute, and during daily peak-hour surges.\n\nTo support that level of responsiveness, we run Azure Container Apps on the Pay-As-You-Go consumption plan, using KEDA-based autoscaling to expand from five idle containers to more than 160 within seconds. Meanwhile, Microsoft Orleans coordinates lightweight in-memory clustering to keep conversations sleek and flowing.\n\nThe results are tangible. Retrieval-augmented generation recall improved from 50 to 70 percent. Execution speed is about 50 percent faster. For SleekFlow’s customers, that means carts are recovered before they’re abandoned, leads are qualified in real time, and support inquiries move forward instead of stalling out.\n\nWith Azure handling the complexity under the hood, conversations flow naturally on the surface—and that’s what keeps customers engaged.\n\n# Secure enough for enterprises, human enough for customers\n\nAgentFlow was built with security-by-design as a first principle, giving businesses confidence that every interaction is private, compliant, and reliable.\n\nOn Azure, every AI agent operates inside guardrails enterprises can depend on. Azure Cosmos DB enforces strict per-tenant isolation through logical partitioning, encryption, and role-based access control, ensuring chat histories, knowledge bases, and embeddings remain auditable and contained. Models deployed through Azure AI Foundry, including Azure OpenAI and Microsoft Phi, process data entirely within SleekFlow’s Azure environment and guarantees it is never used to train public models, with activity logged for transparency. And Azure’s certifications—including ISO 27001, SOC 2, and GDPR—are backed by continuous monitoring and regional data residency options, proving compliance at a global scale.\n\nBut trust is more than a checklist of certifications. AgentFlow brings human-like fluency and empathy to every interaction, powered by Azure OpenAI running with high token-per-second throughput so responses feel natural in real time. Quality control isn’t left to chance. Human override workflows are orchestrated through Azure Container Apps and Azure App Service, ensuring AI agents can carry conversations confidently until they’re ready for human agents.\n\nEnterprises gain the confidence to let AI handle revenue-critical moments, knowing Azure provides the foundation and SleekFlow provides the human-centered design.\n\n# Shaping the next era of conversational AI on Azure\n\nThe benefits of Azure show up not only in customer conversations but also in the way our own teams work. Faster processing speeds and high token-per-second throughput reduce latency, so we spend less time debugging and more time building. Stable infrastructure minimizes downtime and troubleshooting, lowering operational costs.\n\nThat same reliability and scalability have transformed the way we engineer AgentFlow.\n\nAgentFlow started as part of our monolithic system. Shipping new features used to take about a month of development and another week of heavy testing to make sure everything held together. After moving AgentFlow to a microservices architecture on Azure Container Apps, we can now deploy updates almost daily with no down time or customer impact. And this is all thanks to native support for rolling updates and blue-green deployments.\n\nThis agility is what excites us most about what's ahead. With Azure as our foundation, SleekFlow is not simply keeping pace with the evolution of conversational AI—we are shaping what comes next. Every interaction we refine, every second we save, and every workflow we streamline brings us closer to our mission: keeping conversations sleek, flowing, and valuable for enterprises everywhere.",
  "FeedLevelAuthor": "rss.livelink.threads-in-node",
  "OutputDir": "_community",
  "PubDate": "2025-11-10T17:54:01+00:00",
  "Author": "mtoiba"
}
