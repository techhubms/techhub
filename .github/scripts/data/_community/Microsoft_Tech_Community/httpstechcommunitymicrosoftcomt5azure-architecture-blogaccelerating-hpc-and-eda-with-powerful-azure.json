{
  "EnhancedContent": "# Table of Contents\n\nIntroduction\n\nOur Commitment to Innovation in Key HPC/EDA Areas\n\nMost Effective Price/Performance for Any-Size Workload\n\nLarge volume breakthrough mode\n\nLarge volumes up to 7.2 PiB with cool access\n\nUser and Group Quota Reporting\n\nBest–of–Breed Security and Data Management\n\nBackup support for large volumes\n\nSingle file restore from backup\n\nHybrid Cloud Data Mobility\n\nCache volumes for Burst-to-Cloud\n\nMigration assistant\n\nMachine Learning, Data & AI–Ready\n\nObject REST API\n\nWhy All This Matters for HPC & EDA Workloads\n\nReliability\n\nCost Optimization\n\nOperational Excellence\n\nPerformance Efficiency\n\nSecurity\n\nConclusion\n\nLearn more\n\n# Introduction\n\nAzure NetApp Files continues to evolve, delivering ever improving enterprise-grade storage innovations that empower workloads such as High-Performance Computing (HPC) and Electronic Design Automation (EDA) teams to scale, collaborate, and innovate faster. This brand-new [Validating Scalable EDA Storage Performance: Azure NetApp Files and SPECstorage Solution 2020](https://techcommunity.microsoft.com/blog/azurearchitectureblog/validating-scalable-eda-storage-performance-azure-netapp-files-and-specstorage-s/4459517) article provides an in-depth look at the capabilities of Azure NetApp Files and its advantages for EDA teams, highlighting its extreme performance and linear scalability for EDA workloads. Building on our commitment to performance, reliability, and operational simplicity, we are excited to present several recently announced new features, each designed to address the unique challenges of data-intensive workloads and recommended for EDA ISVs seeking scalable, high-performance cloud storage.\n\n**Co-authors:**\n\n- [Ranga Sankar](https://www.linkedin.com/in/ranga-sankar-2594401/), Azure NetApp Files Technical Marketing Engineer\n- [Thomas Willingham](https://www.linkedin.com/in/gotthomas/), Azure NetApp Files Technical Marketing Engineer\n\n# Our Commitment to Innovation in Key HPC/EDA Areas\n\nAt Azure NetApp Files, our innovation strategy is rooted in solving the toughest challenges faced by High-Performance Computing (HPC) and Electronic Design Automation (EDA) teams. These workloads demand not only raw performance, but also precision, scalability, and operational resilience across every phase of design and simulation.\n\nImagine a world where your teams can reach new heights without limits—where scaling up doesn't mean making sacrifices. With Azure NetApp Files, you’re empowered to pursue bold ambitions, supported by the ***Most Effective Price/Performance for Any-Size Workload***. Your most valuable ideas and intellectual property are safeguarded by industry-leading, ***Best-of-Breed Security and Data Management***, giving you the freedom to innovate with confidence and meet the strictest compliance standards. Seamless ***Hybrid Cloud Data Mobility*** unlocks fluid collaboration and enables instant burst-to-cloud agility, while robust ***Machine Learning, Data & AI–Ready*** environments fuel your drive to innovate, learn, and lead the future.\n\nTogether, we’re not just keeping pace; we’re shaping what’s possible. In the next chapters we're diving deeper into the latest innovations in these key areas.\n\n# Most Effective Price/Performance for Any-Size Workload\n\nThe following sections showcase how Azure NetApp Files delivers breakthrough performance, unmatched scalability, and innovative features tailored for demanding workloads. Dive in to explore how these advancements can help you transform your data strategy and achieve more with confidence.\n\n## Large volume breakthrough mode\n\n*Breaking barriers in performance and scale!*\n\n[Large volume breakthrough mode](https://learn.microsoft.com/azure/azure-netapp-files/large-volumes-requirements-considerations#register-for-breakthrough-mode) is a major milestone in our mission to support high-performance workloads with unmatched scalability.\n\nThis feature enables:\n\n- Volumes up to 2 PiB on dedicated capacity. Dedicated capacity eliminates noisy neighbors and multi-tenancy performance issues.\n- Six storage endpoints deliver up to 50 GiB/s throughput\n- Consistent IOPS for write-intensive and metadata-heavy workloads\n\nIt is purpose-built for industries like semiconductors, hyperscale compute, and advanced analytics. This feature would help EDA customers to:\n\n- Accelerate time-to-market by removing infrastructure bottlenecks\n- Improve project predictability with consistent performance\n- Enable global collaboration across distributed teams working on large datasets.\n\n[Explore FIO Scale-Out Test Results on large volumes in breakthrough mode](https://learn.microsoft.com/azure/azure-netapp-files/performance-large-volume-breakthrough-mode-linux).\n\n## Large volumes up to 7.2 PiB with cool access\n\n*Store up to 7.2 PiB in one place!*\n\nCool access automatically moves cold data to cheaper storage. Consolidate massive datasets with support for [large volumes up to 7.2 PiB, combined with cool access storage](https://learn.microsoft.com/azure/azure-netapp-files/large-volumes-requirements-considerations#register-for-large-volumes-up-to-72-pib):\n\n- Massive consolidation—store large design repositories and logs in fewer volumes\n- Cost optimization—cool access automatically moves cold data to lower-cost storage\n- Performance assurance—active data stays on high-performance storage with no QoS ceiling\n- Operational simplicity—transparent tiering, no changes to apps or workflows\n- Scalable growth for long-term retention strategies\n\n## User and Group Quota Reporting\n\n*Fair storage for everyone!*\n\nEnhance governance and collaboration with [user/group quota reporting](https://learn.microsoft.com/azure/azure-netapp-files/generate-user-group-quota-reports). User/group quota reporting provides real-time visibility into individual and group storage usage, making it easy to track consumption. Inform administrators as quotas approach or exceed limits, ensuring proactive management and preventing unexpected overages. This transparency streamlines quota enforcement, supports timely capacity planning, and helps teams respond quickly to resource issues.\n\n- Prevent resource contention—no single user or group monopolizes storage.\n- Improve collaboration efficiency—fair distribution among teams.\n- Simplify capacity planning—predict usage patterns, avoid overflows.\n- Enable cost control—restrict excessive usage, control storage costs\n\n# Best–of–Breed Security and Data Management\n\nReady to take control of your data environment? The following sections dive into robust security and data management features, along with powerful backup capabilities, to ensure your most valuable assets are protected and easy to manage.\n\n## Backup support for large volumes\n\n*Safeguard your innovation with confidence!*\n\nProtect multi-100-terabyte design repositories, simulation outputs, and IP libraries with seamless backup for large volumes. Benefits of [Azure NetApp Files backup support for large volumes](https://learn.microsoft.com/azure/azure-netapp-files/backup-introduction) include:\n\n- Incremental forever backups—keeping up with ever limited time\n- Accelerated recovery of entire environments—keeping tape-out schedules on track\n- Centralized backup policies for simplified management\n- Granular restore options—recover anything from a full project to a single file\n- Compliance readiness for regulated industries\n\n## Single file restore from backup\n\n*Accidentally deleted a file? No worries! Instantly restore just what you need*.\n\nNow, you can restore [individual files from backups](https://learn.microsoft.com/azure/azure-netapp-files/restore-single-file-backup)—no need to roll back entire volumes or snapshots. Single file restore from backup works seamlessly with regular and large volumes, making data management more agile, efficient, and resilient for HPC and EDA teams. For EDA teams managing thousands of critical design files, this means:\n\n- Rapid recovery of accidentally deleted or corrupted files (e.g., Verilog modules, layout definitions) even in huge repositories.\n- Minimized downtime—engineers keep working while specific files are restored\n- Precision recovery for compliance, audit, and iterative design workflows\n- Cost efficiency by avoiding full volume restores\n\nThe [Restore individual files with single-file restore from backups in Azure NetApp Files](https://learn.microsoft.com/en-us/azure/azure-netapp-files/restore-single-file-backup) article outlines the key considerations and provides step-by-step guidance on using this feature.\n\n# Hybrid Cloud Data Mobility\n\nReady to take your data workflows to the next level? The following sections explore how hybrid cloud data mobility and advanced caching strategies empower engineering teams to work faster, collaborate seamlessly, and optimize costs—all without sacrificing control or performance.\n\n## Cache volumes for Burst-to-Cloud\n\n*Supercharge your EDA workflows when it matters most!*\n\nSpeed up jobs during peak demand and boost collaboration across teams.\n\nAccelerate compute- and data-intensive EDA workloads by leveraging [cache volumes](https://learn.microsoft.com/azure/azure-netapp-files/cache-volumes) for burst-to-cloud scenarios:\n\n- Faster job execution during peak demand\n- Reduced I/O bottlenecks for simulation and layout tools\n- Improved collaboration across distributed teams\n- Simplifies EDA job relocations to alternate regions\n- Lower cloud costs by optimizing data movement and access patterns\n\n## Migration assistant\n\n*Accelerate EDA and HPC Workload Transitions to the Cloud*\n\nThe [Azure NetApp Files migration assistant](https://learn.microsoft.com/azure/azure-netapp-files/migrate-volumes?tabs=portal) (now with Azure portal experience) is a purpose-built tool that streamlines the migration of data from on-premises NetApp® ONTAP® systems or Cloud Volumes ONTAP® into Azure NetApp Files. It leverages NetApp’s SnapMirror® replication technology to perform block-level transfers, ensuring efficient, secure, and low-downtime data movement. The assistant automates the setup of replication relationships, handles incremental updates, and preserves file metadata, permissions, and snapshots throughout the migration process.\n\nData can be migrated into regular volumes, large volumes and large volumes in breakthrough mode.\n\nThe migration assistant ensures seamless replication into any volume type, with the ability to scale performance dynamically based on workload demands.\n\nElectronic Design Automation (EDA) and High-Performance Computing (HPC) workloads are characterized by extreme I/O patterns, massive file counts, and the need for consistent low-latency access. The migration assistant offers several advantages:\n\n- **Minimal Downtime**: Continuous synchronization allows live data to be replicated with only a brief cutover window, ensuring uninterrupted operations during migration.\n- **Performance Preservation**: Migrated data retains its structure and access controls, enabling EDA tools and HPC applications to operate without reconfiguration or performance degradation.\n- **Scalability and Flexibility**: Azure NetApp Files large volumes support dynamic scaling, allowing organizations to adjust performance tiers on demand to match simulation or compute cycles.\n- **Data Integrity**: SnapMirror ensures consistent, verified replication, preserving snapshots and metadata critical to design and research workflows.\n\nEDA customers can use the migration assistant to move massive design datasets from their on-premises data centers into Azure NetApp Files volumes quickly and securely. This enables them to leverage cloud-scale compute resources for simulation, verification, and AI-driven analytics without sacrificing performance or data integrity—accelerating tape-out cycles and reducing time-to-market.\n\nBy enabling a lift-and-shift approach with enterprise-grade reliability, the migration assistant enables organizations to transition their EDA and HPC workloads to Azure confidently unlocking cloud agility without compromising performance or control.\n\n# Machine Learning, Data & AI–Ready\n\nThe following section highlights how Azure NetApp Files empowers EDA and HPC customers with advanced object storage capabilities, seamless cloud AI integration. Discover how these features transform design workflows, analytics, and AI readiness.\n\n## Object REST API\n\n[Azure NetApp Files object REST API](https://learn.microsoft.com/azure/azure-netapp-files/object-rest-api-introduction) delivers transformative benefits for customers running Electronic Design Automation (EDA) workloads while making their environments Machine Learning, Data & AI–Ready.\n\nAs semiconductor design complexity grows, EDA and HPC teams face mounting challenges in managing massive datasets while accelerating time-to-market. The Azure NetApp Files object REST API addresses these needs by combining high-performance file storage with modern object-based access, making environments truly Machine Learning, Data & AI–Ready. This capability unlocks seamless integration with Azure’s AI and analytics ecosystem, eliminates costly data movement, and ensures enterprise-grade security.\n\nBelow are the key aspects of the object REST API and how each delivers tangible advantages for EDA and HPC customers:\n\n- **S3-Compatible Access**: Native S3 access allows EDA and HPC applications to interact directly with Azure NetApp Files datasets, eliminating the need for data reformatting or duplication.\n- **Integration with Azure Services**: Connect to Azure AI Search, Azure Databricks, Azure AI Foundry, Fabric and OneLake, enabling advanced analytics and machine learning on the same data used for simulations.\n- **Enhanced Security**: Semiconductor design data is highly sensitive. Keep sensitive design data within Azure NetApp Files’ compliance framework, ensuring secure collaboration and IP protection\n- **Cost Efficiency**: Minimize replication and data transfer, which is critical for workloads generating petabytes of data.\n- **Accelerated Innovation:** Direct, multi-protocol access to design data supports rapid deployment of AI-driven workflows, shortening tape-out cycles.\n\nThe object REST API bridges high-performance engineering storage with cloud-native AI innovation, enabling semiconductor companies to meet tight tape-out schedules and accelerate time-to-market in an increasingly competitive landscape. By making EDA environments AI-ready without disrupting existing workflows, Azure NetApp Files enable design teams to innovate faster, smarter, and more securely.\n\n# Why All This Matters for HPC & EDA Workloads\n\nHigh-Performance Computing (HPC) and Electronic Design Automation (EDA) workloads demand uncompromising performance, scalability, and resilience. Whether you're managing petabyte-scale datasets or running compute intensive simulations, Azure NetApp Files delivers the agility and reliability needed to innovate without limits.\n\nThe latest Azure NetApp Files innovations are purpose-built to meet these needs, aligning with the [five pillars of the Azure Well-Architected Framework](https://learn.microsoft.com/azure/well-architected/service-guides/azure-netapp-files).\n\n## Reliability\n\n*Ensure mission-critical workloads are protected and recoverable*\n\n- Enterprise-grade backup support for large volumes and restore capabilities support rapid recovery from failures or data loss for EDA and HPC workloads.\n- Snapshot-based recovery and targeted single file restore minimize downtime during iterative design or simulation cycles.\n\n## Cost Optimization\n\n*Maximize value while minimizing spend*\n\n- Large volume with cool access reduces storage costs for infrequently accessed data. Cold data is moved to cheaper storage.\n- Efficient data migration and replication reduce network transfer costs and eliminates the need for costly re-architecture.\n- Leveraging cache volumes for burst-to-cloud scenarios and pay-as-you-go scalability allows teams to spin up resources only when needed.\n\n## Operational Excellence\n\n*Simplify management and improve agility*\n\n- Automated migration workflows and volume management streamline operations.\n- User and group quota reporting provide visibility into usage.\n\n## Performance Efficiency\n\n*Accelerate innovation with scalable, high-performance infrastructure*\n\n- Large volume breakthrough mode support delivers up to 50 GiB/s throughput and more than a million IOPS, ideal for EDA simulations and HPC modeling.\n- Dynamic service-level adjustments allow teams to tune performance on demand.\n- Low-latency access ensures fast iteration cycles and real-time responsiveness for compute intensive tasks.\n\n## Security\n\n*Safeguard sensitive workloads*\n\n- Azure NetApp Files large volume breakthrough mode offers dedicated capacity, eliminating noisy neighbor risks and ensuring secure isolation for sensitive workloads.\n- Centralized backup policies and granular restore options help meet compliance and audit requirements. This is especially critical for regulated industries like semiconductors.\n- Single File Restore enables precise recovery of individual files without rolling back entire volumes—supporting audit trails, compliance workflows, and minimizing exposure during recovery operations.\n- User and group quota reporting prevents resource monopolization, supports fair usage, and helps enforce organizational policies around data access and consumption.\n\nAzure NetApp Files is committed to helping HPC and EDA customers innovate without limits—whether you are designing the next semiconductor breakthrough, running complex simulations, or managing compliance in regulated industries.\n\n**Ready to innovate without limits? Azure NetApp Files is here to help you shine!**\n\n# Conclusion\n\nThese latest Azure NetApp Files enhancements aren’t just incremental updates – they’re a **catalyst for a new era of cloud-based HPC and EDA**. By fusing *unprecedented throughput and petabyte-scale storage* with intelligent data management, these innovations **dramatically accelerate time-to-insight and enable next-generation design breakthroughs** for engineers and scientists. HPC researchers can now tackle *grand simulations faster*, and chip design teams can iterate on *next-gen semiconductors* with greater agility – confident that the underlying platform will scale to meet **extreme I/O demands and massive datasets** without compromising performance.\n\nUltimately, Azure NetApp Files **empowers organizations to push the boundaries of what’s possible**, turning ambitious ideas into reality and ensuring that the future of engineering and scientific innovation **knows no limits!**\n\n# Learn more\n\n- [What's new in Azure NetApp Files | November 2025](https://learn.microsoft.com/azure/azure-netapp-files/whats-new#november-2025)\n- [What's new in Azure NetApp Files | October 2025](https://learn.microsoft.com/azure/azure-netapp-files/whats-new#october-2025)\n- [Benefits of using Azure NetApp Files for Electronic Design Automation (EDA)](https://learn.microsoft.com/en-us/azure/azure-netapp-files/solutions-benefits-azure-netapp-files-electronic-design-automation)\n- [Requirements and considerations for Azure NetApp Files large volumes](https://learn.microsoft.com/en-us/azure/azure-netapp-files/large-volumes-requirements-considerations)\n- [Migration Assistant: Migrate volumes to Azure NetApp Files](https://learn.microsoft.com/en-us/azure/azure-netapp-files/migrate-volumes?tabs=restapi)\n- [Validating Scalable EDA Storage Performance: Azure NetApp Files and SPECstorage® Solution 2020](https://techcommunity.microsoft.com/blog/azurearchitectureblog/validating-scalable-eda-storage-performance-azure-netapp-files-and-specstorage-s/4459517)\n- [Boosting Hybrid Cloud Data Efficiency for EDA: The Power of Azure NetApp Files cache volumes](https://techcommunity.microsoft.com/blog/azurearchitectureblog/boosting-hybrid-cloud-data-efficiency-for-eda-the-power-of-azure-netapp-files-ca/4467790)\n\nUpdated Nov 14, 2025\n\nVersion 2.0\n\n[advance analytics](/tag/advance%20analytics?nodeId=board%3AAzureArchitectureBlog)\n\n[application](/tag/application?nodeId=board%3AAzureArchitectureBlog)\n\n[artificial intelligence](/tag/artificial%20intelligence?nodeId=board%3AAzureArchitectureBlog)\n\n[data platform](/tag/data%20platform?nodeId=board%3AAzureArchitectureBlog)\n\n[infrastructure](/tag/infrastructure?nodeId=board%3AAzureArchitectureBlog)\n\n[integration](/tag/integration?nodeId=board%3AAzureArchitectureBlog)\n\n[msignite](/tag/msignite?nodeId=board%3AAzureArchitectureBlog)\n\n[well architected](/tag/well%20architected?nodeId=board%3AAzureArchitectureBlog)\n\n[!\\[GeertVanTeylingen&#x27;s avatar\\](https://techcommunity.microsoft.com/t5/s/gxcuf89792/images/dS0yMjI4NTMtMzI1MjMwaTVERUE2NzdCRkJBNjkxQzg?image-dimensions=50x50)](/users/geertvanteylingen/222853) [GeertVanTeylingen](/users/geertvanteylingen/222853) ![Icon for Microsoft rank](https://techcommunity.microsoft.com/t5/s/gxcuf89792/images/cmstNC05WEo0blc?image-dimensions=100x16&amp;constrain-image=true)Microsoft\n\nJoined October 04, 2018\n\n[View Profile](/users/geertvanteylingen/222853)\n\n/category/azure/blog/azurearchitectureblog [Azure Architecture Blog](/category/azure/blog/azurearchitectureblog) Follow this blog board to get notified when there's new activity",
  "PubDate": "2025-11-14T16:52:12+00:00",
  "FeedName": "Microsoft Tech Community",
  "FeedUrl": "https://techcommunity.microsoft.com/t5/s/gxcuf89792/rss/Category?category.id=Azure",
  "Title": "Accelerating HPC and EDA with Powerful Azure NetApp Files Enhancements",
  "OutputDir": "_community",
  "Link": "https://techcommunity.microsoft.com/t5/azure-architecture-blog/accelerating-hpc-and-eda-with-powerful-azure-netapp-files/ba-p/4469739",
  "Tags": [],
  "Author": "GeertVanTeylingen",
  "FeedLevelAuthor": "rss.livelink.threads-in-node",
  "ProcessedDate": "2025-11-14 17:04:50",
  "Description": "# Table of Contents\n\nIntroduction\n\nOur Commitment to Innovation in Key HPC/EDA Areas\n\nMost Effective Price/Performance for Any-Size Workload\n\nLarge volume breakthrough mode\n\nLarge volumes up to 7.2 PiB with cool access\n\nUser and Group Quota Reporting\n\nBest–of–Breed Security and Data Management\n\nBackup support for large volumes\n\nSingle file restore from backup\n\nHybrid Cloud Data Mobility\n\nCache volumes for Burst-to-Cloud\n\nMigration assistant\n\nMachine Learning, Data & AI–Ready\n\nObject REST API\n\nWhy All This Matters for HPC & EDA Workloads\n\nReliability\n\nCost Optimization\n\nOperational Excellence\n\nPerformance Efficiency\n\nSecurity\n\nConclusion\n\nLearn more\n\n# Introduction\n\n![]()\n\nAzure NetApp Files continues to evolve, delivering ever improving enterprise-grade storage innovations that empower workloads such as High-Performance Computing (HPC) and Electronic Design Automation (EDA) teams to scale, collaborate, and innovate faster. This brand-new [Validating Scalable EDA Storage Performance: Azure NetApp Files and SPECstorage Solution 2020](https://techcommunity.microsoft.com/blog/azurearchitectureblog/validating-scalable-eda-storage-performance-azure-netapp-files-and-specstorage-s/4459517) article provides an in-depth look at the capabilities of Azure NetApp Files and its advantages for EDA teams, highlighting its extreme performance and linear scalability for EDA workloads. Building on our commitment to performance, reliability, and operational simplicity, we are excited to present several recently announced new features, each designed to address the unique challenges of data-intensive workloads and recommended for EDA ISVs seeking scalable, high-performance cloud storage.\n\n**Co-authors:**\n\n- [Ranga Sankar](https://www.linkedin.com/in/ranga-sankar-2594401/), Azure NetApp Files Technical Marketing Engineer\n- [Thomas Willingham](https://www.linkedin.com/in/gotthomas/), Azure NetApp Files Technical Marketing Engineer\n\n# Our Commitment to Innovation in Key HPC/EDA Areas\n\nAt Azure NetApp Files, our innovation strategy is rooted in solving the toughest challenges faced by High-Performance Computing (HPC) and Electronic Design Automation (EDA) teams. These workloads demand not only raw performance, but also precision, scalability, and operational resilience across every phase of design and simulation.\n\nImagine a world where your teams can reach new heights without limits—where scaling up doesn't mean making sacrifices. With Azure NetApp Files, you’re empowered to pursue bold ambitions, supported by the ***Most Effective Price/Performance for Any-Size Workload***. Your most valuable ideas and intellectual property are safeguarded by industry-leading, ***Best-of-Breed Security and Data Management***, giving you the freedom to innovate with confidence and meet the strictest compliance standards. Seamless ***Hybrid Cloud Data Mobility*** unlocks fluid collaboration and enables instant burst-to-cloud agility, while robust ***Machine Learning, Data & AI–Ready*** environments fuel your drive to innovate, learn, and lead the future.\n\nTogether, we’re not just keeping pace; we’re shaping what’s possible. In the next chapters we're diving deeper into the latest innovations in these key areas.\n\n# Most Effective Price/Performance for Any-Size Workload\n\nThe following sections showcase how Azure NetApp Files delivers breakthrough performance, unmatched scalability, and innovative features tailored for demanding workloads. Dive in to explore how these advancements can help you transform your data strategy and achieve more with confidence.\n\n## Large volume breakthrough mode\n\n*Breaking barriers in performance and scale!*\n\n[Large volume breakthrough mode](https://learn.microsoft.com/azure/azure-netapp-files/large-volumes-requirements-considerations#register-for-breakthrough-mode) is a major milestone in our mission to support high-performance workloads with unmatched scalability.\n\nThis feature enables:\n\n- Volumes up to 2 PiB on dedicated capacity. Dedicated capacity eliminates noisy neighbors and multi-tenancy performance issues.\n- Six storage endpoints deliver up to 50 GiB/s throughput\n- Consistent IOPS for write-intensive and metadata-heavy workloads\n\nIt is purpose-built for industries like semiconductors, hyperscale compute, and advanced analytics. This feature would help EDA customers to:\n\n- Accelerate time-to-market by removing infrastructure bottlenecks\n- Improve project predictability with consistent performance\n- Enable global collaboration across distributed teams working on large datasets.\n\n[Explore FIO Scale-Out Test Results on large volumes in breakthrough mode](https://learn.microsoft.com/azure/azure-netapp-files/performance-large-volume-breakthrough-mode-linux).\n\n![]()![]()\n\n## Large volumes up to 7.2 PiB with cool access\n\n*Store up to 7.2 PiB in one place!*\n\nCool access automatically moves cold data to cheaper storage. Consolidate massive datasets with support for [large volumes up to 7.2 PiB, combined with cool access storage](https://learn.microsoft.com/azure/azure-netapp-files/large-volumes-requirements-considerations#register-for-large-volumes-up-to-72-pib):\n\n- Massive consolidation—store large design repositories and logs in fewer volumes\n- Cost optimization—cool access automatically moves cold data to lower-cost storage\n- Performance assurance—active data stays on high-performance storage with no QoS ceiling\n- Operational simplicity—transparent tiering, no changes to apps or workflows\n- Scalable growth for long-term retention strategies\n\n## User and Group Quota Reporting\n\n*Fair storage for everyone!*\n\nEnhance governance and collaboration with [user/group quota reporting](https://learn.microsoft.com/azure/azure-netapp-files/generate-user-group-quota-reports). User/group quota reporting provides real-time visibility into individual and group storage usage, making it easy to track consumption. Inform administrators as quotas approach or exceed limits, ensuring proactive management and preventing unexpected overages. This transparency streamlines quota enforcement, supports timely capacity planning, and helps teams respond quickly to resource issues.\n\n- Prevent resource contention—no single user or group monopolizes storage.\n- Improve collaboration efficiency—fair distribution among teams.\n- Simplify capacity planning—predict usage patterns, avoid overflows.\n- Enable cost control—restrict excessive usage, control storage costs\n\n# Best–of–Breed Security and Data Management\n\nReady to take control of your data environment? The following sections dive into robust security and data management features, along with powerful backup capabilities, to ensure your most valuable assets are protected and easy to manage.\n\n## Backup support for large volumes\n\n*Safeguard your innovation with confidence!*\n\nProtect multi-100-terabyte design repositories, simulation outputs, and IP libraries with seamless backup for large volumes. Benefits of [Azure NetApp Files backup support for large volumes](https://learn.microsoft.com/azure/azure-netapp-files/backup-introduction) include:\n\n- Incremental forever backups—keeping up with ever limited time\n- Accelerated recovery of entire environments—keeping tape-out schedules on track\n- Centralized backup policies for simplified management\n- Granular restore options—recover anything from a full project to a single file\n- Compliance readiness for regulated industries\n\n![]()\n\n## Single file restore from backup\n\n*Accidentally deleted a file? No worries! Instantly restore just what you need*.\n\nNow, you can restore [individual files from backups](https://learn.microsoft.com/azure/azure-netapp-files/restore-single-file-backup)—no need to roll back entire volumes or snapshots. Single file restore from backup works seamlessly with regular and large volumes, making data management more agile, efficient, and resilient for HPC and EDA teams. For EDA teams managing thousands of critical design files, this means:\n\n- Rapid recovery of accidentally deleted or corrupted files (e.g., Verilog modules, layout definitions) even in huge repositories.\n- Minimized downtime—engineers keep working while specific files are restored\n- Precision recovery for compliance, audit, and iterative design workflows\n- Cost efficiency by avoiding full volume restores\n\nThe [Restore individual files with single-file restore from backups in Azure NetApp Files](https://learn.microsoft.com/en-us/azure/azure-netapp-files/restore-single-file-backup) article outlines the key considerations and provides step-by-step guidance on using this feature.\n\n# Hybrid Cloud Data Mobility\n\nReady to take your data workflows to the next level? The following sections explore how hybrid cloud data mobility and advanced caching strategies empower engineering teams to work faster, collaborate seamlessly, and optimize costs—all without sacrificing control or performance.\n\n## Cache volumes for Burst-to-Cloud\n\n*Supercharge your EDA workflows when it matters most!*\n\nSpeed up jobs during peak demand and boost collaboration across teams.\n\nAccelerate compute- and data-intensive EDA workloads by leveraging [cache volumes](https://learn.microsoft.com/azure/azure-netapp-files/cache-volumes) for burst-to-cloud scenarios:\n\n- Faster job execution during peak demand\n- Reduced I/O bottlenecks for simulation and layout tools\n- Improved collaboration across distributed teams\n- Simplifies EDA job relocations to alternate regions\n- Lower cloud costs by optimizing data movement and access patterns\n\n## Migration assistant\n\n*Accelerate EDA and HPC Workload Transitions to the Cloud*\n\nThe [Azure NetApp Files migration assistant](https://learn.microsoft.com/azure/azure-netapp-files/migrate-volumes?tabs=portal) (now with Azure portal experience) is a purpose-built tool that streamlines the migration of data from on-premises NetApp® ONTAP® systems or Cloud Volumes ONTAP® into Azure NetApp Files. It leverages NetApp’s SnapMirror® replication technology to perform block-level transfers, ensuring efficient, secure, and low-downtime data movement. The assistant automates the setup of replication relationships, handles incremental updates, and preserves file metadata, permissions, and snapshots throughout the migration process.\n\nData can be migrated into regular volumes, large volumes and large volumes in breakthrough mode.\n\nThe migration assistant ensures seamless replication into any volume type, with the ability to scale performance dynamically based on workload demands.\n\nElectronic Design Automation (EDA) and High-Performance Computing (HPC) workloads are characterized by extreme I/O patterns, massive file counts, and the need for consistent low-latency access. The migration assistant offers several advantages:\n\n- **Minimal Downtime**: Continuous synchronization allows live data to be replicated with only a brief cutover window, ensuring uninterrupted operations during migration.\n- **Performance Preservation**: Migrated data retains its structure and access controls, enabling EDA tools and HPC applications to operate without reconfiguration or performance degradation.\n- **Scalability and Flexibility**: Azure NetApp Files large volumes support dynamic scaling, allowing organizations to adjust performance tiers on demand to match simulation or compute cycles.\n- **Data Integrity**: SnapMirror ensures consistent, verified replication, preserving snapshots and metadata critical to design and research workflows.\n\nEDA customers can use the migration assistant to move massive design datasets from their on-premises data centers into Azure NetApp Files volumes quickly and securely. This enables them to leverage cloud-scale compute resources for simulation, verification, and AI-driven analytics without sacrificing performance or data integrity—accelerating tape-out cycles and reducing time-to-market.\n\nBy enabling a lift-and-shift approach with enterprise-grade reliability, the migration assistant enables organizations to transition their EDA and HPC workloads to Azure confidently unlocking cloud agility without compromising performance or control.\n\n# Machine Learning, Data & AI–Ready\n\nThe following section highlights how Azure NetApp Files empowers EDA and HPC customers with advanced object storage capabilities, seamless cloud AI integration. Discover how these features transform design workflows, analytics, and AI readiness.\n\n## Object REST API\n\n[Azure NetApp Files object REST API](https://learn.microsoft.com/azure/azure-netapp-files/object-rest-api-introduction) delivers transformative benefits for customers running Electronic Design Automation (EDA) workloads while making their environments Machine Learning, Data & AI–Ready.\n\nAs semiconductor design complexity grows, EDA and HPC teams face mounting challenges in managing massive datasets while accelerating time-to-market. The Azure NetApp Files object REST API addresses these needs by combining high-performance file storage with modern object-based access, making environments truly Machine Learning, Data & AI–Ready. This capability unlocks seamless integration with Azure’s AI and analytics ecosystem, eliminates costly data movement, and ensures enterprise-grade security.\n\nBelow are the key aspects of the object REST API and how each delivers tangible advantages for EDA and HPC customers:\n\n- **S3-Compatible Access**: Native S3 access allows EDA and HPC applications to interact directly with Azure NetApp Files datasets, eliminating the need for data reformatting or duplication.\n- **Integration with Azure Services**: Connect to Azure AI Search, Azure Databricks, Azure AI Foundry, Fabric and OneLake, enabling advanced analytics and machine learning on the same data used for simulations.\n- **Enhanced Security**: Semiconductor design data is highly sensitive. Keep sensitive design data within Azure NetApp Files’ compliance framework, ensuring secure collaboration and IP protection\n- **Cost Efficiency**: Minimize replication and data transfer, which is critical for workloads generating petabytes of data.\n- **Accelerated Innovation:** Direct, multi-protocol access to design data supports rapid deployment of AI-driven workflows, shortening tape-out cycles.\n\n![]()\n\nThe object REST API bridges high-performance engineering storage with cloud-native AI innovation, enabling semiconductor companies to meet tight tape-out schedules and accelerate time-to-market in an increasingly competitive landscape. By making EDA environments AI-ready without disrupting existing workflows, Azure NetApp Files enable design teams to innovate faster, smarter, and more securely.\n\n# Why All This Matters for HPC & EDA Workloads\n\nHigh-Performance Computing (HPC) and Electronic Design Automation (EDA) workloads demand uncompromising performance, scalability, and resilience. Whether you're managing petabyte-scale datasets or running compute intensive simulations, Azure NetApp Files delivers the agility and reliability needed to innovate without limits.\n\n![]()\n\nThe latest Azure NetApp Files innovations are purpose-built to meet these needs, aligning with the [five pillars of the Azure Well-Architected Framework](https://learn.microsoft.com/azure/well-architected/service-guides/azure-netapp-files).\n\n## Reliability\n\n*Ensure mission-critical workloads are protected and recoverable*\n\n- Enterprise-grade backup support for large volumes and restore capabilities support rapid recovery from failures or data loss for EDA and HPC workloads.\n- Snapshot-based recovery and targeted single file restore minimize downtime during iterative design or simulation cycles.\n\n## Cost Optimization\n\n*Maximize value while minimizing spend*\n\n- Large volume with cool access reduces storage costs for infrequently accessed data. Cold data is moved to cheaper storage.\n- Efficient data migration and replication reduce network transfer costs and eliminates the need for costly re-architecture.\n- Leveraging cache volumes for burst-to-cloud scenarios and pay-as-you-go scalability allows teams to spin up resources only when needed.\n\n## Operational Excellence\n\n*Simplify management and improve agility*\n\n- Automated migration workflows and volume management streamline operations.\n- User and group quota reporting provide visibility into usage.\n\n## Performance Efficiency\n\n*Accelerate innovation with scalable, high-performance infrastructure*\n\n- Large volume breakthrough mode support delivers up to 50 GiB/s throughput and more than a million IOPS, ideal for EDA simulations and HPC modeling.\n- Dynamic service-level adjustments allow teams to tune performance on demand.\n- Low-latency access ensures fast iteration cycles and real-time responsiveness for compute intensive tasks.\n\n## Security\n\n*Safeguard sensitive workloads*\n\n- Azure NetApp Files large volume breakthrough mode offers dedicated capacity, eliminating noisy neighbor risks and ensuring secure isolation for sensitive workloads.\n- Centralized backup policies and granular restore options help meet compliance and audit requirements. This is especially critical for regulated industries like semiconductors.\n- Single File Restore enables precise recovery of individual files without rolling back entire volumes—supporting audit trails, compliance workflows, and minimizing exposure during recovery operations.\n- User and group quota reporting prevents resource monopolization, supports fair usage, and helps enforce organizational policies around data access and consumption.\n\nAzure NetApp Files is committed to helping HPC and EDA customers innovate without limits—whether you are designing the next semiconductor breakthrough, running complex simulations, or managing compliance in regulated industries.\n\n**Ready to innovate without limits? Azure NetApp Files is here to help you shine!**\n\n# Conclusion\n\nThese latest Azure NetApp Files enhancements aren’t just incremental updates – they’re a **catalyst for a new era of cloud-based HPC and EDA**. By fusing *unprecedented throughput and petabyte-scale storage* with intelligent data management, these innovations **dramatically accelerate time-to-insight and enable next-generation design breakthroughs** for engineers and scientists. HPC researchers can now tackle *grand simulations faster*, and chip design teams can iterate on *next-gen semiconductors* with greater agility – confident that the underlying platform will scale to meet **extreme I/O demands and massive datasets** without compromising performance.\n\nUltimately, Azure NetApp Files **empowers organizations to push the boundaries of what’s possible**, turning ambitious ideas into reality and ensuring that the future of engineering and scientific innovation **knows no limits!**\n\n# Learn more\n\n- [What's new in Azure NetApp Files | November 2025](https://learn.microsoft.com/azure/azure-netapp-files/whats-new#november-2025)\n- [What's new in Azure NetApp Files | October 2025](https://learn.microsoft.com/azure/azure-netapp-files/whats-new#october-2025)\n- [Benefits of using Azure NetApp Files for Electronic Design Automation (EDA)](https://learn.microsoft.com/en-us/azure/azure-netapp-files/solutions-benefits-azure-netapp-files-electronic-design-automation)\n- [Requirements and considerations for Azure NetApp Files large volumes](https://learn.microsoft.com/en-us/azure/azure-netapp-files/large-volumes-requirements-considerations)\n- [Migration Assistant: Migrate volumes to Azure NetApp Files](https://learn.microsoft.com/en-us/azure/azure-netapp-files/migrate-volumes?tabs=restapi)\n- [Validating Scalable EDA Storage Performance: Azure NetApp Files and SPECstorage® Solution 2020](https://techcommunity.microsoft.com/blog/azurearchitectureblog/validating-scalable-eda-storage-performance-azure-netapp-files-and-specstorage-s/4459517)\n- [Boosting Hybrid Cloud Data Efficiency for EDA: The Power of Azure NetApp Files cache volumes](https://techcommunity.microsoft.com/blog/azurearchitectureblog/boosting-hybrid-cloud-data-efficiency-for-eda-the-power-of-azure-netapp-files-ca/4467790)"
}
