{
  "FeedUrl": "https://techcommunity.microsoft.com/t5/s/gxcuf89792/rss/Category?category.id=Azure",
  "ProcessedDate": "2025-11-13 08:05:48",
  "FeedLevelAuthor": "rss.livelink.threads-in-node",
  "Link": "https://techcommunity.microsoft.com/t5/microsoft-developer-community/demystifying-github-copilot-security-controls-easing-concerns/ba-p/4468193",
  "Author": "jorgebalderas",
  "Title": "Demystifying GitHub Copilot Security Controls: easing concerns for organizational adoption",
  "EnhancedContent": "At a recent developer conference, I delivered a session on Legacy Code Rescue using GitHub Copilot App Modernization. Throughout the day, conversations with developers revealed a clear divide: some have fully embraced Agentic AI in their daily coding, while others remain cautious. Often, this hesitation isn't due to reluctance but stems from organizational concerns around **security and regulatory compliance**. Having witnessed similar patterns during past technology shifts, I understand how these barriers can **slow adoption**.\n\nIn this blog, I'll **demystify** the most common security concerns about GitHub Copilot and explain how its built-in features address them, empowering organizations to confidently modernize their development workflows.\n\n##### **GitHub Copilot Model Training**\n\nA common question I received at the conference was whether GitHub uses your code as training data for GitHub Copilot. I always direct customers to the [GitHub Copilot Trust Center](https://ghec.github.trust.page/) for clarity, but the [answer](https://copilot.github.trust.page/faq?s=v2qe7voltpwtv2usl4ikhs) is straightforward: “*No. GitHub uses neither Copilot Business nor Enterprise data to train the GitHub model.”*\n\nNotice this restriction also applies to [third-party models](https://copilot.github.trust.page/faq?s=qoerjag9v36a9muz82voo) as well (e.g. Anthropic, Google).\n\n##### **GitHub Copilot Intellectual Property indemnification policy**\n\nA frequent concern I hear is, since GitHub Copilot’s underlying models are trained on sources that include public code, it might simply “copy and paste” code from those sources. Let’s clarify how this actually works:\n\n[Does GitHub Copilot “copy/paste”?](https://copilot.github.trust.page/faq?s=kshrwbj4qvp0fw6r2t4kjv)\n\n*“The AI models that create Copilot’s suggestions may be trained on public code, but do not contain any code. When they generate a suggestion, they are not “copying and pasting” from any codebase.”*\n\nTo provide an additional layer of protection, GitHub Copilot includes a [“duplicate detection filter”](https://docs.github.com/en/copilot/how-tos/manage-your-account/manage-policies#enabling-or-disabling-suggestions-matching-public-code). This feature helps prevent suggestions that closely match public code from being surfaced. (Note: This duplicate detection currently does not apply to the Copilot coding agent.)\n\nMore importantly, customers are protected by an [Intellectual Property indemnification](https://blogs.microsoft.com/on-the-issues/2023/09/07/copilot-copyright-commitment-ai-legal-concerns/) policy. This means that if you receive an unmodified suggestion from GitHub Copilot and face a copyright claim as a result, Microsoft will defend you in court.\n\n##### **GitHub Copilot Data Retention**\n\nAnother frequent question I hear concerns GitHub Copilot’s [data retention policies](https://copilot.github.trust.page/faq?s=b9buqrq7o9ssfk3ta50x6). For organizations on GitHub Copilot Business and Enterprise plans, retention practices depend on how and where the service is accessed from:\n\n*Access through IDE for Chat and Code Completions:*\n\n- *Prompts and Suggestions: Not retained.*\n- *User Engagement Data: Kept for two years.*\n- *Feedback Data: Stored for as long as needed for its intended purpose.*\n\n*Other GitHub Copilot access and use:*\n\n- *Prompts and Suggestions: Retained for 28 days.*\n- *User Engagement Data: Kept for two years.*\n- *Feedback Data: Stored for as long as needed for its intended purpose.*\n\n*For Copilot Coding Agent, session logs are retained for the life of the account in order to provide the service.*\n\n##### **Excluding content from GitHub Copilot**\n\nTo prevent GitHub Copilot from indexing sensitive files, you can configure [content exclusions](https://docs.github.com/en/copilot/how-tos/configure-content-exclusion/exclude-content-from-copilot) at the repository or organization level. In VS Code, use the [.copilotignore](https://docs.github.com/en/copilot/how-tos/use-copilot-extensions/build-a-copilot-agent/use-context-passing#hidden-files) file to exclude files client-side. Note that files listed in *.gitignore* are not indexed by default but may still be referenced if open or explicitly referenced (unless they’re excluded through *.copilotignore* or content exclusions).\n\n##### **The life cycle of a GitHub Copilot code suggestion**\n\nHere are the key protections at each stage of the [life cycle](https://resources.github.com/learn/pathways/copilot/essentials/how-github-copilot-handles-data/) of a GitHub Copilot code suggestion:\n\n- In the IDE:\n- [Content exclusions](https://docs.github.com/en/copilot/how-tos/configure-content-exclusion/exclude-content-from-copilot) prevent files, folders, or patterns from being included.\n\n- GitHub proxy (pre-model safety):\n- Prompts go through a GitHub proxy hosted in Microsoft Azure for **pre-inference checks**: screening for *toxic or inappropriate language, relevance, and hacking attempts/jailbreak-style prompts* before reaching the model.\n\n- Model response:\n- With the [public code filter](https://docs.github.com/en/copilot/how-tos/manage-your-account/manage-policies#enabling-or-disabling-suggestions-matching-public-code) enabled, some suggestions are suppressed.\n- The [vulnerability protection](https://github.blog/ai-and-ml/github-copilot/github-copilot-now-has-a-better-ai-model-and-new-capabilities/#filtering-out-security-vulnerabilities-with-a-new-ai-system)feature blocks insecure coding patterns like hardcoded credentials or SQL injections in real time.\n\nDiagram showing how the code editor connects to a proxy which connects to the GitHub Copilot LLM\n\n##### **Disable access to GitHub Copilot Free**\n\nDue to the varying policies associated with GitHub Copilot Free, it is crucial for organizations to ensure it is [disabled both in the IDE and on GitHub.com](https://docs.github.com/en/copilot/how-tos/manage-your-account/disable-copilot-free). Since not all IDEs currently offer a built-in option to disable Copilot Free, the most reliable method to prevent both accidental and intentional access is to implement firewall rule changes, as outlined in the [official documentation](https://docs.github.com/en/copilot/how-tos/administer-copilot/manage-for-enterprise/manage-access/manage-network-access#configuring-copilot-subscription-based-network-routing-for-your-enterprise-or-organization).\n\n##### **Agent Mode Allow List**\n\nAccidental file system deletion by Agentic AI assistants can happen. With GitHub Copilot agent mode, the \"[Terminal auto approve](https://code.visualstudio.com/updates/v1_104#_terminal-auto-approve)” setting in VS Code can be used to prevent this. This setting can be managed [centrally](https://code.visualstudio.com/docs/setup/enterprise#_centrally-manage-vs-code-settings) using a VS Code policy.\n\n##### **MCP registry**\n\nOrganizations often want to restrict access to allow only trusted MCP servers. GitHub now offers an [MCP registry feature](https://docs.github.com/en/copilot/how-tos/administer-copilot/configure-mcp-server-access#support-for-mcp-policies) for this purpose. This feature isn’t available in all IDEs and clients yet, but it's being developed.\n\n##### **Compliance Certifications**\n\nThe GitHub Copilot [Trust Center](https://copilot.github.trust.page/) page lists GitHub Copilot's broad compliance credentials, surpassing many competitors in financial, security, privacy, cloud, and industry coverage.\n\n- **SOC 1 Type 2**: Assurance over internal controls for financial reporting.\n- **SOC 2 Type 2**: In-depth report covering Security, Availability, Processing Integrity, Confidentiality, and Privacy over time.\n- **SOC 3**: General-use version of SOC 2 with broad executive-level assurance.\n- **ISO/IEC** **** **27001:2013**: Certification for a formal Information Security Management System (ISMS), based on risk management controls.\n- **CSA STAR Level 2**: Includes a third-party attestation combining ISO 27001 or SOC 2 with additional cloud control matrix (CCM) requirements.\n- **TISAX**: Trusted Information Security Assessment Exchange, covering automotive-sector security standards.\n\nIn **summary**, while the adoption of AI tools like GitHub Copilot in software development can raise important questions around security, privacy, and compliance, it’s clear that existing safeguards in place help address these concerns. By understanding the **safeguards, configurable controls, and robust compliance certifications** offered, organizations and developers alike can feel more confident in embracing GitHub Copilot to **accelerate innovation** while maintaining trust and peace of mind.\n\nPublished Nov 13, 2025\n\nVersion 1.0\n\n[agents](/tag/agents?nodeId=board%3AAzureDevCommunityBlog)\n\n[ai](/tag/ai?nodeId=board%3AAzureDevCommunityBlog)\n\n[best practices](/tag/best%20practices?nodeId=board%3AAzureDevCommunityBlog)\n\n[copilot](/tag/copilot?nodeId=board%3AAzureDevCommunityBlog)\n\n[github](/tag/github?nodeId=board%3AAzureDevCommunityBlog)\n\n[vs code](/tag/vs%20code?nodeId=board%3AAzureDevCommunityBlog)\n\n[!\\[jorgebalderas&#x27;s avatar\\](https://techcommunity.microsoft.com/t5/s/gxcuf89792/images/dS0yNDkwNTI3LWV5REd1UA?image-coordinates=0%2C0%2C1586%2C1586&amp;image-dimensions=50x50)](/users/jorgebalderas/2490527) [jorgebalderas](/users/jorgebalderas/2490527) ![Icon for Microsoft rank](https://techcommunity.microsoft.com/t5/s/gxcuf89792/images/cmstNC05WEo0blc?image-dimensions=100x16&amp;constrain-image=true)Microsoft\n\nJoined May 25, 2024\n\n[View Profile](/users/jorgebalderas/2490527)\n\n/category/azure/blog/azuredevcommunityblog [Microsoft Developer Community Blog](/category/azure/blog/azuredevcommunityblog) Follow this blog board to get notified when there's new activity",
  "Tags": [],
  "PubDate": "2025-11-13T08:00:00+00:00",
  "FeedName": "Microsoft Tech Community",
  "OutputDir": "_community",
  "Description": "At a recent developer conference, I delivered a session on Legacy Code Rescue using GitHub Copilot App Modernization. Throughout the day, conversations with developers revealed a clear divide: some have fully embraced Agentic AI in their daily coding, while others remain cautious. Often, this hesitation isn't due to reluctance but stems from organizational concerns around **security and regulatory compliance**. Having witnessed similar patterns during past technology shifts, I understand how these barriers can **slow adoption**.\n\nIn this blog, I'll **demystify** the most common security concerns about GitHub Copilot and explain how its built-in features address them, empowering organizations to confidently modernize their development workflows.\n\n##### **GitHub Copilot Model Training**\n\nA common question I received at the conference was whether GitHub uses your code as training data for GitHub Copilot. I always direct customers to the [GitHub Copilot Trust Center](https://ghec.github.trust.page/) for clarity, but the [answer](https://copilot.github.trust.page/faq?s=v2qe7voltpwtv2usl4ikhs) is straightforward: “*No. GitHub uses neither Copilot Business nor Enterprise data to train the GitHub model.”*\n\nNotice this restriction also applies to [third-party models](https://copilot.github.trust.page/faq?s=qoerjag9v36a9muz82voo) as well (e.g. Anthropic, Google).\n\n##### **GitHub Copilot Intellectual Property indemnification policy**\n\nA frequent concern I hear is, since GitHub Copilot’s underlying models are trained on sources that include public code, it might simply “copy and paste” code from those sources. Let’s clarify how this actually works:\n\n[Does GitHub Copilot “copy/paste”?](https://copilot.github.trust.page/faq?s=kshrwbj4qvp0fw6r2t4kjv)\n\n*“The AI models that create Copilot’s suggestions may be trained on public code, but do not contain any code. When they generate a suggestion, they are not “copying and pasting” from any codebase.”*\n\nTo provide an additional layer of protection, GitHub Copilot includes a [“duplicate detection filter”](https://docs.github.com/en/copilot/how-tos/manage-your-account/manage-policies#enabling-or-disabling-suggestions-matching-public-code). This feature helps prevent suggestions that closely match public code from being surfaced. (Note: This duplicate detection currently does not apply to the Copilot coding agent.)\n\nMore importantly, customers are protected by an [Intellectual Property indemnification](https://blogs.microsoft.com/on-the-issues/2023/09/07/copilot-copyright-commitment-ai-legal-concerns/) policy. This means that if you receive an unmodified suggestion from GitHub Copilot and face a copyright claim as a result, Microsoft will defend you in court.\n\n##### **GitHub Copilot Data Retention**\n\nAnother frequent question I hear concerns GitHub Copilot’s [data retention policies](https://copilot.github.trust.page/faq?s=b9buqrq7o9ssfk3ta50x6). For organizations on GitHub Copilot Business and Enterprise plans, retention practices depend on how and where the service is accessed from:\n\n*Access through IDE for Chat and Code Completions:*\n\n- *Prompts and Suggestions: Not retained.*\n- *User Engagement Data: Kept for two years.*\n- *Feedback Data: Stored for as long as needed for its intended purpose.*\n\n*Other GitHub Copilot access and use:*\n\n- *Prompts and Suggestions: Retained for 28 days.*\n- *User Engagement Data: Kept for two years.*\n- *Feedback Data: Stored for as long as needed for its intended purpose.*\n\n*For Copilot Coding Agent, session logs are retained for the life of the account in order to provide the service.*\n\n##### **Excluding content from GitHub Copilot**\n\nTo prevent GitHub Copilot from indexing sensitive files, you can configure [content exclusions](https://docs.github.com/en/copilot/how-tos/configure-content-exclusion/exclude-content-from-copilot) at the repository or organization level. In VS Code, use the [.copilotignore](https://docs.github.com/en/copilot/how-tos/use-copilot-extensions/build-a-copilot-agent/use-context-passing#hidden-files) file to exclude files client-side. Note that files listed in *.gitignore* are not indexed by default but may still be referenced if open or explicitly referenced (unless they’re excluded through *.copilotignore* or content exclusions).\n\n##### **The life cycle of a GitHub Copilot code suggestion**\n\nHere are the key protections at each stage of the [life cycle](https://resources.github.com/learn/pathways/copilot/essentials/how-github-copilot-handles-data/) of a GitHub Copilot code suggestion:\n\n- In the IDE:\n- [Content exclusions](https://docs.github.com/en/copilot/how-tos/configure-content-exclusion/exclude-content-from-copilot) prevent files, folders, or patterns from being included.\n\n- GitHub proxy (pre-model safety):\n- Prompts go through a GitHub proxy hosted in Microsoft Azure for **pre-inference checks**: screening for *toxic or inappropriate language, relevance, and hacking attempts/jailbreak-style prompts* before reaching the model.\n\n- Model response:\n- With the [public code filter](https://docs.github.com/en/copilot/how-tos/manage-your-account/manage-policies#enabling-or-disabling-suggestions-matching-public-code) enabled, some suggestions are suppressed.\n- The [vulnerability protection](https://github.blog/ai-and-ml/github-copilot/github-copilot-now-has-a-better-ai-model-and-new-capabilities/#filtering-out-security-vulnerabilities-with-a-new-ai-system)feature blocks insecure coding patterns like hardcoded credentials or SQL injections in real time.\n\n![]()Diagram showing how the code editor connects to a proxy which connects to the GitHub Copilot LLM\n\n##### **Disable access to GitHub Copilot Free**\n\nDue to the varying policies associated with GitHub Copilot Free, it is crucial for organizations to ensure it is [disabled both in the IDE and on GitHub.com](https://docs.github.com/en/copilot/how-tos/manage-your-account/disable-copilot-free). Since not all IDEs currently offer a built-in option to disable Copilot Free, the most reliable method to prevent both accidental and intentional access is to implement firewall rule changes, as outlined in the [official documentation](https://docs.github.com/en/copilot/how-tos/administer-copilot/manage-for-enterprise/manage-access/manage-network-access#configuring-copilot-subscription-based-network-routing-for-your-enterprise-or-organization).\n\n##### **Agent Mode Allow List**\n\nAccidental file system deletion by Agentic AI assistants can happen. With GitHub Copilot agent mode, the \"[Terminal auto approve](https://code.visualstudio.com/updates/v1_104#_terminal-auto-approve)” setting in VS Code can be used to prevent this. This setting can be managed [centrally](https://code.visualstudio.com/docs/setup/enterprise#_centrally-manage-vs-code-settings) using a VS Code policy.\n\n##### **MCP registry**\n\nOrganizations often want to restrict access to allow only trusted MCP servers. GitHub now offers an [MCP registry feature](https://docs.github.com/en/copilot/how-tos/administer-copilot/configure-mcp-server-access#support-for-mcp-policies) for this purpose. This feature isn’t available in all IDEs and clients yet, but it's being developed.\n\n##### **Compliance Certifications**\n\nThe GitHub Copilot [Trust Center](https://copilot.github.trust.page/) page lists GitHub Copilot's broad compliance credentials, surpassing many competitors in financial, security, privacy, cloud, and industry coverage.\n\n- **SOC 1 Type 2**: Assurance over internal controls for financial reporting.\n- **SOC 2 Type 2**: In-depth report covering Security, Availability, Processing Integrity, Confidentiality, and Privacy over time.\n- **SOC 3**: General-use version of SOC 2 with broad executive-level assurance.\n- **ISO/IEC** **** **27001:2013**: Certification for a formal Information Security Management System (ISMS), based on risk management controls.\n- **CSA STAR Level 2**: Includes a third-party attestation combining ISO 27001 or SOC 2 with additional cloud control matrix (CCM) requirements.\n- **TISAX**: Trusted Information Security Assessment Exchange, covering automotive-sector security standards.\n\nIn **summary**, while the adoption of AI tools like GitHub Copilot in software development can raise important questions around security, privacy, and compliance, it’s clear that existing safeguards in place help address these concerns. By understanding the **safeguards, configurable controls, and robust compliance certifications** offered, organizations and developers alike can feel more confident in embracing GitHub Copilot to **accelerate innovation** while maintaining trust and peace of mind."
}
