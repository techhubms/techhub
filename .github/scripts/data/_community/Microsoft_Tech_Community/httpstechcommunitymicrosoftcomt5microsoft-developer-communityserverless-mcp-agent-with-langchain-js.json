{
  "EnhancedContent": "AI agents that can actually do stuff (not just chat) are the fun part nowadays, but wiring them cleanly into real APIs, keeping things observable, and shipping them to the cloud can get... messy. So we built a fresh end‚Äëto‚Äëend sample to show how to do it right with the brand new **LangChain.js v1** and **Model Context Protocol (MCP)**. In case you missed it, MCP is a recent open standard that makes it easy for LLM agents to consume tools and APIs, and LangChain.js, a great framework for building GenAI apps and agents, has first-class support for it.\n\nYou can quickly get up speed with the [MCP for Beginners](https://aka.ms/mcp-for-beginners) course and[AI Agents for Beginners](https://aka.ms/ai-agents-beginners) course.\n\nThis new sample gives you:\n\n- A LangChain.js v1 agent that streams its result, along reasoning + tool steps\n- An MCP server exposing real tools (burger menu + ordering) from a business API\n- A web interface with authentication, sessions history, and a debug panel (for developers)\n- A production-ready multi-service architecture\n- Serverless deployment on Azure in one command (`azd up`\n)\n\nGIF animation of the agent in action\n\nYes, it‚Äôs a burger ordering system. Who doesn't like burgers? Grab your favorite beverage ‚òï, and let‚Äôs dive in for a quick tour!\n\n## TL;DR key takeaways\n\n- New sample: full-stack Node.js AI agent using LangChain.js v1 + MCP tools\n- Architecture: web app ‚Üí agent API ‚Üí MCP server ‚Üí burger API\n- Runs locally with a single `npm start`\n, deploys with `azd up`\n- Uses streaming (NDJSON) with intermediate tool + LLM steps surfaced to the UI\n- Ready to fork, extend, and plug into your own domain / tools\n\n## What will you learn here?\n\n- What this sample is about and its high-level architecture\n- What LangChain.js v1 brings to the table for agents\n- How to deploy and run the sample\n- How MCP tools can expose real-world APIs\n\n## Reference links for everything we use\n\n- [GitHub repo](https://github.com/Azure-Samples/mcp-agent-langchainjs)\n- [LangChain.js docs](https://docs.langchain.com/oss/javascript/langchain/overview)\n- [Model Context Protocol](https://modelcontextprotocol.io)\n- [Azure Developer CLI](https://learn.microsoft.com/azure/developer/azure-developer-cli/)\n- [MCP Inspector](https://www.npmjs.com/package/@modelcontextprotocol/inspector)\n\n## Use case\n\nYou want an AI assistant that can take a natural language request like ‚ÄúOrder two spicy burgers and show me my pending orders‚Äù and:\n\n- Understand intent (query menu, then place order)\n- Call the right MCP tools in sequence, calling in turn the necessary APIs\n- Stream progress (LLM tokens + tool steps)\n- Return a clean final answer\n\nSwap ‚Äúburgers‚Äù for ‚Äúinventory‚Äù, ‚Äúbookings‚Äù, ‚Äúsupport tickets‚Äù, or ‚ÄúIoT devices‚Äù and you‚Äôve got a reusable pattern!\n\n## Sample overview\n\nBefore we play a bit with the sample, let's have a look at the main services implemented here:\n\n| Service | Role | Tech | | --- | --- | --- | | Agent Web App (`agent-webapp`<br>) | Chat UI + streaming + session history | Azure Static Web Apps, Lit web components | | Agent API (`agent-api`<br>) | LangChain.js v1 agent orchestration + auth + history | Azure Functions, Node.js | | Burger MCP Server (`burger-mcp`<br>) | Exposes burger API as tools over MCP (Streamable HTTP + SSE) | Azure Functions, Express, MCP SDK | | Burger API (`burger-api`<br>) | Business logic: burgers, toppings, orders lifecycle | Azure Functions, Cosmos DB |\n\nHere's a simplified view of how they interact:\n\nArchitecture diagram\n\nThere are also other supporting components like databases and storage not shown here for clarity.\n\nFor this quickstart we'll only interact with the **Agent Web App** and the **Burger MCP Server**, as they are the main stars of the show here.\n\n### LangChain.js v1 agent features\n\nThe recent release of LangChain.js v1 is a huge milestone for the JavaScript AI community! It marks a significant shift from experimental tools to a production-ready framework. The new version doubles down on what‚Äôs needed to build robust AI applications, with a strong focus on **agents**. This includes first-class support for streaming not just the final output, but also intermediate steps like tool calls and agent reasoning. This makes building transparent and interactive agent experiences (like the one in this sample) much more straightforward.\n\n## Quickstart\n\n### Requirements\n\n- [GitHub account](https://github.com/signup)\n- [Azure account](https://azure.microsoft.com/free) (free signup, or if you're a student, [get free credits here](https://azure.microsoft.com/free/students))\n- [Azure Developer CLI](https://learn.microsoft.com/azure/developer/azure-developer-cli/install-azd?tabs=winget-windows%2Cbrew-mac%2Cscript-linux&amp;pivots=os-windows)\n\n### Deploy and run the sample\n\nWe'll use GitHub Codespaces for a quick zero-install setup here, but if you prefer to run it locally, check the [README](https://github.com/Azure-Samples/mcp-agent-langchainjs?tab=readme-ov-file#getting-started).\n\nClick on the following link or open it in a new tab to launch a Codespace:\n\n- [Create Codespace](https://codespaces.new/Azure-Samples/mcp-agent-langchainjs?hide_repo_select=true&amp;ref=main&amp;quickstart=true)\n\nThis will open a VS Code environment in your browser with the repo already cloned and all the tools installed and ready to go.\n\n#### Provision and deploy to Azure\n\nOpen a terminal and run these commands:\n\n```\n# Install dependencies\nnpm install\n\n# Login to Azure\nazd auth login\n\n# Provision and deploy all resources\nazd up\n\n```\n\nFollow the prompts to select your Azure subscription and region. If you're unsure of which one to pick, choose `East US 2` . The deployment will take about 15 minutes the first time, to create all the necessary resources (Functions, Static Web Apps, Cosmos DB, AI Models).\n\nIf you're curious about what happens under the hood, you can take a look at the `main.bicep` file in the `infra` folder, which defines the infrastructure as code for this sample.\n\n### Test the MCP server\n\nWhile the deployment is running, you can run the MCP server and API locally (even in Codespaces) to see how it works. Open another terminal and run:\n\n``` npm start\n\n```\n\nThis will start all services locally, including the Burger API and the MCP server, which will be available at `http://localhost:3000/mcp` . This may take a few seconds, wait until you see this message in the terminal:\n\n``` üöÄ All services ready üöÄ\n\n```\n\nWhen these services are running without Azure resources provisioned, they will use in-memory data instead of Cosmos DB so you can experiment freely with the API and MCP server, though the agent won't be functional as it requires a LLM resource.\n\n#### MCP tools\n\nThe MCP server exposes the following tools, which the agent can use to interact with the burger ordering system:\n\n| Tool Name | Description | | --- | --- | | `get_burgers` | Get a list of all burgers in the menu | | `get_burger_by_id` | Get a specific burger by its ID | | `get_toppings` | Get a list of all toppings in the menu | | `get_topping_by_id` | Get a specific topping by its ID | | `get_topping_categories` | Get a list of all topping categories | | `get_orders` | Get a list of all orders in the system | | `get_order_by_id` | Get a specific order by its ID | | `place_order` | Place a new order with burgers (requires `userId`<br>, optional `nickname`<br>) | | `delete_order_by_id` | Cancel an order if it has not yet been started (status must be `pending`<br>, requires `userId`<br>) |\n\nYou can test these tools using the MCP Inspector. Open another terminal and run:\n\n``` npx -y @modelcontextprotocol/inspector\n\n```\n\nThen open the URL printed in the terminal in your browser and connect using these settings:\n\n- **Transport**: Streamable HTTP\n- **URL**: [http://localhost:3000/mcp](http://localhost:3000/mcp)\n- **Connection Type**: Via Proxy (should be default)\n\nClick on **Connect**, then try listing the tools first, and run `get_burgers` tool to get the menu info.\n\nMCP Inspector screenshort\n\n### Test the Agent Web App\n\nAfter the deployment is completed, you can run the command `npm run env` to print the URLs of the deployed services. Open the Agent Web App URL in your browser (it should look like `https://<your-web-app>.azurestaticapps.net` ).\n\nYou'll first be greeted by an authentication page, you can sign in either with your GitHub or Microsoft account and then you should be able to access the chat interface.\n\nAgent chat interface screenshot\n\nFrom there, you can start asking any question or use one of the suggested prompts, for example try asking: `Recommend me an extra spicy burger` .\n\nAs the agent processes your request, you'll see the response streaming in real-time, along with the intermediate steps and tool calls. Once the response is complete, you can also unfold the debug panel to see the full reasoning chain and the tools that were invoked:\n\nIntermediate steps shown in debug panel\n\n> >\n> **Tip:** Our agent service also sends detailed tracing data using OpenTelemetry. You can explore these either in Azure Monitor for the deployed service, or locally using an OpenTelemetry collector. We'll cover this in more detail in a future post.\n> >\n\n## Wrap it up\n\nCongratulations, you just finished spinning up a full-stack serverless AI agent using LangChain.js v1, MCP tools, and Azure‚Äôs serverless platform. Now it's your turn to dive in the code and extend it for your use cases! üòé And don't forget to `azd down` once you're done to avoid any unwanted costs.\n\n## Going further\n\nThis was just a quick introduction to this sample, and you can expect more in-depth posts and tutorials soon.\n\nSince we're in the era of AI agents, we've also made sure that this sample can be explored and extended easily with code agents like GitHub Copilot. We even built a custom chat mode to help you discover and understand the codebase faster! Check out the [Copilot setup guide](https://github.com/Azure-Samples/mcp-agent-langchainjs/blob/main/docs/copilot.md) in the repo to get started.¬†You can quickly get up speed with the [MCP for Beginners](https://aka.ms/mcp-for-beginners) course and[AI Agents for Beginners](https://aka.ms/ai-agents-beginners) course.\n\nIf you like this sample, don't forget to star the repo ‚≠êÔ∏è! You can also join us in the [Azure AI community Discord](https://aka.ms/foundry/discord) to chat and ask any questions.\n\nHappy coding and burger ordering! üçî\n\nUpdated Oct 22, 2025\n\nVersion 3.0\n\n[agents](/tag/agents?nodeId=board%3AAzureDevCommunityBlog)\n\n[ai](/tag/ai?nodeId=board%3AAzureDevCommunityBlog)\n\n[ai foundry](/tag/ai%20foundry?nodeId=board%3AAzureDevCommunityBlog)\n\n[azure](/tag/azure?nodeId=board%3AAzureDevCommunityBlog)\n\n[azure ai foundry](/tag/azure%20ai%20foundry?nodeId=board%3AAzureDevCommunityBlog)\n\n[cosmosdb](/tag/cosmosdb?nodeId=board%3AAzureDevCommunityBlog)\n\n[developer](/tag/developer?nodeId=board%3AAzureDevCommunityBlog)\n\n[functions](/tag/functions?nodeId=board%3AAzureDevCommunityBlog)\n\n[genai](/tag/genai?nodeId=board%3AAzureDevCommunityBlog)\n\n[javascript](/tag/javascript?nodeId=board%3AAzureDevCommunityBlog)\n\n[!\\[sinedied&#x27;s avatar\\](https://techcommunity.microsoft.com/t5/s/gxcuf89792/images/dS03MzczNDUtVzVOMUNO?image-coordinates=0%2C0%2C1024%2C1024&amp;image-dimensions=50x50)](/users/sinedied/737345) [sinedied](/users/sinedied/737345) ![Icon for Microsoft rank](https://techcommunity.microsoft.com/t5/s/gxcuf89792/images/cmstNC05WEo0blc?image-dimensions=100x16&amp;constrain-image=true)Microsoft\n\nJoined July 23, 2020\n\n[View Profile](/users/sinedied/737345)\n\n/category/azure/blog/azuredevcommunityblog [Microsoft Developer Community Blog](/category/azure/blog/azuredevcommunityblog) Follow this blog board to get notified when there's new activity",
  "Title": "Serverless MCP Agent with LangChain.js v1 ‚Äî Burgers, Tools, and Traces üçî",
  "FeedLevelAuthor": "rss.livelink.threads-in-node",
  "PubDate": "2025-10-22T07:29:14+00:00",
  "OutputDir": "_community",
  "Author": "sinedied",
  "ProcessedDate": "2025-10-22 08:05:37",
  "FeedUrl": "https://techcommunity.microsoft.com/t5/s/gxcuf89792/rss/Category?category.id=Azure",
  "Link": "https://techcommunity.microsoft.com/t5/microsoft-developer-community/serverless-mcp-agent-with-langchain-js-v1-burgers-tools-and/ba-p/4463157",
  "FeedName": "Microsoft Tech Community",
  "Description": "AI agents that can actually do stuff (not just chat) are the fun part nowadays, but wiring them cleanly into real APIs, keeping things observable, and shipping them to the cloud can get... messy. So we built a fresh end‚Äëto‚Äëend sample to show how to do it right with the brand new **LangChain.js v1** and **Model Context Protocol (MCP)**. In case you missed it, MCP is a recent open standard that makes it easy for LLM agents to consume tools and APIs, and LangChain.js, a great framework for building GenAI apps and agents, has first-class support for it.\n\nYou can quickly get up speed with the [MCP for Beginners](https://aka.ms/mcp-for-beginners) course and[AI Agents for Beginners](https://aka.ms/ai-agents-beginners) course.\n\nThis new sample gives you:\n\n- A LangChain.js v1 agent that streams its result, along reasoning + tool steps\n- An MCP server exposing real tools (burger menu + ordering) from a business API\n- A web interface with authentication, sessions history, and a debug panel (for developers)\n- A production-ready multi-service architecture\n- Serverless deployment on Azure in one command (`azd up`\n)\n\n![]()GIF animation of the agent in action\n\nYes, it‚Äôs a burger ordering system. Who doesn't like burgers? Grab your favorite beverage ‚òï, and let‚Äôs dive in for a quick tour!\n\n## TL;DR key takeaways\n\n- New sample: full-stack Node.js AI agent using LangChain.js v1 + MCP tools\n- Architecture: web app ‚Üí agent API ‚Üí MCP server ‚Üí burger API\n- Runs locally with a single `npm start`\n, deploys with `azd up`\n- Uses streaming (NDJSON) with intermediate tool + LLM steps surfaced to the UI\n- Ready to fork, extend, and plug into your own domain / tools\n\n## What will you learn here?\n\n- What this sample is about and its high-level architecture\n- What LangChain.js v1 brings to the table for agents\n- How to deploy and run the sample\n- How MCP tools can expose real-world APIs\n\n## Reference links for everything we use\n\n- [GitHub repo](https://github.com/Azure-Samples/mcp-agent-langchainjs)\n- [LangChain.js docs](https://docs.langchain.com/oss/javascript/langchain/overview)\n- [Model Context Protocol](https://modelcontextprotocol.io)\n- [Azure Developer CLI](https://learn.microsoft.com/azure/developer/azure-developer-cli/)\n- [MCP Inspector](https://www.npmjs.com/package/@modelcontextprotocol/inspector)\n\n## Use case\n\nYou want an AI assistant that can take a natural language request like ‚ÄúOrder two spicy burgers and show me my pending orders‚Äù and:\n\n- Understand intent (query menu, then place order)\n- Call the right MCP tools in sequence, calling in turn the necessary APIs\n- Stream progress (LLM tokens + tool steps)\n- Return a clean final answer\n\nSwap ‚Äúburgers‚Äù for ‚Äúinventory‚Äù, ‚Äúbookings‚Äù, ‚Äúsupport tickets‚Äù, or ‚ÄúIoT devices‚Äù and you‚Äôve got a reusable pattern!\n\n## Sample overview\n\nBefore we play a bit with the sample, let's have a look at the main services implemented here:\n\n| Service | Role | Tech | | --- | --- | --- | | Agent Web App (`agent-webapp`<br>) | Chat UI + streaming + session history | Azure Static Web Apps, Lit web components | | Agent API (`agent-api`<br>) | LangChain.js v1 agent orchestration + auth + history | Azure Functions, Node.js | | Burger MCP Server (`burger-mcp`<br>) | Exposes burger API as tools over MCP (Streamable HTTP + SSE) | Azure Functions, Express, MCP SDK | | Burger API (`burger-api`<br>) | Business logic: burgers, toppings, orders lifecycle | Azure Functions, Cosmos DB |\n\nHere's a simplified view of how they interact:\n\n![]()Architecture diagram\n\nThere are also other supporting components like databases and storage not shown here for clarity.\n\nFor this quickstart we'll only interact with the **Agent Web App** and the **Burger MCP Server**, as they are the main stars of the show here.\n\n### LangChain.js v1 agent features\n\nThe recent release of LangChain.js v1 is a huge milestone for the JavaScript AI community! It marks a significant shift from experimental tools to a production-ready framework. The new version doubles down on what‚Äôs needed to build robust AI applications, with a strong focus on **agents**. This includes first-class support for streaming not just the final output, but also intermediate steps like tool calls and agent reasoning. This makes building transparent and interactive agent experiences (like the one in this sample) much more straightforward.\n\n## Quickstart\n\n### Requirements\n\n- [GitHub account](https://github.com/signup)\n- [Azure account](https://azure.microsoft.com/free) (free signup, or if you're a student, [get free credits here](https://azure.microsoft.com/free/students))\n- [Azure Developer CLI](https://learn.microsoft.com/azure/developer/azure-developer-cli/install-azd?tabs=winget-windows%2Cbrew-mac%2Cscript-linux&pivots=os-windows)\n\n### Deploy and run the sample\n\nWe'll use GitHub Codespaces for a quick zero-install setup here, but if you prefer to run it locally, check the [README](https://github.com/Azure-Samples/mcp-agent-langchainjs?tab=readme-ov-file#getting-started).\n\nClick on the following link or open it in a new tab to launch a Codespace:\n\n- [Create Codespace](https://codespaces.new/Azure-Samples/mcp-agent-langchainjs?hide_repo_select=true&ref=main&quickstart=true)\n\nThis will open a VS Code environment in your browser with the repo already cloned and all the tools installed and ready to go.\n\n#### Provision and deploy to Azure\n\nOpen a terminal and run these commands:\n\n```\n# Install dependencies\nnpm install\n\n# Login to Azure\nazd auth login\n\n# Provision and deploy all resources\nazd up\n\n```\n\nFollow the prompts to select your Azure subscription and region. If you're unsure of which one to pick, choose `East US 2` . The deployment will take about 15 minutes the first time, to create all the necessary resources (Functions, Static Web Apps, Cosmos DB, AI Models).\n\nIf you're curious about what happens under the hood, you can take a look at the `main.bicep` file in the `infra` folder, which defines the infrastructure as code for this sample.\n\n### Test the MCP server\n\nWhile the deployment is running, you can run the MCP server and API locally (even in Codespaces) to see how it works. Open another terminal and run:\n\n``` npm start\n\n```\n\nThis will start all services locally, including the Burger API and the MCP server, which will be available at `http://localhost:3000/mcp` . This may take a few seconds, wait until you see this message in the terminal:\n\n``` üöÄ All services ready üöÄ\n\n```\n\nWhen these services are running without Azure resources provisioned, they will use in-memory data instead of Cosmos DB so you can experiment freely with the API and MCP server, though the agent won't be functional as it requires a LLM resource.\n\n#### MCP tools\n\nThe MCP server exposes the following tools, which the agent can use to interact with the burger ordering system:\n\n| Tool Name | Description | | --- | --- | | `get_burgers` | Get a list of all burgers in the menu | | `get_burger_by_id` | Get a specific burger by its ID | | `get_toppings` | Get a list of all toppings in the menu | | `get_topping_by_id` | Get a specific topping by its ID | | `get_topping_categories` | Get a list of all topping categories | | `get_orders` | Get a list of all orders in the system | | `get_order_by_id` | Get a specific order by its ID | | `place_order` | Place a new order with burgers (requires `userId`<br>, optional `nickname`<br>) | | `delete_order_by_id` | Cancel an order if it has not yet been started (status must be `pending`<br>, requires `userId`<br>) |\n\nYou can test these tools using the MCP Inspector. Open another terminal and run:\n\n``` npx -y @modelcontextprotocol/inspector\n\n```\n\nThen open the URL printed in the terminal in your browser and connect using these settings:\n\n- **Transport**: Streamable HTTP\n- **URL**: [http://localhost:3000/mcp](http://localhost:3000/mcp)\n- **Connection Type**: Via Proxy (should be default)\n\nClick on **Connect**, then try listing the tools first, and run `get_burgers` tool to get the menu info.\n\n![]()MCP Inspector screenshort\n\n### Test the Agent Web App\n\nAfter the deployment is completed, you can run the command `npm run env` to print the URLs of the deployed services. Open the Agent Web App URL in your browser (it should look like `https://.azurestaticapps.net` ).\n\nYou'll first be greeted by an authentication page, you can sign in either with your GitHub or Microsoft account and then you should be able to access the chat interface.\n\n![]()Agent chat interface screenshot\n\nFrom there, you can start asking any question or use one of the suggested prompts, for example try asking: `Recommend me an extra spicy burger` .\n\nAs the agent processes your request, you'll see the response streaming in real-time, along with the intermediate steps and tool calls. Once the response is complete, you can also unfold the debug panel to see the full reasoning chain and the tools that were invoked:\n\n![]()Intermediate steps shown in debug panel\n\n> >\n> **Tip:** Our agent service also sends detailed tracing data using OpenTelemetry. You can explore these either in Azure Monitor for the deployed service, or locally using an OpenTelemetry collector. We'll cover this in more detail in a future post.\n> >\n\n## Wrap it up\n\nCongratulations, you just finished spinning up a full-stack serverless AI agent using LangChain.js v1, MCP tools, and Azure‚Äôs serverless platform. Now it's your turn to dive in the code and extend it for your use cases! üòé And don't forget to `azd down` once you're done to avoid any unwanted costs.\n\n## Going further\n\nThis was just a quick introduction to this sample, and you can expect more in-depth posts and tutorials soon.\n\nSince we're in the era of AI agents, we've also made sure that this sample can be explored and extended easily with code agents like GitHub Copilot. We even built a custom chat mode to help you discover and understand the codebase faster! Check out the [Copilot setup guide](https://github.com/Azure-Samples/mcp-agent-langchainjs/blob/main/docs/copilot.md) in the repo to get started. You can quickly get up speed with the [MCP for Beginners](https://aka.ms/mcp-for-beginners) course and[AI Agents for Beginners](https://aka.ms/ai-agents-beginners) course.\n\nIf you like this sample, don't forget to star the repo ‚≠êÔ∏è! You can also join us in the [Azure AI community Discord](https://aka.ms/foundry/discord) to chat and ask any questions.\n\nHappy coding and burger ordering! üçî",
  "Tags": []
}
