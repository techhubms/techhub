{
  "FeedName": "Microsoft Tech Community",
  "FeedLevelAuthor": "rss.livelink.threads-in-node",
  "PubDate": "2025-11-27T08:00:00+00:00",
  "FeedUrl": "https://techcommunity.microsoft.com/t5/s/gxcuf89792/rss/Category?category.id=Azure",
  "Author": "riturajjana",
  "Link": "https://techcommunity.microsoft.com/t5/microsoft-developer-community/background-tasks-in-net/ba-p/4472341",
  "Description": "What is a **Background Task**?\n\nA **background task** (or **background service**) is work that runs *behind the scenes* in an application without blocking the main user flow and often without direct user interaction.\n\nThink of it as a *worker* or *helper* that performs tasks independently while the main app continues doing other things.\n\n**Problem Statement -** What do you do when your downstream API is flaky or sometimes down for hours or even days , yet your UI and main API must stay responsive? **Solution -** This is a very common architecture problem in enterprise systems, and .NET gives us excellent tools to solve it cleanly: **BackgroundService** and **exponential backoff retry logic**.\n\nIn this article, I’ll walk you through:\n\n- A real production-like use case\n- The architecture needed to make it reliable\n- Why exponential backoff matters\n- How to build a robust BackgroundService\n- A full working code example\n\n**The Use Case**\n\nYou have two APIs:\n\n- **API 1** : called frequently by the UI (hundreds or thousands of times).\n- **API 2** : a downstream system you *must* call, but it is known to be\n**unstable, slow, or completely offline for long periods**.\n\nIf API 1 directly calls API 2: \\* Users experience lag \\* API 1 becomes slow or unusable \\* You overload API 2 with retries \\* Calls fail when API 2 is offline \\* You lose data\n\n**What do we do then? Here goes the solutionThe Architecture**Instead of calling API 2 synchronously, API 1 simply **stores the intended call**, and returns immediately.\n\nA **BackgroundService** will later:\n\n1. Poll for pending jobs\n2. Call API 2\n3. Retry with exponential backoff if API 2 is still unavailable\n4. Mark jobs as completed when successful\n\nThis creates a resilient, smooth, non-blocking system.\n\n![]()\n\n**Why Exponential Backoff?**\n\nWhen a downstream API is completely offline, retrying every 1–5 seconds is disastrous:\n\n- It wastes CPU and bandwidth\n- It floods logs\n- It overloads API 2 when it comes back online\n- It burns resources\n\nExponential backoff solves this.\n\n**Examples retry delays:**\n\n- Retry 1 → 2 sec\nRetry 2 → 4 sec Retry 3 → 8 sec Retry 4 → 16 sec Retry 5 → 32 sec Retry 6 → 64 sec (Max delay capped at 5 minutes)\n\nThis gives the system room to breathe.\n\n**Complete Working Example (Using In-Memory Store)1. The Model** -\n- public class PendingJob {\npublic Guid Id { get; set; } = Guid.NewGuid(); public string Payload { get; set; } = string.Empty; public int RetryCount { get; set; } = 0; public DateTime NextRetryTime { get; set; } = DateTime.UtcNow; public bool Completed { get; set; } = false; }\n\n**2. The In-Memory Store**\n- public interface IPendingJobStore\n{ Task AddJobAsync(string payload); Task> GetExecutableJobsAsync(); Task MarkJobAsCompletedAsync(Guid jobId); Task UpdateJobAsync(PendingJob job); } public class InMemoryPendingJobStore : IPendingJobStore { private readonly List \\_jobs = new(); private readonly object \\_lock = new(); public Task AddJobAsync(string payload) { lock (\\_lock) { \\_jobs.Add(new PendingJob { Payload = payload, RetryCount = 0, NextRetryTime = DateTime.UtcNow }); } return Task.CompletedTask; } public Task> GetExecutableJobsAsync() { lock (\\_lock) { return Task.FromResult(\\_jobs.Where(j => !j.Completed && j.NextRetryTime j.Id == jobId); if (job != null) job.Completed = true; } return Task.CompletedTask; } public Task UpdateJobAsync(PendingJob job) => Task.CompletedTask; }\n\n**3. The BackgroundService with Exponential Backoff**\n- using System.Text;\npublic class Api2RetryService : BackgroundService { private readonly IHttpClientFactory \\_clientFactory; private readonly IPendingJobStore \\_store; private readonly ILogger \\_logger; public Api2RetryService(IHttpClientFactory clientFactory, IPendingJobStore store, ILogger logger) { \\_clientFactory = clientFactory; \\_store = store; \\_logger = logger; } protected override async Task ExecuteAsync(CancellationToken stoppingToken) { \\_logger.LogInformation(\"Background retry service started.\"); while (!stoppingToken.IsCancellationRequested) { var jobs = await \\_store.GetExecutableJobsAsync(); foreach (var job in jobs) { var client = \\_clientFactory.CreateClient(\"api2\"); try { var response = await client.PostAsync(\"/simulate\", new StringContent(job.Payload, Encoding.UTF8, \"application/json\"), stoppingToken); if (response.IsSuccessStatusCode) { \\_logger.LogInformation(\"Job {JobId} processed successfully.\", job.Id); await \\_store.MarkJobAsCompletedAsync(job.Id); } else { await HandleFailure(job); } } catch (Exception ex) { \\_logger.LogError(ex, \"Error calling API 2.\"); await HandleFailure(job); } } await Task.Delay(TimeSpan.FromSeconds(5), stoppingToken); } } private async Task HandleFailure(PendingJob job) { job.RetryCount++; var delay = CalculateBackoff(job.RetryCount); job.NextRetryTime = DateTime.UtcNow.Add(delay); await \\_store.UpdateJobAsync(job); \\_logger.LogWarning(\"Retrying job {JobId} in {Delay}. RetryCount={RetryCount}\", job.Id, delay, job.RetryCount); } private TimeSpan CalculateBackoff(int retryCount) { var seconds = Math.Pow(2, retryCount); var maxSeconds = TimeSpan.FromMinutes(5).TotalSeconds; return TimeSpan.FromSeconds(Math.Min(seconds, maxSeconds)); } }\n\n**4. The API 1 — Public Endpoint**\n- using System.Runtime.InteropServices;\nusing System.Text.Json; [ApiController] [Route(\"api1\")] public class Api1Controller : ControllerBase { private readonly IPendingJobStore \\_store; private readonly ILogger \\_logger; public Api1Controller(IPendingJobStore store, ILogger logger) { \\_store = store; \\_logger = logger; } [HttpPost(\"process\")] public async Task Process([FromBody] object data) { var payload = JsonSerializer.Serialize(data); await \\_store.AddJobAsync(payload); \\_logger.LogInformation(\"Stored job for background processing.\"); return Ok(\"Request received. Will process when API 2 recovers.\"); } }\n\n**5. The API 2 (Simulating Downtime)**\n- using System.Runtime.InteropServices;\n[ApiController][Route(\"api2\")] public class Api2Controller: ControllerBase { private static bool shouldFail = true; [HttpPost(\"simulate\")] public IActionResult Simulate([FromBody] object payload) { if (shouldFail) return StatusCode(503, \"API 2 is down\"); return Ok(\"API 2 processed payload\"); } [HttpPost(\"toggle\")] public IActionResult Toggle() { shouldFail = !shouldFail; return Ok($\"API 2 failure mode = {shouldFail}\"); } }\n\n**6. The Program.cs**\n- var builder = WebApplication.CreateBuilder(args);\nbuilder.Services.AddControllers(); builder.Services.AddSingleton(); builder.Services.AddHttpClient(\"api2\", c => { c.BaseAddress = new Uri(\"http://localhost:5000/api2\"); }); builder.Services.AddHostedService(); var app = builder.Build(); app.MapControllers(); app.Run();\n\n**Testing the Whole Flow** **#1** API 2 starts in failure mode All attempts will fail and exponential backoff kicks in. **#2** Send a request to API 1 POST /api1/process { \"name\": \"hello\" } Job is stored. **#3** Watch logs You’ll see: Retrying job in 2 seconds... Retrying job in 4 seconds... Retrying job in 8 seconds... ... **#4** Bring API 2 back online: POST /api2/toggle Next retry will succeed: Job {id} processed successfully.\n\n**Conclusion**\n\nThis pattern is extremely powerful for:\n\n- Payment gateways\n- ERP integrations\n- Long-running partner APIs\n- Unstable third-party services\n- Internal microservices that spike or go offline\n\nReferences\n\n- [Background tasks with hosted services in ASP.NET Core](https://learn.microsoft.com/en-us/aspnet/core/fundamentals/host/hosted-services?view=aspnetcore-10.0&amp;tabs=visual-studio)",
  "ProcessedDate": "2025-11-27 08:05:10",
  "Title": "Background tasks in .NET",
  "EnhancedContent": "## Building Reliable Background Processing in .NET\n\nWhat is a **Background Task**?\n\nA **background task** (or **background service**) is work that runs *behind the scenes* in an application without blocking the main user flow and often without direct user interaction.\n\nThink of it as a *worker* or *helper* that performs tasks independently while the main app continues doing other things.\n\n**Problem Statement -**What do you do when your downstream API is flaky or sometimes down for hours or even days , yet your UI and main API must stay responsive? **Solution -** This is a very common architecture problem in enterprise systems, and .NET gives us excellent tools to solve it cleanly: **BackgroundService** and **exponential backoff retry logic**.\n\nIn this article, I’ll walk you through:\n\n- A real production-like use case\n- The architecture needed to make it reliable\n- Why exponential backoff matters\n- How to build a robust BackgroundService\n- A full working code example\n\n**The Use Case**\n\nYou have two APIs:\n\n- **API 1** :  called frequently by the UI (hundreds or thousands of times).\n- **API 2** : a downstream system you *must* call, but it is known to be\n**unstable, slow, or completely offline for long periods**.\n\nIf API 1 directly calls API 2: \\*  Users experience lag \\*  API 1 becomes slow or unusable \\*  You overload API 2 with retries \\*  Calls fail when API 2 is offline \\*  You lose data\n\n**What do we do then? Here goes the solutionThe Architecture**Instead of calling API 2 synchronously, API 1 simply **stores the intended call**, and returns immediately.\n\nA **BackgroundService** will later:\n\n1. Poll for pending jobs\n2. Call API 2\n3. Retry with exponential backoff if API 2 is still unavailable\n4. Mark jobs as completed when successful\n\nThis creates a resilient, smooth, non-blocking system.\n\n**Why Exponential Backoff?**\n\nWhen a downstream API is completely offline, retrying every 1–5 seconds is disastrous:\n\n- It wastes CPU and bandwidth\n- It floods logs\n- It overloads API 2 when it comes back online\n- It burns resources\n\nExponential backoff solves this.\n\n**Examples retry delays:**\n\n``` Retry 1 → 2 secRetry 2 → 4 secRetry 3 → 8 sec Retry 4 → 16 sec Retry 5 → 32 sec Retry 6 → 64 sec (Max delay capped at 5 minutes) ```\n\nThis gives the system room to breathe.\n\n**Complete Working Example (Using In-Memory Store)1. The Model**\n\n``` public class PendingJob { public Guid Id { get; set; } = Guid.NewGuid(); public string Payload { get; set; } = string.Empty; public int RetryCount { get; set; } = 0; public DateTime NextRetryTime { get; set; } = DateTime.UtcNow; public bool Completed { get; set; } = false; }\n\n```\n\n**2. The In-Memory Store**\n\n``` public interface IPendingJobStore { Task AddJobAsync(string payload); Task<List<PendingJob>> GetExecutableJobsAsync(); Task MarkJobAsCompletedAsync(Guid jobId); Task UpdateJobAsync(PendingJob job); } public class InMemoryPendingJobStore : IPendingJobStore { private readonly List<PendingJob> _jobs = new(); private readonly object _lock = new(); public Task AddJobAsync(string payload) { lock (_lock) { _jobs.Add(new PendingJob { Payload = payload, RetryCount = 0, NextRetryTime = DateTime.UtcNow }); } return Task.CompletedTask; } public Task<List<PendingJob>> GetExecutableJobsAsync() { lock (_lock) { return Task.FromResult(_jobs.Where(j => !j.Completed && j.NextRetryTime <= DateTime.UtcNow).ToList()); } } public Task MarkJobAsCompletedAsync(Guid jobId) { lock (_lock) { var job = _jobs.FirstOrDefault(j => j.Id == jobId); if (job != null) job.Completed = true; } return Task.CompletedTask; } public Task UpdateJobAsync(PendingJob job) => Task.CompletedTask; } ```\n\n**3. The BackgroundService with Exponential Backoff**\n\n``` using System.Text; public class Api2RetryService : BackgroundService { private readonly IHttpClientFactory _clientFactory; private readonly IPendingJobStore _store; private readonly ILogger<Api2RetryService> _logger; public Api2RetryService(IHttpClientFactory clientFactory, IPendingJobStore store, ILogger<Api2RetryService> logger) { _clientFactory = clientFactory; _store = store; _logger = logger; } protected override async Task ExecuteAsync(CancellationToken stoppingToken) { _logger.LogInformation(\"Background retry service started.\"); while (!stoppingToken.IsCancellationRequested) { var jobs = await _store.GetExecutableJobsAsync(); foreach (var job in jobs) { var client = _clientFactory.CreateClient(\"api2\"); try { var response = await client.PostAsync(\"/simulate\", new StringContent(job.Payload, Encoding.UTF8, \"application/json\"), stoppingToken); if (response.IsSuccessStatusCode) { _logger.LogInformation(\"Job {JobId} processed successfully.\", job.Id); await _store.MarkJobAsCompletedAsync(job.Id); } else { await HandleFailure(job); } } catch (Exception ex) { _logger.LogError(ex, \"Error calling API 2.\"); await HandleFailure(job); } } await Task.Delay(TimeSpan.FromSeconds(5), stoppingToken); } } private async Task HandleFailure(PendingJob job) { job.RetryCount++; var delay = CalculateBackoff(job.RetryCount); job.NextRetryTime = DateTime.UtcNow.Add(delay); await _store.UpdateJobAsync(job); _logger.LogWarning(\"Retrying job {JobId} in {Delay}. RetryCount={RetryCount}\", job.Id, delay, job.RetryCount); } private TimeSpan CalculateBackoff(int retryCount) { var seconds = Math.Pow(2, retryCount); var maxSeconds = TimeSpan.FromMinutes(5).TotalSeconds; return TimeSpan.FromSeconds(Math.Min(seconds, maxSeconds)); } } ```\n\n**4. The API 1 — Public Endpoint**\n\n``` using System.Runtime.InteropServices; using System.Text.Json; [ApiController] [Route(\"api1\")] public class Api1Controller : ControllerBase { private readonly IPendingJobStore _store; private readonly ILogger<Api1Controller> _logger; public Api1Controller(IPendingJobStore store, ILogger<Api1Controller> logger) { _store = store; _logger = logger; } [HttpPost(\"process\")] public async Task<IActionResult> Process([FromBody] object data) { var payload = JsonSerializer.Serialize(data); await _store.AddJobAsync(payload); _logger.LogInformation(\"Stored job for background processing.\"); return Ok(\"Request received. Will process when API 2 recovers.\"); } } ```\n\n**5. The API 2 (Simulating Downtime)**\n\n``` using System.Runtime.InteropServices; [ApiController][Route(\"api2\")] public class Api2Controller: ControllerBase { private static bool shouldFail = true; [HttpPost(\"simulate\")] public IActionResult Simulate([FromBody] object payload) { if (shouldFail) return StatusCode(503, \"API 2 is down\"); return Ok(\"API 2 processed payload\"); } [HttpPost(\"toggle\")] public IActionResult Toggle() { shouldFail = !shouldFail; return Ok($\"API 2 failure mode = {shouldFail}\"); } } ```\n\n**6. The Program.cs**\n\n``` var builder = WebApplication.CreateBuilder(args); builder.Services.AddControllers(); builder.Services.AddSingleton<IPendingJobStore, InMemoryPendingJobStore>(); builder.Services.AddHttpClient(\"api2\", c => { c.BaseAddress = new Uri(\"http://localhost:5000/api2\"); }); builder.Services.AddHostedService<Api2RetryService>(); var app = builder.Build(); app.MapControllers(); app.Run(); ```\n\n**Testing the Whole Flow** **#1** API 2 starts in failure mode All attempts will fail and exponential backoff kicks in. **#2** Send a request to API 1 POST /api1/process { \"name\": \"hello\" } Job is stored. **#3** Watch logs You’ll see: Retrying job in 2 seconds... Retrying job in 4 seconds... Retrying job in 8 seconds... ... **#4** Bring API 2 back online: POST /api2/toggle Next retry will succeed: Job {id} processed successfully.\n\n**Conclusion**\n\nThis pattern is extremely powerful for:\n\n- Payment gateways\n- ERP integrations\n- Long-running partner APIs\n- Unstable third-party services\n- Internal microservices that spike or go offline\n\nReferences\n\n- [Background tasks with hosted services in ASP.NET Core](https://learn.microsoft.com/en-us/aspnet/core/fundamentals/host/hosted-services?view=aspnetcore-10.0&amp;amp;tabs=visual-studio)\n\nUpdated Nov 25, 2025\n\nVersion 1.0\n\n[.net](/tag/.net?nodeId=board%3AAzureDevCommunityBlog)\n\n[azure](/tag/azure?nodeId=board%3AAzureDevCommunityBlog)\n\n[developer](/tag/developer?nodeId=board%3AAzureDevCommunityBlog)\n\n[software architecture](/tag/software%20architecture?nodeId=board%3AAzureDevCommunityBlog)\n\n[!\\[riturajjana&#x27;s avatar\\](https://techcommunity.microsoft.com/t5/s/gxcuf89792/images/dS0zMjQwMTQ3LUhqQ29PNQ?image-coordinates=0%2C69%2C662%2C731&amp;image-dimensions=50x50)](/users/riturajjana/3240147) [riturajjana](/users/riturajjana/3240147) ![Icon for Microsoft rank](https://techcommunity.microsoft.com/t5/s/gxcuf89792/images/cmstNC05WEo0blc?image-dimensions=100x16&amp;constrain-image=true)Microsoft\n\nJoined October 24, 2025\n\n[View Profile](/users/riturajjana/3240147)\n\n/category/azure/blog/azuredevcommunityblog [Microsoft Developer Community Blog](/category/azure/blog/azuredevcommunityblog) Follow this blog board to get notified when there's new activity",
  "OutputDir": "_community",
  "Tags": []
}
