{
  "Author": "kyleknapp",
  "Link": "https://techcommunity.microsoft.com/t5/microsoft-developer-community/introducing-langchain-azure-storage-azure-storage-integrations/ba-p/4465268",
  "OutputDir": "_community",
  "EnhancedContent": "We're excited to introduce [`langchain-azure-storage`](https://pypi.org/project/langchain-azure-storage/), the first official [Azure Storage](https://learn.microsoft.com/en-us/azure/storage/common/storage-introduction) integration package built by Microsoft for [LangChain](https://docs.langchain.com/oss/python/langchain/overview) 1.0. As part of its launch, we've built a new [Azure Blob Storage document loader](https://docs.langchain.com/oss/python/integrations/document_loaders/azure_blob_storage) (currently in public preview) that improves upon prior [LangChain community](https://github.com/langchain-ai/langchain-community) implementations. This new loader unifies both blob and container level access, simplifying loader integration. More importantly, it offers enhanced security through default OAuth 2.0 authentication, supports reliably loading millions to billions of documents through efficient memory utilization, and allows pluggable parsing, so you can leverage other document loaders to parse specific file formats.\n\n## What are LangChain document loaders?\n\nA typical [Retrieval‑Augmented Generation (RAG)](https://docs.langchain.com/oss/python/langchain/rag#build-a-rag-agent-with-langchain) pipeline follows these main steps:\n\n1. Collect source content (PDFs, DOCX, Markdown, CSVs) — often stored in Azure Blob Storage.\n2. Parse into text and associated metadata (i.e., represented as LangChain [`Document`](https://reference.langchain.com/python/langchain_core/documents/#langchain_core.documents.base.Document) objects).\n3. Chunk + embed those documents and store in a vector store (e.g., Azure AI Search, Postgres pgvector, etc.).\n4. At query time, retrieve the most relevant chunks and feed them to an LLM as grounded context.\n\n[LangChain document loaders](https://docs.langchain.com/oss/python/integrations/document_loaders) make steps 1–2 turnkey and consistent so the rest of the stack (splitters, vector stores, retrievers) “just works”. See this [LangChain RAG tutorial](https://docs.langchain.com/oss/python/langchain/rag#build-a-rag-agent-with-langchain) for a full example of these steps when building a RAG application in LangChain.\n\n## How can the Azure Blob Storage document loader help?\n\nThe `langchain-azure-storage` package offers the [`AzureBlobStorageLoader`](https://reference.langchain.com/python/integrations/langchain_azure/storage), a document loader that simplifies retrieving documents stored in Azure Blob Storage for use in a LangChain RAG application. Key benefits of the `AzureBlobStorageLoader` include:\n\n- Flexible loading of Azure Storage blobs to LangChain `Document`\nobjects. You can load blobs as documents from an entire container, a specific prefix within a container, or by blob names. Each document loaded corresponds 1:1 to a blob in the container.\n- Lazy loading support for improved memory efficiency when dealing with large document sets. Documents can now be loaded one-at-a-time as you iterate over them instead of all at once.\n- Automatically uses [`DefaultAzureCredential`](https://learn.microsoft.com/en-us/azure/developer/python/sdk/authentication/credential-chains?tabs=dac#defaultazurecredential-overview) to enable seamless OAuth 2.0 authentication across various environments, from local development to Azure-hosted services. You can also explicitly pass your own credential (e.g., [`ManagedIdentityCredential`](https://learn.microsoft.com/en-us/python/api/azure-identity/azure.identity.managedidentitycredential?view=azure-python), [SAS](https://learn.microsoft.com/en-us/azure/storage/common/storage-sas-overview) token).\n- Pluggable parsing. Easily customize how documents are parsed by providing your own LangChain document loader to parse downloaded blob content.\n\n## Using the Azure Blob Storage document loader\n\n### Installation\n\nTo install the `langchain-azure-storage` package, run:\n\n``` pip install langchain-azure-storage\n\n```\n\n### Loading documents from a container\n\nTo load all blobs from an Azure Blob Storage container as LangChain [`Document`](https://reference.langchain.com/python/langchain_core/documents/#langchain_core.documents.base.Document) objects, instantiate the [`AzureBlobStorageLoader`](https://reference.langchain.com/python/integrations/langchain_azure/storage) with the Azure Storage account URL and container name:\n\n``` from langchain_azure_storage.document_loaders import AzureBlobStorageLoader\n\nloader = AzureBlobStorageLoader( \"https://<your-storage-account>.blob.core.windows.net/\", \"<your-container-name>\" )\n\n# lazy_load() yields one Document per blob for all blobs in the container\nfor doc in loader.lazy_load(): print(doc.metadata[\"source\"]) # The \"source\" metadata contains the full URL of the blob print(doc.page_content) # The page_content contains the blob's content decoded as UTF-8 text ```\n\n### Loading documents by blob names\n\nTo only load specific blobs as LangChain `Document` objects, you can additionally provide a list of blob names:\n\n``` from langchain_azure_storage.document_loaders import AzureBlobStorageLoader\n\nloader = AzureBlobStorageLoader( \"https://<your-storage-account>.blob.core.windows.net/\", \"<your-container-name>\", [\"<blob-name-1>\", \"<blob-name-2>\"] )\n\n# lazy_load() yields one Document per blob for only the specified blobs\nfor doc in loader.lazy_load(): print(doc.metadata[\"source\"]) # The \"source\" metadata contains the full URL of the blob print(doc.page_content) # The page_content contains the blob's content decoded as UTF-8 text ```\n\n### Pluggable parsing\n\nBy default, loaded `Document` objects contain the blob's UTF-8 decoded content. To parse non-UTF-8 content (e.g., PDFs, DOCX, etc.) or chunk blob content into smaller documents, provide a LangChain document loader via the `loader_factory` parameter.\n\nWhen `loader_factory` is provided, the `AzureBlobStorageLoader` processes each blob with the following steps:\n\n1. Downloads the blob to a new temporary file\n2. Passes the temporary file path to the `loader_factory`\ncallable to instantiate a document loader\n3. Uses that loader to parse the file and yield [`Document`](https://reference.langchain.com/python/langchain_core/documents/#langchain_core.documents.base.Document) objects\n4. Cleans up the temporary file\n\nFor example, below shows parsing PDF documents with the [`PyPDFLoader`](https://docs.langchain.com/oss/python/integrations/document_loaders/pypdfloader) from the [`langchain-community`](https://github.com/langchain-ai/langchain-community) package:\n\n``` from langchain_azure_storage.document_loaders import AzureBlobStorageLoader from langchain_community.document_loaders import PyPDFLoader # Requires langchain-community and pypdf packages\n\nloader = AzureBlobStorageLoader( \"https://<your-storage-account>.blob.core.windows.net/\", \"<your-container-name>\", prefix=\"pdfs/\", # Only load blobs that start with \"pdfs/\" loader_factory=PyPDFLoader # PyPDFLoader will parse each blob as a PDF )\n\n# Each blob is downloaded to a temporary file and parsed by PyPDFLoader instance\nfor doc in loader.lazy_load(): print(doc.page_content) # Content parsed by PyPDFLoader (yields one Document per page in the PDF) ```\n\nThis file path-based interface allows you to use any [LangChain document loader](https://docs.langchain.com/oss/python/integrations/document_loaders) that accepts a local file path as input, giving you access to a wide range of parsers for different file formats.\n\n## Migrating from community document loaders to `langchain-azure-storage`\n\nIf you're currently using [`AzureBlobStorageContainerLoader`](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.azure_blob_storage_container.AzureBlobStorageContainerLoader.html) or [`AzureBlobStorageFileLoader`](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.azure_blob_storage_file.AzureBlobStorageFileLoader.html) from the [`langchain-community`](https://github.com/langchain-ai/langchain-community) package, the new [`AzureBlobStorageLoader`](https://reference.langchain.com/python/integrations/langchain_azure/storage) provides an improved alternative. This section provides step-by-step guidance for migrating to the new loader.\n\n### Steps to migrate\n\nTo migrate to the new Azure Storage document loader, make the following changes:\n\n1. Depend on the `langchain-azure-storage`\npackage\n2. Update import statements from `langchain_community.document_loaders`\nto `langchain_azure_storage.document_loaders` .\n3. Change class names from `AzureBlobStorageFileLoader`\nand `AzureBlobStorageContainerLoader` to `AzureBlobStorageLoader` .\n4. Update document loader constructor calls to:\n1. Use an account URL instead of a connection string.\n2. Specify `UnstructuredLoader`\nas the `loader_factory` to continue to use [Unstructured](https://pypi.org/project/unstructured/) for parsing documents.\n5. Enable Microsoft Entra ID authentication in environment (e.g., run `az login`\nor configure managed identity) instead of using connection string authentication.\n\n### Migration samples\n\nBelow shows code snippets of what usage patterns look like before and after migrating from `langchain-community` to `langchain-azure-storage` :\n\n#### Before migration\n\n``` from langchain_community.document_loaders import AzureBlobStorageContainerLoader, AzureBlobStorageFileLoader\n\ncontainer_loader = AzureBlobStorageContainerLoader( \"DefaultEndpointsProtocol=https;AccountName=<account>;AccountKey=<account-key>;EndpointSuffix=core.windows.net\", \"<container>\", )\n\nfile_loader = AzureBlobStorageFileLoader( \"DefaultEndpointsProtocol=https;AccountName=<account>;AccountKey=<account-key>;EndpointSuffix=core.windows.net\", \"<container>\", \"<blob>\" ) ```\n\n#### After migration\n\n``` from langchain_azure_storage.document_loaders import AzureBlobStorageLoader from langchain_unstructured import UnstructuredLoader # Requires langchain-unstructured and unstructured packages\n\ncontainer_loader = AzureBlobStorageLoader( \"https://<account>.blob.core.windows.net\", \"<container>\", loader_factory=UnstructuredLoader # Only needed if continuing to use Unstructured for parsing )\n\nfile_loader = AzureBlobStorageLoader( \"https://<account>.blob.core.windows.net\", \"<container>\", \"<blob>\", loader_factory=UnstructuredLoader # Only needed if continuing to use Unstructured for parsing ) ```\n\n## What's next?\n\nWe're excited for you to try the new Azure Blob Storage document loader and would love to hear your feedback! Here are some ways you can help shape the future of `langchain-azure-storage` :\n\n- **Show support for interface stabilization** - The document loader is currently in public preview and the interface may change in future versions based on feedback. If you'd like to see the current interface marked as stable, [upvote the proposal PR](https://github.com/langchain-ai/langchain-azure/pull/148) to show your support.\n- **Report issues or suggest improvements** - Found a bug or have an idea to make the document loaders better? [File an issue](https://github.com/langchain-ai/langchain-azure/issues/new) on our GitHub repository.\n- **Propose new LangChain integrations** - Interested in other ways to use Azure Storage with LangChain (e.g., checkpointing for agents, persistent memory stores, retriever implementations)? [Create a feature request](https://github.com/langchain-ai/langchain-azure/issues/new) or [write to us](mailto:AzureStorageFeedback@microsoft.com) to let us know.\n\nYour input is invaluable in making `langchain-azure-storage` better for the entire community!\n\n## Resources\n\n- `langchain-azure`\n[GitHub repository](https://github.com/langchain-ai/langchain-azure)\n- `langchain-azure-storage`\n[PyPI package](https://pypi.org/project/langchain-azure-storage/)\n- `AzureBlobStorageLoader`\n[usage guide](https://docs.langchain.com/oss/python/integrations/document_loaders/azure_blob_storage)\n- `AzureBlobStorageLoader`\n[documentation reference](https://reference.langchain.com/python/integrations/langchain_azure/storage)\n\nUpdated Oct 29, 2025\n\nVersion 1.0\n\n[ai](/tag/ai?nodeId=board%3AAzureDevCommunityBlog)\n\n[azure](/tag/azure?nodeId=board%3AAzureDevCommunityBlog)\n\n[llm](/tag/llm?nodeId=board%3AAzureDevCommunityBlog)\n\n[python](/tag/python?nodeId=board%3AAzureDevCommunityBlog)\n\n[rag](/tag/rag?nodeId=board%3AAzureDevCommunityBlog)\n\n[!\\[kyleknapp&#x27;s avatar\\](https://techcommunity.microsoft.com/t5/s/gxcuf89792/images/dS0zMjQ1MjI0LXRtVHBscg?image-coordinates=0%2C0%2C241%2C241&amp;image-dimensions=50x50)](/users/kyleknapp/3245224) [kyleknapp](/users/kyleknapp/3245224) ![Icon for Microsoft rank](https://techcommunity.microsoft.com/t5/s/gxcuf89792/images/cmstNC05WEo0blc?image-dimensions=100x16&amp;constrain-image=true)Microsoft\n\nJoined October 28, 2025\n\n[View Profile](/users/kyleknapp/3245224)\n\n/category/azure/blog/azuredevcommunityblog [Microsoft Developer Community Blog](/category/azure/blog/azuredevcommunityblog) Follow this blog board to get notified when there's new activity",
  "FeedLevelAuthor": "rss.livelink.threads-in-node",
  "FeedUrl": "https://techcommunity.microsoft.com/t5/s/gxcuf89792/rss/Category?category.id=Azure",
  "Tags": [],
  "FeedName": "Microsoft Tech Community",
  "ProcessedDate": "2025-10-30 16:04:27",
  "Title": "Introducing langchain-azure-storage: Azure Storage integrations for LangChain",
  "Description": "We're excited to introduce [`langchain-azure-storage`](https://pypi.org/project/langchain-azure-storage/), the first official [Azure Storage](https://learn.microsoft.com/en-us/azure/storage/common/storage-introduction) integration package built by Microsoft for [LangChain](https://docs.langchain.com/oss/python/langchain/overview) 1.0. As part of its launch, we've built a new [Azure Blob Storage document loader](https://docs.langchain.com/oss/python/integrations/document_loaders/azure_blob_storage) (currently in public preview) that improves upon prior [LangChain community](https://github.com/langchain-ai/langchain-community) implementations. This new loader unifies both blob and container level access, simplifying loader integration. More importantly, it offers enhanced security through default OAuth 2.0 authentication, supports reliably loading millions to billions of documents through efficient memory utilization, and allows pluggable parsing, so you can leverage other document loaders to parse specific file formats.\n\n## What are LangChain document loaders?\n\nA typical [Retrieval‑Augmented Generation (RAG)](https://docs.langchain.com/oss/python/langchain/rag#build-a-rag-agent-with-langchain) pipeline follows these main steps:\n\n1. Collect source content (PDFs, DOCX, Markdown, CSVs) — often stored in Azure Blob Storage.\n2. Parse into text and associated metadata (i.e., represented as LangChain [`Document`](https://reference.langchain.com/python/langchain_core/documents/#langchain_core.documents.base.Document) objects).\n3. Chunk + embed those documents and store in a vector store (e.g., Azure AI Search, Postgres pgvector, etc.).\n4. At query time, retrieve the most relevant chunks and feed them to an LLM as grounded context.\n\n[LangChain document loaders](https://docs.langchain.com/oss/python/integrations/document_loaders) make steps 1–2 turnkey and consistent so the rest of the stack (splitters, vector stores, retrievers) “just works”. See this [LangChain RAG tutorial](https://docs.langchain.com/oss/python/langchain/rag#build-a-rag-agent-with-langchain) for a full example of these steps when building a RAG application in LangChain.\n\n## How can the Azure Blob Storage document loader help?\n\nThe `langchain-azure-storage` package offers the [`AzureBlobStorageLoader`](https://reference.langchain.com/python/integrations/langchain_azure/storage), a document loader that simplifies retrieving documents stored in Azure Blob Storage for use in a LangChain RAG application. Key benefits of the `AzureBlobStorageLoader` include:\n\n- Flexible loading of Azure Storage blobs to LangChain `Document`\nobjects. You can load blobs as documents from an entire container, a specific prefix within a container, or by blob names. Each document loaded corresponds 1:1 to a blob in the container.\n- Lazy loading support for improved memory efficiency when dealing with large document sets. Documents can now be loaded one-at-a-time as you iterate over them instead of all at once.\n- Automatically uses [`DefaultAzureCredential`](https://learn.microsoft.com/en-us/azure/developer/python/sdk/authentication/credential-chains?tabs=dac#defaultazurecredential-overview) to enable seamless OAuth 2.0 authentication across various environments, from local development to Azure-hosted services. You can also explicitly pass your own credential (e.g., [`ManagedIdentityCredential`](https://learn.microsoft.com/en-us/python/api/azure-identity/azure.identity.managedidentitycredential?view=azure-python), [SAS](https://learn.microsoft.com/en-us/azure/storage/common/storage-sas-overview) token).\n- Pluggable parsing. Easily customize how documents are parsed by providing your own LangChain document loader to parse downloaded blob content.\n\n## Using the Azure Blob Storage document loader\n\n### Installation\n\nTo install the `langchain-azure-storage` package, run:\n\n- pip install langchain-azure-storage\n\n### Loading documents from a container\n\nTo load all blobs from an Azure Blob Storage container as LangChain [`Document`](https://reference.langchain.com/python/langchain_core/documents/#langchain_core.documents.base.Document) objects, instantiate the [`AzureBlobStorageLoader`](https://reference.langchain.com/python/integrations/langchain_azure/storage) with the Azure Storage account URL and container name:\n- from langchain\\_azure\\_storage.document\\_loaders import AzureBlobStorageLoader\n\nloader = AzureBlobStorageLoader( \"https://.blob.core.windows.net/\", \"\" )\n\n# lazy\\_load() yields one Document per blob for all blobs in the container\nfor doc in loader.lazy\\_load(): print(doc.metadata[\"source\"]) # The \"source\" metadata contains the full URL of the blob print(doc.page\\_content) # The page\\_content contains the blob's content decoded as UTF-8 text\n\n### Loading documents by blob names\n\nTo only load specific blobs as LangChain `Document` objects, you can additionally provide a list of blob names:\n- from langchain\\_azure\\_storage.document\\_loaders import AzureBlobStorageLoader\n\nloader = AzureBlobStorageLoader( \"https://.blob.core.windows.net/\", \"\", [\"\", \"\"] )\n\n# lazy\\_load() yields one Document per blob for only the specified blobs\nfor doc in loader.lazy\\_load(): print(doc.metadata[\"source\"]) # The \"source\" metadata contains the full URL of the blob print(doc.page\\_content) # The page\\_content contains the blob's content decoded as UTF-8 text\n\n### Pluggable parsing\n\nBy default, loaded `Document` objects contain the blob's UTF-8 decoded content. To parse non-UTF-8 content (e.g., PDFs, DOCX, etc.) or chunk blob content into smaller documents, provide a LangChain document loader via the `loader_factory` parameter.\n\nWhen `loader_factory` is provided, the `AzureBlobStorageLoader` processes each blob with the following steps:\n\n1. Downloads the blob to a new temporary file\n2. Passes the temporary file path to the `loader_factory`\ncallable to instantiate a document loader\n3. Uses that loader to parse the file and yield [`Document`](https://reference.langchain.com/python/langchain_core/documents/#langchain_core.documents.base.Document) objects\n4. Cleans up the temporary file\n\nFor example, below shows parsing PDF documents with the [`PyPDFLoader`](https://docs.langchain.com/oss/python/integrations/document_loaders/pypdfloader) from the [`langchain-community`](https://github.com/langchain-ai/langchain-community) package:\n- from langchain\\_azure\\_storage.document\\_loaders import AzureBlobStorageLoader\nfrom langchain\\_community.document\\_loaders import PyPDFLoader # Requires langchain-community and pypdf packages\n\nloader = AzureBlobStorageLoader( \"https://.blob.core.windows.net/\", \"\", prefix=\"pdfs/\", # Only load blobs that start with \"pdfs/\" loader\\_factory=PyPDFLoader # PyPDFLoader will parse each blob as a PDF )\n\n# Each blob is downloaded to a temporary file and parsed by PyPDFLoader instance\nfor doc in loader.lazy\\_load(): print(doc.page\\_content) # Content parsed by PyPDFLoader (yields one Document per page in the PDF)\n\nThis file path-based interface allows you to use any [LangChain document loader](https://docs.langchain.com/oss/python/integrations/document_loaders) that accepts a local file path as input, giving you access to a wide range of parsers for different file formats.\n\n## Migrating from community document loaders to `langchain-azure-storage`\n\nIf you're currently using [`AzureBlobStorageContainerLoader`](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.azure_blob_storage_container.AzureBlobStorageContainerLoader.html) or [`AzureBlobStorageFileLoader`](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.azure_blob_storage_file.AzureBlobStorageFileLoader.html) from the [`langchain-community`](https://github.com/langchain-ai/langchain-community) package, the new [`AzureBlobStorageLoader`](https://reference.langchain.com/python/integrations/langchain_azure/storage) provides an improved alternative. This section provides step-by-step guidance for migrating to the new loader.\n\n### Steps to migrate\n\nTo migrate to the new Azure Storage document loader, make the following changes:\n\n1. Depend on the `langchain-azure-storage`\npackage\n2. Update import statements from `langchain_community.document_loaders`\nto `langchain_azure_storage.document_loaders` .\n3. Change class names from `AzureBlobStorageFileLoader`\nand `AzureBlobStorageContainerLoader` to `AzureBlobStorageLoader` .\n4. Update document loader constructor calls to:\n1. Use an account URL instead of a connection string.\n2. Specify `UnstructuredLoader`\nas the `loader_factory` to continue to use [Unstructured](https://pypi.org/project/unstructured/) for parsing documents.\n5. Enable Microsoft Entra ID authentication in environment (e.g., run `az login`\nor configure managed identity) instead of using connection string authentication.\n\n### Migration samples\n\nBelow shows code snippets of what usage patterns look like before and after migrating from `langchain-community` to `langchain-azure-storage` :\n\n#### Before migration\n- from langchain\\_community.document\\_loaders import AzureBlobStorageContainerLoader, AzureBlobStorageFileLoader\n\ncontainer\\_loader = AzureBlobStorageContainerLoader( \"DefaultEndpointsProtocol=https;AccountName=;AccountKey=;EndpointSuffix=core.windows.net\", \"\", )\n\nfile\\_loader = AzureBlobStorageFileLoader( \"DefaultEndpointsProtocol=https;AccountName=;AccountKey=;EndpointSuffix=core.windows.net\", \"\", \"\" )\n\n#### After migration\n- from langchain\\_azure\\_storage.document\\_loaders import AzureBlobStorageLoader\nfrom langchain\\_unstructured import UnstructuredLoader # Requires langchain-unstructured and unstructured packages\n\ncontainer\\_loader = AzureBlobStorageLoader( \"https://.blob.core.windows.net\", \"\", loader\\_factory=UnstructuredLoader # Only needed if continuing to use Unstructured for parsing )\n\nfile\\_loader = AzureBlobStorageLoader( \"https://.blob.core.windows.net\", \"\", \"\", loader\\_factory=UnstructuredLoader # Only needed if continuing to use Unstructured for parsing )\n\n## What's next?\n\nWe're excited for you to try the new Azure Blob Storage document loader and would love to hear your feedback! Here are some ways you can help shape the future of `langchain-azure-storage` :\n\n- **Show support for interface stabilization** - The document loader is currently in public preview and the interface may change in future versions based on feedback. If you'd like to see the current interface marked as stable, [upvote the proposal PR](https://github.com/langchain-ai/langchain-azure/pull/148) to show your support.\n- **Report issues or suggest improvements** - Found a bug or have an idea to make the document loaders better? [File an issue](https://github.com/langchain-ai/langchain-azure/issues/new) on our GitHub repository.\n- **Propose new LangChain integrations** - Interested in other ways to use Azure Storage with LangChain (e.g., checkpointing for agents, persistent memory stores, retriever implementations)? [Create a feature request](https://github.com/langchain-ai/langchain-azure/issues/new) or [write to us](mailto:AzureStorageFeedback@microsoft.com) to let us know.\n\nYour input is invaluable in making `langchain-azure-storage` better for the entire community!\n\n## Resources\n\n- `langchain-azure`\n[GitHub repository](https://github.com/langchain-ai/langchain-azure)\n- `langchain-azure-storage`\n[PyPI package](https://pypi.org/project/langchain-azure-storage/)\n- `AzureBlobStorageLoader`\n[usage guide](https://docs.langchain.com/oss/python/integrations/document_loaders/azure_blob_storage)\n- `AzureBlobStorageLoader`\n[documentation reference](https://reference.langchain.com/python/integrations/langchain_azure/storage)",
  "PubDate": "2025-10-30T16:00:00+00:00"
}
