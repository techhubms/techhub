{
  "Tags": [
    "AI & ML",
    "generative AI",
    "GitHub Copilot",
    "MCP",
    "Model Context Protocol",
    "Rubber Duck Thursdays"
  ],
  "Link": "https://github.blog/ai-and-ml/github-copilot/building-smarter-interactions-with-mcp-elicitation-from-clunky-tool-calls-to-seamless-user-experiences/",
  "OutputDir": "_news",
  "FeedUrl": "https://github.blog/feed/",
  "FeedName": "The GitHub Blog",
  "EnhancedContent": "When we build software, we‚Äôre not just shipping features. We‚Äôre shipping experiences that surprise and delight our users ‚Äî and making sure that we‚Äôre providing natural and seamless experiences is a core part of what we do.\n\nIn my last post, I [wrote about an MCP server that we started building for a turn-based-game](https://github.blog/ai-and-ml/github-copilot/building-your-first-mcp-server-how-to-extend-ai-tools-with-custom-capabilities?utm_campaign=rdt-blog-devrel&amp;utm_source=blog&amp;utm_medium=turnbased-mcp-blog-1) (like tic-tac-toe, or rock, paper, scissors). While it had the core capabilities, like tool calls, resources, and prompts, the experience could still be improved. For example, the player always took the first move, the player could only change the difficulty if they specified in their initial message, and a slew of other papercuts.\n\nSo on my most recent **Rubber Duck Thursdays** stream, I covered a feature that‚Äôs helped improve the user experience: **elicitation**.¬†*See the full stream below üëá*\n\nElicitation is kind of like saying, ‚Äúif we don‚Äôt have all the information we need, let‚Äôs go and get it.‚Äù But it‚Äôs more than that. It‚Äôs about creating intuitive interactions where the AI (via the MCP server) can pause, ask for what it needs, and then continue with the task. No more default assumptions that provide hard-coded paths of interaction.\n\nüëÄ **Be aware:** Elicitation is not supported by all AI application hosts. GitHub Copilot in Visual Studio Code supports it, but you‚Äôll want to check the latest state [from the MCP docs for other AI apps](https://modelcontextprotocol.io/clients#feature-support-matrix). Elicitation is a relative newcomer to the MCP spec, [having been added in the June 2025 revision](https://modelcontextprotocol.io/specification/2025-06-18/client/elicitation), and so the design may continue to evolve.\n\nLet me walk you through how I implemented elicitation in¬†[my turn-based game MCP server](https://gh.io/rdt-blog/game-mcp)¬†and the challenges I encountered along the way.\n\n## Enter elicitation: Making AI interactions feel natural\n\nBefore we reached the livestream, I had put together a basic implementation of elicitation, which asked for required information when creating a new game, like difficulty and player name. For tic-tac-toe, it asks which player goes first. For rock, paper, scissors, it asked how many rounds to play.\n\nBut rather than completely replacing our existing tools, I implemented these as new tools, so we could clearly see the behavior between the two approaches until we tested and standardized the approach. As a result, we began to see sprawl in the server with some duplicative tools:\n\n- `create-tic-tac-toe-game`\nand `create-tic-tac-toe-game-interactive`\n- `create-rock-paper-scissors-game`\nand `create-rock-paper-scissors-game-interactive`\n- `play-tic-tac-toe`\nand `play-rock-paper-scissors`\n\nThe problem? When you give AI agents like Copilot tools with similar names and descriptions, it doesn‚Äôt know which one to pick. On several occasions, Copilot chose the wrong tool because I had created this confusing landscape of overlapping functionality. This was an unexpected learning experience, but an important one to pick up along the way.\n\nThe next logical step was to consolidate our tool calls, and make sure we‚Äôre using DRY (don‚Äôt repeat yourself) principles throughout the codebase instead of redefining constants and having nearly identical implementations for different game types.\n\nAfter a lot of refactoring and consolidation, when someone prompts ‚Äúlet‚Äôs play a game of tic-tac-toe,‚Äù the tool call identifies that more information is needed to ensure the user has made an explicit choice, rather than creating a game with a pre-determined set of defaults.\n\n![A screenshot of GitHub Copilot Chat in Visual Studio Code where the user has asked &quot;Let's play a game of tictactoe&quot;. Copilot has triggered the elicitation experience, requesting additional preferences to customize the experience.](https://github.blog/wp-content/uploads/2025/09/image1.png?resize=1024%2C576)\n\nThe user provides their preferences, and the server creates the game based upon those, improving that overall user experience.\n\nIt‚Äôs worth adding that my code (like I‚Äôm sure many of us would admit?) is far from perfect, and I noticed a bug live on the stream. The elicitation step triggered for **every** invocation of the tool, regardless of whether the user had already provided the needed information.\n\nAs part of my rework after the livestream, I added some checks after the tool was invoked to determine what information had already been provided. I also aligned the property names between the tool and elicitation schemas, bringing a bit more clarity. So if you said ‚ÄúLet‚Äôs play a game of tic-tac-toe, I‚Äôll go first,‚Äù you would be asked to confirm the game difficulty and to provide your name.\n\n## How my elicitation implementation now works under the hood\n\nThe magic happens in the MCP server implementation. As part of my [up-to-date implementation](https://gh.io/rdt-blog/game-mcp), when the MCP server invokes the `create_game` tool, it:\n\n1. [**Checks for required parameters**](https://github.com/github-samples/turn-based-game-mcp/blob/fe1d54d960ad99e2d6c9574fce8c5211301753a1/mcp-server/src/handlers/tool-handlers.ts#L167): Do we know which game the user wants to play, or did they specify an ID?\n2. [**Passes the optional identified arguments to a separate method**](https://github.com/github-samples/turn-based-game-mcp/blob/fe1d54d960ad99e2d6c9574fce8c5211301753a1/mcp-server/src/handlers/tool-handlers.ts#L175): Are we missing difficulty, player name, or turn order?\n3. [**Initiates elicitation**](https://github.com/github-samples/turn-based-game-mcp/blob/fe1d54d960ad99e2d6c9574fce8c5211301753a1/mcp-server/src/handlers/tool-handlers.ts#L191-L234): If information is missing, it pauses the tool execution and gathers only the missing information from the user. This was an addition that I made after the stream to further improve the user experience.\n4. [**Presents schema-driven prompts**](https://github.com/github-samples/turn-based-game-mcp/blob/fe1d54d960ad99e2d6c9574fce8c5211301753a1/mcp-server/src/handlers/elicitation-handlers.ts#L16): The user sees formatted questions for each missing parameter.\n5. **Collects responses**: The MCP client (VS Code in this case) handles the UI interaction.\n6. [**Completes the original request**](https://github.com/github-samples/turn-based-game-mcp/blob/fe1d54d960ad99e2d6c9574fce8c5211301753a1/mcp-server/src/handlers/tool-handlers.ts#L237): Once the server collects all the information, the tool executes the createGame method with the user‚Äôs preferences.\n\nHere‚Äôs what you see in the VS Code interface when elicitation kicks in, and you must provide some preferences:\n\n![A screenshot of GitHub Copilot Chat in Visual Studio Code where a new UI modal appears, prompting the user for their preferences. This example shows the user selecting the Difficulty as hard.](https://github.blog/wp-content/uploads/2025/09/image2.png?resize=1024%2C576)\n\nThe result? Instead of ‚ÄúPlayer vs AI (Medium)‚Äù, I get ‚ÄúChris vs AI (Hard)‚Äù with the AI making the opening move because I chose to go second.\n\n## What I learned while implementing elicitation\n\n### Challenge 1: Tool naming confusion\n\n**Problem:** Tools with similar names and descriptions confuse the AI about which one to use.\n\n**Solution:** Where it‚Äôs appropriate, merge tools and use clear, distinct names and descriptions. I went from eight tools down to four:\n\n- `create-game`\n(handles all game types with elicitation)\n- `play-game`\n(unified play interface)\n- `analyze-game`\n(game state analysis)\n- `wait-for-player-move`\n(turn management)\n\n### Challenge 2: Handling partial information\n\n**Problem:** What if the user provides some information upfront? (‚ÄúLet‚Äôs play tic-tac-toe on hard mode‚Äù)\n\n**Observation:** During the livestream, we saw that the way I built elicitation asked for all of the preferences each time it was invoked, which is not an ideal user experience.\n\n**Solution:** Parse the initial request and only elicit the missing information. This was fixed after the livestream, and is now [in the latest version of the sample](https://gh.io/rdt-blog/game-mcp).\n\n## Key lessons from this development session\n\n### 1. User experience is still a consideration with MCP servers\n\nHow often do you provide all the needed information straight up? Elicitation provides this capability, but you need to consider how this is included as part of your tool calling and overall MCP experience. It can add complexity, but is it better to ask users for their preferences than force them to work around poor defaults?\n\n### 2. Tool naming matters more than you think\n\nWhen building (and even using) tools in MCP servers, naming and descriptions are critical. Ambiguous tool names and similar descriptions can lead to unpredictable behavior, where the ‚Äúwrong‚Äù tool is called.\n\n### 3. Iterative development wins\n\nRather than trying to build the perfect implementation upfront, I iterated to:\n\n- Build basic functionality first\n- Identify pain points through usage\n- Add elicitation to improve the user experience\n- Use Copilot coding agent and Copilot agent mode to help cleanup\n\n## Try it yourself\n\nWant to see how elicitation works in an MCP server? Or seeking inspiration to build¬† your own MCP server?\n\n1. **Fork the repository:** [gh.io/rdt-blog/game-mcp](https://gh.io/rdt/game-mcp)\n2. **Set up your dev environment** by creating a GitHub Codespace\n3. **Run the sample** by building the code, starting the MCP server and running the web app / API server.\n\n## Take this with you\n\nBuilding better AI tools isn‚Äôt all about the underlying models ‚Äî it‚Äôs about creating experiences that can interpret context, ask good questions, and deliver exactly what users need. Elicitation is a step in that direction, and I‚Äôm excited to see how the MCP ecosystem continues to evolve and support even richer interactions.\n\nJoin us for the next [Rubber Duck Thursdays stream](https://gh.io/rubberduckthursdays) where we‚Äôll continue exploring the intersection of AI tools and developer experience.\n\n[**Get the guide**](https://github.blog/ai-and-ml/github-copilot/building-your-first-mcp-server-how-to-extend-ai-tools-with-custom-capabilities?utm_campaign=rdt-blog-devrel&amp;utm_source=blog&amp;utm_medium=turnbased-mcp-blog-1) to build your first MCP server &gt;",
  "Description": "Explore how MCP elicitation transforms AI tool interactions by gathering missing information upfront.\n\nThe post [Building smarter interactions with MCP elicitation: From clunky tool calls to seamless user experiences](https://github.blog/ai-and-ml/github-copilot/building-smarter-interactions-with-mcp-elicitation-from-clunky-tool-calls-to-seamless-user-experiences/) appeared first on [The GitHub Blog](https://github.blog).",
  "Title": "Building smarter interactions with MCP elicitation: From clunky tool calls to seamless user experiences",
  "FeedLevelAuthor": "The GitHub Blog",
  "Author": "Chris Reddington",
  "ProcessedDate": "2025-09-04 16:14:09",
  "PubDate": "2025-09-04T16:00:00+00:00"
}
