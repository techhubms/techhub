{
  "EnhancedContent": "![Three white icons on a blue-to-purple gradient background: the first icon shows a node cluster, the second shows a person in front of a screen with another person, the third is a magnifying glass](https://www.microsoft.com/en-us/research/wp-content/uploads/2025/10/PIKERAG-BlogHeroFeature-1400x788-1.jpg)\n\nAs a world leader in connected LED lighting products, systems, and services, Signify (formerly Philips Lighting) serves not only everyday consumers but also a large number of professional users who have stringent requirements for technical specifications and engineering compatibility. Faced with thousands of product models, complex component parameters, and technical documentation spanning multiple versions, delivering accurate, professional answers efficiently has become a core challenge for Signify’s knowledge management system.\n\nTo address this challenge, [Signify (opens in new tab)](https://www.signify.com) collaborated with [Microsoft Research Asia](https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/) on a proof-of-concept (PoC) using [PIKE-RAG technology](https://www.microsoft.com/en-us/research/publication/pike-rag-specialized-knowledge-and-rationale-augmented-generation/), integrating it into their upgraded knowledge management system built on Microsoft Azure. The result: a 12% improvement in answer accuracy.\n\n## Challenges of applying RAG in lighting\n\nIn an era where AI is rapidly transforming how enterprises manage information, Signify recognized the strategic importance of precise and efficient knowledge systems. It adopted large AI models and retrieval-augmented generation (RAG) techniques to better support its wide range of customer inquiries.\n\nPODCAST SERIES\n\n[!\\[Illustrated headshots of Daniel Carpenter, Timo Minssen, Chad Atalla, and Kathleen Sullivan for the Microsoft Research Podcast\\](https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP2-AI-TE_Hero_Feature_River_No_Text_1400x788.jpg)](https://www.microsoft.com/en-us/research/story/ai-testing-and-evaluation-learnings-from-science-and-industry/)\n\n## AI Testing and Evaluation: Learnings from Science and Industry\n\nDiscover how Microsoft is learning from other domains to advance evaluation and testing as a pillar of AI governance.\n\n[Listen now](https://www.microsoft.com/en-us/research/story/ai-testing-and-evaluation-learnings-from-science-and-industry/)\n\nOpens in a new tab\n\nYet applying RAG to lighting scenarios involving professional users presented unique challenges. Product data spanned multimodal documents, unstructured tables, and complex product parameters, demanding continuous customization that slowed development and limited scalability. Despite improvements through keyword tuning, system optimization, and refined prompts, Signify sought more advanced approaches to further raise accuracy and reliability.\n\nSeeking to unlock greater value from its knowledge management system, Signify began exploring more suitable technical solutions that are better aligned with their professional use cases. Upon learning that PIKE-RAG had been successfully applied in domains like healthcare and law, significantly improving information accuracy, Signify worked with Microsoft Research Asia on a PoC of PIKE-RAG on Microsoft Azure.\n\n## How PIKE-RAG addressed Signify’s pain points\n\nCompared to traditional RAG, PIKE-RAG efficiently retrieves textual information and also understands multimodal content like charts and tables. Its built-in domain adaptation module quickly learns reasoning patterns aligned with specific domains to generate responses that are consistent with engineering contexts. These differentiated advantages stem from PIKE-RAG’s unique approach to understanding and processing professional knowledge. In Signify’s use case, this manifests in three key areas:\n\n### Multimodal document parsing and learning of industry-specific reasoning patterns\n\nSignify’s product documentation includes diverse formats, such as nonstandard tables (e.g., comparison charts of voltage ranges under different currents) and circuit diagrams (e.g., driver power limits). Traditional systems often fail to process this information effectively—either ignoring it or extracting disorganized text fragments.\n\nPIKE-RAG integrates Microsoft Research Asia’s Document Intelligence technology with Microsoft Azure OpenAI models to accurately identify table structures and parse key parameters in circuit diagrams. For example, when a customer service agent queries, “What is the output voltage of a specific driver model at 0.15A current,” the system automatically locates the curve chart in the document and infers a range of 40–54V based on the current interval—an area where traditional systems frequently err, due to their inability to “read” diagrams.\n\n### End-to-end knowledge loop, eliminating reliance on erroneous data sources\n\nEnterprise knowledge systems often integrate data from multiple sources, which can lead to discrepancies, especially when database updates are not fully synchronized. PIKE-RAG captures diverse information sources and establishes citation relationships, supporting complex reasoning tasks that rely on multi-source data.\n\nIn other words, PIKE-RAG can directly use original documents as data sources, efficiently parsing and understanding product manuals and PDF charts. By extracting key information from these text- and graphic-rich documents, PIKE-RAG enables more efficient and trustworthy knowledge retrieval.\n\n### Dynamic task decomposition and multi-hop reasoning for precise answers to complex questions\n\nTraditional RAG systems typically follow a “one question, one answer” model and struggle with multi-step reasoning. In Signify’s lighting domain, customer inquiries often involve multi-level associations. PIKE-RAG dynamically decomposes user questions into executable subtasks and solves them through multi-hop reasoning. For example, when asked, “List all bases compatible with the G8 series lamps,” if no document directly provides the answer, PIKE-RAG’s reasoning proceeds as follows:\n\nStep 1: The system identifies implicit knowledge. One document notes that the G7 and G8 series have identical dimensions and that all bases compatible with the G7 series are also compatible with the G8 series.\n\nStep 2: Based on this, the system retrieves the base list for the G7 series.\n\nStep 3: Since the list uses abbreviations, the system searches for a table that maps abbreviations to full names and generates a complete list of G8-compatible bases.\n\nThrough this automated multi-hop reasoning, the system delivers accurate and complete answers.\n\n![Figure 1: A flowchart illustrating the PIKE-RAG framework for orchestrating and integrating heterogeneous information across multi-source and multimodal environments. At the center is a language model (LM) connected to PIKE-RAG, which performs iterative retrieval by tool calling. The process starts with a task (e.g., “What wireless drivers are available?”), followed by iterative task decomposition and retrieval from a tools repository. The tools repository includes similarity and keyword retrieval, Text2SQL, decomposers, VLMs, verifiers, and atomizers. Below, domain knowledge is shown in various forms: textual (terminology, specifications), multi-modal (figures, tables), structural (databases, knowledge graphs), and others (search engine, internal FAQ). The LM generates responses and updates memory while fetching context as needed.](https://www.microsoft.com/en-us/research/wp-content/uploads/2025/10/PIKERAG_figure-1-new.png)Figure 1: PIKE-RAG orchestrates and integrates heterogeneous information in multi-source and multimodal environments.\n\nTesting showed that the PIKE-RAG-powered knowledge management platform provided a significant advantage. It achieved a 12% improvement in performance compared with the original system.\n\nThese results were achieved without any question-specific customization, only algorithmic optimization, demonstrating precise knowledge matching and generation. As the system continues to learn and integrate Signify’s proprietary knowledge, accuracy is expected to improve further.\n\n“In the PoC for our product specification insight tool, PIKE-RAG helped us significantly improve the original system’s performance. This will enhance overall customer satisfaction. We’re currently evaluating PIKE-RAG’s application path from multiple angles, including technical implementation, cost control, and future adaptability, and we look forward to deepening our collaboration with Microsoft Research Asia to drive further innovation,” said Haitao Liu, head of Signify Research China.\n\n“It’s also worth noting that the researchers at Microsoft Research Asia demonstrated strong industry knowledge and rigorous scientific methodology. They proactively studied and analyzed the issues, tracing and clarifying the root causes of our issues to make PIKE-RAG better suited to Signify’s real-world needs.”\n\n## Beyond lighting: Generalization across industries\n\nIn Signify’s successful test, PIKE-RAG demonstrated strong generalization capabilities in complex industrial scenarios, enabling rapid cross-domain adaptation. Its three core strengths are:\n\n- **Support for self-evolution and continuous learning**: PIKE-RAG continuously analyzes error cases in interaction logs and uses evolutionary algorithms to automatically optimize knowledge extraction strategies, such as trying different table parsing methods or adjusting multimodal content weights. Validated strategies are then solidified for future Q&A, allowing the system to adapt to new knowledge types without manual intervention.\n- **Modular architecture driven by capability needs**: PIKE-RAG flexibly combines modules for document parsing, knowledge extraction, storage, retrieval, organization, knowledge-centered reasoning, and task decomposition. It dynamically adjusts focus areas based on scenario needs (e.g., fact retrieval, multi-hop reasoning, innovative generation) and flexibly builds RAG methods that adapt to real-world applications, efficiently handling various complex tasks.\n- **Strong adaptation to domain-specific reasoning patterns**: With dynamic updates through the Domain Tips feature, enterprises can add domain-specific logic (e.g., “the maximum output voltage of an LED driver should be the maximum of the operating range, not the spec sheet’s max output”) in real time, enabling the system to process information according to professional engineering standards and follow industry conventions.\n\n![Figure 2: Diagram showing the PIKE-RAG framework overview. At the center is a language model (LM) connected to PIKE-RAG, which performs iterative retrieval by tool calling. The process begins with a task input, decomposes it into sub-tasks, retrieves information from a tools repository, and integrates domain knowledge from multiple modalities such as textual documents, diagrams, tables, relational databases, and knowledge graphs. The LM generates responses and updates memory while orchestrating heterogeneous information sources.](https://www.microsoft.com/en-us/research/wp-content/uploads/2025/10/PIKERAG_figure-2.png)Figure 2: Overview of the PIKE-RAG framework\n\nPIKE-RAG’s generalization capabilities have been validated not only in Signify’s knowledge management platform but also in pilot applications across industries like manufacturing, mining, and pharmaceuticals—significantly improving Q&A system accuracy.\n\n“A leader in lighting, Signify presents a complex industrial knowledge system with a highly challenging real-world scenario for PIKE-RAG. Through this collaboration, we validated that PIKE-RAG’s general approach can greatly improve the accuracy of professional knowledge Q&A and accelerate scenario customization. Our researchers also gained valuable experience in handling domain-specific data,” explained [Jiang Bian](https://www.microsoft.com/en-us/research/people/jiabia/), partner research manager at Microsoft Research Asia.\n\n“Our goal isn’t to build a universal chatbot but to create a professional assistant that aligns with domain-specific logic and performs rigorous knowledge reasoning. That’s the true driving force behind intelligent transformation in industrial knowledge management.”\n\nOpens in a new tab",
  "Tags": [
    "Company News",
    "Technology"
  ],
  "FeedName": "Microsoft News",
  "FeedLevelAuthor": "Source",
  "OutputDir": "_news",
  "Link": "https://www.microsoft.com/en-us/research/blog/when-industry-knowledge-meets-pike-rag-the-innovation-behind-signifys-customer-service-boost/",
  "Title": "Illuminating results: Signify and Microsoft Research boost customer service, answer accuracy",
  "PubDate": "2025-11-06T17:14:37+00:00",
  "Description": "The post [Illuminating results: Signify and Microsoft Research boost customer service, answer accuracy](https://www.microsoft.com/en-us/research/blog/when-industry-knowledge-meets-pike-rag-the-innovation-behind-signifys-customer-service-boost/) appeared first on [Source](https://news.microsoft.com/source).",
  "ProcessedDate": "2025-11-06 18:03:33",
  "Author": "stclarke",
  "FeedUrl": "https://news.microsoft.com/source/feed/"
}
