{
  "OutputDir": "_news",
  "ProcessedDate": "2025-11-12 18:04:34",
  "FeedLevelAuthor": "Source",
  "Title": "AI and the next generation: New research, policy recommendations and the AI Futures Youth Council",
  "FeedUrl": "https://news.microsoft.com/source/feed/",
  "PubDate": "2025-11-12T17:28:19+00:00",
  "Description": "The post [AI and the next generation: New research, policy recommendations and the AI Futures Youth Council](https://blogs.microsoft.com/on-the-issues/2025/11/12/uplifting-and-empowering-young-people-for-an-ai-future/) appeared first on [Source](https://news.microsoft.com/source).",
  "FeedName": "Microsoft News",
  "Tags": [
    "Company News",
    "On the issues"
  ],
  "Link": "https://blogs.microsoft.com/on-the-issues/2025/11/12/uplifting-and-empowering-young-people-for-an-ai-future/",
  "Author": "stclarke",
  "EnhancedContent": "![child looking at a computer](https://blogs.microsoft.com/wp-content/uploads/sites/5/2025/11/FY26_OML_PA_Child_online_safety_and_age_assurance_blog-_Header_2.png)\n\nToday, I had the pleasure of joining a range of leaders for timely, impactful discussions on child well-being in the age of AI at the Vatican, building on thoughtful conversations held during the United Nations General Assembly. These issues are top of mind globally, from parents to policymakers to physicians.\n\nAt Microsoft, we remain focused on our goal of empowering young people to use technology safely, mindfully, and in pursuit of social, educational, and economic opportunities. That means taking new steps spurred by regulation, such as [new](https://news.xbox.com/en-us/2025/07/28/xbox-age-verification-uk/) age verification measures for our UK Xbox users, as well as adapting our longstanding commitments to responsible AI and child online safety and privacy to build trust in the AI era. Today, we’re sharing new research on youth perspectives, announcing the AI Futures Youth Council to amplify teen voices, and offering policy recommendations to help families navigate the digital world with confidence.\n\n**Centering young people’s voices: Announcing the AI Futures Youth Council and new age assurance research**\n\nIn 2017, Microsoft led the industry with our first Council for Digital Good—a forum where we could hear directly from young people about their experiences and perceptions of online risk. In 2025, with AI reshaping our world—and their future—we again need to center the voices of young people as we think about responsible design for AI and how we set students up for the future. We are actively working with teens from the Asia-Pacific region to develop our first “for teens, by teens” guide to AI chatbots. Today, I’m pleased to announce the upcoming launch of our first “AI Futures Youth Council,” bringing together teens from the US and Europe to have their say on their future. We’ll share more about the application process soon.\n\nWe know that a critical precursor to providing young people positive and productive online experiences is understanding *which* users are young people. Around the globe, the debate over how to achieve age assurance online continues unabated. We have been grateful to work with CIPL and the WeProtect Global Alliance over the last year to explore how to achieve improved age assurance that is consistent with fundamental rights of privacy and access to information. As with any other safety intervention, our goal is to be proportionate and thoughtful where we take new steps, which is why we have focused on gaming in the first instance—reflecting the responsibilities we have to our youngest users and our ongoing commitment to player safety.\n\nTo inform our strategy and the broader policy conversation, we partnered with Praesidio Safeguarding to better understand youth perspectives on age assurance approaches across the UK, Ghana, and Indonesia. We are pleased to share [that research today.](https://blogs.microsoft.com/wp-content/uploads/sites/5/2025/11/Microsoft-Age-Assurance-Report-Accessible.pdf) The findings reinforce the importance of transparency, choice, and trust: teens want clear explanations of how their data is used, express concerns about exclusion where formal proof of age is lacking and show varying comfort levels with the use of biometric and behavioral data. Notably, young people value parental involvement but also highlight the need for independence and privacy as they mature. The results also highlight some of the important differences across geographies. For example, teenagers in Ghana often not only share devices with their families but may also share an account—underscoring a need for nuanced global approaches at multiple layers of the technology stack.\n\nThese insights underscore our belief that proportionality—matching safeguards to actual risks—is essential to building trust and empowering youth online. They also highlight the need for age assurance models that are inclusive, flexible, and respectful of youth autonomy—especially in global contexts where device and account sharing are common. We remain committed to ongoing dialogue and innovation, ensuring that our solutions evolve alongside the needs and expectations of children, families, and society at large.\n\n**Our policy recommendations: Empower young people to use technology safely**\n\nWe believe technology should empower young people, not put them at risk. Given the diverse range of online services, it is important to remember there is no single “digital seatbelt” to protect and empower young people online.\n\nWe therefore offer the following recommendations as policymakers, regulators, and experts continue to discuss these issues, building on our 2024 [blog](https://blogs.microsoft.com/on-the-issues/2024/01/16/youth-online-safety-ai-safer-internet/):\n\n- **Avoid blanket access restrictions.** Age assurance requirements that block full access to a service—except in limited cases like sites dedicated to age-restricted content (e.g., pornography)—can unintentionally limit child rights, such as access to information. Instead, age assurance should be applied at the service level, target specific design features that pose heightened risks, and enable tailored experiences for children.\n- **Focus on the highest risks for impact**, such as content and features associated with documented harms to children, and as determined through democratic processes. Providers should take steps to assess and mitigate risks to children on their services, while ensuring documentation requirements or compliance obligations do not inadvertently undermine safety. A risk-based and proportionate approach—grounded in clear criteria and supported by interoperable standards—can also help ensure that age assurance is applied where most needed, without introducing unnecessary friction. Providers of high-risk services should bear the responsibility of age assurance.\n\n- **Strengthen safeguards for AI companions**. Recent tragic events have highlighted the need for continued care in developing AI companions, especially where these may be used by young people. At Microsoft, we are building AI services for empowerment and want the right guardrails in place to protect *all* users but welcome new, commonsense measures such as those enacted in California and Australia to reduce the potential harms related to suicide and self-injury risks, as well as to sexualized or violent content. We will continue to work closely with researchers and experts to understand and mitigate potential risks to young people in this fast-evolving field.\n- **Incentivize age-appropriate design.** Banning kids from online services isn’t the answer, but what constitutes an “age-appropriate” experience will vary. We have supported a duty of care approach to child safety where the duty can be implemented flexibly, guided by thoughtful and evidence-based regulatory guidance. Ongoing research and expert engagement are needed to understand how to advance child safety and rights on diverse services—not just social media.\n- **Protect the privacy and security of all users.** Tailoring age assurance requirements will help enable proportionate approaches to data processing. Current proposals for age verification by app stores risk creating significant privacy risks by collecting sensitive information and sharing unnecessary age data with a wide variety of services while also not solving the challenges lawmakers want to address. We continue to support federal privacy legislation in the US and encourage global efforts to develop standards and certifications for age assurance providers. Trusted credential sharing can also increasingly be enabled by emerging digital identity ecosystems—including government-issued IDs and wallet-based models—that preserve mutual privacy between issuers and relying parties.\n- **Support, not overwhelm** Our Global Online Safety Survey results show that while parents might underestimate the risks teens face online, teens are most likely to turn to a parent for help. Parents should not face a deluge of notifications nor bear the sole responsibility for safety but have access, awareness, and education on family safety tools that can help them make informed choices appropriate for their family and their values.\n- **Foster multistakeholder collaboration.** We believe it’s essential to elevate the voices and perspectives of young people, as well as for regulators and industry to engage with civil society and partner to advance practical solutions. As child safety regulations come into force, it will also be important to get feedback from affected communities on where regulation may have adverse rights impacts, as well as to understand where harm may have been averted. Public education will be needed to help all users understand why their online experiences might be changing.\n\nWe will continue learning, listening, and collaborating, especially with our new Council, and look forward to sharing our insights.\n\nTags: [AI](https://blogs.microsoft.com/on-the-issues/tag/ai/), [Online Safety](https://blogs.microsoft.com/on-the-issues/tag/online-safety/), [Responsible AI](https://blogs.microsoft.com/on-the-issues/tag/responsible-ai/)"
}
