{
  "FeedUrl": "https://news.microsoft.com/source/feed/",
  "Link": "https://www.microsoft.com/en-us/research/blog/self-adaptive-reasoning-for-science/",
  "Tags": [
    "AI",
    "Company News"
  ],
  "OutputDir": "_news",
  "FeedName": "Microsoft News",
  "ProcessedDate": "2025-08-08 15:35:06",
  "Title": "Self-adaptive reasoning coming to challenging scientific domains",
  "FeedLevelAuthor": "Source",
  "EnhancedContent": "![A gradient background transitioning from blue to pink with three white icons: a DNA double helix, a light bulb with rays, and a stylized path with arrows and nodes.](https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/MDQ-BlogHeroFeature-1400x788-1.jpg)\n\n## Unlocking self-adaptive cognitive behavior that is more controllable and explainable than reasoning models in challenging scientific domains\n\nLong-running LLM agents equipped with strong reasoning, planning, and execution skills have the potential to transform scientific discovery with high-impact advancements, such as developing new materials or pharmaceuticals. As these agents become more autonomous, ensuring effective human oversight and clear accountability becomes increasingly important, presenting challenges that must be addressed to unlock their full transformative power. Today’s approaches to long-term reasoning are established during the post-training phase, prior to end-user deployment and typically by the model provider. As a result, the expected actions of these agents are pre-baked by the model developer, offering little to no control from the end user.\n\nAt Microsoft, we are pioneering a vision for a continually steerable virtual scientist. In line with this vision, we created the ability to have a non-reasoning model develop thought patterns that allow for control and customizability by scientists. Our approach, a cognitive loop via in-situ optimization (CLIO), does not rely on reinforcement learning post-training to develop reasoning patterns yet still yields equivalent performance as demonstrated through our evaluation on Humanity’s Last Exam (HLE). Notably, we increased OpenAI GPT-4.1’s base model accuracy on text-only biology and medicine from **8.55%** to **22.37%**, an absolute increase of **13.82%** (**161.64%** relative), surpassing o3 (high). This demonstrates that an optimization-based, self-adaptive AI system developed without further post-training can rival post-trained models in domains where adaptability, explainability, and control matter most.\n\n![Bar chart that represents the Head-to-head comparison of OpenAI’s GPT-4.1 with CLIO, o3, and GPT-4.1 with no tools on HLE biology and medicine questions](https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/MDQ_Figure-1_Updated.png)Figure 1. Head-to-head comparison of OpenAI’s GPT-4.1 with CLIO, o3, and GPT-4.1 with no tools on HLE biology and medicine questions\n\n### In-situ optimization with internal self-reflection to enable self-adaptive reasoning\n\nModel development has advanced from using reinforcement learning human feedback (RLHF) for answer alignment to external grading in reinforcement learning (RLVR). Recent approaches show promise in the utilization of intrinsic rewards for training reasoning models (RLIR). Traditionally, these reasoning processes are learned during the post-training process before any user interaction. While today’s reasoning models require additional data in the training phase and limit user control during the reasoning generation process, CLIO’s approach enables users to steer reasoning from scratch without additional data. Rather, CLIO generates its own necessary data by creating reflection loops at runtime. These reflection loops are utilized for a wide array of activities that CLIO self-defines, encompassing idea exploration, memory management, and behavior control. Most interesting is CLIO’s ability to leverage prior inferences to adjust future behaviors, handling uncertainties and raising flags for correction when necessary. Through this open architecture approach to reasoning, we alleviate the necessity for further model post-training to achieve desired reasoning behavior. Performing novel scientific discoveries often has no prior established patterns for reasoning, much less a large enough corpus of high-quality data to train on.\n\nSpotlight: Microsoft research newsletter\n\n[!\\[\\](https://www.microsoft.com/en-us/research/wp-content/uploads/2019/09/Newsletter_Banner_08_2019_v1_1920x1080.png)](https://info.microsoft.com/ww-landing-microsoft-research-newsletter.html)\n\n## Microsoft Research Newsletter\n\nStay connected to the research community at Microsoft.\n\n[Subscribe today](https://info.microsoft.com/ww-landing-microsoft-research-newsletter.html)\n\nOpens in a new tab\n\nCLIO reasons by continuously reflecting on progress, generating hypotheses, and evaluating multiple discovery strategies. For the HLE test, CLIO was specifically steered to follow the scientific method as a guiding framework. Our research shows that equipping language models with self-adapting reasoning enhances their problem-solving ability. It provides a net benefit in quality for science questions, as well as providing exposure and control to the end user.\n\n![Figure 2. CLIO can raise key areas of uncertainty within its self-formulated reasoning process, balancing multiple different viewpoints using graph structures.](https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/MDQ_FIG2-2-scaled.png)Figure 2. CLIO can raise key areas of uncertainty within its self-formulated reasoning process, balancing multiple different viewpoints using graph structures.\n\n### Control over uncertainty: Building trust in AI\n\nOrchestrated reasoning systems like CLIO are valuable for scientific discovery, as they provide features beyond accuracy alone. Capabilities such as explaining the outcomes of internal reasoning are standard in the scientific field and are present in current reasoning model approaches. However, elements like displaying complete work, including final outcomes, internal thought processes, and uncertainty thresholds to support reproducibility or correction, as well as indicating uncertainty, are not yet universally implemented. Current models and systems do not have this same innate humility.  Rather, we are left with models that produce confident results, whether correct or incorrect. When correct, it is valuable. When incorrect, it is dangerous to the scientific process. Hence, understanding a model or system’s uncertainty is a crucial aspect that we have developed natively into CLIO.\n\nOn the other end of the spectrum, orchestrated reasoning systems tend to oversaturate the user by raising too many flags. We enable prompt-free control knobs within CLIO to set thresholds for raising uncertainty flags. This allows CLIO to flag uncertainty for itself and the end user at the proper point in time. This also enables scientists to revisit CLIO’s reasoning path with critiques, edit beliefs during the reasoning process, and re-execute them from the desired point in time. Ultimately, this builds a foundational level of trust with scientists to use them in a scientifically defensible and rigorous way.\n\n### How does CLIO perform?\n\nWe evaluate CLIO against text-based biology and medicine questions from HLE. For this domain, we demonstrate a **61.98%** relative increase or an **8.56%** net increase **** in accuracy over OpenAI’s o3 and substantially outperform base completion models like OpenAI’s GPT-4.1, while enabling the requisite explainability and control. This technique applies to all models, showing similar increases in OpenAI’s GPT-4o model, which we observe performs poorly on HLE-level questions. On average, GPT-4.1 is not considered competent for HLE scale questions (GraphRAG. This extension of the cognition pattern provides a further 7.90% over a non-ensembled approach.\n\n![Waterfall chart that demonstrates the impact of thinking effort on CLIO’s effectiveness.](https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/MDQ_Fig3.png)Figure 3. The impact of thinking effort on CLIO’s effectiveness.\n\nFurthermore, CLIO’s design offers different knobs of control, for example, how much time to think and which technique to utilize for a given problem. In Figure 3, we demonstrate these knobs of control and their increase on GPT-4.1 and GPT-4o’s performance. In this case, we analyze performance for a subset of biomedical questions, those focused on immunology. CLIO increases GPT-4o’s base performance to be at par with the best reasoning models for immunology questions. We observe a **13.60%** improvement over the base model, GPT-4o. This result shows CLIO to be model agnostic, similar to [Microsoft AI Diagnostic Orchestrator’s (MAI-DxO) (opens in new tab)](https://microsoft.ai/new/the-path-to-medical-superintelligence/)‘s approach and corresponding performance boost.\n\n### Implications for science and trustworthy discovery\n\nThe future of scientific discovery demands more than reasoning over knowledge and raw computational power alone. Here, we demonstrate how CLIO not only increases model performance but establishes new layers of control for scientists. In our upcoming work, we will demonstrate how CLIO increases tool utility for highly valuable scientific questions in the drug discovery space which requires precise tools designed for the language of science. While our experiments focus on scientific discovery, we believe CLIO can apply in a domain-agnostic fashion. Experts tackling problems in domains such as financial analysis, engineering, and legal services could potentially benefit from AI systems with a transparent, steerable reasoning approach. Ultimately, we envision CLIO as an enduring control-layer in hybrid AI stacks that combine traditional completion and reasoning models, with external memory systems, and advanced tool calling. These continuous checks and balances that CLIO enables will continue to remain valuable even as components within the AI stacks evolve. This combination of intelligent and steerable scientific decision making and tool optimization is the basis of the recently announced [Microsoft Discovery platform (opens in new tab)](https://azure.microsoft.com/en-us/blog/transforming-rd-with-agentic-ai-introducing-microsoft-discovery/?msockid=394581ce06c567df2171946b073d6601).\n\nAt Microsoft, we’re committed to advancing AI research that earns the trust of scientists, empowering them to discover new frontiers of knowledge. Our work is a testament to what’s possible when we blend innovation with trustworthiness and a human-centered vision for the future of AI-assisted scientific discovery. We invite the research and scientific community to join us in shaping that future.\n\n**Further information:**\n\nTo learn more details about our approach, please read our [pre-print paper](https://www.microsoft.com/en-us/research/publication/cognitive-loop-via-in-situ-optimization-self-adaptive-reasoning-for-science/) published alongside this blog. We are in the process of submitting this work for external peer review and encourage partners to explore the utilization of CLIO in Microsoft Discovery. To learn more about Microsoft’s research on this or contact our team, please reach out to [discoverylabs@microsoft.com](mailto:discoverylabs@microsoft.com).\n\n## Acknowledgements\n\nWe are grateful for Jason Zander and Nadia Karim’s support. We extend our thanks to colleagues both inside and outside Microsoft Discovery and Quantum for sharing their insights and feedback, including Allen Stewart, Yasser Asmi, David Marvin, Harsha Nori, Scott Lundberg, and Phil Waymouth.\n\nOpens in a new tab",
  "Author": "stclarke",
  "PubDate": "2025-08-07T18:08:54+00:00",
  "Description": "The post [Self-adaptive reasoning coming to challenging scientific domains](https://www.microsoft.com/en-us/research/blog/self-adaptive-reasoning-for-science/) appeared first on [Source](https://news.microsoft.com/source)."
}
