{
  "Author": "stclarke",
  "PubDate": "2025-10-22T15:43:25+00:00",
  "Title": "Tell me when: Building agents that can wait, monitor and act",
  "Tags": [
    "AI",
    "Company News"
  ],
  "ProcessedDate": "2025-10-22 16:03:31",
  "FeedName": "Microsoft News",
  "EnhancedContent": "![Workflow icons showing tasks, thinking, and time, linked to a person symbol on a gradient background.](https://www.microsoft.com/en-us/research/wp-content/uploads/2025/10/MagenticUIupdate-BlogHeroFeature-1400x788-1-1024x576.jpg)\n\nModern LLM Agents can debug code, analyze spreadsheets, and book complex travel. Given those capabilities, it’s reasonable to assume that they could handle something simpler: waiting. Ask an agent to monitor your email for a colleague’s response or watch for a price drop over several days, and it will fail. Not because it can’t check email or scrape prices. It can do both. It fails because it doesn’t know *when* to check. Agents either give up after a few attempts or burn through their context window, checking obsessively. Neither work.\n\nThis matters because monitoring tasks are everywhere. We track emails for specific information, watch news feeds for updates, and monitor prices for sales. Automating these tasks would save hours, but current agents aren’t built for patience.\n\nTo address this, we are introducing [SentinelStep (opens in new tab)](https://github.com/microsoft/magentic-ui), a mechanism that enables agents to complete long-running monitoring tasks. The approach is simple. SentinelStep wraps the agent in a workflow with dynamic polling and careful context management. This enables the agent to monitor conditions for hours or days without getting sidetracked. We’ve implemented SentinelStep in [Magentic-UI](https://www.microsoft.com/en-us/research/blog/magentic-ui-an-experimental-human-centered-web-agent/?msockid=16c285fb8306647b25f593b982ef6516), our research prototype agentic system, to enable users to build agents for long-running tasks, whether they involve web browsing, coding, or external tools.\n\nPODCAST SERIES\n\n[!\\[Illustrated headshots of Daniel Carpenter, Timo Minssen, Chad Atalla, and Kathleen Sullivan for the Microsoft Research Podcast\\](https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP2-AI-TE_Hero_Feature_River_No_Text_1400x788.jpg)](https://www.microsoft.com/en-us/research/story/ai-testing-and-evaluation-learnings-from-science-and-industry/)\n\n## AI Testing and Evaluation: Learnings from Science and Industry\n\nDiscover how Microsoft is learning from other domains to advance evaluation and testing as a pillar of AI governance.\n\n[Listen now](https://www.microsoft.com/en-us/research/story/ai-testing-and-evaluation-learnings-from-science-and-industry/)\n\nOpens in a new tab\n\n## How it works\n\nThe core challenge is polling frequency. Poll too often, and tokens get wasted. Poll too infrequently, and the user’s notification gets delayed. SentinelStep makes an educated guess at the polling interval based on the task at hand—checking email gets different treatment than monitoring quarterly earnings—then dynamically adjusts based on observed behavior.\n\nThere’s a second challenge: context overflow. Because monitoring tasks can run for days, context overflow becomes inevitable. SentinelStep handles this by saving the agent state after the first check, then using that state for each subsequent check.\n\nThese demonstrations capture Magentic-UI with SentinelStep at work, completing a range of tasks in a timelapse sequence.\n\n### Core components\n\nAs the name suggests, SentinelStep consists of individual steps taken as part of an agent’s broader workflow. As illustrated in Figure 1, there are three main components: the actions necessary to collect information, the condition that determines when the task is complete, and the polling interval that determines timing. Once these components are identified, the system’s behavior is simple: every*[polling interval]*do*[actions]*until*[condition]*is satisfied*.*\n\n![Figure 1. SentinelSteps’s three main components in Magentic-UI’s co-planning interface. ](https://www.microsoft.com/en-us/research/wp-content/uploads/2025/10/Figure-1-Sentinel-UI.png)Figure 1. SentinelSteps’s three main components in Magentic-UI’s co-planning interface.\n\nThese three components are defined and exposed in the co-planning interface of Magentic-UI. Given a user prompt, Magentic-UI proposes a complete multi-step plan, including pre-filled parameters for any monitoring steps. Users can accept the plan or adjust as needed.\n\n### Processing\n\nOnce a run starts, Magentic-UI assigns the most appropriate agent from a team of agents to perform each action. This team includes agents capable of web surfing, code execution, and calling arbitrary MCP servers.\n\nWhen the workflow reaches a monitoring step, the flow is straightforward. The assigned agent collects the necessary information through the actions described in the plan. The Magentic-UI orchestrator then checks whether the condition is satisfied. If it is, the SentinelStep is complete, and the orchestrator moves to the next step. If not, the orchestrator determines the timestamp for the next check and resets the agent’s state to prevent context overflow.\n\n## Evaluation\n\nEvaluating monitoring tasks in real-world settings is nearly impossible. Consider a simple example: monitoring the Magentic-UI repository on GitHub until it reaches 10,000 stars (a measure of how many people have bookmarked it). That event occurs only once and can’t be repeated. Most real-world monitoring tasks share this limitation, making systematic bench marking very challenging.\n\nIn response, we are developing SentinelBench, a suite of synthetic web environments for evaluating monitoring tasks. These environments make experiments repeatable. SentinelBench currently supports 28 configurable scenarios, each allowing the user to schedule exactly when a target event should occur. It includes setups like GitHub Watcher, which simulates a repository accumulating stars over time; Teams Monitor, which models incoming messages, some urgent; and Flight Monitor, which replicates evolving flight-availability dynamics.\n\nInitial tests show clear benefits. As shown in Figure 2, success rates remain high for short tasks (30 sec and 1 min) regardless of whether SentinelStep is used. For longer tasks, SentinelStep markedly improves reliability: at 1 hour, task reliability rises from 5.6% without SentinelStep to 33.3% with it; and at 2 hours, it rises from 5.6% to 38.9%. These gains demonstrate that SentinelStep effectively addresses the challenge of maintaining performance over extended durations.\n\n![Figure 2. SentinelStep improves success rates on longer running tasks (1–2 hours) while maintaining comparable performance on shorter tasks. ](https://www.microsoft.com/en-us/research/wp-content/uploads/2025/10/Figure-2-Eval.png)Figure 2. SentinelStep improves success rates on longer running tasks (1–2 hours) while maintaining comparable performance on shorter tasks.\n\n## Impact and availability\n\nSentinelStep is a first step toward practical, proactive, longer‑running agents. By embedding patience into plans, agents can responsibly monitor conditions and act when it matters—staying proactive without wasting resources. This lays the groundwork for always‑on assistants that stay efficient, respectful of limits, and aligned with user intent.\n\nWe’ve open-sourced SentinelStep as part of Magentic-UI, available on [GitHub (opens in new tab)](https://github.com/microsoft/magentic-ui) or via `pip install magnetic-ui` . As with any new technique, production deployment should be preceded through testing and validation for the specific use case. For guidance on intended use, privacy considerations, and safety guidelines, see the Magentic-UI [Transparency Note. (opens in new tab)](https://github.com/microsoft/magentic-ui/blob/main/TRANSPARENCY_NOTE.md)\n\nOur goal is to make it easier to implement agents that can handle long-running monitoring tasks and lay the groundwork for systems that anticipate, adapt, and evolve to meet real-world needs.\n\nOpens in a new tab",
  "OutputDir": "_news",
  "Link": "https://www.microsoft.com/en-us/research/blog/tell-me-when-building-agents-that-can-wait-monitor-and-act/",
  "Description": "The post [Tell me when: Building agents that can wait, monitor and act](https://www.microsoft.com/en-us/research/blog/tell-me-when-building-agents-that-can-wait-monitor-and-act/) appeared first on [Source](https://news.microsoft.com/source).",
  "FeedLevelAuthor": "Source",
  "FeedUrl": "https://news.microsoft.com/source/feed/"
}
