{
  "FeedUrl": "https://devblogs.microsoft.com/all-things-azure/feed/",
  "Title": "Codex Azure OpenAI Integration: Fast & Secure Code Development",
  "ProcessedDate": "2025-08-31 17:09:19",
  "EnhancedContent": "## Introduction\n\nWe have contributed the following five pull requests to add Azure OpenAI support to Codex, letting you enjoy the same Codex experience as in ChatGPT while running securely on Azure:\n\n- [PR #769](https://github.com/openai/codex/pull/769)\n- [PR #1324](https://github.com/openai/codex/pull/1324)\n- [PR #1321](https://github.com/openai/codex/pull/1321)\n- [PR #1778](https://github.com/openai/codex/pull/1778) (awaiting merge – Entra ID token-based authentication related to [PR #92](https://github.com/openai/codex/pull/92))\n\nWe are collaborating with OpenAI on additional updates and integrations, so stay tuned. Meanwhile, follow the steps below to get Codex running on your Azure subscription.\n\nOpenAI’s [**Codex CLI**](https://github.com/openai/codex) is the same coding agent that powers ChatGPT’s Codex. You can now run this coding agent *entirely on Azure infrastructure*, which keeps your data inside your compliance boundary and gives you the advantages of enterprise-grade security, private networking, role-based access control, and predictable cost management. Codex is more than a chat with your code agent – it is an **asynchronous coding agent** that can be triggered from your terminal or from a GitHub Actions runner, automatically opening pull requests, refactoring files, and writing tests with the credentials of your Azure OpenAI deployment. Explore deploying it with Azure OpenAI for use cases such as language translation, data-to-code, and legacy migration as detailed in the original [Introducing Codex blog post](https://openai.com/index/introducing-codex/). After you are up and running, visit [aifoundry.app](https://aifoundry.app) (and [asyncloom.com](https://asyncloom.com)) to configure your repository for Codex and to browse a growing catalog of other Azure-hosted coding agents, including GitHub Copilot Coding Agent, Cognition Devin, SRE Agent, and more.\n\n### Prerequisites\n\n- An active Azure subscription with access to **Azure OpenAI**.\n- Contributor permissions in [Azure AI Foundry](https://ai.azure.com).\n- `homebrew`\nor `npm` for installing the CLI.\n\n| **Requirement** | **Details** | | --- | --- | | Operating systems | macOS 12+, Ubuntu 20.04+/Debian 10+, or Windows 11 via WSL2 | | Git (optional, recommended) | 2.23+ for built-in PR helpers | | RAM | 4-GB minimum (8-GB recommended) |\n\n### Step 1 – Deploy a Codex model in Azure AI Foundry\n\n1. Go to Azure AI Foundry @ `ai.azure.com`\nand create a new project.\n2. Select a reasoning model such as [`codex-mini`](https://devblogs.microsoft.com/foundry/codex-mini-fast-scalable-code-generation-for-the-cli-era/), `gpt-5`\n, or `gpt-5-mini` .\n3. Click **Deploy**, choose a name, and wait about two minutes.\n4. Copy the **Endpoint URL** and **API key**.\n\n### Step 2 – Install and Run the Codex CLI\n\n```default brew install codex codex --version # verify installation ```\n\n| **Command** | **Purpose** | | --- | --- | | codex | Interactive TUI | | codex “…” | Initial prompt for interactive TUI | | codex exec “…” | Non-interactive “automation mode” |\n\n### Step 3 – Configure `~/.codex/config.toml`\n\nCreate a TOML configuration file to tell Codex how to connect to Azure and other tools. Here is an example that configures both Azure OpenAI and an MCP server for Microsoft Learn documentation.\n\n```toml\n# Set the default model and provider\nmodel = \"gpt-5\" model_provider = \"azure\"\n\n# Configure the Azure provider\n[model_providers.azure] name = \"Azure\"\n# Make sure you set the appropriate subdomain for this URL.\nbase_url = \"https://YOUR_PROJECT_NAME.openai.azure.com/openai\" env_key = \"AZURE_OPENAI_API_KEY\" query_params = { api-version = \"2025-04-01-preview\" } wire_api = \"responses\"\n\n# Example of configuring an MCP server for MS Learn Docs\n[mcp_servers.server-name] command = \"npx\" args = [\"-y\", \"mcp-remote\", \"https://learn.microsoft.com/api/mcp\"] ```\n\n```default\n# Linux, macOS, or WSL\nexport AZURE_OPENAI_API_KEY=\"<your-api-key>\" ```\n\n### Step 4 – Giving Codex Memory with AGENTS.md\n\nYou can give Codex extra instructions and guidance using `AGENTS.md` files. Codex looks for `AGENTS.md` files in the following places and merges them top-down, giving it context about your personal preferences, project-specific details, and the current task:\n\n- `~/.codex/AGENTS.md`\n– personal global guidance.\n- `AGENTS.md`\nat your repository’s root – shared project notes.\n- `AGENTS.md`\nin the current working directory – sub-folder/feature specifics.\n\nFor example, to help Codex understand how to write code for Azure AI Foundry Agents, you could create an `AGENTS.md` in your project root with the following content, derived from the Azure AI Agents SDK documentation:\n\n```markdown\n# Instructions for working with Azure AI Foundry Agents\n\nYou are an expert in the Azure AI Agents client library for Python.\n\n## Key Concepts\n\n- **Client Initialization**: Always start by creating an `AIProjectClient` or `AgentsClient`. The recommended way is via `AIProjectClient`.\n- **Authentication**: Use `DefaultAzureCredential` from `azure.identity`.\n- **Agent Creation**: Use `agents_client.create_agent()`. Key parameters are `model`, `name`, and `instructions`.\n- **Tools**: Agents use tools to perform actions like file search, code interpretation, or function calls.\n- To use tools, they must be passed to `create_agent` via the `tools` and `tool_resources` parameters or a `toolset`.\n- Example: `file_search_tool = FileSearchTool(vector_store_ids=[...])`\n- Example: `code_interpreter = CodeInterpreterTool(file_ids=[...])`\n- Example: `functions = FunctionTool(user_functions)`\n\n## Example: Creating a basic agent\n\n```python import os from azure.ai.projects import AIProjectClient from azure.identity import DefaultAzureCredential\n\n# 1. Create Project Client\nproject_client = AIProjectClient( endpoint=os.environ[\"PROJECT_ENDPOINT\"], credential=DefaultAzureCredential(), )\n\n# 2. Get Agents Client\nwith project_client: agents_client = project_client.agents\n\n# 3. Create Agent\nagent = agents_client.create_agent( model=os.environ[\"MODEL_DEPLOYMENT_NAME\"], name=\"my-helpful-agent\", instructions=\"You are a helpful agent that can answer questions.\", ) print(f\"Created agent with ID: {agent.id}\") ``` ```\n\n### Step 5 – Explore with your coding agent\n\n``` codex \"write a python script to create an Azure AI Agent with file search capabilities\"\n\n```\n\n- `# generate a unit test for src/utils/date.ts`\n- `# refactor this agent to use the Code Interpreter tool instead`\n\n### Step 6 – Run Codex in GitHub Actions\n\n[![codex blog featured image image](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAASwAAADIAQMAAABoEU4WAAAAA1BMVEXW1taWrGEgAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAAHklEQVRYhe3BMQEAAADCoPVPbQdvoAAAAAAAAADgNx54AAHw+DPXAAAAAElFTkSuQmCC)](https://devblogs.microsoft.com/all-things-azure/wp-content/uploads/sites/83/2025/06/codex-blog-featured-image-1.png)\n\nCodex can execute as part of your CI pipeline. Store your API key in the repository’s secret store as `AZURE_OPENAI_KEY` and add a job like this to automatically update your changelog before a release:\n\n```yaml jobs: update_changelog: runs-on: ubuntu-latest steps:\n- uses: actions/checkout@v4\n- name: Update changelog via Codex\nrun: | npm install -g @openai/codex export AZURE_OPENAI_API_KEY=\"${{ secrets.AZURE_OPENAI_KEY }}\" codex -p azure exec --full-auto \"update CHANGELOG for next release\"\n\n```\n\n### Step 7 – Explore more agents with [AsyncLoom](https://asyncloom.com)\n\n- Browse detailed docs and benchmarks for other Azure-hosted agents.\n- Create repo-ready configuration guides with one click.\n- Experiment with GitHub Copilot Coding Agent, Cognition Devin, SRE Agent, and others.\n\n### Troubleshooting\n\n| Symptom | Fix | | --- | --- | | `401 Unauthorized`<br> or `403 Forbidden` | Export your `AZURE_OPENAI_API_KEY`<br> environment variable correctly.<br>Confirm that your key has *project/deployment* access. | | `ENOTFOUND`<br>, DNS error, or `404 Not Found` | Verify `base_url`<br> in `config.toml`<br> uses your resource name and correct domain, e.g.<br>`base_url = \"https://<your-resource>.openai.azure.com/openai\"`<br>. | | CLI ignores Azure settings | Open `~/.codex/config.toml`<br> and ensure:<br><ul><br><li><code>model_provider = \"azure\"</code><br> is set.</li><br><br><li>The <code>[model_providers.azure]</code><br> section exists.</li><br><br><li><code>env_key = \"AZURE_OPENAI_API_KEY\"</code><br> matches your exported variable.</li><br><br></ul> | | In Codex, you get a warning that “codex-mini” is not in the list of available models for provider “azure” | This is a known issue, and we have a PR in progress to address this. Ignore this warning and proceed with codex-cli tasks. |\n\n### Conclusion\n\nIn just a few minutes you can connect an AI coding agent to your Azure tenant, keep intellectual property secure, and accelerate software delivery. Combine Codex CLI, GitHub Actions, and Gitagu’s agent catalog to build a flexible AI-powered engineering workflow. Give it a try and share what you create.\n\nQuestions or feedback? Drop a comment below",
  "FeedName": "Microsoft All Things Azure Blog",
  "FeedLevelAuthor": "All things Azure",
  "Tags": [
    "Agents",
    "AI Foundry",
    "All things Azure",
    "App Development",
    "Azure",
    "Azure OpenAI",
    "codex",
    "codex-mini",
    "coding-agent",
    "Developer Productivity",
    "openai"
  ],
  "Description": "Introduction We have contributed the following five pull requests to add Azure OpenAI support to Codex, letting you enjoy the same Codex experience as in ChatGPT while running securely on Azure: PR #769 PR #1324 PR #1321 PR #1778 (awaiting merge – Entra ID token-based authentication related to PR #92) We are collaborating with OpenAI on additional updates and integrations, so […]\n\nThe post [Codex Azure OpenAI Integration: Fast & Secure Code Development](https://devblogs.microsoft.com/all-things-azure/codex-azure-openai-integration-fast-secure-code-development/) appeared first on [All things Azure](https://devblogs.microsoft.com/all-things-azure).",
  "OutputDir": "_news",
  "Link": "https://devblogs.microsoft.com/all-things-azure/codex-azure-openai-integration-fast-secure-code-development/",
  "Author": "Govind Kamtamneni",
  "PubDate": "2025-06-17T22:54:11+00:00"
}
