{
  "Link": "https://devblogs.microsoft.com/all-things-azure/build-your-own-microsoft-docs-ai-assistant-with-azure-container-apps-and-azure-openai/",
  "FeedName": "Microsoft All Things Azure Blog",
  "PubDate": "2025-09-04T22:09:45+00:00",
  "FeedUrl": "https://devblogs.microsoft.com/all-things-azure/feed/",
  "ProcessedDate": "2025-09-04 22:11:02",
  "Tags": [
    "AI Apps",
    "AI Foundry",
    "All things Azure"
  ],
  "OutputDir": "_news",
  "Author": "Ricardo Macedo Martins",
  "Description": "Learn how to deploy a self-hosted AI assistant that leverages Microsoft Learn content via the Model Context Protocol (MCP) and Azure OpenAI. It‚Äôs fast, secure, and ready for developer use in real-world apps. Prerequisite This guide assumes you already have an Azure OpenAI resource provisioned in your subscription, with a deployed model (e.g., gpt-4, gpt-4.1, [‚Ä¶]\n\nThe post [Build your own Microsoft Docs AI assistant with Azure Container Apps and Azure OpenAI](https://devblogs.microsoft.com/all-things-azure/build-your-own-microsoft-docs-ai-assistant-with-azure-container-apps-and-azure-openai/) appeared first on [All things Azure](https://devblogs.microsoft.com/all-things-azure).",
  "FeedLevelAuthor": "All things Azure",
  "EnhancedContent": "Learn how to deploy a self-hosted AI assistant that leverages Microsoft Learn content via the **Model Context Protocol (MCP)** and Azure OpenAI. It‚Äôs fast, secure, and ready for developer use in real-world apps.\n\n**Prerequisite** This guide assumes you already have an Azure OpenAI resource provisioned in your subscription, with a deployed model (e.g., `gpt-4` , `gpt-4.1` , or `gpt-35-turbo` ). If not, follow the [Azure OpenAI Quickstart](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/how-to/create-resource) before proceeding.\n\n### The goal\n\nImagine being able to ask Microsoft Learn, ‚ÄúHow do I monitor AKS workloads?‚Äù or ‚ÄúWhat are best practices for Azure Bicep deployments?‚Äù and instantly get a precise, summarized answer powered by GPT-4.1 and grounded in documentation.\n\nThis blog post walks through deploying a **production-ready AI assistant**, using:\n\n- Microsoft‚Äôs **Model Context Protocol (MCP)**\n- **Azure OpenAI** (GPT-4.1 Mini deployment)\n- **Azure Container Apps** for secure, serverless hosting\n- Docker and ACR for packaging and image delivery\n\n### Architecture overview\n\nThe flow is based on [Model Context Protocol (MCP)](https://learn.microsoft.com/api/mcp), an emerging standard designed to provide trusted, contextual information for LLMs and copilots.\n\n[![msdocs assistant architecture](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAlQAAAQAAQMAAAAdmVWxAAAAA1BMVEXW1taWrGEgAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAAYklEQVR4nO3BAQ0AAADCoPdPbQ43oAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHgwMA8AAQjPQBAAAAAASUVORK5CYII=)](https://devblogs.microsoft.com/all-things-azure/wp-content/uploads/sites/83/2025/09/mcp.png)\n\nThe result: an agent that‚Äôs grounded in official content and capable of serving precise answers to developers.\n\n### Deploying your own instance\n\nLet‚Äôs walk through building and deploying your own instance of [mslearn-mcp-chat](https://github.com/passadis/mslearn-mcp-chat), a lightweight web app powered by Next.js.\n\n#### Step 1: Clone the Project\n\n```default git clone https://github.com/passadis/mslearn-mcp-chat.git cd mslearn-mcp-chat\n\n```\n\n#### Step 2: Auto-discover Azure OpenAI config\n\nIf you‚Äôve already deployed an Azure OpenAI resource and a GPT-4 deployment, you can auto-discover everything and generate .env.local like this:\n\n```default #!/bin/bash\n\n# Get resource group and AOAI resource name\nRESOURCE_GROUP=$(az cognitiveservices account list \\ --query \"[?kind=='OpenAI'].resourceGroup\" -o tsv | head -n1)\n\nAOAI_RESOURCE_NAME=$(az cognitiveservices account list \\ --query \"[?kind=='OpenAI'].name\" -o tsv | head -n1)\n\n# Get endpoint\nAOAI_ENDPOINT=$(az cognitiveservices account show \\ --name \"$AOAI_RESOURCE_NAME\" \\ --resource-group \"$RESOURCE_GROUP\" \\ --query \"properties.endpoint\" -o tsv)\n\n# Get API key\nAOAI_KEY=$(az cognitiveservices account keys list \\ --name \"$AOAI_RESOURCE_NAME\" \\ --resource-group \"$RESOURCE_GROUP\" \\ --query \"key1\" -o tsv)\n\n# Get deployment name (adjust model name filter if needed)\nDEPLOYMENT_NAME=$(az cognitiveservices account deployment list \\ --name \"$AOAI_RESOURCE_NAME\" \\ --resource-group \"$RESOURCE_GROUP\" \\ --query \"[?contains(properties.model.name, 'gpt-4')].name\" -o tsv | head -n1)\n\n# Write to .env.local\ncat <<EOF > .env.local AZURE_OPENAI_KEY=$AOAI_KEY AZURE_OPENAI_ENDPOINT=$AOAI_ENDPOINT AZURE_OPENAI_DEPLOYMENT_NAME=$DEPLOYMENT_NAME EOF\n\necho \".env.local created\" cat .env.local ```\n\n#### Step 3: Export for CLI Usage\n\nSince Azure CLI doesn‚Äôt parse .env.local, create a temp exported version:\n\n```default sed 's/^/export /' .env.local > .env.exported source .env.exported ```\n\nNow you can use those variables in your az commands.\n\n#### Step 4: Create Azure Resources\n\n```default az group create --name rg-mcp-chat --location eastus\n\naz acr create --name acrmcpchat \\ --resource-group rg-mcp-chat \\ --sku Basic --admin-enabled true ```\n\n#### Step 5: Dockerize and push the image\n\n##### Create a Dockerfile\n\n```default FROM node:20 WORKDIR /app COPY . . RUN npm install && npm run build EXPOSE 3000 CMD [\"npm\", \"start\"] ```\n\n##### Build & Push\n\n```default docker build -t acrmcpchat.azurecr.io/mcp-chat:latest . az acr login --name acrmcpchat docker push acrmcpchat.azurecr.io/mcp-chat:latest\n\n```\n\n#### Step 6: Create a Container App Environment\n\n```default az containerapp env create \\ --name env-mcp-chat \\ --resource-group rg-mcp-chat \\ --location eastus ```\n\n#### Step 7: Deploy the Container App\n\n```default az containerapp create \\ --name mcp-chat-app \\ --resource-group rg-mcp-chat \\ --environment env-mcp-chat \\ --image acrmcpchat.azurecr.io/mcp-chat:latest \\ --registry-server acrmcpchat.azurecr.io \\ --cpu 1.0 --memory 2.0Gi \\ --target-port 3000 \\ --ingress external \\ --env-vars \\ AZURE_OPENAI_KEY=$AZURE_OPENAI_KEY \\ AZURE_OPENAI_ENDPOINT=$AZURE_OPENAI_ENDPOINT \\ AZURE_OPENAI_DEPLOYMENT_NAME=$AZURE_OPENAI_DEPLOYMENT_NAME ```\n\n#### Step 8: Get the Public URL\n\n```default az containerapp show \\ --name mcp-chat-app \\ --resource-group rg-mcp-chat \\ --query properties.configuration.ingress.fqdn \\ --output tsv ```\n\nOpen that URL in your browser and try questions like:\n\n- ‚ÄúWhat‚Äôs the best way to deploy Azure Functions using Bicep?‚Äù\n- ‚ÄúHow does Azure Policy work with management groups?‚Äù\n- ‚ÄúWhat‚Äôs the difference between vCore and DTU in Azure SQL?‚Äù\n\n### Why model context protocol (MCP) matters\n\nMCP is a structured protocol that helps AI assistants ground responses in official sources, such as Microsoft Learn and Docs, by returning text fragments (chunks) for use in RAG pipelines or summarization prompts.\n\n#### Sample MCP Payload:\n\n```json { \"jsonrpc\": \"2.0\", \"id\": \"chat-123\", \"method\": \"tools/call\", \"params\": { \"name\": \"microsoft_docs_search\", \"arguments\": { \"question\": \"How do I deploy AKS with Bicep?\" } } } ```\n\nThe assistant receives those docs, crafts a system message, and sends the question and context to Azure OpenAI for synthesis.\n\n### What you get\n\n| Feature | Benefit | | --- | --- | | üß© MCP Integration | Answers grounded in Microsoft Learn docs | | üîê AOAI Security | Backend-only key usage, never exposed in client | | üöÄ Container Apps | Scalable, secure hosting with no infrastructure to manage | | üõ†Ô∏è Dev-Focused Stack | Next.js + Node + Azure CLI + ACR ‚Äî fast to iterate |\n\n### Final Thoughts\n\nWhether you‚Äôre building an internal dev assistant, an Azure learning tool, or testing out custom copilots, the MCP + Azure OpenAI combo is powerful, trustworthy, and fully customizable. And thanks to Azure Container Apps, deploying it is just a few CLI commands away.\n\n### References\n\n- [Microsoft Model Context Protocol (MCP)](https://learn.microsoft.com/api/mcp)\n- [Azure OpenAI Overview](https://learn.microsoft.com/en-us/azure/ai-foundry/what-is-azure-ai-foundry)\n- [Azure Container Apps](https://learn.microsoft.com/en-us/azure/container-apps/overview)\n- [Original GitHub Project ‚Äì mslearn-mcp-chat](https://github.com/passadis/mslearn-mcp-chat)",
  "Title": "Build your own Microsoft Docs AI assistant with Azure Container Apps and Azure OpenAI"
}
