{
  "FeedName": "Microsoft All Things Azure Blog",
  "ProcessedDate": "2025-10-04 23:03:48",
  "EnhancedContent": "Until recently, building real-time voice AI for production was challenging. Developers faced hurdles such as managing audio streams and ensuring low-latency performance.\n\nThat landscape is changing. The [general availability of the Azure Voice Live API](https://techcommunity.microsoft.com/blog/azure-ai-foundry-blog/upgrade-your-voice-agent-with-azure-ai-voice-live-api/4458247) marks a turning point, providing a unified abstraction layer that simplifies the development of real-time voice and avatar experiences. This shift inspired me to build a reference implementation called the AI Sales Coach to demonstrate how these new capabilities can be applied to solve a practical business challenge: skill development.\n\n### A Practical Application: The AI Sales Coach\n\n[![prepre image](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA/kAAAI8AQMAAACQ2fn8AAAAA1BMVEXW1taWrGEgAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAAXUlEQVR4nO3BAQEAAACCIP+vbkhAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADwbiBLAAEmAjSVAAAAAElFTkSuQmCC)](https://devblogs.microsoft.com/all-things-azure/wp-content/uploads/sites/83/2025/09/prepre.png)\n\nSales training is a universal need, making it an ideal use case. The AI Sales Coach application simulates sales conversations, allowing a user to select a scenario and engage with an AI-powered virtual customer, complete with a voice and a lifelike avatar. A sales professional can practice their pitch, handle objections, and navigate a realistic dialogue. Once the simulation ends, the application provides a performance analysis, turning the experience into a powerful learning tool.\n\n### Session Configuration\n\nWhen the connection to Voice Live API is opened, the backend constructs a **session configuration message**. This sets up modalities, voice, avatar, and audio settings.\n\n``` def _build_session_config(self) -> Dict[str, Any]: \"\"\"Build the base session configuration.\"\"\" return { \"type\": \"session.update\", \"session\": { \"modalities\": [\"text\", \"audio\"], \"turn_detection\": {\"type\": \"azure_semantic_vad\"}, \"input_audio_noise_reduction\": {\"type\": \"azure_deep_noise_suppression\"}, \"input_audio_echo_cancellation\": {\"type\": \"server_echo_cancellation\"}, \"avatar\": { \"character\": \"lisa\", \"style\": \"casual-sitting\", }, \"voice\": { \"name\": config[\"azure_voice_name\"], \"type\": config[\"azure_voice_type\"], }, }, } ```\n\nThis message is sent as the first step in establishing the conversation.\n\n- **modalities** define if both text and audio are active.\n- **turn detection** specifies how the system decides when the speaker has finished.\n- **noise reduction** and **echo cancellation** improve audio quality.\n- **avatar** and **voice** personalize the agent’s presence.\n\n### Adding Local Agent Behavior\n\nThe **behavior** of the agent is not controlled by session settings alone. Instead, the backend injects the **model, instructions, temperature, and max tokens** into the session.\n\n``` def _add_local_agent_config(self, config_message: Dict[str, Any], agent_config: Dict[str, Any]) -> None: \"\"\"Add local agent configuration to session config.\"\"\" session = config_message[\"session\"] session[\"model\"] = agent_config.get(\"model\", config[\"model_deployment_name\"]) session[\"instructions\"] = agent_config[\"instructions\"] session[\"temperature\"] = agent_config[\"temperature\"] session[\"max_response_output_tokens\"] = agent_config[\"max_tokens\"] ```\n\nWith this, we can dynamically swap out models (e.g., GPT-4o vs GPT-5), adjust creativity with **temperature**, and add **prompt instructions** that define how the AI should behave.\n\n### The Instructions\n\nThe instructions enforce conversational realism, ensuring the AI responds like a real person in a role-play setting.\n\n``` BASE_INSTRUCTIONS = \"\"\" CRITICAL INTERACTION GUIDELINES:\n- Keep responses SHORT and conversational (3 sentences max, as if speaking on phone)\n- ALWAYS stay in character, never break role\n- Simulate natural human speech patterns with pauses, um, well, occasional hesitation\n- Respond as a real person would in this business context\n- Use natural phone conversation style, direct but personable\n- Show genuine emotions and reactions appropriate to the situation\n- Ask follow-up questions to keep the conversation flowing naturally\n- Avoid overly formal or robotic language\n\"\"\" ```\n\nThese are appended to the role-play scenario instructions to guide the AI toward natural, in-character responses.\n\n### Feedback System\n\nAt the end of the conversation, the full transcript is sent to a GPT-4o model for evaluation. This “LLM-as-judge” pattern allows us to display a detailed scorecard covering key competencies.\n\n[![feedy image](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABAAAAALrAQMAAABagGe7AAAAA1BMVEXW1taWrGEgAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAAdElEQVR4nO3BMQEAAADCoPVPbQwfoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADgbeHoAAUhEpsEAAAAASUVORK5CYII=)](https://devblogs.microsoft.com/all-things-azure/wp-content/uploads/sites/83/2025/09/feedy.png)\n\n### The Manifestation of AI\n\nA key feature of the sample implementation is the avatar. This is not a gimmick; it addresses a fundamental design question we must now ask about AI: **How should it manifest?**\n\nIn a sales simulation, giving the AI a face makes the interaction more personal and realistic, improving the training’s effectiveness. However, an avatar is not always the right choice. In a high-stress customer support scenario, it might be distracting or inappropriate. This project highlights the need to be intentional about the “body” we give our AI, tailoring its manifestation to the specific use case and user’s emotional state.\n\n### The Technical Architecture\n\n[![archi image](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA6MAAAPoAQMAAAARN7rwAAAAA1BMVEXW1taWrGEgAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAAiUlEQVR4nO3BMQEAAADCoPVPbQo/oAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHgazP8AASzkPX4AAAAASUVORK5CYII=)](https://devblogs.microsoft.com/all-things-azure/wp-content/uploads/sites/83/2025/09/archi.png)\n\nThe Azure Voice Live API is the core of the system, handling the real-time, speech-to-speech conversation and avatar simulation. It serves as an abstraction layer, allowing different voice and language models to be used as the underlying reasoning engine without rewriting the application.\n\n### Final Thoughts\n\nWe have moved from text-based assistants to fully interactive, voice-driven experiences that can collaborate in increasingly human-like ways. The technology to build these systems is no longer a future concept; it’s here and ready to be deployed.\n\nThis project is a demonstration of what is now possible. I encourage you to explore the repository, envision how these capabilities could be used in your own organization, and start building. For a deeper dive into the Azure Voice Live API, check the [official documentation](https://learn.microsoft.com/en-us/azure/ai-services/speech-service/voice-live).\n\nThe full code for this technology demonstrator is available on GitHub. You can deploy it to your own Azure subscription in minutes using the Azure Developer CLI (`azd up` ).\n\n**GitHub Repository:** [https://github.com/Azure-Samples/voicelive-api-salescoach](https://github.com/Azure-Samples/voicelive-api-salescoach)",
  "Link": "https://devblogs.microsoft.com/all-things-azure/from-lab-to-live-a-blueprint-for-a-voice-powered-ai-sales-coach/",
  "Title": "From Lab to Live: A Blueprint for a Voice-Powered AI Sales Coach",
  "Author": "Aymen Furter",
  "OutputDir": "_news",
  "FeedUrl": "https://devblogs.microsoft.com/all-things-azure/feed/",
  "Tags": [
    "All things Azure"
  ],
  "Description": "Until recently, building real-time voice AI for production was challenging. Developers faced hurdles such as managing audio streams and ensuring low-latency performance. That landscape is changing. The general availability of the Azure Voice Live API marks a turning point, providing a unified abstraction layer that simplifies the development of real-time voice and avatar experiences. This […]\n\nThe post [From Lab to Live: A Blueprint for a Voice-Powered AI Sales Coach](https://devblogs.microsoft.com/all-things-azure/from-lab-to-live-a-blueprint-for-a-voice-powered-ai-sales-coach/) appeared first on [All things Azure](https://devblogs.microsoft.com/all-things-azure).",
  "PubDate": "2025-10-03T06:47:00+00:00",
  "FeedLevelAuthor": "All things Azure"
}
