{
  "PubDate": "2025-10-08T17:00:00+00:00",
  "FeedLevelAuthor": ".NET Blog",
  "EnhancedContent": "> >\n> This article is cross-posted from Maoni‚Äôs blog post original Medium article [Preparing for the .NET 10 GC](https://maoni0.medium.com/preparing-for-the-net-10-gc-88718b261ef2) by permission.\n> >\n\n## Preparing for the .NET 10 GC\n\nIn .NET 9 we enabled DATAS by default. But .NET 9 is not an LTS release so for many people they will be getting DATAS for the first time when they upgrade to .NET 10. This was a tough decision because GC features are usually the kind that don‚Äôt require user intervention ‚Äî but DATAS is a bit different. That‚Äôs why this post is titled ‚Äúpreparing for‚Äù instead of just ‚Äúwhat‚Äôs new‚Äù üòä.\n\nIf you‚Äôre using Server GC, you might notice a performance profile that‚Äôs more noticeably different than what you saw in previous runtime upgrades. Memory usage may look drastically different (very likely smaller) ‚Äî and that may or may not be desirable. It all depends on whether the tradeoff is noticeable, and if it is, whether it aligns with your optimization goals. I‚Äôd recommend taking at least a quick look at your application performance metrics to see if you are happy with the results of this change. Many people will absolutely welcome it ‚Äî but if you are not one of them, don‚Äôt panic. I encourage you to read on to see whether it makes sense to simply turn DATAS off or if a bit of tuning could make it work in your favor.\n\nI‚Äôll talk about how we generally decide which performance features to add, why DATAS is so different from typical GC features, and the tuning changes introduced since my last DATAS blog post. I‚Äôll also share two examples of how I tuned DATAS in first-party scenarios.\n\nIf you‚Äôre mainly here to see which scenarios DATAS isn‚Äôt designed for ‚Äî to help decide whether to turn it off ‚Äî feel free to skip ahead to this section.\n\n## Glossary\n\nBefore diving in, here are the acronyms used throughout this article:\n\n- **GC**: Garbage Collector manages the allocation and release of memory for your application\n- **DATAS**: Dynamic Adaptation To Application Sizes\n- **TCP**: Throughput Cost Percentage ‚Äì measures GC overhead including GC pauses and allocation waits\n- **BCD**: Budget Computed via DATAS ‚Äì the upper bound for generation 0 allocation budget\n- **LDS**: Live Data Size, ie, the application size meaning that if we did the most aggressive GC possible, this is how much memory your application uses\n- **UOH**: User Old Heap, ie, the old generations user code allocates into, this includes LOH and POH.\n- **LOH**: Large Object Heap, for objects ‚â•85,000 bytes, you can change this number with the GCLOHThreshold config\n- **POH**: Pinned Object Heap ‚Äì the area of the heap specifically for objects indicated to be pinned when they are allocated.\n\n## General policies of adding GC performance features\n\nMost GC performance features ‚Äî whether it‚Äôs a new GC flavor, a new mechanism that enables the GC to do something it couldn‚Äôt before, or optimizations that improve an existing mechanism ‚Äî are typically lit up automatically when you upgrade to a new runtime version. We don‚Äôt require users to take action because these features are designed to improve a wide range of scenarios. In fact, that‚Äôs often why we choose to implement them: we analyze many scenarios to understand the most common problems, figure out what it would take to solve them, and then prioritize which ones to design and implement.\n\nOf course, with any performance changes, there‚Äôs always the risk of regressions ‚Äî and for a framework used by millions, you‚Äôre guaranteed to regress someone. These regressions can be especially visible in microbenchmarks, where the behavior is so extreme that even small changes can cause wild swings in results.\n\nA recent example being the change we made in how we handle the free regions for UOH (ie, LOH + POH) generations. We changed from the budget based trimming policy to an age based because it‚Äôs more robust in general (so we don‚Äôt either quickly decommit memory and have to recommit again, or keep extra free regions around even after a long time because we continue not consuming nearly all of the UOH budgets). But this can totally change a microbenchmark that used to observe the primary memory go down to a very low value after one `GC.Collect()` now requires 3 `GC.Collect()` calls (because we have to wait for the UOH free regions to age out in 2 gen2 GCs and the 3rd one will put it on the decommit list).\n\nBut for DATAS, we knew it was by definition not necessarily for a wide range of scenarios. As I mentioned in my last blog post, there were 2 specific kinds of scenarios that DATAS targeted. I‚Äôll reiterate them here ‚Äì\n\n1. Bursty workloads running in memory constraint environments. DATAS aims to retract the heap size back when the application doesn‚Äôt require as much memory and grow it when the app requires more. This is especially important for apps running in containers with memory limits.\n2. Small workloads using Server GC ‚Äî for example, if someone wants to try out a small asp.net core app to see what the experience is like in .NET, DATAS aims to provide a heap size much more inline with what the small app actually needs.\n\nI should give more explanation about 1). It‚Äôs not uncommon to see bursty workloads at all. If you have an app that handles requests, which is completely common, naturally you could have many more users during a specific time of the day than the rest of the day. However, the key here is the action that follows it ‚Äî if you have memory freed up during the non peak hours, what would you do with this memory? It turns out that sometimes folks don‚Äôt actually know ‚Äî they want to see the memory go down when the workload lightens, but they have no plans to do anything with this memory. And for some teams, they don‚Äôt need to the memory usage to go down because they already budgeted all that memory to their apps. I was just talking to a customer recently and when I asked them ‚Äúif DATAS frees up memory for you, what would you use for it?‚Äù. The answer was ‚Äúthat‚Äôs a good question, we never thought about it‚Äù.\n\nFor folks who do want to make use of the freed up memory, a common way is to use an orchestrated environment. DATAS makes this scenario more robust as heap sizes will be much more predictable, as I‚Äôll explain below, which helps with setting sensible memory limits. For example, in k8s, you can determine appropriate request and limit values for both non-peak and peak workloads to better leverage HPA. I have also seen teams that schedule tasks to run when the machines/VMs have free memory ‚Äî this is more involved (and these teams usually are equipped with a team of dedicated perf engineers) but gives them more control.\n\nThen there are plenty of teams that have dedicated fleets of machines and want to maximize their throughput during peak hours as much as possible. They do not want to tolerate any type of slow down. They are definitely not the target of DATAS which will almost always regress their throughput ‚Äî when it comes to perf it‚Äôs rarely an all or none situation and I will discuss below how to make a decision if you should turn DATAS off.\n\nAll these made it difficult to make DATAS the default because we know there are a lot of teams that don‚Äôt want to sacrifice throughput at all or don‚Äôt make use of freed up memory.\n\nI will discuss in detail below if you do want to look at the perf differences and make a decision if DATAS is for you or not (maybe when you see the memory reduction you will have ideas of using the freed up memory).\n\n## Performance differences between DATAS and the traditional Server GC\n\nDATAS is a GC feature that I spent more time explaining to my coworkers than any other ‚Äî being such a user visible feature, it naturally attracted more questions than pretty much any other GC features I added. And there were lots of misconceptions. Some thought that DATAS only affected startup; some assumed it would just ‚Äúreduce memory by x% and throughput by y%‚Äù; some expected it to ‚Äúmagically reducing memory without any other perf differences‚Äù (okay, I added the ‚Äúmagically‚Äù part üòÜ); and etc.\n\nTo understand the differences properly, we need to understand the difference in policies. First and foremost, Server GC does not adapt to the application size ‚Äî it was never a goal. Server GC looks mostly at the survival rate of each generation and does GCs based on that (there are a number of other factors that affect when GCs are triggered but survival rate is one of the most significant). In the last DATAS post I talked about the number of heaps which can affect the heap size significantly, especially in workloads that allocate a lot of temporary data. Since Server GC creates the same number of heaps as the number of cores the process is allowed to use, it means you can see very different heap sizes when running the same app with a different number of cores (by running it on a machine with a different number of cores or let your process use different number of cores on the same machine).\n\nDATAS, on the other hand, aims to adapt to the application size which means you should see similar heap sizes even when the number of cores varies a lot. So there‚Äôs no ‚ÄúDATAS will reduce memory by X%‚Äù compared to Server GC.\n\nIf we look at the ‚ÄúMax heap size‚Äù metric for asp.net benchmarks, it‚Äôs obvious that Server GC behaves very differently when running on a 28-core machine (28c) vs a 12-core machine (12c) ‚Äì\n\n![Max heap size 28c vs 12c (Server GC) before DATAS](https://devblogs.microsoft.com/dotnet/wp-content/uploads/sites/10/2025/09/1.webp)\n\nCareful readers will notice that the order of which color is on top is not consistent. For example, for MultipleQueriesPlatform, the max heap size is actually much larger for 12c than 28c. Looking at the data in more detail reveals that the max heap size happens at the very beginning of the test for the 12c case ‚Äì\n\n![Early phase heap size spike 12-core vs 28-core run](https://devblogs.microsoft.com/dotnet/wp-content/uploads/sites/10/2025/09/2.webp)\n\n(Heap size (before) is right before a GC before that GC could possibly shrink the heap size. So ‚ÄúMax Heap Size‚Äù would be the max of this metric)\n\nThis is because at the beginning, there were a lot more allocations happened before the first GC happened on 28c with 28 heaps. So after that GC, a smaller survival rate was observed which caused the gen0 budget to be much smaller than on 12c. 12c quickly dropped to the steady state which has a much lower heap size than 28c. For steady state, these benchmarks always exhibit a much higher heap size on 28c. This illustrates 2 points ‚Äìif you just measure ‚Äúmax heap size‚Äù, it can easily be affected by the non-steady state behavior; secondly, the heap size can vary a lot due to the machine the test runs on. Note that these effects can be magnified because we are looking at small benchmarks, but the reasoning applies to real-world apps.\n\nWith DATAS we see this picture ‚Äì\n\n![Max heap sizes similar with DATAS on 28c vs 12c](https://devblogs.microsoft.com/dotnet/wp-content/uploads/sites/10/2025/09/3.webp)\n\nThe max heap sizes are very similar on 28c and 12c which is exactly what DATAS is for ‚Äî it adapts to the application size.\n\n### Do I need to care if I‚Äôm using Workstation GC?\n\nThe answer depends on why you are using Workstation GC. If you are using Workstation GC because your workload simply does not call for using Server GC at all, then there‚Äôs no need to change. This could be due to your app being single threaded or the allocation is simply not stressful and you are totally fine with having one thread doing the collection work, in which case Workstation GC not only suffices but is exactly the correct choice to make.\n\nBut if you are using it because Server GC‚Äôs memory usage was too large and you are just using Workstation to limit the memory usage, you could find DATAS very attractive because it can both limit the memory usage and make the GC pauses lower with more GC threads doing the collection work.\n\n## How DATAS does its job\n\nIf you understood how DATAS does it job, it would be natural to arrive at the recommendations below for deciding if DATAS is for you. You could also skip this section, but I always like to understand how something works if I care about it, so I can come to my own conclusions instead of just memorizing some rules. In the last blog post I mentioned some details of DATAS at the time (.NET 8), noting that it would likely change dramatically ‚Äî and it did, both in design and implementation. The implementation we had in .NET 8 was mostly for functional ‚Äî we spent very little time in tuning. The majority of the tuning work happened after .NET 8.\n\nThe goal of DATAS is to adapt to the application size, or the LDS (Live Data Size). So there needs to be some way to adapt to it. Because the .NET GC is generational, it means we don‚Äôt collect the whole heap often. And since most full GCs we do are background GCs which don‚Äôt compact, it‚Äôs reasonable to approximate the LDS with the space objects take up in the old generations, i.e., (total size ‚Äî fragmentation). Another convenient number to use when you do your perf investigations is to look at the promoted size when a full GC is done.\n\nIn the last blog post I mentioned the [conserve memory](https://learn.microsoft.com/dotnet/core/runtime-config/garbage-collector#conserve-memory) config is part of the DATAS implementation ‚Äî that part did not change. But conserve memory only affects when full GCs are triggered. For apps that allocate very frequently, unless these are temporary UOH objects, most of the GCs are ephemeral GCs. And ephemeral generation sizes can be a significant portion of the whole heap especially for small heaps.\n\nAfter experimenting with various approaches, I settled on the approach of ‚Äúadapting to the app size while maintaining reasonable performance‚Äù which consisted of 2 key components ‚Äì\n\n1) introduced a concept of ‚ÄúBudget Computed via DATAS (BCD)‚Äù which is calculated based on the application size and gives us an upper bound of the gen0 budget for that size, which can approximate the generation size for gen0 (since there‚Äôs pinning it may not be exactly the generation size for gen0).\n\n2) within this upper bound, we can further reduce memory if we can still maintain reasonable performance. And we define this ‚Äúreasonable performance‚Äù with a target Throughput Cost Percentage (TCP). This takes into consideration both GC pauses and how much allocating threads have to wait. But you can approximate TCP with % pause time in GC in steady state. The idea is to keep TCP around this target if we can, which means if the workload gets lighter, we‚Äôd be adjusting the gen0 budget smaller. And that in turn means gen0 will be smaller before the next GC, which translates to smaller heap size. The default target TCP is 2%. This can be changed via the [GCDTargetTCP](https://learn.microsoft.com/dotnet/core/runtime-config/garbage-collector#target-tcp) config.\n\nLet‚Äôs look at 2 example scenarios to see how this manifests. For simplicity, I‚Äôm ignoring background GCs, and I‚Äôll use % pause time in GC to approximate TCP.\n\n**Scenario A** ‚Äî I have an e-commerce app which stores the whole catalog in memory, and this remains the same during the process lifetime. This is our LDS. Now the process starts to process requests and for each request there‚Äôs memory allocated and only used for the duration of that request.\n\nDuring peak hours, it processes many concurrent requests. We hit our max budget which is our BCD. Let‚Äôs say this is 1gb, it means we are doing a GC each time 1GB is allocated. If we use the % pause time in GC to approximate TCP, let‚Äôs say during each second it allocates 1GB and observes one GC that has a 20ms pause. So the % time in GC is 2%. And that‚Äôs the same as our target TCP.\n\nWhen it‚Äôs outside the peak hours and handling way fewer concurrent requests, let‚Äôs say we allocate ~200MB per second. If we keep our 1GB budget, it means we are doing a GC every 5s. And our % time in GC would be (20ms / 5s = 0.4%), much lower than 2%. So to reach the target TCP we‚Äôd want to reduce the budget and trigger a GC much sooner. If we reduce the budget to 200MB, and we‚Äôll still use 20ms as our GC pause just to make it simple (it‚Äôll likely be shorter as it‚Äôs roughly proportional to the survival and there‚Äôs likely less survival out of 200MB vs 1GB), now we are achieving 2% TCP again.\n\nSo for this scenario, the heap size is reduced by ~800MB when it‚Äôs outside peak hours. Depending on your total heap size, this can be a very significant reduction.\n\n**Scenario B** is built on top of A but we‚Äôll throw in a cache that‚Äôs part of the LDS but gets smaller during lighter workload as we don‚Äôt need to cache as much. Because the LDS is smaller it means your BCD will be smaller as it‚Äôs a function of LDS. So during the lighter workload, the gen0 budget will be further reduced which again reflects the adapting to size nature. The conserve memory mechanism is still in effect too and would adjust the old generation budget and size accordingly.\n\nNotice that so far I have not talked about the number of heaps at all! This is completely taken care of by DATAS itself so you don‚Äôt need to worry about it. Previously, some of our customers were using the [GCHeapCount](https://learn.microsoft.com/dotnet/core/runtime-config/garbage-collector#heap-count) config to specify the number of heaps for Server GC. But DATAS makes it more robust as it can take advantage of more heaps if needed (which usually means shorter individual pause times) and reduces the heap size when the LDS goes down, without your having to specify a heap count yourself.\n\nDATAS has specific events that indicate the actual TCP and LDS but that requires you to programmatically get them via the TraceEvent library. The approximations I mentioned above are sufficient for almost all perf investigations.\n\n## When DATAS might not be applicable to your scenario\n\nIf you read the previous sections, what‚Äôs listed below hopefully makes sense.\n\n1. If you have no use for free memory, you don‚Äôt need DATAS\n\nThis one should be obvious ‚Äî why change it at all if you don‚Äôt have any use for the memory that gets freed up by DATAS anyway? You can turn DATAS off by the [GCDynamicAdaptationMode](https://learn.microsoft.com/dotnet/core/runtime-config/garbage-collector#enabling-or-disabling-datas) config.\n\nI‚Äôve come across a few first party teams who simply didn‚Äôt need DATAS ‚Äî they have dedicated machines to run their processes and have no use for free memory as they don‚Äôt plan to run anything else on the machine. So they have no use for DATAS. One team did say ‚Äúnow we probably want to think about taking advantage of free memory‚Äù (they were not thinking about it because Server GC isn‚Äôt aggressive at reducing memory usage). So for them, they will disable DATAS for now but will enable it when they can take advantage of memory during non peak hours.\n2. If startup perf is critical, DATAS is not for you\n\nDATAS always starts with 1 heap. We cannot predict how stressful your workload will be and since we are optimizing for size here, it starts with the smallest heap count which is 1. So if your startup perf is critical, you will see a regression because it takes time to go from 1 heap to multiple.\n3. If you do not tolerate any throughput regression, DATAS may not be for you\n\nIf this includes the startup throughput, as 2) also states, DATAS is not for you. However, some scenarios aren‚Äôt concerned with startup perf so DATAS may or may not be desirable. Let‚Äôs say your % pause time in GC is 1% with Server GC, you can just set the [GCDTargetTCP](https://learn.microsoft.com/dotnet/core/runtime-config/garbage-collector#target-tcp) config to 1. If you were restricting the heap count you could very possibly see a perf improvement because the pause time can be shorter with DATAS. If the adaptation to the size aspect is beneficial to you, using DATAS can be a much better choice. But as stated in 1) if you don‚Äôt have any use for the freed up memory anyway, it wouldn‚Äôt justify spending time on using DATAS.\n4. If you are doing mostly gen2 GCs, DATAS may not be for you\n\nOne case I haven‚Äôt spent much time tuning is when your scenario mostly does gen2 GCs (this is almost always due to excessive allocation of temporary large objects). If this is the case for you, and if you‚Äôve tried DATAS and weren‚Äôt happy with the results, I would suggest to disable DATAS. You could investigate to see if you can make it work by following the tuning section if it‚Äôs justified to spend the time.\n\n## Tuning DATAS if necessary\n\nI‚Äôve tried DATAS on some first party workloads and in general it worked out great. I‚Äôll show a couple of examples where the default parameters of DATAS weren‚Äôt great but tuning one or 2 configs made it work.\n\n### Customer case 1\n\nThis is a server app running on dedicated machines. But they are in the process of containerizing it so there‚Äôs definitely merit to use DATAS. With DATAS they observed a 6.8% regression in throughput with a 10% reduction in working set. For now they‚Äôve disabled DATAS ‚Äî I will explain how I debugged it and determined what DATAS config to use to make it work if/when they want to enable DATAS.\n\nBecause DATAS limits the largest gen0 budget based on the LDS, we want to see if we are hitting that limit. It‚Äôd be easiest if you captured a GC trace with DATAS and one without DATAS. If you are seeing more GCs triggered, that means most likely you are hitting that limit.\n\nYou can approximate the TCP with what‚Äôs shown in the ‚Äú% Pause Time‚Äù column, and gen0 budget with the ‚ÄúGen0 Alloc MB‚Äù column. And you‚Äôd want to find the phase when you have the highest % pause time and see if you are triggering more GCs.\n\nSo for this particular customer, here are some excerpts of the GC (I‚Äôve trimmed down the columns of the GCStats view) ‚Äì\n\nWithout DATAS\n\n| GC index | Trigger reason | Gen | % pause time | Gen0 Alloc (MB) | Promoted (MB) | | --- | --- | --- | --- | --- | --- | | 7017 | AllocSmall | 0N | 0.7 | 4,243.75 | 382.855 | | 7018 | AllocSmall | 1N | 1.2 | 4,157.85 | 1,074.82 | | 7019 | AllocSmall | 0N | 0.8 | 4,218.46 | 484.276 | | 7020 | AllocSmall | 1N | 2.0 | 4,249.86 | 1,072.56 | | 7021 | AllocSmall | 0N | 1.5 | 4,258.12 | 453.534 | | 7022 | AllocSmall | 1N | 1.8 | 4,244.21 | 1,026.41 | | 7023 | AllocSmall | 0N | 1.0 | 4,254.77 | 461.702 | | 7024 | AllocSmall | 1N | 1.4 | 4,239.38 | 992.243 | | 7025 | AllocSmall | 0N | 1.0 | 4,252.54 | 465.904 | | 7026 | AllocSmall | 1N | 2.5 | 4,252.47 | 1,153.60 | | 7027 | AllocSmall | 0N | 1.7 | 4,216.14 | 442.233 | | 7028 | AllocSmall | 2B | 0.3 | 0 | 15,039.20 | | 7029 | AllocSmall | 0N | 0.6 | 4,166.23 | 411.238 | | 7030 | AllocSmall | 1N | 1.0 | 4,104.28 | 681.430 | | 7031 | AllocSmall | 0N | 1.4 | 4,229.11 | 582.256 | | 7032 | AllocSmall | 1N | 1.1 | 4,222.06 | 963.817 | | 7033 | AllocSmall | 0N | 1.5 | 4,248.45 | 463.555 | | 7034 | AllocSmall | 1N | 1.1 | 4,230.40 | 889.286 | | 7035 | AllocSmall | 0N | 0.8 | 4,255.81 | 467.854 | | 7036 | AllocSmall | 1N | 1.4 | 4,254.73 | 926.103 | | 7037 | AllocSmall | 0N | 2.3 | 4,220.31 | 448.918 | | 7038 | AllocSmall | 1N | 1.2 | 4,249.19 | 963.297 |\n\nWith DATAS\n\n| GC index | Trigger reason | Gen | % pause time | Gen0 Alloc (MB) | Promoted (MB) | | --- | --- | --- | --- | --- | --- | | 17632 | AllocSmall | 0N | 2.6 | 1,645.46 | 236.155 | | 17633 | AllocSmall | 1N | 1.9 | 1,637.37 | 430.244 | | 17634 | AllocSmall | 0N | 1.4 | 1,648.58 | 228.611 | | 17635 | AllocSmall | 1N | 1.8 | 1,633.46 | 461.741 | | 17636 | AllocSmall | 0N | 3.8 | 1,644.98 | 257.461 | | 17637 | AllocSmall | 1N | 2.6 | 1,646.77 | 492.176 | | 17638 | AllocSmall | 0N | 1.5 | 1,650.46 | 217.604 | | 17639 | AllocSmall | 1N | 2.2 | 1,652.98 | 446.634 | | 17640 | AllocSmall | 0N | 2.0 | 1,647.49 | 176.047 | | 17641 | AllocSmall | 1N | 2.2 | 1,638.71 | 495.137 | | 17642 | AllocSmall | 0N | 1.3 | 1,643.52 | 194.353 | | 17643 | AllocSmall | 1N | 4.1 | 1,589.32 | 451.100 | | 17644 | AllocSmall | 0N | 2.8 | 1,645.70 | 220.343 | | 17645 | AllocSmall | 1N | 2.4 | 1,644.41 | 479.159 | | 17646 | AllocSmall | 0N | 1.1 | 1,642.08 | 229.877 | | 17647 | AllocSmall | 1N | 1.2 | 1,638.72 | 436.051 | | 17648 | AllocSmall | 0N | 1.2 | 1,653.15 | 158.115 | | 17649 | AllocSmall | 1N | 1.5 | 1,648.69 | 487.923 | | 17650 | AllocSmall | 0N | 1.6 | 1,649.91 | 211.391 | | 17651 | AllocSmall | 1N | 5.2 | 1,624.07 | 412.570 | | 17652 | AllocSmall | 0N | 1.9 | 1,644.00 | 213.895 | | 17653 | AllocSmall | 2B | 0.3 | 0 | 14,936.54 |\n\nComparing their gen0 budget and % pause time in GC ‚Äì\n\n| Metric | no DATAS | DATAS | no DATAS / DATAS | | --- | --- | --- | --- | | gen0 budget (GB) | 4.22 | 1.64 | 2.6 | | % pause time | 1.2 | 2.1 | 0.6 |\n\nSo gen0 budget without DATAS is 2.6x with DATAS. Another useful thing we notice is the % Pause Time is basically exactly the target TCP ‚Äî 2%. That tells us that this is working exactly as by design from DATAS‚Äôs POV. But without DATAS we got 2.6x budget so naturally we triggered GC less frequently and % pause time is 1.2 instead of 2.1.\n\nBut if we want to enable DATAS and not regress throughput for this phase, we‚Äôd like to have DATAS use a larger gen0 budget. To do that we should understand how DATAS determines the BCD. Since we are adapting to the size, we want to multiply the size with something. But this should not be a constant value because when the size is very small, this multiplier should be quite large ‚Äî if the LDS is only 2MB (which is totally possible for a tiny app), we wouldn‚Äôt want to trigger a GC for every 0.2MB of allocation ‚Äî the overhead would be too high. Let‚Äôs say we want to allow 20MB of allocation before triggering a GC, that makes the multiplier 10. But if the LDS is 20GB, we wouldn‚Äôt want to allocate 200GB before doing a GC, which means we want a much smaller multiplier. This means a power function but we also want to clamp it between a min and max value ‚Äì\n\n```csharp m = constant / sqrt (LDS); // default for max_m is 10 m = min (max_m, m); // default for min_m is 0.1 m = max (min_m, m); ```\n\nThe actual formula for the power function is\n\n```csharp m = (20 - conserve_memory) / sqrt (LDS / 1000 / 1000); ```\n\nwhich can be simplified to\n\n```csharp m = (20 - conserve_memory) * 1000 / sqrt (LDS); m = (20 - 5) * 1000 / sqrt (LDS); m = 15000 / sqrt (LDS); ```\n\nSo the constant is 15000, or we could just say it‚Äôs 15 if we use MB for size. here‚Äôre some example with different LDS ‚Äì\n\n| LDS (MB) | m | m clamped | BCD (MB) | | --- | --- | --- | --- | | 1 | 15.00 | 10.00 | 10 | | 5 | 6.71 | 6.71 | 34 | | 10 | 4.74 | 4.74 | 47 | | 50 | 2.12 | 2.12 | 106 | | 100 | 1.50 | 1.50 | 150 | | 500 | 0.67 | 0.67 | 335 | | 1,000 | 0.47 | 0.47 | 474 | | 5,000 | 0.21 | 0.21 | 1,061 | | 10,000 | 0.15 | 0.15 | 1,500 | | 15,000 | 0.12 | 0.12 | 1,837 | | 30,000 | 0.09 | 0.10 | 3,000 | | 50,000 | 0.07 | 0.10 | 5,000 |\n\n[https://gist.github.com/Maoni0/15064a505db2d06189a875d4b7e9e211/raw/2153a4f57c1d5c30401dd796573e553bb8f4cb36/bcd.csv](https://gist.github.com/Maoni0/15064a505db2d06189a875d4b7e9e211/raw/2153a4f57c1d5c30401dd796573e553bb8f4cb36/bcd.csv)\n\nThis constant, max\\_m and min\\_m can all be adjusted by configs. Please see the config page for detailed explanation.\n\nNow it‚Äôs quite obvious why DATAS came up with the gen0 budget and how we can adjust it. If we want to bring this up to the same budget without DATAS, we‚Äôd want to use the [GCDGen0GrowthPercent](https://learn.microsoft.com/dotnet/core/runtime-config/garbage-collector#gen0-max-budget-settings) config to increase the constant to 2.6x, and increase min\\_m with the [GCDGen0GrowthMinFactor](https://learn.microsoft.com/dotnet/core/runtime-config/garbage-collector#gen0-max-budget-settings) config so it‚Äôs not clamped to 0.1 ‚Äî you don‚Äôt need to be very accurate since you just need to make it not be the limiting factor. So in this case if we use 15GB to approximate the LDS (the ‚ÄúPromoted (mb)‚Äù column for both gen2 GCs says ~15GB), and without DATAS the gen0 budget is 4.22GB. So min\\_m should be around (4.22/15 = 0.28). We can just set min\\_m to 300 which translates to 0.3 of LDS.\n\n### Customer case 2\n\nThis is an asp.net app on a staging server from the customer that represents one of their key scenarios. I used a load test tool to generate variable workloads.\n\nThe team was already using some GC configs ‚Äì\n\n¬∑ [GCHeapCount](https://learn.microsoft.com/dotnet/core/runtime-config/garbage-collector#heap-count) is set to 2 to use 2 heaps\n\n¬∑ Affinity is turned off with the [GCNoAffinitize](https://learn.microsoft.com/dotnet/core/runtime-config/garbage-collector#affinitize) config.\n\nIf the [GCHeapCount](https://learn.microsoft.com/dotnet/core/runtime-config/garbage-collector#heap-count) config is specified, DATAS would be disabled because it‚Äôs telling the GC to not change the heap count. And since changing the heap count is one of the key mechanisms to adjust perf for DATAS, it‚Äôs an indication to disable DATAS.\n\nBecause this is a process that co-exist with many others on the same machine, before DATAS was available they chose to give it 2 heaps to limit the memory usage while still getting reasonable throughput. But this is not flexible ‚Äî when the load becomes higher the throughput can suffer with 2 heaps and also the GC pauses can be noticeably higher since there‚Äôs only 2 GC threads collecting. They can adjust the number of GC heaps but that means more work and since Server GC isn‚Äôt very aggressive at reducing memory usage they can end up with a much bigger heap than desired when the load is lighter.\n\nI‚Äôll demonstrate how using DATAS makes this robust. When I made the load pretty high I could see that % pause time in GC is quite high ‚Äî not surprising with just 2 heaps. So I enabled DATAS by simply getting rid of the [GCHeapCount](https://learn.microsoft.com/dotnet/core/runtime-config/garbage-collector#heap-count) config (I kept the [GCNoAffinitize](https://learn.microsoft.com/dotnet/core/runtime-config/garbage-collector#affinitize) config as I still wanted the GC threads to not be affinitized). I could see the % pause time in GC was also high because even with BCD we still ended up triggering GCs quite often. So I decided to make BCD 2x the default value with the [GCDGen0GrowthPercent](https://learn.microsoft.com/dotnet/core/runtime-config/garbage-collector#gen0-max-budget-settings) config (I didn‚Äôt need to use the [GCDGen0GrowthMinFactor](https://learn.microsoft.com/dotnet/core/runtime-config/garbage-collector#gen0-max-budget-settings) config since 2x is still well within our max\\_m/min\\_m clamping values). And now the process behaves in a much more desirable way with the following characteristics ‚Äì\n\nthe % pause time is dramatically lower. With the default DATAS the % pause time is basically comparable and the heap size is noticeably lower. Depending on your optimization goal this could be exactly what you want. DATAS is able to achieve this with smaller budgets and more GC threads doing the collection work. But I know for this customer, they don‚Äôt want % pause time in GC to be this high as it affects their throughput. I could also make DATAS use a smaller target TCP but in this case the default TCP seems quite sufficient. ![Customer case 2 baseline: higher % pause time with 2 heaps](https://devblogs.microsoft.com/dotnet/wp-content/uploads/sites/10/2025/09/4.webp)\n\n![Customer case 2 with DATAS: reduced % pause time after tuning](https://devblogs.microsoft.com/dotnet/wp-content/uploads/sites/10/2025/09/5.webp)\n\nindividual GC pauses are a lot lower since we have a lot more GC threads collecting. ![Customer case 2: individual GC pauses lower with more GC threads](https://devblogs.microsoft.com/dotnet/wp-content/uploads/sites/10/2025/09/6.webp)\n\nwhen the load becomes lighter (# of concurrent client threads went from 200 to 100), the heap also becomes smaller. And we are still maintaining a much lower % pause time in GC and individual GC pauses. ![Customer case 2: heap smaller after workload lightens (200 -&gt; 100 threads)](https://devblogs.microsoft.com/dotnet/wp-content/uploads/sites/10/2025/09/7.webp)\n\n![Customer case 2: sustained lower pause and pause times after load reduction](https://devblogs.microsoft.com/dotnet/wp-content/uploads/sites/10/2025/09/8.webp)\n\nI hope this helps with your DATAS tuning, if you need to do any.\n\n## DATAS Events\n\nI expect most users never needing to look at these events, so I‚Äôll keep it brief. The approximations that I mentioned above should suffice. For the small number of folks who want to do a detailed analysis for whatever reason, DATAS fires an event that accurately represents the metrics we discussed. Note that we only use these events programmatically, so they are not surfaced in PerfView‚Äôs Events view (all you‚Äôll see is the GC/DynamicTraceEvent which shows you the name but not individual fields of that event). See this blog article for an example how to programmatically retrieve GC info as a list of TraceGC objects from a trace.\n\nLDS and TCP are indicated in the SizeAdaptationTuning event, assuming you have a gc object of the type TraceGC ‚Äî\n\n```csharp // LDS gc.DynamicEvents().SizeAdaptationTuning?.TotalSOHStableSize // TCP gc.DynamicEvents().SizeAdaptationTuning?.TcpToConsider ```\n\nThis event is not fired every GC since we only check to see if we need to change the tuning for DATAS every few GCs.",
  "Link": "https://devblogs.microsoft.com/dotnet/preparing-for-dotnet-10-gc/",
  "OutputDir": "_news",
  "ProcessedDate": "2025-10-08 17:02:38",
  "Tags": [
    ".NET",
    "DATAS",
    "GC",
    "Memory",
    "Performance",
    "Throughput",
    "Tuning"
  ],
  "FeedName": "Microsoft .NET Blog",
  "FeedUrl": "https://devblogs.microsoft.com/dotnet/feed/",
  "Description": "Learn how DATAS in .NET 10 adapts heap size, what changes to expect versus previous Server Garbage Collection (GC) behavior, and how to decide whether to tune or disable it.\n\nThe post [Preparing for the .NET 10 GC (DATAS)](https://devblogs.microsoft.com/dotnet/preparing-for-dotnet-10-gc/) appeared first on [.NET Blog](https://devblogs.microsoft.com/dotnet).",
  "Author": "maoni",
  "Title": "Preparing for the .NET 10 GC (DATAS)"
}
