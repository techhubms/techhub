{
  "OutputDir": "_news",
  "Title": "Semantic Kernel Python Gets a Major Vector Store Upgrade",
  "FeedUrl": "https://devblogs.microsoft.com/semantic-kernel/feed/",
  "Link": "https://devblogs.microsoft.com/semantic-kernel/semantic-kernel-python-gets-a-major-vector-store-upgrade/",
  "Author": "Eduard van Valkenburg",
  "ProcessedDate": "2025-08-05 07:57:56",
  "EnhancedContent": "Weâ€™re excited to announce a significant update to Semantic Kernel Pythonâ€™s vector store implementation. Version 1.34 brings a complete overhaul that makes working with vector data simpler, more intuitive, and more powerful. This update consolidates the API, improves developer experience, and adds new capabilities that streamline AI development workflows.\n\n## What Makes This Release Special?\n\nThe new vector store architecture consolidates everything under `semantic_kernel.data.vector` and delivers three key improvements:\n\n1. **Simplified API**: One unified field model replaces multiple complex field types\n2. **Integrated Embeddings**: Embedding generation happens automatically where you need it\n3. **Enhanced Features**: Advanced filtering, hybrid search, and streamlined operations\n\nLetâ€™s explore what makes these changes valuable.\n\n## Unified Field Model â€“ Simplified Configuration\n\nWeâ€™ve replaced three separate field types with one powerful `VectorStoreField` class that handles everything you need.\n\n### Before: The Old Way (Complex and Verbose)\n\n```py from semantic_kernel.data import ( VectorStoreRecordKeyField, VectorStoreRecordDataField, VectorStoreRecordVectorField )\n\n# Multiple classes to remember and configure\nfields = [ VectorStoreRecordKeyField(name=\"id\"), VectorStoreRecordDataField(name=\"text\", is_filterable=True, is_full_text_searchable=True), VectorStoreRecordVectorField(name=\"vector\", dimensions=1536, distance_function=\"cosine\") ]\n\n```\n\n### After: The New Way (Clean and Intuitive)\n\n```py from semantic_kernel.data.vector import VectorStoreField from semantic_kernel.connectors.ai.open_ai import OpenAITextEmbedding\n\nembedding_service = OpenAITextEmbedding(ai_model_id=\"text-embedding-3-small\")\n\n# One class handles all field types\nfields = [ VectorStoreField(\"key\", name=\"id\"), VectorStoreField(\"data\", name=\"text\", is_indexed=True, is_full_text_indexed=True), VectorStoreField(\"vector\", name=\"vector\", dimensions=1536, distance_function=\"cosine\", embedding_generator=embedding_service) ]\n\n```\n\nThis approach provides cleaner code with better IDE support, including improved autocomplete and clearer intentions.\n\n## Integrated Embeddings â€“ Automatic Generation\n\nThe new architecture includes automatic embedding generation directly in your field definitions. No more manual embedding stepsâ€”just define what you want embedded, and it happens automatically.\n\n```py from semantic_kernel.data.vector import VectorStoreField, vectorstoremodel from semantic_kernel.connectors.ai.open_ai import OpenAITextEmbedding from typing import Annotated from dataclasses import dataclass\n\n@vectorstoremodel @dataclass class MyRecord: content: Annotated[str, VectorStoreField('data', is_indexed=True, is_full_text_indexed=True)] title: Annotated[str, VectorStoreField('data', is_indexed=True, is_full_text_indexed=True)] id: Annotated[str, VectorStoreField('key')] vector: Annotated[list[float] | str | None, VectorStoreField( 'vector', dimensions=1536, distance_function=\"cosine\", embedding_generator=OpenAITextEmbedding(ai_model_id=\"text-embedding-3-small\"), )] = None\n\ndef __post_init__(self): if self.vector is None:\n# Combine multiple fields for richer embeddings\nself.vector = f\"Title: {self.title}, Content: {self.content}\"\n\n```\n\nYou can now easily combine multiple fields to create richer embeddings with simple field assignment.\n\n## Lambda-Powered Filtering â€“ Type-Safe and Expressive\n\nThe new filtering system uses lambda expressions that are type-safe, IDE-friendly, and highly expressive, replacing the previous string-based `FilterClause` objects.\n\n### Before: String-Based Complexity\n\n```py from semantic_kernel.data.text_search import SearchFilter\n\n# Multiple objects and method calls\ntext_filter = SearchFilter() text_filter.equal_to(\"category\", \"AI\") text_filter.equal_to(\"status\", \"active\")\n\n```\n\n### After: Lambda Expression Power\n\n```py\n# Clean, readable, and type-safe\nresults = await collection.search( \"query text\", filter=lambda record: record.category == \"AI\" and record.status == \"active\" )\n\n# Complex filtering with multiple conditions\nresults = await collection.search( \"machine learning concepts\", filter=lambda record: ( record.category == \"AI\" and record.score > 0.8 and \"important\" in record.tags and 0.5 <= record.confidence_score <= 0.9 ) )\n\n```\n\nYour IDE can now provide full autocomplete support and catch errors at development time.\n\n## Streamlined Operations â€“ Consistent Interface\n\nThe new API provides a consistent interface that works with both single records and batches:\n\n```py from semantic_kernel.connectors.in_memory import InMemoryCollection\n\ncollection = InMemoryCollection( record_type=MyRecord, embedding_generator=OpenAITextEmbedding(ai_model_id=\"text-embedding-3-small\") )\n\n# Single record or batch - same method\nawait collection.upsert(single_record) await collection.upsert([record1, record2, record3])\n\n# Flexible retrieval\nawait collection.get([\"id1\", \"id2\"]) # Get specific records await collection.get(top=10, skip=0, order_by='title') # Browse with pagination\n\n# Powerful search with automatic embedding\nresults = await collection.search(\"find AI articles\", top=10) results = await collection.hybrid_search(\"machine learning\", top=10)\n\n```\n\n## Instant Search Functions â€“ Simplified Creation\n\nCreating search functions for your kernel is now straightforward:\n\n### Before: Multiple Steps and Setup\n\n```py from semantic_kernel.data import VectorStoreTextSearch\n\ncollection = InMemoryCollection(collection_name='collection', record_type=MyRecord) search = VectorStoreTextSearch.from_vectorized_search( vectorized_search=collection, embedding_generator=OpenAITextEmbedding(ai_model_id=\"text-embedding-3-small\") ) search_function = search.create_search(function_name='search')\n\n```\n\n### After: Streamlined Creation\n\n```py\n# Create a search function directly on your collection\nsearch_function = collection.create_search_function( function_name=\"search\", search_type=\"vector\", # or \"keyword_hybrid\" top=10, vector_property_name=\"vector\" )\n\n# Add to kernel\nkernel.add_function(plugin_name=\"memory\", function=search_function)\n\n```\n\n## Enhanced Data Model Expressiveness\n\nThe simplified API doesnâ€™t sacrifice expressiveness. Data models are more capable than before:\n\n```py @vectorstoremodel(collection_name=\"documents\") @dataclass class DocumentRecord:\n# Rich metadata\nid: Annotated[str, VectorStoreField('key')] title: Annotated[str, VectorStoreField('data', is_indexed=True, is_full_text_indexed=True)] content: Annotated[str, VectorStoreField('data', is_full_text_indexed=True)] category: Annotated[str, VectorStoreField('data', is_indexed=True)] tags: Annotated[list[str], VectorStoreField('data', is_indexed=True)] created_date: Annotated[datetime, VectorStoreField('data', is_indexed=True)] confidence_score: Annotated[float, VectorStoreField('data', is_indexed=True)]\n\n# Multiple vectors for different purposes\ncontent_vector: Annotated[list[float] | str | None, VectorStoreField( 'vector', dimensions=1536, storage_name=\"content_embedding\", embedding_generator=OpenAITextEmbedding(ai_model_id=\"text-embedding-3-small\") )] = None\n\ntitle_vector: Annotated[list[float] | str | None, VectorStoreField( 'vector', dimensions=1536, storage_name=\"title_embedding\", embedding_generator=OpenAITextEmbedding(ai_model_id=\"text-embedding-3-small\") )] = None\n\ndef __post_init__(self): if self.content_vector is None: self.content_vector = self.content if self.title_vector is None: self.title_vector = self.title\n\n```\n\n## Better Connector Experience\n\nWeâ€™ve also streamlined the connector imports and naming. Everything is now logically organized under `semantic_kernel.connectors` :\n\n```py\n# Clean, consistent imports\nfrom semantic_kernel.connectors.azure_ai_search import AzureAISearchStore from semantic_kernel.connectors.chroma import ChromaVectorStore from semantic_kernel.connectors.pinecone import PineconeVectorStore from semantic_kernel.connectors.qdrant import QdrantVectorStore\n\n# Or use the convenient lazy loading\nfrom semantic_kernel.connectors.memory import ( AzureAISearchStore, ChromaVectorStore, PineconeVectorStore, QdrantVectorStore )\n\n```\n\n## Real-World Example: Complete Implementation\n\nHereâ€™s how a complete example looks with the new architecture:\n\n### The New Way (Simple and Powerful)\n\n```py from semantic_kernel.data.vector import VectorStoreField, vectorstoremodel from semantic_kernel.connectors.in_memory import InMemoryCollection from semantic_kernel.connectors.ai.open_ai import OpenAITextEmbedding from typing import Annotated from dataclasses import dataclass\n\n@vectorstoremodel(collection_name=\"knowledge_base\") @dataclass class KnowledgeBase: id: Annotated[str, VectorStoreField('key')] content: Annotated[str, VectorStoreField('data', is_full_text_indexed=True)] category: Annotated[str, VectorStoreField('data', is_indexed=True)] vector: Annotated[list[float] | str | None, VectorStoreField( 'vector', dimensions=1536, embedding_generator=OpenAITextEmbedding(ai_model_id=\"text-embedding-3-small\") )] = None\n\ndef __post_init__(self): if self.vector is None: self.vector = self.content\n\n# Create collection with automatic embedding\nasync with InMemoryCollection(record_type=KnowledgeBase) as collection: await collection.ensure_collection_exists()\n\n# Add documents (embeddings created automatically)\ndocs = [ KnowledgeBase(id=\"1\", content=\"Semantic Kernel is awesome\", category=\"general\"), KnowledgeBase(id=\"2\", content=\"Python makes AI development easy\", category=\"programming\"), ] await collection.upsert(docs)\n\n# Search with intelligent filtering\nresults = await collection.search( \"AI development\", top=5, filter=lambda doc: doc.category == \"programming\" )\n\n# Create kernel search function\nsearch_func = collection.create_search_function(\"knowledge_search\", search_type=\"vector\") kernel.add_function(plugin_name=\"kb\", function=search_func)\n\n```\n\n## What This Means for Your Projects\n\nThis update brings several concrete benefits:\n\n- **Faster Development**: Less boilerplate, more focus on your AI logic\n- **Better Maintainability**: Clearer code thatâ€™s easier to understand and modify\n- **Enhanced Performance**: Built-in optimizations and batch operations\n- **Future-Proof Architecture**: Aligned with .NET SDK for consistent cross-platform development\n- **Richer Functionality**: Hybrid search, advanced filtering, and integrated embeddings\n\n## Ready to Upgrade?\n\nThe migration path is well-documented ([here](https://learn.microsoft.com/en-us/semantic-kernel/support/migration/vectorstore-python-june-2025)), and the benefits are immediate. Check out the comprehensive migration guide and explore the updated samples in `samples/concepts/memory/` to see these changes in action.\n\nThis release represents a significant step forward in making vector search more accessible and powerful while maintaining the flexibility developers need for sophisticated AI applications.\n\nAs part of this release we have also marked the following things as deprecated, MemoryStore abstractions, MemoryStore implementations, Semantic Text Memory and the TextMemoryPlugin. The connectors have been moved to `semantic_kernel.connectors.memory_stores` so that you can still find them if you really need them, otherwise they will be removed in August.\n\nThe future of vector search in Semantic Kernel Python is here. ðŸŒŸ\n\n*Ready to experience the new vector store architecture? Update to Semantic Kernel Python 1.34 and start building with the improved API today.*",
  "Tags": [
    "Semantic Kernel"
  ],
  "PubDate": "2025-06-25T00:40:21+00:00",
  "Description": "Weâ€™re excited to announce a significant update to Semantic Kernel Pythonâ€™s vector store implementation. Version 1.34 brings a complete overhaul that makes working with vector data simpler, more intuitive, and more powerful. This update consolidates the API, improves developer experience, and adds new capabilities that streamline AI development workflows. What Makes This Release Special? The [â€¦]\n\nThe post [Semantic Kernel Python Gets a Major Vector Store Upgrade](https://devblogs.microsoft.com/semantic-kernel/semantic-kernel-python-gets-a-major-vector-store-upgrade/) appeared first on [Semantic Kernel](https://devblogs.microsoft.com/semantic-kernel).",
  "FeedLevelAuthor": "Semantic Kernel",
  "FeedName": "Microsoft DevBlog"
}
