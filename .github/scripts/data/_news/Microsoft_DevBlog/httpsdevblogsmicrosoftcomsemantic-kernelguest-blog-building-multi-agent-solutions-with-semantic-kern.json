{
  "OutputDir": "_news",
  "Title": "Guest Blog: Building Multi-Agent Solutions with Semantic Kernel and A2A Protocol",
  "FeedUrl": "https://devblogs.microsoft.com/semantic-kernel/feed/",
  "Link": "https://devblogs.microsoft.com/semantic-kernel/guest-blog-building-multi-agent-solutions-with-semantic-kernel-and-a2a-protocol/",
  "Author": "Kinfey Lo",
  "ProcessedDate": "2025-08-05 07:57:45",
  "EnhancedContent": "In the rapidly evolving landscape of AI application development, the ability to orchestrate multiple intelligent agents has become crucial for building sophisticated, enterprise-grade solutions. While individual AI agents excel at specific tasks, complex business scenarios often require coordination between specialized agents running on different platforms, frameworks, or even across organizational boundaries. This is where the combination of Microsoft’s Semantic Kernel orchestration capabilities and Agent-to-Agent (A2A) protocol creates a powerful foundation for building truly interoperable multi-agent systems.\n\n## Understanding the A2A Protocol: Beyond Traditional Tool Integration\n\nThe Agent-to-Agent (A2A) protocol, introduced by Google in April 2025 with support from over 50 technology partners, addresses a fundamental challenge in the AI ecosystem: enabling intelligent agents to communicate and collaborate as peers, not just as tools. Unlike protocols like MCP (Model Context Protocol) that focus on connecting agents to external tools and data sources, A2A establishes a standardized communication layer specifically designed for agent-to-agent interaction.\n\n### Core A2A Capabilities\n\nThe A2A protocol is built around four fundamental capabilities that enable sophisticated agent collaboration:\n\n**1. Agent Discovery through Agent Cards** Every A2A-compliant agent exposes a machine-readable “Agent Card” — a JSON document that advertises its capabilities, endpoints, supported message types, authentication requirements, and operational metadata. This discovery mechanism allows client agents to dynamically identify and select the most appropriate remote agent for specific tasks.\n\n**2. Task Management with Lifecycle Tracking** A2A structures all interactions around discrete “tasks” that have well-defined lifecycles. Tasks can be completed immediately or span extended periods with real-time status updates, making the protocol suitable for everything from quick API calls to complex research operations that may take hours or days.\n\n**3. Rich Message Exchange** Communication occurs through structured messages containing “parts” with specified content types. This enables agents to negotiate appropriate interaction modalities and exchange diverse data types including text, structured JSON, files, and even multimedia streams.\n\n**4. Enterprise-Grade Security** Built on familiar web standards (HTTP, JSON-RPC 2.0, Server-Sent Events), A2A incorporates enterprise-grade authentication and authorization with support for OpenAPI authentication schemes, ensuring secure collaboration without exposing internal agent state or proprietary tools.\n\n### A2A vs. MCP: Complementary Rather Than Competing\n\nA common misconception is that A2A competes with Anthropic’s Model Context Protocol (MCP). In reality, these protocols address different layers of the agentic AI stack:\n\n- **MCP connects agents to tools and data** — enabling access to external APIs, databases, file systems, and other structured resources\n- **A2A connects agents to other agents** — enabling peer-to-peer collaboration, task delegation, and distributed problem-solving\n\nThink of it as the difference between giving an agent a hammer (MCP) versus teaching it to work with a construction crew (A2A). Most sophisticated applications will leverage both protocols.\n\n## Semantic Kernel: The Orchestration Engine\n\nMicrosoft’s Semantic Kernel provides the ideal foundation for building A2A-enabled multi-agent systems. As an open-source SDK, Semantic Kernel excels at:\n\n- **Plugin-Based Architecture**: Easily extending agent capabilities through reusable plugins\n- **Multi-Model Support**: Orchestrating different AI models for specialized tasks\n- **Enterprise Integration**: Seamlessly connecting with existing enterprise systems and APIs\n- **Agent Framework**: Providing experimental but powerful multi-agent coordination capabilities\n\n### Why Semantic Kernel + A2A?\n\nThe integration of Semantic Kernel with A2A protocol creates several compelling advantages:\n\n1. **Framework Agnostic Interoperability**: Semantic Kernel agents can communicate with agents built using LangGraph, CrewAI, Google’s ADK, or any other A2A-compliant framework\n2. **Retained Semantic Kernel Benefits**: Leverage SK’s plugin ecosystem, prompt engineering capabilities, and enterprise features while gaining cross-platform compatibility\n3. **Gradual Migration Path**: Existing Semantic Kernel applications can incrementally adopt A2A without major architectural changes\n4. **Cloud-Native Design**: Built for enterprise scenarios with proper authentication, logging, and observability\n\n## Architecture Patterns for A2A-Enabled Systems\n\nWhen designing multi-agent systems with Semantic Kernel and A2A, the architecture from our implementation demonstrates several key patterns:\n\n### 1. Centralized Routing with Azure AI Foundry\n\nOur primary pattern uses a central routing agent powered by Azure AI Foundry to intelligently delegate tasks to specialized remote agents:\n\n[![arch image](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAASwAAAEIAQMAAADfjlsWAAAAA1BMVEXW1taWrGEgAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAAIElEQVRoge3BAQEAAACCIP+vbkhAAQAAAAAAAAAAAC8GKDgAAXLEW9YAAAAASUVORK5CYII=)](https://devblogs.microsoft.com/semantic-kernel/wp-content/uploads/sites/78/2025/07/arch.png)\n\n**Key Components:**\n\n- **Host Agent**: Central routing system using Azure AI Agents for intelligent decision-making\n- **A2A Protocol**: Standardized agent-to-agent communication\n- **Semantic Kernel**: Advanced agent framework with MCP integration\n- **Remote Agents**: Specialized task executors with different communication protocols\n\n**Benefits:**\n\n- Centralized conversation state management through Azure AI Foundry threads\n- Intelligent task delegation based on agent capabilities and user intent\n- Consistent user experience across diverse agent interactions\n- Clear audit trail and comprehensive error handling\n\n### 2. Multi-Protocol Agent Communication\n\nThe system demonstrates how different communication protocols can coexist:\n\n[![Screenshot 2025 07 18 at 8 50 16 PM image](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAASwAAAAwAQMAAACR0NViAAAAA1BMVEXW1taWrGEgAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAAF0lEQVQ4jWNgGAWjYBSMglEwCkYBpQAAB1AAAZC8h68AAAAASUVORK5CYII=)](https://devblogs.microsoft.com/semantic-kernel/wp-content/uploads/sites/78/2025/07/Screenshot-2025-07-18-at-8.50.16 PM.png)\n\n**Communication Patterns:**\n\n- **A2A HTTP/JSON-RPC**: For general-purpose tool agents with standardized discovery\n- **STDIO**: For process-based agents like Playwright automation\n- **Server-Sent Events (SSE)**: For serverless MCP functions in Azure\n\n### 3. Hybrid MCP + A2A Integration\n\nOur architecture showcases how MCP and A2A protocols complement each other:\n\n[![Screenshot 2025 07 18 at 8 51 50 PM image](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAASwAAAAbAQMAAAD8uyCXAAAAA1BMVEXW1taWrGEgAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAAEklEQVQ4jWNgGAWjYBSMAiwAAAQdAAFMZ/ZSAAAAAElFTkSuQmCC)](https://devblogs.microsoft.com/semantic-kernel/wp-content/uploads/sites/78/2025/07/Screenshot-2025-07-18-at-8.51.50 PM.png)\n\n- **MCP for Tools**: Direct integration with Azure Functions, development tools, and data sources\n- **A2A for Agents**: Inter-agent communication and task delegation\n- **Semantic Kernel**: Orchestration layer that bridges both protocols\n\n## Implementation Deep Dive\n\n### Project Structure and Components\n\nOur multi-agent system follows a modular architecture:\n\n[![Screenshot 2025 07 18 at 8 48 46 PM image](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAASwAAABpAQMAAAC6UYxdAAAAA1BMVEXW1taWrGEgAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAAGklEQVRIie3BAQ0AAADCoPdPbQ8HFAAAAHBuD/8AAcBq0pIAAAAASUVORK5CYII=)](https://devblogs.microsoft.com/semantic-kernel/wp-content/uploads/sites/78/2025/07/Screenshot-2025-07-18-at-8.48.46 PM.png)\n\n### Development Environment Setup\n\nTo build this A2A-enabled Semantic Kernel system, you’ll need:\n\n```default\n# Initialize Python project with uv (recommended)\nuv init multi_agent_system cd multi_agent_system\n\n# Core dependencies for Semantic Kernel and Azure integration\nuv add semantic-kernel[azure] uv add azure-identity uv add azure-ai-agents uv add python-dotenv\n\n# A2A protocol dependencies\nuv add a2a-client uv add httpx\n\n# MCP integration dependencies\nuv add semantic-kernel[mcp]\n\n# Web interface dependencies\nuv add gradio\n\n# Development dependencies\nuv add --dev pytest pytest-asyncio ```\n\n### Environment Configuration\n\nConfigure your environment variables:\n\n```default\n# Azure AI Foundry configuration\nAZURE_AI_AGENT_ENDPOINT=https://your-ai-foundry-endpoint.azure.com AZURE_AI_AGENT_MODEL_DEPLOYMENT_NAME=Your AI Foundry Model Deployment Name\n\n# Remote agent endpoints\nPLAYWRIGHT_AGENT_URL=http://localhost:10001 TOOL_AGENT_URL=http://localhost:10002\n\n# Optional: MCP server configuration\nMCP_SSE_URL=http://localhost:7071/runtime/webhooks/mcp/sse ```\n\n### Creating the Central Routing Agent\n\nThe heart of our system is the routing agent that uses Azure AI Foundry for intelligent task delegation:\n\n```py import json import os import time import uuid from typing import Any, Dict, List import httpx from a2a.client import A2ACardResolver from azure.ai.agents import AgentsClient from azure.identity import DefaultAzureCredential from dotenv import load_dotenv\n\nclass RoutingAgent: \"\"\"Central routing agent powered by Azure AI Foundry.\"\"\"\n\ndef __init__(self): self.remote_agent_connections = {} self.cards = {} self.agents_client = AgentsClient( endpoint=os.environ[\"AZURE_AI_AGENT_ENDPOINT\"], credential=DefaultAzureCredential(), ) self.azure_agent = None self.current_thread = None\n\nasync def initialize(self, remote_agent_addresses: list[str]): \"\"\"Initialize with A2A agent discovery.\"\"\"\n# Discover remote agents via A2A protocol\nasync with httpx.AsyncClient(timeout=30) as client: for address in remote_agent_addresses: try: card_resolver = A2ACardResolver(client, address) card = await card_resolver.get_agent_card()\n\nfrom remote_agent_connection import RemoteAgentConnections remote_connection = RemoteAgentConnections( agent_card=card, agent_url=address ) self.remote_agent_connections[card.name] = remote_connection self.cards[card.name] = card\n\nexcept Exception as e: print(f'Failed to connect to agent at {address}: {e}')\n\n# Create Azure AI agent for intelligent routing\nawait self._create_azure_agent()\n\nasync def _create_azure_agent(self): \"\"\"Create Azure AI agent with function calling capabilities.\"\"\" instructions = self._get_routing_instructions()\n\n# Define function for task delegation\ntools = [{ \"type\": \"function\", \"function\": { \"name\": \"send_message\", \"description\": \"Delegate task to specialized remote agent\", \"parameters\": { \"type\": \"object\", \"properties\": { \"agent_name\": {\"type\": \"string\"}, \"task\": {\"type\": \"string\"} }, \"required\": [\"agent_name\", \"task\"] } } }]\n\nmodel_name = os.environ.get(\"AZURE_AI_AGENT_MODEL_DEPLOYMENT_NAME\", \"gpt-4\") self.azure_agent = self.agents_client.create_agent( model=model_name, name=\"routing-agent\", instructions=instructions, tools=tools )\n\nself.current_thread = self.agents_client.threads.create() print(f\"Routing agent initialized: {self.azure_agent.id}\")\n\ndef _get_routing_instructions(self) -> str: \"\"\"Generate context-aware routing instructions.\"\"\" agent_info = [ {'name': card.name, 'description': card.description} for card in self.cards.values() ]\n\nreturn f\"\"\"You are an intelligent routing agent for a multi-agent system.\n\nAvailable Specialist Agents: {json.dumps(agent_info, indent=2)} ```\n\nRouting Guidelines:\n\n- Web automation, screenshots, browser tasks → Playwright Agent\n- Development tasks, file operations, repository management → Tool Agent\n- Always provide comprehensive task context when delegating\n- Explain to users what specialist is handling their request\n\n### Building Specialized Agents with MCP Integration\n\nOur remote agents leverage Semantic Kernel’s MCP integration for extensible capabilities:\n\n```py from semantic_kernel.agents import AzureAIAgent, AzureAIAgentSettings from semantic_kernel.connectors.mcp import MCPStdioPlugin, MCPSsePlugin from azure.identity.aio import DefaultAzureCredential\n\nclass SemanticKernelMCPAgent: \"\"\"Specialized agent with MCP plugin integration.\"\"\"\n\ndef __init__(self): self.agent = None self.client = None self.credential = None self.plugins = []\n\nasync def initialize_playwright_agent(self): \"\"\"Initialize with Playwright automation via MCP STDIO.\"\"\" try: self.credential = DefaultAzureCredential() self.client = await AzureAIAgent.create_client( credential=self.credential ).__aenter__()\n\n# Create Playwright MCP plugin\nplaywright_plugin = MCPStdioPlugin( name=\"Playwright\", command=\"npx\", args=[\"@playwright/mcp@latest\"], )\n\nawait playwright_plugin.__aenter__() self.plugins.append(playwright_plugin)\n\n# Create specialized agent\nagent_definition = await self.client.agents.create_agent( model=AzureAIAgentSettings().model_deployment_name, name=\"PlaywrightAgent\", instructions=( \"You are a web automation specialist. Use Playwright to \" \"navigate websites, take screenshots, interact with elements, \" \"and perform browser automation tasks.\" ), )\n\nself.agent = AzureAIAgent( client=self.client, definition=agent_definition, plugins=self.plugins, )\n\nexcept Exception as e: await self.cleanup() raise\n\nasync def initialize_tools_agent(self, mcp_url: str): \"\"\"Initialize with development tools via MCP SSE.\"\"\" try: self.credential = DefaultAzureCredential() self.client = AzureAIAgent.create_client(credential=self.credential)\n\n# Create development tools MCP plugin\ntools_plugin = MCPSsePlugin( name=\"DevTools\", url=mcp_url, )\n\nawait tools_plugin.__aenter__() self.plugins.append(tools_plugin)\n\nagent_definition = await self.client.agents.create_agent( model=AzureAIAgentSettings().model_deployment_name, name=\"DevAssistant\", instructions=( \"You are a development assistant. Help with repository \" \"management, file operations, opening projects in VS Code, \" \"and other development tasks.\" ), )\n\nself.agent = AzureAIAgent( client=self.client, definition=agent_definition, plugins=self.plugins, )\n\nexcept Exception as e: await self.cleanup() raise\n\nasync def invoke(self, user_input: str) -> dict[str, Any]: \"\"\"Process tasks through the specialized agent.\"\"\" if not self.agent: return { 'is_task_complete': False, 'content': 'Agent not initialized.', }\n\ntry: responses = [] async for response in self.agent.invoke( messages=user_input, thread=self.thread, ): responses.append(str(response)) self.thread = response.thread\n\nreturn { 'is_task_complete': True, 'content': \"\\n\".join(responses) or \"No response received.\", } except Exception as e: return { 'is_task_complete': False, 'content': f'Error: {str(e)}', } ```\n\n### Web Interface with Gradio\n\nThe system provides a modern chat interface powered by Gradio:\n\n```py import asyncio import gradio as gr from routing_agent import RoutingAgent\n\nasync def get_response_from_agent( message: str, history: list[gr.ChatMessage] ) -> gr.ChatMessage: \"\"\"Process user messages through the routing system.\"\"\" global ROUTING_AGENT\n\ntry: response = await ROUTING_AGENT.process_user_message(message) return gr.ChatMessage(role=\"assistant\", content=response) except Exception as e: return gr.ChatMessage( role=\"assistant\", content=f\"❌ Error: {str(e)}\" )\n\nasync def main(): \"\"\"Launch the multi-agent system.\"\"\"\n# Initialize routing agent\nglobal ROUTING_AGENT ROUTING_AGENT = await RoutingAgent.create([ os.getenv('PLAYWRIGHT_AGENT_URL', 'http://localhost:10001'), os.getenv('TOOL_AGENT_URL', 'http://localhost:10002'), ]) ROUTING_AGENT.create_agent()\n\n# Create Gradio interface\nwith gr.Blocks(theme=gr.themes.Ocean()) as demo: gr.Markdown(\"# 🤖 Azure AI Multi-Agent System\")\n\ngr.ChatInterface( get_response_from_agent, title=\"Chat with AI Agents\", examples=[ \"Navigate to github.com/microsoft and take a screenshot\", \"Clone repository https://github.com/microsoft/semantic-kernel\", \"Open the cloned project in VS Code\", ] )\n\ndemo.launch(server_name=\"0.0.0.0\", server_port=8083) ```\n\n### Deployment and Operations\n\n**Local Development:**\n\n```default\n# Start MCP server (Azure Functions)\ncd mcp_sse_server/MCPAzureFunc func start\n\n# Start remote agents in separate terminals\ncd remote_agents/playwright_agent && uv run . cd remote_agents/tool_agent && uv run .\n\n# Start the host agent with web interface\ncd host_agent && uv run . ```\n\n**Production Considerations:**\n\n- Deploy each agent as a separate microservice using Azure Container Apps\n- Use Azure Service Bus for robust agent discovery and communication\n- Implement comprehensive logging with Azure Application Insights\n- Configure proper authentication and network security\n\n### Real-World Usage Examples\n\nBased on our implementation, here are practical examples of how the multi-agent system handles different types of requests:\n\n**Example 1: Web Automation Task**\n\n```default User: \"Navigate to github.com/microsoft and take a screenshot\"\n\nFlow:\n1. Host Agent (Azure AI) analyzes the request\n2. Identifies this as a web automation task\n3. Delegates to Playwright Agent via A2A protocol\n4. Playwright Agent uses MCP STDIO to execute browser automation\n5. Returns screenshot and navigation details to user\n```\n\n**Example 2: Development Workflow**\n\n```default User: \"Clone https://github.com/microsoft/semantic-kernel and open it in VS Code\"\n\nFlow:\n1. Host Agent recognizes repository management + IDE operation\n2. Delegates to Tool Agent via A2A protocol\n3. Tool Agent uses MCP SSE connection to Azure Functions\n4. Executes git clone and VS Code launch commands\n5. Reports success status back to user\n```\n\n***Note*** You can click this [link](https://github.com/a2aproject/a2a-samples/blob/main/samples/python/agents/azureaifoundry_sdk/multi_agent/README.md) and get this sample\n\n## Future Considerations and Roadmap\n\nAs both Semantic Kernel and the A2A protocol continue to evolve, several developments are worth monitoring:\n\n### Emerging Features\n\n1. **Enhanced Streaming Support**: Better support for real-time streaming interactions between agents\n2. **Multimodal Communication**: Expanded support for audio, video, and other rich media types\n3. **Dynamic UX Negotiation**: Agents that can negotiate and adapt their interaction modalities mid-conversation\n4. **Improved Client-Initiated Methods**: Better support for scenarios where clients need to initiate actions beyond basic task management\n\n### Integration Opportunities\n\n1. **Azure AI Foundry Integration**: Native A2A support within Azure’s AI platform\n2. **Copilot Studio Compatibility**: Seamless integration with Microsoft’s low-code agent building platform\n3. **Enterprise Service Integration**: Better integration with enterprise identity and governance systems\n\n### Community and Ecosystem\n\nThe A2A protocol benefits from strong industry backing, with over 50 technology partners contributing to its development. As the ecosystem matures, expect:\n\n- More comprehensive tooling and SDK support\n- Standardized patterns for common multi-agent scenarios\n- Enhanced interoperability testing and certification programs\n- Growing library of reusable A2A-compliant agents\n\n## Conclusion\n\nThe combination of Semantic Kernel’s powerful orchestration capabilities with Google’s A2A protocol represents a significant step forward in building truly interoperable multi-agent systems. This integration enables developers to:\n\n- **Break down silos** between different AI frameworks and platforms\n- **Leverage existing investments** in Semantic Kernel while gaining cross-platform compatibility\n- **Build scalable, enterprise-grade** multi-agent solutions with proper security and observability\n- **Future-proof applications** by adopting open standards for agent communication\n\nAs the agentic AI landscape continues to evolve rapidly, the ability to create flexible, interoperable systems becomes increasingly valuable. By combining the orchestration power of Semantic Kernel with the standardized communication capabilities of A2A, developers can build sophisticated multi-agent applications that are both powerful and portable.\n\nThe journey toward truly collaborative AI systems is just beginning, and the tools and patterns demonstrated in this article provide a solid foundation for building the next generation of intelligent applications. Whether you’re enhancing existing Semantic Kernel applications or building new multi-agent systems from scratch, the integration of these technologies offers a path toward more capable, flexible, and interoperable AI solutions.",
  "Tags": [
    "A2A",
    "Semantic Kernel"
  ],
  "PubDate": "2025-07-21T08:10:23+00:00",
  "Description": "In the rapidly evolving landscape of AI application development, the ability to orchestrate multiple intelligent agents has become crucial for building sophisticated, enterprise-grade solutions. While individual AI agents excel at specific tasks, complex business scenarios often require coordination between specialized agents running on different platforms, frameworks, or even across organizational boundaries. This is where the […]\n\nThe post [Guest Blog: Building Multi-Agent Solutions with Semantic Kernel and A2A Protocol](https://devblogs.microsoft.com/semantic-kernel/guest-blog-building-multi-agent-solutions-with-semantic-kernel-and-a2a-protocol/) appeared first on [Semantic Kernel](https://devblogs.microsoft.com/semantic-kernel).",
  "FeedLevelAuthor": "Semantic Kernel",
  "FeedName": "Microsoft DevBlog"
}
