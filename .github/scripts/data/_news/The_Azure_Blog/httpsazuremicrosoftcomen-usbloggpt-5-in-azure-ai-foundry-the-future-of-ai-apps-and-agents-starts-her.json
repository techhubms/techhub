{
  "Description": "Today, we’re announcing general availability of OpenAI’s new flagship, GPT-5, in Azure AI Foundry. This is more than a new model release; it is the most powerful large language model (LLM) ever released across key benchmarks.\n\nThe post [GPT-5 in Azure AI Foundry: The future of AI apps and agents starts here](https://azure.microsoft.com/en-us/blog/gpt-5-in-azure-ai-foundry-the-future-of-ai-apps-and-agents-starts-here/) appeared first on [Microsoft Azure Blog](https://azure.microsoft.com/en-us/blog).",
  "PubDate": "2025-08-07T17:00:00+00:00",
  "Link": "https://azure.microsoft.com/en-us/blog/gpt-5-in-azure-ai-foundry-the-future-of-ai-apps-and-agents-starts-here/",
  "FeedUrl": "https://azure.microsoft.com/en-us/blog/feed/",
  "Title": "GPT-5 in Azure AI Foundry: The future of AI apps and agents starts here",
  "FeedLevelAuthor": "Microsoft Azure Blog",
  "OutputDir": "_news",
  "Author": "Steve Sweetman",
  "Tags": [
    "AI",
    "AI + machine learning",
    "Azure AI"
  ],
  "FeedName": "The Azure Blog",
  "ProcessedDate": "2025-09-07 15:09:51",
  "EnhancedContent": "Today, we’re announcing general availability of OpenAI’s new flagship, GPT-5, in Azure AI Foundry. This is more than a new model release; it is the most powerful large language model (LLM) ever released across key benchmarks.\n\nFor business leaders building with AI, the conversation has moved beyond chat. The bar is higher: can your AI generate, reason, and deliver measurable outcomes—safely and at scale?\n\nToday, we’re announcing general availability of **OpenAI’s new flagship model, GPT-5, in Azure AI Foundry**. This is more than a new model release; it is the most powerful LLM ever released across key benchmarks. GPT-5 in [Azure AI Foundry](https://ai.azure.com/) pairs frontier reasoning with high-performance generation and cost efficiency, delivered on Microsoft Azure’s enterprise-grade platform so organizations can move from pilots to production with confidence.\n\n[Get started with GPT-5 in Azure AI Foundry](https://azure.microsoft.com/en-us/products/ai-foundry/)\n\n## GPT-5 in Azure AI Foundry: Built for real-world workloads\n\nIn Azure AI Foundry, the GPT-5 models are available via API and orchestrated by themodel router. The GPT-5 series spans complementary strengths:\n\n- **GPT-5**, a full reasoning model provides deep, richer reasoning for analytics and complex tasks, like code generation, with a 272k token context.\n- **GPT-5 mini** powers real-time experiences for apps and agents that require reasoning, tool calling to solve customer problems.\n- **GPT-5 nano** is a new class of reasoning model which focuses on ultra-low-latency and speed with rich Q&A capabilities.\n- **GPT-5 chat** enables natural, multimodal, multi-turn conversations that remain context-aware throughout agentic workflows, with 128k token context.\n\nTogether, the suite delivers a seamless continuum from rigorous agentic coding tasks, to relatively simple Q&A—all delivered with the same Azure AI Foundry endpoint using model router in Foundry Models.\n\nUnder the hood, GPT-5 unifies advanced reasoning, code generation, and natural language interaction. It combines analytical depth with intuitive dialogue to solve end-to-end problems and explain its approach. Agentic capabilities allow multi-step tool use and long action chains with transparent, auditable decisions. As a frontier-level coding model, GPT-5 can plan complex agentic workflow, build migrations, and refactor code, as well as produce tests and documentation with clear rationale. Developer controls—including parameters like **`reasoning_effort`** and verbosity—let teams tune depth, speed, and detail, while **new freeform tool-calling features** enable broadens tool compatibility without rigid schemas.\n\n## Orchestrate with the model router—then scale with agents\n\nIntroducing GPT-5 to Azure AI Foundry is more than a model drop: it’s a leap forward for the platform. Starting today, developers can use the model router in Foundry Models to maximize the capabilities of the GPT-5 family models (and other models in Foundry Models) while saving up to 60% on inferencing cost with no loss in fidelity. Powered by a fine-tuned SLM under the hood, the model router evaluates each prompt and decides the optimal model based on the complexity, performance needs, and cost efficiency of each task. Let the model router pick the right model so that you can build your AI-powered applications with ease.\n\nAnd orchestration doesn’t stop at routing—Foundry carries the same intelligence into agents. Coming soon, GPT-5 will be available in the Foundry Agent Service, pairing frontier models with built-in tools including [new browser automation](https://aka.ms/Foundry/BrowserAutomation) and Model Context Protocol (MCP) integrations. The result: policy-governed, tool-using agents that can search, act in web apps, and complete end-to-end tasks—instrumented with Foundry telemetry and aligned to Microsoft Responsible AI.\n\n## Accelerating business impact with GPT-5\n\nThese capabilities map directly to business impact.\n\nIn research and knowledge work, GPT-5 accelerates financial and legal analysis, market intelligence, and due diligence—reading at scale and producing decision-ready output with traceability. In operations and decisioning, it strengthens logistics support, risk assessment, and claims processing by pairing robust reasoning with policy adherence. Copilots and customer experience teams benefit from multi-turn, multimodal agents that reason in real time, call tools, resolve tasks, and revert to humans with more helpful context.\n\nIn software engineering, GPT-5 excels at code generation, application modernization, and quality engineering—improving code style and explanations to compress review cycles.\n\nAnd for use cases which are cost or latency sensitive, GPT-5-nano’s ultra‑low‑latency architecture delivers rapid, high‑accuracy responses, making it the ideal target for fine‑tuning and the go‑to model for high‑volume, straightforward requests.\n\n## GPT-5 customer spotlight\n\nCustomers are unleashing GPT-5 across complex, mission-critical workloads—accelerating decision-making, supercharging coding, and catalyzing product innovation.\n\n### SAP\n\n> >\n> *SAP is excited to be among the first to leverage the power of GPT-5 in Azure AI Foundry within our generative AI hub in AI Foundation. GPT-5 in Azure AI Foundry will enable our product team and our developer community to deliver impactful business innovations to our customers.*\n> >\n> —Dr. Walter Sun, SVP and Global Head of AI, SAP SE\n\n### Relativity\n\n> >\n> *The GPT-5 in Azure AI Foundry raises the bar for putting legal data intelligence into action… This next-generation AI will empower legal teams to uncover deeper insights, accelerate decision-making, and drive stronger strategies across the entire legal process.*\n> >\n> —Dr. Aron Ahmadia, Senior Director, Applied Science, Relativity\n\n### Hebbia\n\n> >\n> *The partnership between Hebbia and Azure AI Foundry gives financial professionals an unprecedented edge. With GPT-5’s advanced reasoning in Hebbia, they can pinpoint critical figures across thousands of documents and structuring complex financial analysis with speed and accuracy.*\n> >\n> —Danny Wheller, VP of Business and Strategy\n\n## Building with AI in GitHub Copilot and Visual Studio Code\n\nGPT-5 begins rolling out today to millions of developers using **[GitHub Copilot](https://github.com/features/copilot)** and **[Visual Studio Code](https://code.visualstudio.com/)**, applying the flagship model’s advanced reasoning capabilities to increasingly complex problems—from sophisticated refactoring to navigating large codebases more effectively. GPT-5 helps developers write, test, and deploy code faster, while supporting agentic coding tasks with significant improvements to coding style and overall code quality. With GPT-5, developers not only code faster, but code better.\n\n![A screenshot of a computer](https://azure.microsoft.com/en-us/blog/wp-content/uploads/2025/08/VSCode_GPT-5_1920x1080VidSocialPost-GIF.gif)\n\nWith today’s VS Code release, developers also gain a more powerful agentic coding experience directly within the editor: GitHub Copilot’s coding agent has an improved experience for autonomously tackling tasks in the background. Additionally, the GitHub Copilot chat experience brings increased productivity, including support beyond 128 tools for a single chat request and chat checkpoints allowing users to restore workspace changes to a prior point. Today, we are also announcing an updated extension to develop agents using the Azure AI Foundry extension all within VS Code environment.\n\nThese announcements extend Microsoft’s strategy to transform software development with AI, bringing advanced AI capabilities to the entire software lifecycle.\n\n## Security, safety, and governance by design\n\nIn all domains, security and safety is a layer cake of protections, which together provide protection for risk scenarios—and AI is no different. For AI, we think about layers with the model as the core. With GPT-5, the core is safer than before:\n\n> >\n> *The Microsoft AI Red Team found GPT-5 to have one of the strongest safety profiles of any OpenAI model, performing on par with—or better than—o3.*\n> >\n> —Dr. Sarah Bird, Chief Product Officer of Responsible AI, Microsoft\n\nAs we think about the safety, security, and governance layers around this core—**Azure AI Foundry** provides a number of additional controls:\n\n- **Azure AI Content Safety** protections are applied to every prompt and completion, such as prompt shields, which help to detect and mitigate prompt-injection attempts before they reach the model.\n\n![A diagram of a company](https://azure.microsoft.com/en-us/blog/wp-content/uploads/2025/08/foundry-image.jpg)\n- Built-in agent evaluators work with the **AI Red Teaming Agent** to run alignment, bias, and security tests throughout development and production, while **continuous evaluation** streams real-time metrics—latency, quality, safety, and fairness—stream into Azure Monitor and Application Insights for single-pane visibility.\n\n- Finally, security signals integrate directly with **Microsoft Defender for Cloud**, and runtime metadata and evaluation results are integrated to **Microsoft Purview** for audit, data-loss prevention, and regulatory reporting, extending protection and governance across the entire GPT-5 lifecycle.\n\n## Bringing AI into every workflow with GitHub Copilot and Visual Studio Code\n\nStarting today, GPT-5 begins rolling out to **millions of developers** who use **GitHub Copilot** and Visual Studio Code who will be able to **select GPT-5 to write, test, and deploy code**—and develop agents using the Azure AI Foundry extension all within VS Code environment. GPT-5 supports complex agentic coding tasks with significant improvements to coding personality, front-end aesthetics, and code quality, highly desired improvements for the developer community.\n\nOur evaluations show OpenAI GPT-5’s reasoning capabilities and contextual awareness exceed o3, enabling developers to tackle more complex problems—from refactoring to navigating large codebases. With GPT-5, users in the Visual Studio family can not only code faster, but code better.\n\nVS Code and our [**recent decision to open-source GitHub Copilot**](https://code.visualstudio.com/blogs/2025/06/30/openSourceAIEditorFirstMilestone), represents our commitment to open tools and standards and demonstrates our ability to meet the rapid pace of model innovations while keeping the developer experience at the forefront. In today’s release of VS Code, developers can. In [**today’s VS Code release**](https://aka.ms/VSCode/1103/m), developers have even more control over their experience in chat—with improvements to the reliability of terminal tools, updates to the tool picker and limits, new checkpoints, and more.\n\nToday’s announcement extends Microsoft’s strategy to transform software development with AI, bringing advanced AI capabilities to the entire software lifecycle.\n\n## Start building today\n\nGPT-5 is available via our Standard offering in Azure AI Foundry, with deployment choices optimized for cost-efficiency and governance needs, including Global and Data Zone (United States, European Union) deployment options for data residency and compliance.1\n\n![A table with numbers and text](https://azure.microsoft.com/en-us/blog/wp-content/uploads/2025/08/Screenshot-2025-08-07-152630.webp)\n\nWith Azure AI Foundry’s first-class reliability, realtime evaluations, built-in observability, and secure deployment options, you can confidently move from pilot to production—all aided while unique tools like Model Router optimizes quality, latency, and cost across workloads.\n\n1Pricing is accurate as of August 2025"
}
