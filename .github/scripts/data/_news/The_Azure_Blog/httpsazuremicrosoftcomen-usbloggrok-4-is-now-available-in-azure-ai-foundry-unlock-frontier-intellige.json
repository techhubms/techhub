{
  "Tags": [
    "AI + machine learning",
    "Large language models (LLMs)"
  ],
  "OutputDir": "_news",
  "Link": "https://azure.microsoft.com/en-us/blog/grok-4-is-now-available-in-azure-ai-foundry-unlock-frontier-intelligence-and-business-ready-capabilities/",
  "FeedUrl": "https://azure.microsoft.com/en-us/blog/feed/",
  "Author": "The Azure AI Foundry Team",
  "EnhancedContent": "Microsoft has collaborated closely with xAI to bring Grok 4, their most advanced model, to Azure AI Foundry—delivering powerful reasoning within a platform designed for business-ready safety and control.\n\n**Today’s enterprises are entering a new phase of AI adoption—one where trust, flexibility, and production readiness aren’t optional; they’re foundational**. Microsoft has collaborated closely with xAI to bring **Grok 4**, their most advanced model, to [Azure AI Foundry](https://azure.microsoft.com/en-us/products/ai-foundry)—delivering powerful reasoning within a platform designed for business-ready safety and control.\n\n[Check out the Azure AI Foundry Grok 4 model card](https://aka.ms/grok_4)\n\n**Grok 4 undeniably has exceptional performance**. **** With a 128K-token context window, native tool use, and integrated web search, it pushes the boundaries of what’s possible in contextual reasoning and dynamic response generation. But performance alone isn’t enough. AI at the frontier must also be accountable. Over the last month, xAI and Microsoft have worked closely to enhance responsible design. The team has evaluated from a responsible AI perspective, putting Grok 4 through a suite of safety tests and compliance checks. Azure AI Content Safety is on by default, adding another layer of protection for enterprise use. Please see the [Foundry model card](https://aka.ms/grok_4) for more information about model safety.\n\nIn this blog, we’ll explore what makes Grok 4 stand out, how it compares to other frontier models, and how developers can access it via Azure AI Foundry.\n\n## Grok 4: Enhanced reasoning, expanded context, and real-time insights\n\nGrok models were trained on xAI’s Colossus supercomputer, utilizing a massive compute infrastructure that xAI claims delivers a 10 times leap in training scale compared to Grok 3. Grok 4’s architecture marks a significant shift from its predecessors, emphasizing reinforcement learning (RL) and multi-agent systems. According to xAI, the model prioritizes reasoning over traditional pre-training, with a heavy focus on RL to refine its problem-solving capabilities.\n\nKey architectural highlights include:\n\n### First-principles reasoning: “think mode”\n\nOne of Grok 4’s headline features is its **first-principles reasoning ability**. Essentially, the model tries to “think” like a scientist or detective, breaking problems down step by step. Instead of just blurting out an answer, Grok 4 can work through the logic internally and refine its response. It has strong proficiency in math (solving competition-level problems), science, and humanities questions. Early users have noted it excels at logic puzzles and nuanced reasoning better than some incumbent models, often finding correct answers where others get confused. Put simply, Grok 4 doesn’t just *recall* information—it actively reasons through problems. This focus on logical consistency makes it especially attractive if your use case requires step-by-step answers (think of research analysis, tutoring, or complex troubleshooting scenarios).\n\n**Example prompt**: *Explain how you would generate electricity on Mars if you had no existing infrastructure. Start from first principles: what are the fundamental resources, constraints, and physical laws you would use?*\n\n### Extended context window\n\nPerhaps one of Grok 4’s most impressive technical feats is its handling of extremely large contexts. The model is built to process and remember massive amounts of text in one go. In practical terms, this means Grok 4 can ingest extensive documents, lengthy research papers, or even a large codebase, and then reason about them without needing to truncate or forget earlier parts. For use cases like:\n\n- **Document analysis**: You could feed in hundreds of pages of a document and ask Grok to summarize, find inconsistencies, or answer specific questions. Grok 4 is far less likely to miss the details simply because it ran out of context window, compared to other models.\n- **Research and academia**: Load an entire academic journal issue or a very long historical text and have Grok analyze it or answer questions across the whole text. It could, for example, take in all of Shakespeare’s plays and answer a question that requires connecting info from multiple plays.\n- **Code repositories:** Developers could input an entire code repository or multiple files (up to millions of characters of code) and ask Grok 4 to find where a certain function is defined, or to detect bugs across the codebase. This is huge for understanding large legacy projects.\n\nxAI has claimed that this is not just “memory” but “smart memory.” Grok can intelligently compress or prioritize information in very long inputs, remembering the crucial pieces more strongly. For the end user or developer, the takeaway is: **Grok 4 can handle very large input texts in one shot**. This reduces the need to chop up documents or code and manage context fragments manually. You can throw a ton of information at it and it can keep the whole thing “in mind” as it responds.\n\n**Example prompt**: *Read this Shakespeare play and find my password (password is buried in the long context text).*\n\n### Data-aware responses and real-time insights\n\nAnother strength of Grok 4 is how it can integrate external data sources and trending information into its answers—effectively acting as a data analyst or real-time researcher when needed. It understands that sometimes the best answer needs to come from *outside* its training data, and it has mechanisms to retrieve and incorporate that external data. It turns the chatbot into more of an autonomous research assistant. You ask a question, it might go read a few things online, and come back with an answer that’s enriched by real data. Of course, caution is needed—live data can sometimes be incorrect, or the model might pick up on biased sources; one should verify critical outputs.\n\n**Example prompt**: *Check the latest news on global AI regulations (past 48 hours).*\n\n1. *Summarize the top 3 developments.*\n2. *Highlight which regions or governments are driving the changes.*\n3. *Explain what impact these updates could have on companies deploying foundation models.*\n4. *Provide the sources you referenced.*\n\n## Stacking up Grok 4: How it performs against top models\n\nGrok 4 showcases impressive capabilities on high-complexity tasks. These benchmarks underscore Grok 4’s leading-edge capabilities in high-level reasoning, STEM disciplines, complex problem-solving, and industry-specific tasks. These benchmark numbers are calculated using our own internal Azure AI Foundry benchmarking service, which we use to compare models across a set of industry standard benchmarks.\n\n![Table of model benchmarks.](https://azure.microsoft.com/en-us/blog/wp-content/uploads/2025/09/word-image-46787-1.webp)\n\n## Family of Grok models\n\nIn addition to Grok 4, Azure AI Foundry also has 3 additional Grok models already available.\n\n- [Grok 4 Fast Reasoning](https://aka.ms/grok-4-fast-reasoning) is optimized for tasks requiring logical inference, problem-solving, and complex decision-making, making it ideal for analytical applications.\n\n- [Grok 4 Fast Non-Reasoning](https://aka.ms/grok-4-fast-non-reasoning) focuses on speed and efficiency for straightforward tasks like summarization or classification, without deep logical processing.\n\n- [Grok Code Fast 1](https://aka.ms/grok-code-fast-1) is tailored specifically for code generation and debugging, excelling in programming-related tasks across multiple languages.\n\nWhile all three models prioritize speed, their core strengths differ: reasoning for logic-heavy tasks, non-reasoning for lightweight operations, and code for developer workflows.\n\nPricing including Azure AI Content Safety:\n\n| Model | Deployment Type | Price $/1M tokens | | --- | --- | --- | | Grok 4 | Global Standard | Input- $5.5 <br>Output- $27.5 |\n\n## Get started with Grok 4 in Azure AI Foundry\n\n**Lead with insight, build with trust**. Grok 4 unlocks frontier‑level reasoning and real‑time intelligence, but it is not a deploy and forget model. Pair Azure’s guardrails with your own domain checks, monitor outputs against evolving standards, and iterate responsibly—while we continue to harden the model and disclose new safety scores. Please see the [Azure AI Foundry Grok 4 model card](https://aka.ms/grok_4) for more information about model safety.\n\nHead over to [ai.azure.com](https://ai.azure.com/), search for “Grok,” and start exploring what these powerful models can do.",
  "FeedName": "The Azure Blog",
  "ProcessedDate": "2025-10-07 15:03:39",
  "Description": "Microsoft has collaborated closely with xAI to bring Grok 4, their most advanced model, to Azure AI Foundry—delivering powerful reasoning within a platform designed for business-ready safety and control.\n\nThe post [Grok 4 is now available in Azure AI Foundry: Unlock frontier intelligence and business-ready capabilities](https://azure.microsoft.com/en-us/blog/grok-4-is-now-available-in-azure-ai-foundry-unlock-frontier-intelligence-and-business-ready-capabilities/) appeared first on [Microsoft Azure Blog](https://azure.microsoft.com/en-us/blog).",
  "Title": "Grok 4 is now available in Azure AI Foundry: Unlock frontier intelligence and business-ready capabilities",
  "PubDate": "2025-09-29T16:15:00+00:00",
  "FeedLevelAuthor": "Microsoft Azure Blog"
}
