{
  "OutputDir": "_news",
  "ProcessedDate": "2025-11-12 18:04:13",
  "FeedLevelAuthor": "Visual Studio Blog",
  "Title": "Introducing Copilot auto model selection (preview)",
  "FeedUrl": "https://devblogs.microsoft.com/visualstudio/feed/",
  "PubDate": "2025-11-12T17:38:43+00:00",
  "Description": "Faster responses, a lower chance of rate limiting, and 10% off premium requests for paid users â€“ auto picks the best available model for each request based on current capacity and performance. With auto, you donâ€™t need to choose a specific model. Copilot automatically selects the best one for your task. Auto model selection in [â€¦]\n\nThe post [Introducing Copilot auto model selection (preview)](https://devblogs.microsoft.com/visualstudio/introducing-copilot-auto-model-selection-preview/) appeared first on [Visual Studio Blog](https://devblogs.microsoft.com/visualstudio).",
  "FeedName": "Microsoft VisualStudio Blog",
  "Tags": [
    "Artificial Intelligence",
    "Auto",
    "Copilot",
    "GitHub Copilot",
    "Models"
  ],
  "Link": "https://devblogs.microsoft.com/visualstudio/introducing-copilot-auto-model-selection-preview/",
  "Author": "Rhea Patel, Nhu Do",
  "EnhancedContent": "Faster responses, a lower chance of rate limiting, and 10% off premium requests for paid users â€“ auto picks the best available model for each request based on current capacity and performance. With [auto](https://docs.github.com/en/copilot/concepts/auto-model-selection), you donâ€™t need to choose a specific model. Copilot automatically selects the best one for your task. Auto model selection in Chat is rolling out in preview to all GitHub Copilot users.\n\n## How auto model selection works\n\nAuto selects the best model to ensure that you get the optimal performance and reduce the likelihood of rate limits. Auto will choose between GPT-5, GPT-5 mini, GPT-4.1, Sonnet 4.5, and Haiku 4.5 and other models, unless your organization has [disabled access to these models](https://docs.github.com/en/copilot/how-tos/use-ai-models/configure-access-to-ai-models). Once auto picks a model, it uses that same model for the entire chat session. As we introduce picking models based on task complexity, this behavior will change over the next iterations.\n\nFor paid users, we currently primarily rely on Claude Sonnet 4.5 as the model powering auto.\n\n[![auto image](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABAsAAAEiAQMAAAClb8mtAAAAA1BMVEXW1taWrGEgAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAAPElEQVR4nO3BMQEAAADCoPVPbQhfoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIDPAJRmAAGLF2rZAAAAAElFTkSuQmCC)](https://devblogs.microsoft.com/visualstudio/wp-content/uploads/sites/4/2025/11/auto-1.webp)\n\nWhen using auto model selection, Visual Studio uses a variable [model multiplier](https://docs.github.com/en/copilot/concepts/billing/copilot-requests#model-multipliers) based on the automatically selected model. If you are a paid user, auto applies a 10% request discount. For example, if auto selects Sonnet 4.5, it will be counted as 0.9x of a premium request; You can see which model and model multiplier are used by hovering over the chat response.\n\nIf you are a paid user and run out of premium requests, auto will always choose a 0x model (for example, GPT-4.1), so you can continue using auto without interruption.\n\n## Whatâ€™s next\n\nOur long-term vision for auto. We aim to make auto the best model selection for most users and to achieve this, hereâ€™s what we plan next:\n\n- Dynamically switch between small and large models based on the task â€“ this flexibility ensures that you get the right balance of performance and efficiency, while saving on requests\n- Add more language models to auto\n- Let users on a free plan take advantage of the latest models through auto\n- Improve the model dropdown to make it more obvious which models and discounts are used\n\nThanks ðŸ˜Š"
}
