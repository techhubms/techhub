{
  "Title": "What‚Äôs new in Azure AI Foundry | August 2025",
  "Author": "Nick Brady",
  "OutputDir": "_news",
  "FeedLevelAuthor": "Azure AI Foundry Blog",
  "Description": "August 2025 highlights GPT‚Äë5 arrives in Foundry, Model Router adds GPT‚Äë5 support, Responses API is GA, Browser Automation enters public preview, plus Sora updates, Mistral Document AI, FLUX image models, OpenAI gpt‚Äëoss with Foundry Local, and SDK/documentation updates.\n\nThe post [What‚Äôs new in Azure AI Foundry | August 2025](https://devblogs.microsoft.com/foundry/whats-new-in-azure-ai-foundry-august-2025/) appeared first on [Azure AI Foundry Blog](https://devblogs.microsoft.com/foundry).",
  "ProcessedDate": "2025-09-03 15:12:01",
  "PubDate": "2025-09-03T15:00:50+00:00",
  "EnhancedContent": "## TL;DR\n\n**Models**: GPT‚Äë5 family now in Azure AI Foundry (gpt‚Äë5 requires registration; launch regions: East US 2, Sweden Central). Also new: Sora API updates (image‚Üívideo, inpainting; Global Standard in East US 2 and Sweden Central), Mistral Document AI (OCR), Black Forest Labs FLUX.1 Kontext [pro] and FLUX1.1 [pro], OpenAI gpt‚Äëoss (with Foundry Local support), and VibeVoice long‚Äëform TTS (coming soon).\n\n**Agents**: Browser Automation tool (public preview) and expanded Agent Service regional availability (Brazil South, Germany West Central, Italy North, South Central US).\n\n**Tools**: Browser Automation integrates with Microsoft Playwright Testing Workspaces; refreshed MCP samples; updated Deep Research guidance and samples.\n\n**Platform**: Model Router adds GPT‚Äë5 support (limited access); Responses API is GA. August updates across Python, .NET, Java, and JavaScript/TypeScript; Agent Service Java SDK enters public preview. Doc updates include new status dashboard (Preview), API lifecycle v1 guidance, updated quotas/limits (incl. GPT‚Äë5 and Model Router), tracing/observability, CMK clarifications, enterprise chat web app tutorial, and region/model availability matrices.\n\n## üì¨ Subscribe to ‚ÄúWhat‚Äôs New in Foundry‚Äù monthly\n\nPrefer a nudge each month?\n\n1. Copy this RSS feed URL\n2. Use a preferred RSS Reader like Feedly\n3. Add this üëáüèª URL to follow\n\n[Subscribe via RSS](https://devblogs.microsoft.com/foundry/category/whats-new/feed/)\n\n## Models\n\n### GPT‚Äë5 arrives: models, pricing, regions, and access\n\n`gpt-5` , `gpt-5-mini` , `gpt-5-nano` , and `gpt-5-chat` are now available in Azure AI Foundry. Registration is required for `gpt-5` access; mini, nano, and chat do not require registration.\n\n#### Details\n\n- Roles and context windows\n- `gpt-5`\n: next‚Äëgen reasoning with long horizon tasks; up to ~272K tokens context.\n- `gpt-5-chat`\n: multimodal conversational model; ~128K tokens context.\n- `gpt-5-mini`\n: fast, tool‚Äëcalling/real‚Äëtime friendly baseline.\n- `gpt-5-nano`\n: ultra‚Äëlow‚Äëlatency Q&A and lightweight tasks.\n- Provisioned throughput: `gpt-5`\nsupports provisioned throughput (PTUs); mini/nano/chat are available as standard deployments.\n- Deployment options: Global and Data Zone (US, EU).\n- API: Available via the v1 Responses API (recommended) and Chat Completions.\n\n#### Freeform tool calling\n\nFreeform tool calling in GPT‚Äë5 enables the model to send raw text payloads like Python scripts, SQL queries, or configuration files directly to external tools without needing to wrap them in structured JSON‚Äîeliminating rigid schemas and reducing integration overhead. In this episode, April shows how the model executes model‚Äëgenerated SQL to compute results, routes the output to Python for formatting and visualization, and returns reproducible artifacts (CSVs, charts) from a natural‚Äëlanguage prompt.\n\nTry it yourself in Azure AI Foundry:\n\n[Learn more](https://devblogs.microsoft.com/foundry/unlocking-gpt-5s-freeform-tool-calling-a-new-era-of-seamless-integration/)\n\n#### Pricing (per 1M tokens)\n\n| Model | Input (G) | Cached input (G) | Output (G) | | Input (DZ) | Cached input (DZ) | Output (DZ) | | --- | --- | --- | --- | --- | --- | --- | --- | | gpt‚Äë5 | $1.25 | $0.125 | $10.00 | | $1.375 | $0.1375 | $11.00 | | gpt‚Äë5‚Äëmini | $0.25 | $0.025 | $2.00 | | $0.275 | $0.0275 | $2.20 | | gpt‚Äë5‚Äënano | $0.05 | $0.005 | $0.40 | | $0.055 | $0.0055 | $0.44 | | gpt‚Äë5‚Äëchat | $1.25 | $0.125 | $10.00 | | ‚Äî | ‚Äî | ‚Äî |\n\nLegend: G = Global. DZ = Data Zone (US, EU).\n\n#### Regions & access\n\n- Regions (at launch): `eastus2`\nand `swedencentral`\n- Access: Registration is required for `gpt-5`\n([request access](https://aka.ms/oai/gpt5access)). If you already have o3 access, no additional request is required.\n- `gpt‚Äë5‚Äëmini`\n, `gpt‚Äë5‚Äënano` , and `gpt‚Äë5‚Äëchat` do not require registration.\n\n[Quickstart: Reasoning models](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/how-to/reasoning)\n\n### Model router: GPT‚Äë5 series support\n\nThe model router now supports dynamic selection across the GPT‚Äë5 family for cost and quality optimization. Access is limited for the latest router version‚Äîrequest via the GPT‚Äë5 access form (if you already have o3 access, no additional request is required). When the router selects a reasoning model, some parameters (for example, `temperature` /`top_p` ) may be ignored; `reasoning_effort` isn‚Äôt settable through the router. Billing is based on the underlying model the router selects.\n\n#### Quickstart: route with Chat Completions (Python)\n\n```python import os from openai import OpenAI\n\nclient = OpenAI( api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"), base_url=\"https://YOUR-RESOURCE-NAME.openai.azure.com/\", )\n\n# Replace with your model router deployment name\nresponse = client.chat.completions.create( model=\"model-router\", messages=[ {\"role\": \"user\", \"content\": \"Write a two-sentence product description for a smart thermostat.\"} ], )\n\nprint(response.choices[0].message.content) ```\n\n#### Watch: Model Router demo\n\n### Black Forest Labs FLUX image models\n\nFLUX.1 Kontext [pro] and FLUX1.1 [pro] are now available ‚ÄúDirect from Azure‚Äù in Foundry Models. Kontext is multimodal‚Äîtext-to-image plus in‚Äëcontext image editing‚Äîsupporting edit instructions, character/style/object reference without fine‚Äëtuning, and robust multi‚Äëstep refinements with minimal drift (up to ~8√ó faster at 1024√ó1024). FLUX1.1 [pro] focuses on text‚Äëto‚Äëimage generation only, achieves top-tier Elo on Artificial Analysis (evaluated as ‚Äúblueberry‚Äù), and is significantly faster than earlier FLUX releases, with an Ultra mode up to 4 MP.\n\n#### Model details\n\n| Model | Performance notes | Resolution / modes | Regions | Pricing (per 1K images) | | --- | --- | --- | --- | --- | | FLUX.1 Kontext [pro] | Up to 8√ó faster at 1024√ó1024; robust multi‚Äëedit consistency | 1024√ó1024 (default) | `swedencentral`<br>, `eastus2` | $40 | | FLUX1.1 [pro] | High Elo on Artificial Analysis; ~10s for 4 MP; up to 6√ó faster than FLUX 1‚Äëpro\\* | Up to 4 MP (Ultra mode) | `swedencentral`<br>, `eastus2` | $40 |\n\n\\*Performance depends on configuration.\n\n#### Get started\n\n- Find them under Foundry Models ‚Üí ‚ÄúDirect from Azure‚Äù; deploy to get an endpoint/key and try them in the Image Playground.\n\n[Read the announcement](https://techcommunity.microsoft.com/blog/azure-ai-foundry-blog/black-forest-labs-flux-1-kontext-pro-and-flux1-1-pro-now-available-in-azure-ai-f/4434659)\n\n### Mistral Document AI (OCR) ‚Äî serverless in Foundry\n\nUnlock high‚Äëfidelity, layout‚Äëaware document understanding with structured outputs. Mistral Document AI combines vision + language to preserve tables, figures, and headings; returns structured JSON and markdown‚Äëlike tables; and supports multilingual scans, PDFs, and complex forms. It‚Äôs sold ‚ÄúDirect from Azure‚Äù and deploys in one click as a serverless endpoint in Azure AI Foundry.\n\n![Mistral Document AI converting a scientific PDF into structured JSON with preserved tables and headings](https://devblogs.microsoft.com/foundry/wp-content/uploads/sites/89/2025/09/mistral-doc-structured-output.png) Source: @MistralAI post [2025-08-18](https://x.com/MistralAI/status/1957516008043729243)\n\n#### Watch: Mistral Document AI demo\n\nSee how Mistral Document AI parses complex PDFs, preserves layout, and returns structured JSON ‚Äî including tables, headings, and figures. The demo walks through serverless inference in Azure AI Foundry and exporting results for downstream RAG and automation workflows.\n\n#### Details\n\n| Model | Global | Data Zone | Regions | | --- | --- | --- | --- | | mistral-document-ai-2505 | $3.00 | $3.30 | `eastus2`<br>, `swedencentral` |\n\n#### Quickstart (Python, serverless REST)\n\n```python import os, base64, requests\n\nendpoint = os.environ[\"MISTRAL_DOC_AI_ENDPOINT\"] # e.g., https://{project}.eastus2.models.ai.azure.com/inference api_key = os.environ[\"MISTRAL_DOC_AI_KEY\"]\n\nheaders = { \"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {api_key}\", }\n\nwith open(\"sample.pdf\", \"rb\") as f: encoded = base64.b64encode(f.read()).decode(\"utf-8\")\n\npayload = { \"model\": \"mistral-document-ai-2505\", \"document\": { \"type\": \"document_url\", \"document_url\": f\"data:application/pdf;base64,{encoded}\", }, }\n\nresponse = requests.post(endpoint, json=payload, headers=headers) print(response.json()[\"pages\"][0][\"markdown\"]) # first page as markdown ```\n\nGet started with these [mistral/python](https://github.com/azure-ai-foundry/foundry-samples/tree/main/samples/mistral/python) Foundry samples in our GitHub repo.\n\n[Read the announcement](https://techcommunity.microsoft.com/blog/azure-ai-foundry-blog/unlocking-document-intelligence-mistral-ocr-now-available-in-azure-ai-foundry/4401836)\n\n### Sora API ‚Äî new updates (Preview)\n\nWe‚Äôve rolled out powerful new capabilities in Sora that unlock even more creative potential:\n\n#### What‚Äôs new\n\n- Image‚Äëto‚ÄëVideo support via API, including frame indexing and region‚Äëspecific inpainting.\n- Global Standard expansion: Sora is now available in East US 2 and Sweden Central under the Global Standard SKU.\n\n#### Get started\n\n- [Concepts](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/concepts/video-generation)\n- [Quickstart](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/video-generation-quickstart?tabs=windows%2Ckeyless)\n\n### VibeVoice ‚Äî long conversational TTS (Coming soon to Foundry Models)\n\nAn open-source, frontier text-to-speech framework for expressive, long-form, multi-speaker audio (think podcasts and panel shows).\n\n![VibeVoice hero image showing long‚Äëform, multi‚Äëspeaker TTS in Azure AI Foundry](https://devblogs.microsoft.com/foundry/wp-content/uploads/sites/89/2025/09/VibeVoice.png) Source: [VibeVoice GitHub Page](https://microsoft.github.io/VibeVoice/)\n\n#### Overview\n\nVibeVoice synthesizes expressive, long‚Äëform, multi‚Äëspeaker audio‚Äîup to ~90 minutes per session with natural turn‚Äëtaking across as many as four distinct voices. It brings context‚Äëaware expression (including spontaneous emotion and singing), cross‚Äëlingual transfer, and occasional background‚Äëmusic moments together with efficient continuous acoustic/semantic tokenizers operating at 7.5 Hz and a next‚Äëtoken diffusion head guided by an LLM for dialogue flow. Status: Coming soon to Foundry Models; in the meantime you can try the open weights in a live demo playground made with Gradio.\n\n#### Models (open weights)\n\n| Model | Parameters | Context length | Generation length | Weight | | --- | --- | --- | --- | --- | | VibeVoice-1.5B | 1.5 billion | 64K tokens | ~90 min | [HF link](https://huggingface.co/microsoft/VibeVoice-1.5B) | | VibeVoice-Large | 7 billion | 32K tokens | ~45 min | [HF link](https://huggingface.co/microsoft/VibeVoice-Large) | | VibeVoice-0.5B-Streaming | 0.5 billion | TBD | TBD | On the way |\n\n#### Get started\n\n- [Live demo (Gradio)](https://aka.ms/VibeVoice-Demo)\n- [GitHub](https://github.com/microsoft/VibeVoice)\n- [Hugging Face collection](https://huggingface.co/collections/microsoft/vibevoice-68a2ef24a875c44be47b034f)\n\n### OpenAI gpt‚Äëoss\n\nOpenAI‚Äôs first open‚Äëweight models since GPT‚Äë2‚Äî`gpt‚Äëoss‚Äë120b` and `gpt‚Äëoss‚Äë20b` ‚Äîare available in Azure AI Foundry. `gpt‚Äëoss‚Äë20b` also runs locally via Foundry Local and Windows AI Foundry.\n\n#### Models\n\n- `gpt‚Äëoss‚Äë120b`\n: reasoning‚Äëfocused, data‚Äëcenter class GPU (single‚ÄëGPU capable in cloud deployments).\n- `gpt‚Äëoss‚Äë20b`\n: lightweight, tool‚Äësavvy; optimized for local/edge including modern Windows PCs with 16GB+ VRAM.\n- API compatibility with the Responses API is coming‚Äîswap into existing apps with minimal changes.\n\n#### Run locally with Foundry Local\n\n- Install Foundry Local (preview). On Windows: winget install Microsoft.FoundryLocal\n- Requirements for `gpt‚Äëoss‚Äë20b`\n: Foundry Local 0.6.87+ and NVIDIA GPU with 16GB+ VRAM.\n- Quick CLI: foundry model run gpt-oss-20b\n\n#### Hello world (Python, Foundry Local)\n\n```python import openai from foundry_local import FoundryLocalManager\n\n# Use the GPT-OSS 20B model locally.\nalias = \"gpt-oss-20b\" # Requires Foundry Local >= 0.6.87 and ~16GB+ VRAM GPU\n\n# Start Foundry Local (if not running) and load the model\nmanager = FoundryLocalManager(alias)\n\n# Point OpenAI SDK to the local Foundry endpoint (no real key needed locally)\nclient = openai.OpenAI( base_url=manager.endpoint, api_key=manager.api_key )\n\n# Minimal chat request\nresp = client.chat.completions.create( model=manager.get_model_info(alias).id, messages=[{\"role\": \"user\", \"content\": \"Say hello from gpt-oss locally.\"}] )\n\nprint(resp.choices[0].message.content) ```\n\n#### Learn more\n\n- [Azure blog](https://azure.microsoft.com/en-us/blog/openais-open%E2%80%91source-model-gpt%E2%80%91oss-on-azure-ai-foundry-and-windows-ai-foundry/)\n- [Quickstart](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/get-started)\n\n## Agents\n\n### Browser Automation tool (Public Preview)\n\nShip agents that drive a real browser‚Äîsearch, navigate, fill forms, and even book appointments‚Äîusing natural language. Browser Automation runs inside your Azure subscription using your Microsoft Playwright Testing Workspace, so you don‚Äôt manage VMs or standalone browsers. Because it reasons over the page‚Äôs DOM (roles/labels) instead of pixels, it‚Äôs much more resilient than click‚Äëby‚Äëcoordinates flows. Learn how it works in the Browser Automation docs and what a Playwright Workspace is here: [Browser Automation](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/browser-automation) ¬∑ [Playwright Workspaces](https://learn.microsoft.com/en-us/azure/playwright-testing/overview-what-is-microsoft-playwright-testing).\n\nWhere it shines: automating multi‚Äëstep bookings and calendars, product discovery with criteria‚Äëbased navigation and summaries, and robust web form interactions (submissions, profile updates, document uploads). Multi‚Äëturn conversations mean you can correct and iterate without restarting the flow.\n\nSetup is straightforward: create a Playwright Workspace and token, add a Serverless connection to its wss:// regional endpoint in your Foundry project (Management center ‚Üí Connected resources), and grant the project identity the Contributor role on the Workspace. Then attach the tool to your agent by referencing the connection ID.\n\nHeads‚Äëup: review the transparency notes and warnings before pointing the tool at production sites; prefer low‚Äëprivilege, isolated environments.\n\nAdd the tool to an agent (Agents REST):\n\n```json { \"model\": \"MODEL_DEPLOYMENT_NAME\", \"instructions\": \"You can browse and fill forms on the specified site to accomplish the user's goal.\", \"tools\": [ { \"type\": \"browser_automation\", \"connection_id\": \"AZURE_PLAYWRIGHT_CONNECTION_NAME\" } ] } ```\n\nQuickstart (Python SDK):\n\n```python import os from azure.identity import DefaultAzureCredential from azure.ai.projects import AIProjectClient from azure.ai.agents.models import MessageRole, BrowserAutomationTool\n\nproject_client = AIProjectClient( endpoint=os.environ[\"PROJECT_ENDPOINT\"], credential=DefaultAzureCredential() )\n\nconnection_id = os.environ[\"AZURE_PLAYWRIGHT_CONNECTION_ID\"] # from Connected resources (wss://...) model = os.environ[\"MODEL_DEPLOYMENT_NAME\"]\n\nbrowser_tool = BrowserAutomationTool(connection_id=connection_id)\n\nwith project_client: agent = project_client.agents.create_agent( model=model, name=\"browser-agent\", instructions=\"Use the browser tool to complete the task.\", tools=browser_tool.definitions, )\n\nthread = project_client.agents.threads.create() project_client.agents.messages.create( thread_id=thread.id, role=MessageRole.USER, content=( \"Go to https://finance.yahoo.com, search for MSFT, switch the chart to YTD, \" \"and report the percent change.\" ), )\n\nrun = project_client.agents.runs.create_and_process(thread_id=thread.id, agent_id=agent.id) print(\"Run status:\", run.status) ```\n\n[Get started with Browser Automation](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/browser-automation)\n\n### Foundry Agent Service expands to four new regions\n\nAgent Service is now available in `brazilsouth` , `germanywestcentral` , `italynorth` , and `southcentralus` bringing the region support total to [17 Azure regions](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/concepts/model-region-support?tabs=global-standard#available-models).\n\n>\n> **NOTE**: The `file_search_tool`\n> is currently unavailable in the following regions `italynorth`\n> and `brazilsouth`\n> .\n>\n\n## Tools\n\n### Browser Automation (Public Preview)\n\nBuild agents that operate real browsers with natural language. Sessions run in your Azure subscription using Microsoft Playwright Workspaces, so you get isolation without any browser or VM management. Because the tool reads the accessibility tree and DOM roles/labels, it‚Äôs robust against minor UI shifts and avoids brittle pixel‚Äëmatching.\n\nCommon workflows include multi‚Äëstep bookings and calendars, product discovery with criteria‚Äëbased navigation and summarization, web‚Äëform submissions and profile updates, and support tasks that retrieve ticket or account status across web apps. To wire it up, create a Playwright Workspace and token, add a Serverless Model connection in your Foundry project to the Workspace‚Äôs wss:// regional endpoint, and grant your project identity the Contributor role.\n\nLearn more in the docs and the announcement post: [Docs](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/browser-automation) ¬∑ [Blog](https://devblogs.microsoft.com/foundry/announcing-the-browser-automation-tool-preview-in-azure-ai-foundry-agent-service/)\n\n[Run the samples](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/browser-automation-samples)\n\n## Platform (API, SDK, UI, and more)\n\n### Responses API ‚Äî Generally Available (GA)\n\nBuild intelligent, tool‚Äëusing agents with stateful, multi‚Äëturn conversations in a single API call. Now GA, the Responses API automatically maintains conversation state, stitches multiple tool calls with model reasoning and outputs in one flow, supports popular Azure OpenAI models‚Äîincluding the GPT‚Äë5 series and fine‚Äëtuned variants‚Äîfor predictable, structured outputs, and scales on Azure‚Äôs enterprise‚Äëgrade identity, security, and compliance.\n\n#### Tools (built‚Äëin and current limits)\n\n- Built‚Äëin: File Search, Function Calling, Code Interpreter (Python), Computer Use, Image Generation, and Remote MCP Server.\n- Not supported: Web search tool. Use Grounding with Bing Search instead.\n- Coming soon: Image generation multi‚Äëturn editing/streaming and image uploads referenced from prompts.\n\n#### API support\n\n- v1 API is required for access to the latest features. Learn more: https://learn.microsoft.com/en-us/azure/ai-foundry/openai/api-version-lifecycle#api-evolution\n\n#### Regions\n\n- Available in: `australiaeast`\n, `eastus` , `eastus2` , `francecentral` , `japaneast` , `norwayeast` , `polandcentral` , `southindia` , `swedencentral` , `switzerlandnorth` , `uaenorth` , `uksouth` , `westus` , `westus3` .\n- Note: Not every model is available in every region‚Äîsee model region availability: https://learn.microsoft.com/en-us/azure/ai-foundry/openai/concepts/models\n\n#### Model support\n\n- `GPT‚Äë5`\n, `GPT‚Äë4o` , and `GPT‚Äë4.1` , `o‚Äëseries` model families, plus `gpt‚Äëimage‚Äë1` and `computer‚Äëuse‚Äëpreview` .\n\n#### Notes & known limits\n\n- PDFs as input are supported, but file upload purpose `user_data`\nisn‚Äôt currently supported. Background mode with streaming may show performance issues (fix coming).\n\n#### Quickstart (Python, API key)\n\n```python import os from openai import OpenAI\n\nclient = OpenAI( api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"), base_url=\"https://YOUR-RESOURCE-NAME.openai.azure.com/openai/v1/\", )\n\nresponse = client.responses.create( model=\"MODEL_DEPLOYMENT_NAME\", # e.g., gpt-4.1-nano or your deployment name input=\"This is a test.\", )\n\nprint(response.model_dump_json(indent=2)) ```\n\n#### Get started\n\n- [Blog](https://techcommunity.microsoft.com/blog/azure-ai-services-blog/the-responses-api-in-azure-ai-foundry-is-now-generally-available/4446567)\n- [API reference (latest)](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/latest#create-response)\n\n[Build with Responses API](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/how-to/responses?tabs=python-key)\n\n### Python SDK release highlights\n\n- Agents: 1.1.0 stable is based on 1.0.2 (excludes beta features); 1.2.0b1 beta continues the experimental line and adds tool\\_resources support for async runs, with multiple fixes and public type promotions.\n- AI Evaluation: 1.10.0 adds `evaluate_query`\nfor RAI evaluators (default False) and delivers significant performance/variance improvements plus new grader and threshold controls.\n- AI Projects: 1.0.0 stable removes preview features and renames classes/APIs; 1.1.0b1 adds Evaluations cancel/delete; 1.1.0b2 fixes a Red‚ÄëTeam regression.\n\n[View Python SDK Release Notes](https://azure.github.io/azure-sdk/releases/2025-08/python.html)\n\n### .NET SDK release highlights\n\n- AI Agents Persistent 1.1.0 adds tracing for Agents, an include parameter to CreateRunStreaming/CreateRunStreamingAsync, and a tool\\_resources parameter to CreateRun/CreateRunAsync.\n- AI Agents Persistent 1.2.0-beta.1 fixes an issue where the after parameter was ignored when retrieving pageable lists.\n- OpenAI Inference 2.3.0-beta.1 carries forward a substantial number of features from the OpenAI library (see OpenAI 2.3.0 release notes for details).\n\n[View .NET SDK Release Notes](https://azure.github.io/azure-sdk/releases/2025-08/dotnet.html)\n\n### Java SDK Updates\n\n#### Agent Service Java SDK (Public Preview)\n\nPublic preview of the Agent Service Java SDK with Quickstart and tool samples. [Get started](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/quickstart?pivots=programming-language-java).\n\n##### Tool samples (Java)\n\n- [Azure AI Search](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/azure-ai-search-samples?pivots=java)\n- [Azure Functions](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/azure-functions-samples?pivots=java)\n- [Code Interpreter](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/code-interpreter-samples?pivots=java)\n- [File Search](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/file-search-upload-files?pivots=java)\n- [Bing Search](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/bing-code-samples?pivots=java)\n- [OpenAPI tools](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/openapi-spec-samples?pivots=java)\n\n[View Java SDK Release Notes](https://azure.github.io/azure-sdk/releases/2025-08/java.html)\n\n### JavaScript/TypeScript release highlights\n\n- AI Agents 1.1.0-beta.1 adds MCP tool, Deep Research tool and sample, and brings back SharepointGroundingTool, BingCustomSearchTool, MicrosoftFabricTool, and SharepointTool; includes a breaking change to DeepResearchDetails field names.\n- AI Agents 1.1.0-beta.2 fixes message image upload type error and stream event deserialization in runs.create.\n- AI Agents 1.1.0-beta.3 fixes missing required parameter json\\_schema in runs.createAndPoll.\n- AI Agents 1.1.0 (stable) removes preview-only tools (MCP, Deep Research, Sharepoint, BingCustomSearch, MicrosoftFabric) from the stable line.\n- AI Projects 1.0.0 includes breaking changes removing redTeams/evaluations and legacy inference helpers, plus renames for telemetry and Azure OpenAI client access.\n\n[View JavaScript/TypeScript SDK Release Notes](https://azure.github.io/azure-sdk/releases/2025-08/js.html)\n\n### Documentation Updates\n\n- [New] Capability hosts ‚Äî Concept: package tools/resources for agents; guidance on hosting, security, and deployment ([link](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/concepts/capability-hosts))\n- [New] Cost management for fine‚Äëtuning ‚Äî Track/limit spend, clean up artifacts, and optimize job configurations ([link](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/how-to/fine-tuning-cost-management))\n- [Updated] Deep Research tool ‚Äî How to enable and use the Deep Research tool in Agent Service ([link](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/deep-research))\n- [Updated] Deep Research samples ‚Äî End‚Äëto‚Äëend examples for Deep Research flows ([link](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/deep-research-samples))\n- [New] Evaluations storage account setup ‚Äî Configure storage for evaluations in projects ([link](https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/evaluations-storage-account))\n- [New] Migrate from hubs to Foundry projects ‚Äî Step‚Äëby‚Äëstep migration guidance and considerations ([link](https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/migrate-project))\n- [New] Serverless API inference for Foundry Models ‚Äî Code patterns for calling serverless ‚ÄúDirect from Azure‚Äù models ([link](https://learn.microsoft.com/en-us/azure/ai-foundry/concepts/models-inference-examples))\n- [New] Create Foundry resources with Terraform ‚Äî IaC guide for consistent provisioning ([link](https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/create-resource-terraform))\n- [Updated] Responses API ‚Äî Latest how‚Äëto for GA Responses API with v1 semantics ([link](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/how-to/responses))\n- [Updated] MCP tool samples ‚Äî Model Context Protocol samples and patterns ([link](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/model-context-protocol-samples))\n- [Updated] Customer‚Äëmanaged keys ‚Äî Concepts and setup for CMK across projects/hubs ([link](https://learn.microsoft.com/en-us/azure/ai-foundry/concepts/encryption-keys-portal))\n- [Updated] Evaluate apps ‚Äî Portal guide for evaluating generative AI applications ([link](https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/evaluate-generative-ai-app))\n- [Updated] Evaluate agents locally ‚Äî SDK guide for local agent evaluation workflows ([link](https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/develop/agent-evaluate-sdk))\n- [Updated] Evaluate apps locally ‚Äî SDK guide for app evaluation workflows ([link](https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/develop/evaluate-sdk))\n- [Updated] Foundry Models and capabilities ‚Äî Catalog concepts, capabilities, and model families ([link](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-models/concepts/models))\n- [New] Evaluation simulators ‚Äî Preview simulators to generate synthetic/adversarial data with end‚Äëto‚Äëend samples, multi‚Äëturn flows, regions, and JSONL helpers ([link](https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/develop/simulator-interaction-data))\n- [Updated] SharePoint tool samples ‚Äî Samples for the SharePoint tool ([link](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/sharepoint-samples))\n- [Updated] View evaluation results in the portal ‚Äî Portal views and interpretation tips ([link](https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/evaluate-results))\n- [Updated] Managed network for hubs ‚Äî Clarifies isolation modes (Internet outbound vs Approved outbound), hub‚Äëbased only, irreversible once enabled, Azure Firewall FQDN rules (cost), and adds the Enterprise Network Connection Approver role ([link](https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/configure-managed-network))\n- [Updated] Role‚Äëbased access control ‚Äî Expanded role definitions (Azure AI User, Project Manager, Account Owner) with JSON permission blocks and conditional delegation; Contributor can deploy models ([link](https://learn.microsoft.com/en-us/azure/ai-foundry/concepts/rbac-azure-ai-foundry))\n- [Updated] Customer‚Äëenabled disaster recovery ‚Äî No automatic failover; guidance for hot/hot, hot/warm, hot/cold; hub‚Äëbased only; paired regions and replication responsibilities table ([link](https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/disaster-recovery))\n- [Updated] Deploy Azure OpenAI models ‚Äî Refined portal flows from Catalog/Project, updated inference guidance, and quota/region pointers ([link](https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/deploy-models-openai))\n- [New] Azure AI Foundry status dashboard (Preview) ‚Äî Live status, incident timelines/RCAs, historical uptime; subscribe via email/SMS/webhook ([link](https://learn.microsoft.com/en-us/azure/ai-foundry/azure-ai-foundry-status-dashboard-documentation))\n- [Updated] Azure OpenAI API lifecycle (v1) ‚Äî GA endpoints; preview opt‚Äëin via headers or path; use OpenAI client with base\\_url to /openai/v1; APIM OpenAPI 3.1 caveat ([link](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/api-version-lifecycle))\n- [Updated] Quotas and limits ‚Äî Adds GPT‚Äë5 TPM/RPM tables, model‚Äërouter tier limits, o‚Äëseries capacity unit RPM/TPM ratios; capacity API to check regional availability ([link](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/quotas-limits))\n- [Updated] Tracing & observability ‚Äî How to instrument agents/apps with OpenTelemetry, view traces in portal, and export to Azure Monitor ([link](https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/develop/trace-agents-sdk))\n- [Updated] Deploy an enterprise chat web app ‚Äî Deploy from the playground to App Service with Microsoft Entra authentication and key setup tips ([link](https://learn.microsoft.com/en-us/azure/ai-foundry/tutorials/deploy-chat-web-app))\n- [Updated] Model availability & regions ([link](https://learn.microsoft.com/en-us/azure/ai-foundry/reference/region-support)) ‚Äî Canonical region support across Foundry features and model matrices with per‚Äëregion availability. ([link](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/concepts/models#model-summary-table-and-region-availability))\n\nHappy building‚Äîlet us know what you ship with #AzureAIFoundry over in [Discord](https://aka.ms/foundry/discord) or [GitHub Discussions](https://aka.ms/foundry/forum)!",
  "FeedName": "Microsoft AI Foundry Blog",
  "FeedUrl": "https://devblogs.microsoft.com/foundry/feed/",
  "Link": "https://devblogs.microsoft.com/foundry/whats-new-in-azure-ai-foundry-august-2025/",
  "Tags": [
    "agents",
    "Azure AI Foundry",
    "Azure SDKs",
    "azure-openai",
    "Browser Automation",
    "FLUX",
    "Foundry Local",
    "GPT-5",
    "GPT-OSS",
    "Mistral Document AI",
    "Model Router",
    "responses-api",
    "Sora",
    "What's New"
  ]
}
