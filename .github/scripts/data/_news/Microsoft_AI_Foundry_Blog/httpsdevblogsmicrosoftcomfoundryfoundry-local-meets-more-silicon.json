{
  "Tags": [
    "AI Development",
    "Azure AI Foundry",
    "Foundry Local",
    "FoundryLocal",
    "What's New"
  ],
  "Description": "Foundry Local is a high-performance local AI runtime stack that brings Azure AI Foundry’s power to client devices. Foundry Local lets you build and ship cross-platform AI apps that run models with acceleration on a wide range of hardware. The Evolution of AI Acceleration On-device AI has progressed rapidly. Early workloads ran on CPUs, but […]\n\nThe post [Foundry Local Meets More Silicon](https://devblogs.microsoft.com/foundry/foundry-local-meets-more-silicon/) appeared first on [Azure AI Foundry Blog](https://devblogs.microsoft.com/foundry).",
  "FeedLevelAuthor": "Azure AI Foundry Blog",
  "Title": "Foundry Local Meets More Silicon",
  "FeedUrl": "https://devblogs.microsoft.com/foundry/feed/",
  "EnhancedContent": "Foundry Local is a high-performance local AI runtime stack that brings Azure AI Foundry’s power to client devices. Foundry Local lets you build and ship cross-platform AI apps that run models with acceleration on a wide range of hardware.\n\n## The Evolution of AI Acceleration\n\nOn-device AI has progressed rapidly. Early workloads ran on CPUs, but performance and power limits made real-time inference difficult. GPUs improved things with parallelism, faster inference. The latest breakthrough is NPUs (Neural Processing Units), designed specifically for neural networks. NPUs deliver far greater efficiency and throughput, making advanced models practical on desktop and mobile applications. This shift enables AI that is faster, more energy-efficient, and privacy-preserving — without constant reliance on the cloud.\n\n## What’s New\n\nWith the release of Foundry Local v0.7, we are pleased to announce expanded NPU support, now including Intel and AMD NPUs on Windows 11. We are also continuing to make Foundry Local improvements for NVIDIA and Qualcomm silicon, in partnership with our silicon partners. Furthermore, leveraging [Windows ML](https://blogs.windows.com/windowsdeveloper/?p=57575), Foundry Local automatically detects users’ silicon across NPU, GPU, and CPU and downloads the appropriate execution providers, removing the necessity for these to be bundled with Foundry Local.\n\n[![Example screenshot](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA50AAAESAQMAAABEmyMtAAAAA1BMVEXW1taWrGEgAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAANklEQVR4nO3BMQEAAADCoPVPbQhfoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABeA306AAFC5jXPAAAAAElFTkSuQmCC)](https://devblogs.microsoft.com/foundry/wp-content/uploads/sites/89/2025/09/FL_dev_blog_refresh.png)\n\n## Get Started\n\n##\n\n**On Windows**\n\n1. Open Windows Terminal\n2. Install Foundry Local using winget\n\n```default winget install Microsoft.FoundryLocal ```\n3. Run a model\n\n```default foundry model run qwen2.5-0.5b ```\n\n**On MacOS**\n\n1. Open Terminal\n2. Install Foundry Local\n\n```default brew tap microsoft/foundrylocal brew install foundrylocal ```\n3. Run a model\n\n```default foundry model run qwen2.5-0.5b ```\n\nFor more information, check out Foundry Local documentation and samples [here](http://aka.ms/foundry-local-docs). For developers interested in bringing their own models to Windows, check out [Windows ML](https://blogs.windows.com/windowsdeveloper/?p=57575) now available in general availability.",
  "PubDate": "2025-09-23T19:01:15+00:00",
  "Author": "Meng Tang",
  "Link": "https://devblogs.microsoft.com/foundry/foundry-local-meets-more-silicon/",
  "FeedName": "Microsoft AI Foundry Blog",
  "OutputDir": "_news",
  "ProcessedDate": "2025-09-23 19:09:48"
}
