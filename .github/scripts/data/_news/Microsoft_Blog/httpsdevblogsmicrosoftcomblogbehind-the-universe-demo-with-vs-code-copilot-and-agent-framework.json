{
  "OutputDir": "_news",
  "EnhancedContent": "At this year’s **GitHub Universe**, we set out to answer a simple question:\n\n***What would it take to go from an idea to production in under 30 minutes – using only natural language, your editor, and AI?*** On stage, we built a cloud-native, intelligent app from scratch using [Visual Studio Code](https://code.visualstudio.com), [GitHub Copilot](https://github.com/features/copilot), and the [Microsoft Agent Framework](https://learn.microsoft.com/en-us/agent-framework/). In this post, we’ll walk through the journey step-by-step:\n\n1. From **spec to code** – generating a working app from a simple prompt\n2. Adding **intelligence and agents** – building AI into your workflow\n3. Letting an **AI SRE** keep things humming in production\n\n## From spec to code\n\nModern greenfield apps aren’t just “hosted in the cloud” anymore – they’re *born* there. They’re expected to be cloud-native and auto-scaling. The **table stakes have been raised**, and they should now be **intelligent and self-healing by default too**. But getting there shouldn’t require weeks of trawling docs or endless click-ops.\n\nThe only scalable path is to move from writing *instructions* to defining *intent.*\n\nThat’s where [GitHub Spec Kit](https://github.com/github/spec-kit) comes in. You describe *what* you want – the problem you’re trying to solve, the expected users you’re aiming to support, the outcomes you want to achieve, and your preferences in how to approach the work – and then you let AI generating the scaffolding. We showed how you can initialize a new project using Spec Kit’s CLI and a single high-level prompt:\n\n```default uvx --from git+https://github.com/github/spec-kit.git specify init Octopets ```\n\n[https://devblogs.microsoft.com/wp-content/uploads/2025/10/speckit-start.mp4](https://devblogs.microsoft.com/wp-content/uploads/2025/10/speckit-start.mp4)\n\nThen, directly inside VS Code, we guided the build with structured commands:\n\n- `/constitution`\n– establish principles like code quality, testing standards, user experience consistency, and performance baselines\n- `/specify`\n– describe your app; Spec Kit expands it into a **product spec** .prd file, user stories, and success criteria.\n- `/plan`\n– choose your tech stack (say, node.js on Azure Functions + React) and get a full **technical design**.\n- `/tasks`\n– auto-generate a backlog of tasks (“create an API endpoint” or “set up database schema”, etc.)\n\nFrom there, Copilot’s **implementation** phase kicks in, writing and refining each task. You review, steer, and commit. It’s like running a mini AI-powered scrum team.\n\n[https://devblogs.microsoft.com/wp-content/uploads/2025/10/speckit-impl.mp4](https://devblogs.microsoft.com/wp-content/uploads/2025/10/speckit-impl.mp4)\n\nBecause Spec Kit integrates with the [**Azure Model Context Protocol (MCP) Server**](https://learn.microsoft.com/en-us/azure/developer/azure-mcp-server/get-started)**,** Copilot understands your environment – regions, databases, configs, best practices. This makes it a super powerful tool so that you can use natural language prompts and agentic workflows to:\n\n- Configure cloud resources and CI / CD\n- Align code generation with your performance and compliance targets\n- Deploy the whole app, end-to-end\n\nWhat used to take hours of boilerplate setup now happens in minutes. When your intent is unambiguous, AI can generate *not just code* – but a working, deployable project.\n\n## Adding intelligence and AI-powered agents\n\nNext, we made the app *smart.*\n\nAgents aren’t just functions — they’re systems that **perceive, reason,** and **act.** Building them requires orchestration, not just code.\n\nThat’s why we built the [AI Toolkit for VS Code](https://aka.ms/aitoolkit) – so you can have all the tools at your fingertips to build great intelligent applications. From within your code editor, you can use natural language to help you:\n\n- Explore over 200 models in the catalog and select the right models for your use case\n- Compose multi-agent workflows\n- Add observability and agent traces\n- Evaluate response quality and add guardrails\n\nIn our demo, we built a vision-and-language agent that takes a pet photo and answers questions about it. Inside VS Code you can literally *watch* its reasoning trace—calling the vision model, interpreting results, querying the LLM, and returning the final answer. Debugging AI logic now feels as natural as debugging regular code.\n\nOne thing that really helps is that the **toolkit traces and visualizes an agent’s thought process**.\n\n**![Visual Studio Code showing toolkit traces and visualization](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAB3sAAAS3AQMAAADVV4JjAAAAA1BMVEXW1taWrGEgAAAACXBIWXMAAA7EAAAOxAGVKw4bAAABMUlEQVR4nO3BMQEAAADCoPVPbQwfoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgJMBcIMAAVsfl50AAAAASUVORK5CYII=)**\n\nAnd just like CI for traditional software, you can **add CI for your agents** using the new *[Azure AI Agent Evaluation](https://github.com/microsoft/ai-agent-evals) SDK.* Every push triggers automated tests against example inputs and expected behaviors. If your agent regresses, the build fails. Continuous integration – but now for AI behavior.\n\n**![Visual Studio Code showing Sitter Agent Evaluation Results, all tests passing](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAB34AAAS0AQMAAAC16juJAAAAA1BMVEXW1taWrGEgAAAACXBIWXMAAA7EAAAOxAGVKw4bAAABMElEQVR4nO3BAQ0AAADCoPdPbQ43oAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAfgxtsAABdG8wdAAAAABJRU5ErkJggg==)**\n\n## Letting an SRE agent run ops\n\nShipping is only half the story. Anyone who’s been on call for a cloud service knows the stress of late-night alerts and the grind of troubleshooting issues under pressure. Running production services is where things get real.\n\nEnter the [**Azure SRE Agent**](https://aka.ms/SREAgent) – your tireless, code-capable teammate for operations.\n\nWe demo’d this by *breaking our own app* on stage, causing HTTP 500 errors in one of the APIs. Normally, this would page an engineer and lead to a scramble. But here’s what happened instead – automatically and autonomously:\n\n1. The agent detected a spike in HTTP 500s, parsed the logs, and recognized a pattern from the exceptions\n2. It opened a detailed GitHub issue with stack traces and timestamps\n3. It diagnosed a `NullReferenceException`\nin the location validation code (our code wasn’t handling a missing coordinate properly)\n4. It took a mitigation action **immediately** – scaling out the affected service on Azure Container Apps to reduce the error rate and keep the app responsive.\n5. It **proposed and committed a fix** for the bug and opened a pull request on our GitHub repo with the code change. (Yes, our SRE Agent has coding capabilities, via Copilot!)\n6. Finally, once the fix was applied, it verified recovery and closed the incident\n\nHere’s a snippet of the log that the SRE Agent produced, which pretty much tells the story:\n\n```default 1 // SRE Agent: 500 errors detected in Octopets pet-locations-api service 2 // Time: Saturday, 6:17 AM 3 // Action: Analyzed logs and identified NullReferenceException in location validation code 4 // Root cause: Incorrect handling of null coordinates in location filter 5 // Resolution: Applied hotfix to properly validate location parameters before processing 6 // Status: Deployed to production, error rate returned to normal 7 // GitHub Issue #4728 created with full incident report and fix details ```\n\nThis is **agentic DevOps** in action: systems that not only observe but *act*—while keeping humans in the loop. The SRE Agent doesn’t replace engineers; it handles the repetitive, high-pressure tasks so you can focus on architecture, quality, and user experience.\n\n## The developer’s new role\n\nThe **craft of software development is evolving** – from typing code to **articulating intent.**\n\nWhen your source of truth is *what you want built,* not just *how it’s written,* AI becomes an amplifier. Developers evolve into orchestrators: designing specs, guiding agents, and validating outcomes. It’s not less creative – it’s *more* creative.\n\nYou spend less time wrestling with scaffolding and ops, and more time shaping ideas that matter.\n\nDevelopers build the future – and with AI, we can build it *faster*, *better,* and with a lot more *fun*.\n\nWe can’t wait to see what you create when your editor becomes an intelligent workspace and your agents become collaborators.\n\n## Try it yourself!\n\nAll the tools we showed are available today:\n\n- [**GitHub Spec Kit**](https://github.com/github/spec-kit) – open source on GitHub, contributions welcome!\n- [**VS Code AI Toolkit**](https://marketplace.visualstudio.com/items?itemName=ms-ai-toolkit) – build and test agents directly in your editor\n- [**Microsoft Agent Framework**](https://github.com/microsoft/agent-framework) –learn the basics of how to build and orchestrate agents and workflows and experiment locally\n- [**Azure AI Foundry**](https://azure.microsoft.com/en-us/products/ai-foundry/) – the platform for making models, agents, tools, and context work together\n- [**Azure SRE Agent**](https://azure.microsoft.com/en-us/services/sre-agent/) – preview now and start training your tireless AI SRE that can take those 2am live site calls for you\n\n## See it in action\n\nWatch as we explain and build this out live in our GitHub Universe presentation, [Build apps & agents that scale with VS Code, GitHub Copilot, and Agent Framework](https://reg.githubuniverse.com/flow/github/universe25/attendee-portal/page/sessioncatalog/session/1759234736313001IaUs).",
  "Tags": [
    "AI",
    "Developer Events",
    "GitHub Copilot",
    "Microsoft for Developers"
  ],
  "Link": "https://devblogs.microsoft.com/blog/behind-the-universe-demo-with-vs-code-copilot-and-agent-framework",
  "FeedUrl": "https://devblogs.microsoft.com/feed",
  "FeedLevelAuthor": "Microsoft for Developers",
  "ProcessedDate": "2025-10-31 19:05:13",
  "Author": "Amanda Silver, Rong Lu, Shayne Boyer",
  "Title": "Behind the Universe demo: From prompt to production with VS Code, GitHub Copilot and the Microsoft Agent Framework",
  "FeedName": "Microsoft Blog",
  "Description": "At this year’s GitHub Universe, we set out to answer a simple question: What would it take to go from an idea to production in under 30 minutes – using only natural language, your editor, and AI? On stage, we built a cloud-native, intelligent app from scratch using Visual Studio Code, GitHub Copilot, and the […]\n\nThe post [Behind the Universe demo: From prompt to production with VS Code, GitHub Copilot and the Microsoft Agent Framework](https://devblogs.microsoft.com/blog/behind-the-universe-demo-with-vs-code-copilot-and-agent-framework) appeared first on [Microsoft for Developers](https://devblogs.microsoft.com).",
  "PubDate": "2025-10-31T19:00:45+00:00"
}
