{
  "FeedUrl": "https://blog.fabric.microsoft.com/en-us/blog/feed/",
  "Description": "Read and Write integration announcement between Microsoft OneLake and Azure Databricks",
  "Link": "https://blog.fabric.microsoft.com/en-US/blog/microsoft-and-databricks-advancing-openness-and-interoperability-with-onelake/",
  "Tags": [],
  "Author": "Microsoft Fabric Blog",
  "FeedLevelAuthor": "Microsoft Fabric Blog",
  "EnhancedContent": "*Co-authored by [Adam Conway](https://www.linkedin.com/in/adammconway/), SVP Products at Databricks, and [Arun Ulag](https://www.linkedin.com/in/arunulag/), President of Microsoft Azure Data*\n\nFor nearly a decade, Microsoft and Databricks have closely partnered with the goal of empowering organizations to unlock the value of their data. Together, we’ve delivered solutions that combine the flexibility of the lakehouse architecture with the scale and security of Azure. Today, we’re taking that collaboration even further by deepening integration between Azure Databricks and Microsoft OneLake.\n\n## **Delivering on the promise of an open data lakehouse**\n\nThe current pace of technological innovation requires data estates to be more flexible than ever before. Seamless interoperability between platforms is no longer an ideal goal but a technical imperative. Organizations need the freedom to choose the right tools for their data project without worrying about data silos or complex integrations. That’s why Databricks pioneered the **open** **lakehouse architecture**, and why Microsoft built **OneLake**—an open data lake designed to serve as the foundation for data and AI.\n\nTogether, we’re making this vision real:\n\n- **Mirroring data into OneLake – already generally available**\nEarlier this year we released Azure Databricks mirroring. Customers can already [**mirror Databricks data into OneLake**](https://learn.microsoft.com/fabric/mirroring/azure-databricks) through Unity Catalog. ensuring that all data—including the highest performance tables managed by Azure Databricks—are instantly available across Microsoft Fabric workloads. Both platforms can work over the same copy of data stored in Delta Lake format with no data movement.\n- **Reading data from OneLake – coming by year-end**\nWhile Databricks managed data is available in OneLake, reading OneLake data from Databricks will soon be enabled with the recent OneLake catalog API. By the end of 2025, Azure Databricks will enable **native reading from OneLake** through Unity Catalog in preview, allowing users to seamlessly access data stored in OneLake without duplication or complex pipelines. Data can come from any Fabric workload. This means faster analytics and lower costs.\n\n![Image of &quot;creating a new catalog&quot; UI in Azure Databricks with the OneLake connection selected](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/11/Databricks-blog-image-1024x507.png)Connecting to OneLake data in Azure Databricks\n\n## **Writing and storing data natively in OneLake – on the horizon**\n\nLooking ahead, Azure Databricks will support **writing and storing data directly in OneLake**, without any additional storage resources to manage. This will deliver additional simplicity and interoperability for customers building on the lakehouse architecture. We’ll share timelines for this capability at FabCon in March 2026.\n\n## **Why this matters for customers**\n\nThese new integrations go beyond technical progress—they underscore our shared commitment to openness, flexibility, and empowering customers with choice. Together, Microsoft and Databricks are helping organizations unlock more value from their data with a seamless, unified foundation across both platforms.\n\nWith these integrations, customers can:\n\n- **Choose the right engine and tool for the job at hand:** Gain full flexibility to pick the engine, tool, or platform you want for every task—based on your goals, workloads, or team expertise—without compromise.\n- **Bring data directly into your productivity apps:** The OneLake catalog is now woven into Microsoft 365 experiences such as Teams, Excel, and Copilot Studio. This means business users can easily discover, access, and apply insights right where they work. For example, Teams users can enrich chats, channels, and meetings with data-driven context, with any data governed by OneLake or Unity Catalog.\n- **Scale resources efficiently and focus on innovation:** With a single, shared copy of data across Microsoft Fabric and Azure Databricks, you can eliminate costly duplication, streamline governance, and redirect time and investment toward innovation instead of data movement.\n- **Deliver richer AI and analytics outcomes:** Whether you’re building copilots in Microsoft Copilot Studio and AI Foundry, building Agents in Azure Databricks, or visualizing data in Power BI, you can unify and integrate data across Azure Databricks and Microsoft solutions—without ever moving it. Likewise, data in OneLake can seamlessly flow into Azure Databricks to power advanced AI, analytics, and data-sharing scenarios.\n\n## **A shared commitment to innovation**\n\nOur collaboration is built on trust and a shared belief that openness drives innovation. By bringing Azure Databricks and OneLake closer together, we’re giving customers the freedom to build modern data architectures without compromise.\n\nWe’re excited about what’s next—and we’re just getting started.",
  "PubDate": "2025-11-18T08:00:00+00:00",
  "ProcessedDate": "2025-11-19 19:02:42",
  "OutputDir": "_news",
  "FeedName": "Microsoft Fabric Blog",
  "Title": "Microsoft and Databricks: Advancing Openness and Interoperability with OneLake"
}
