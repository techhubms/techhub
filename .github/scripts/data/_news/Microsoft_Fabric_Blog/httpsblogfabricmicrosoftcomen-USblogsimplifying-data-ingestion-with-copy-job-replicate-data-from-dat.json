{
  "OutputDir": "_news",
  "EnhancedContent": "Copy job is the recommended approach in Microsoft Fabric Data Factory for moving data from any sources to any destinations in a simplified and efficient way—whether you’re transferring data across clouds, from on-premises systems, or between services. With native support for multiple delivery patterns, including bulk copy, incremental copy, and change data capture (CDC) replication, Copy job provides the flexibility to handle a wide range of data movement scenarios, all through an intuitive and easy-to-use experience.\n\nCopy job already supports a list of CDC-enabled sources and destinations, allowing changed data—including inserts, updates, and deletions—to be automatically captured and replicated to supported targets. You can get more details in [Change data capture (CDC) in Copy Job – Microsoft Fabric | Microsoft Learn](https://learn.microsoft.com/en-us/fabric/data-factory/cdc-copy-job).\n\nFor source systems that Copy job does not yet natively support for CDC, such as Dataverse, you can still achieve CDC replication by using Copy job together with Fabric Link. Copy job becomes essential when you need to move data across regions or tenants, or when you want to replicate Dataverse data to multiple destinations beyond Fabric.\n\nThis blog provides step-by-step guidance on how to use Copy job to replicate data—including inserts, updates, and deletions—from Dataverse through Fabric to multiple destinations.\n\n## How it works\n\n**Prerequisites**\n\nYour Dynamics Finance & Operations (F&O) ERP environment is always linked to an associated Dataverse environment. You can view this mapping in the Power Platform Admin Center, where you can check which F&O environment is connected to which Dataverse environment.\n\n![](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/11/image-116.png)\n\n1. Go to the Power Apps maker portal ([https://make.powerapps.com](https://make.powerapps.com)), and select **“Link to Microsoft Fabric”** to replicate data from your Dataverse environment to a Fabric Lakehouse.\n\n![](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/11/image-115.png)\n\n2. Enter the required connection information to connect Dataverse to a Fabric Lakehouse.\n\nYou can either create a new workspace or use an existing one in Microsoft Fabric, and a Fabric Lakehouse will be created in the selected workspace.\n\n![](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/11/image-117.png)\n\n3. After you click “Review and Create,” a Fabric Lakehouse will be provisioned.\n\n![](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/11/image-118.png)\n\n4. Select the tables from Dataverse and F&O that you want to synchronize to Fabric.\n\n![](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/11/image-119.png)\n\n5. Access your newly created Fabric Lakehouse by clicking “View in Microsoft Fabric.”\n\n![](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/11/image-120.png)\n\n6. Now, go to Microsoft Fabric ([https://app.powerbi.com](https://app.powerbi.com)/) to create a Copy job to replicate the same data to multiple destinations.\n\n![](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/11/image-121.png)\n\n7. From the creation wizard of Copy job, select the Fabric Lakehouse you just created via the Fabric Link (in step 3) as data source, and then choose any tables from the Lakehouse that you want to copy from.\n\n![](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/11/image-122.png)\n\n8. Select the destination where you want to copy the data to. To replicate all changes—including inserts, updates, and deletions—choose a CDC-supported destination.\n\nYou can get the concrete supported connector list from [Change data capture (CDC) in Copy Job – Microsoft Fabric | Microsoft Learn](https://learn.microsoft.com/en-us/fabric/data-factory/cdc-copy-job). For example, you can replicate data into an Azure SQL Database.\n\n![](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/11/image-123.png)\n\n9. Select incremental copy.\n\n![](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/11/image-124.png)\n\n10. Choose an update method to merge data to your destination.\n\n![](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/11/image-125.png)\n\n11. After completing the creation wizard, a new Copy job will be created. When you run it, the first run will perform an initial full copy, and subsequent runs will replicate changes, including inserts, updates, and deletions.\n\n![](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/11/image-126.png) ![](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/11/image-127.png)\n\n## **Summary**\n\nYou can easily use Copy job from Fabric Data Factory, via the Fabric Link, to replicate data—including inserts, updates, and deletions—from Dataverse into multiple destinations. This also enables replicate data from Dataverse across different tenants or regions.\n\n## **Additional Resources**\n\nTo learn more, explore [Microsoft Fabric Copy job](https://learn.microsoft.com/fabric/data-factory/what-is-copy-job) documentation.\n\nSubmit your feedback on [Fabric Ideas](https://community.fabric.microsoft.com/t5/Fabric-Ideas/idb-p/fbc_ideas/label-name/data%20factory%20%7C%20copy%20job) and join the conversation in [the Fabric Community](https://community.fabric.microsoft.com/t5/Copy-job/bd-p/db_copyjob).\n\nIf you have a question or want to share your feedback, please leave us a comment below!",
  "FeedUrl": "https://blog.fabric.microsoft.com/en-us/blog/feed/",
  "Title": "Simplifying Data Ingestion with Copy job – Replicate data from Dataverse through Fabric to multiple destinations",
  "ProcessedDate": "2025-12-01 17:03:58",
  "Tags": [],
  "Description": "Copy job is the recommended approach in Microsoft Fabric Data Factory for moving data from any sources to any destinations in a simplified and efficient way—whether you’re transferring data across clouds, from on-premises systems, or between services. With native support for multiple delivery patterns, including bulk copy, incremental copy, and change data capture (CDC) replication, …\n\n[Continue reading “Simplifying Data Ingestion with Copy job – Replicate data from Dataverse through Fabric to multiple destinations”](https://blog.fabric.microsoft.com/en-us/blog/simplifying-data-ingestion-with-copy-job-replicate-data-from-dataverse-through-fabric-to-multiple-destinations/)",
  "FeedLevelAuthor": "Microsoft Fabric Blog",
  "Author": "Microsoft Fabric Blog",
  "Link": "https://blog.fabric.microsoft.com/en-US/blog/simplifying-data-ingestion-with-copy-job-replicate-data-from-dataverse-through-fabric-to-multiple-destinations/",
  "FeedName": "Microsoft Fabric Blog",
  "PubDate": "2025-12-01T09:00:00+00:00"
}
