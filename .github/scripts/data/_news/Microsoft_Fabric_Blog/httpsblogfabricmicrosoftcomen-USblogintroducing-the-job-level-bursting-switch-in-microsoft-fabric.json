{
  "Title": "Introducing the Job-Level Bursting Switch in Microsoft Fabric",
  "Description": "We’re introducing a new feature that gives you more granular control over your Spark compute resources in Microsoft Fabric: The Job-Level Bursting Switch. This highly anticipated addition empowers capacity administrators to fine-tune how Spark jobs utilize burst capacity, optimizing for either peak performance or higher concurrency based on your specific workload needs. Microsoft Fabric’s Compute …\n\n[Continue reading “Introducing the Job-Level Bursting Switch in Microsoft Fabric”](https://blog.fabric.microsoft.com/en-us/blog/introducing-the-job-level-bursting-switch-in-microsoft-fabric/)",
  "Tags": [],
  "PubDate": "2025-10-14T07:00:00+00:00",
  "OutputDir": "_news",
  "ProcessedDate": "2025-10-14 14:03:17",
  "EnhancedContent": "We’re introducing a new feature that gives you more granular control over your Spark compute resources in Microsoft Fabric: The Job-Level Bursting Switch. This highly anticipated addition empowers capacity administrators to fine-tune how Spark jobs utilize burst capacity, optimizing for either peak performance or higher concurrency based on your specific workload needs.\n\nMicrosoft Fabric’s Compute Units offer a powerful 3× bursting capability, allowing a single Spark job to temporarily consume significantly more compute cores than your base capacity provides. This intelligent design helps accelerate job performance during intensive periods, ensuring full utilization of your available resources when it matters most.\n\n### Taking Control – The ‘Disable job-level bursting’ Switch\n\nWith this new release, capacity administrators now have direct control over this behavior via the ‘Disable job-level bursting’ switch, conveniently located in the Admin Portal:\n\n**Location:** Admin Portal → Capacity Settings → [Select Capacity] → Data Engineering/Science Settings → Job Management\n\n![](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/08/image-23-1024x591.png)\n\n## How it Works\n\n- **Enabled (Default):** When enabled, a single Spark job can leverage the full burst limit, consuming up to 3× CUs. This is ideal for demanding ETL processes or large analytical tasks that benefit from maximum immediate compute power.\n- **Disabled:** If you disable this switch, individual Spark jobs will be capped at the base capacity allocation. This prevents a single job from monopolizing the burst capacity, thereby preserving concurrency and improving the experience for multi-user, interactive scenarios.\n\n### Important Considerations for Autoscale Billing\n\nIt’s crucial to note that this switch is **only available** when running Spark jobs on **Fabric Capacity**. If the Autoscale Billing option is enabled for your capacity, this switch will be automatically disabled. This is because Autoscale Billing operates on a pure pay-as-you-go model with no smoothing window, meaning all Spark usage is billed on demand without relying on reserved capacity bursting.\n\n### Optimizing for Your Workloads: Use Cases and Examples\n\nThe Job-Level Bursting Switch provides flexibility to cater to diverse data engineering and science requirements:\n\n| Scenario | Setting | Behavior | | --- | --- | --- | | **Heavy ETL Workload** | Bursting **enabled** | Job can use the entire burst capacity (e.g., 192 CUs in an F64 capacity), accelerating execution. | | **Multi-user Interactive Notebooks** | Bursting **disabled** | Job usage is capped (e.g., 64 CUs in an F64 capacity), improving overall concurrency for many users. | | **Autoscale Billing is enabled** | Bursting control **unavailable** | All Spark usage is billed on demand; no bursting from base capacity as it follows a pay-as-you-go model. |\n\n### Choose Your Optimization – Throughput vs. Concurrency\n\nThis new switch is a powerful tool to help you fine-tune your Fabric Spark environment:\n\n- Keep bursting enabled for large-scale jobs, critical ETL pipelines, and compute-intensive tasks where maximizing single-job throughput is paramount.\n- Disable it for interactive development, shared environments, or scenarios with many concurrent users where maintaining consistent responsiveness for multiple jobs is more important.\n\nWe believe the Job-Level Bursting Switch will provide our customers with even greater control and flexibility in managing their Spark workloads on Microsoft Fabric. This feature, combined with our existing capabilities like Optimistic Job Admission, empowers you to build highly efficient and responsive data solutions.\n\nTo learn more about optimizing your Spark workloads in Microsoft Fabric, please refer to our documentation:\n\n- [Job bursting control in Capacity Settings](https://learn.microsoft.com/fabric/data-engineering/capacity-settings-management#admin-control-job-level-bursting-switch)\n- [Concurrency limits and queueing in Microsoft Fabric Spark](https://learn.microsoft.com/fabric/data-engineering/spark-job-concurrency-and-queueing)\n- [Job queueing for Fabric Spark](https://learn.microsoft.com/fabric/data-engineering/job-admission-management)",
  "Author": "Microsoft Fabric Blog",
  "FeedLevelAuthor": "Microsoft Fabric Blog",
  "FeedName": "Microsoft Fabric Blog",
  "Link": "https://blog.fabric.microsoft.com/en-US/blog/introducing-the-job-level-bursting-switch-in-microsoft-fabric/",
  "FeedUrl": "https://blog.fabric.microsoft.com/en-us/blog/feed/"
}
