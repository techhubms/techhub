{
  "EnhancedContent": "User Data Functions has been hard at work to bring you the functionality you need to tie together your Fabric architectures and create robust data solutions. This blog post will introduce the latest features in Fabric User Data Functions for Microsoft Ignite 2025.\n\nThe following are the features and integrations that are now available in your User Data Functions items:\n\n- **Fabric Activator support**\n- **Variable Library integration**\n- **Azure Key Vault support**\n- **Cosmos DB support**\n\nFirst, let’s talk about what you can use Fabric User Data Functions for. You can also skip to the updates if you are already familiar with this feature.\n\n![](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/11/ignite_blog_gif_2.gif)Integrate your Fabric User Data Functions with more Fabric items!\n\n## What is Fabric User Data Functions?\n\n[User Data Functions](https://learn.microsoft.com/fabric/data-engineering/user-data-functions/user-data-functions-overview) is an item that allows you to create fully managed Python functions to run in your Fabric architectures. You can use functions to reuse your business logic across your Fabric items. User Data Functions supports different Fabric [integrations](https://learn.microsoft.com/fabric/data-engineering/user-data-functions/user-data-functions-overview#fabric-integrations), such as data sources, Power BI reports, Pipelines, Notebooks, Airflow and more. Your data architectures will benefit from having a centralized place to maintain and update your logic.\n\nFor instance, consider this simplified data architecture where the web application on the left generates user activity data. Your unstructured data will flow from a Lakehouse into a structured Warehouse and can interact with Pipelines or Notebooks along the way.\n\n![](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/11/image-32-1024x393.png)A simple data architecture with different storage and consumption items.\n\nWhile you have the option to embed your logic in any item, you can end up with many one-off solutions that will eventually become challenging to manage and maintain.\n\n![](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/11/ignite_blog_gif_3.gif)Even a simple data architecture can get complicated quickly with too many one-off solutions.\n\nInstead, you can create functions to capture your logic in a single place. This simplifies making improvements and managing your resources. Your functions can also interact with external services and APIs which you can use to enrich your data or integrate with external systems.\n\n![](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/11/ignite_blog_gif_4.gif)A centralized place for your functions means more predictability and manageability.\n\n## What is new in Fabric User Data Functions?\n\nThe following features are now available in your Fabric User Data Functions. This list includes new features and recently announced features.\n\n### Fabric Activator integration (Preview)\n\n*Run your functions from an Activator rule!*\n\n![](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/11/image-36-1024x624.png)Fabric Activator interface with the option to create a ‘New rule’ for an event category\n\nYou can now invoke User Data Functions from the rules in your Fabric Activator items. This feature allows you to create functions to process events from any source, including Fabric events and OneLake events.\n\n![](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/11/image-38-1024x795.png)Pass event data as parameters into your functions.\n\nThis feature supports mapping properties from your event data into your function parameters. You can use these properties to determine your event processing logic or to determine a custom destination for your events. You can configure your Activator rules with any functions – there’s no need for any special configurations inside of your User Data Functions item.\n\n### Variable Library item integration\n\n*Store and use your variable sets across your functions!*\n\nYou can now connect to your [Variable Library items](https://learn.microsoft.com/fabric/cicd/variable-library/get-started-variable-libraries?tabs=home-page) using the [Manage connections](https://learn.microsoft.com/fabric/data-engineering/user-data-functions/connect-to-data-sources)experience in the Functions portal. You can use this to store configuration settings, global constants, environment variables, and much more!\n\n![](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/11/image-43-1024x337.png)\n\nOne useful way to leverage this integration is to store the names of the tables that you can connect to depending on your environment. For example, the default value set is targeting a Fabric Cosmos DB container used while the medicine delivery event processing functions, creatively called `LuisDevContainer` is developed.\n\nOnce the functions are ready, activate the alternative value set with staging, more serious, environment called `MedicineDeliveries` . This approach is useful because there is no need to make any code changes to switch environments. This is a code sample of how to read those values:\n\n``` @udf.connection(alias=\"TestEnvironment\", argName=\"varLib\") @udf.function() def accessVariableLibrary(varLib: fn.FabricVariablesClient) -> str: containerName = varLib.getVariables().get(\"CosmosDbContainer\")\n\nreturn containerName ```\n\nThe key elements are the `@udf.connection( ... ) ` decorator where the newly created Variable Library connection for, and the `varLib.getVariables().get(\"CosmosDbContainer\")` call where it can be retrieved by value name.\n\n### Azure Key Vault support\n\n*Securely access your secrets from your functions!*\n\nUsing a Key Vault is the best practice way to use secrets, such as API keys, passwords, and certificates. Azure Key Vault is one of the most popular services to securely store and retrieve your secrets in your code. With this method, you can access any Key Vault that your user account in Fabric has access to. Make sure to assign Reader permissions to your account for your secrets.\n\nYou can now access your Key Vaults programmatically in your functions using the following code:\n\n``` @udf.generic_connection(argName=\"keyVaultClient\", audienceType=\"KeyVault\") @udf.function() def retrieveNews(keyVaultClient: fn.FabricItem, requestBody:str) -> str: KEY_VAULT_URL = 'YOUR_KEY_VAULT_URL' KEY_VAULT_SECRET_NAME= 'YOUR_SECRET' API_URL = 'YOUR_API_URL'\n\ncredential = keyVaultClient.get_access_token()\n\nclient = SecretClient(vault_url=KEY_VAULT_URL, credential=credential)\n\napi_key = client.get_secret(KEY_VAULT_SECRET_NAME).value\n\nreturn \"Success\" ```\n\nThe key elements in this code are the `@udf.generic_connection(...)` decorator at the top, the `SecretClient(...)` method call and the `client.get_secret(...)` code line where you get your secrets by name.\n\nRefer to the [Connect to Azure Key Vault using a generic connection](https://learn.microsoft.com/fabric/data-engineering/user-data-functions/python-programming-model#connect-to-azure-key-vault-using-a-generic-connection) documentation to learn more.\n\n### Cosmos DB support\n\n*Store and access JSON objects without creating a schema*!\n\nYou can now access both Fabric and Azure Cosmos DB databases from your functions using a similar approach to the Key Vault integration.\n\n![](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/11/image-44-1024x583.png)\n\nFor those of you who don’t know Cosmos DB, it’s the one of the easiest databases to set up because it does need a table creation step. You can simply create a new container to logically separate your documents and then store any data in a JSON object format. Cosmos DB will internally organize and index your data so it’s readily available for you to search.\n\nTo get started, you can navigate to the ‘Insert sample’ feature in your Portal editor and select any of the Cosmos DB samples. Once you create your Fabric Cosmos DB database and container, you can retrieve the connection URI by visiting the settings page in your Cosmos DB item.\n\n![](//dataplatformblogwebfd-d3h9cbawf0h8ecgf.b01.azurefd.net/wp-content/uploads/2025/11/ignite_blog_png_5-1024x349.png)Get your Cosmos DB endpoint from the settings page, and then the connection tab.\n\nFor example, this sample shows how to create a new document:\n\n``` from fabric.functions.cosmosdb import get_cosmos_client from azure.cosmos import exceptions\n\n@udf.generic_connection(argName=\"cosmosDb\", audienceType=\"CosmosDB\") @udf.function() def insert_product(cosmosDb: fn.FabricItem) -> list[dict[str, Any]]: COSMOS_DB_URI = \"{my-cosmos-artifact-uri}\" DB_NAME = \"{my-cosmos-artifact-name}\" CONTAINER_NAME = \"SampleData\"\n\ncosmosClient = get_cosmos_client(cosmosDb, COSMOS_DB_URI) database = cosmosClient.get_database_client(DB_NAME) container = database.get_container_client(CONTAINER_NAME)\n\nproductId = \"8a82f850-a33b-4734-80ce-740ba16c39f1\"\n\niso_now = datetime.now(timezone.utc).isoformat() + \"Z\"\n\n# Create the product document\nproduct = { \"id\": productId, \"docType\": \"product\", \"timestamp\": iso_now }\n\nreturn container.create_item(body=product) ```\n\nThe key parts of this sample are the `@udf.generic_connection(...)` decorator at the top, the `get_cosmos_client(...)` line to create a new client and the `COSMOS_DB_URI` variable.\n\nTo learn more, refer to the [generic connections](https://learn.microsoft.com/fabric/data-engineering/user-data-functions/python-programming-model#connect-to-fabric-cosmos-db-container-using-a-generic-connection) documentation.\n\n## Resources\n\nIf you made it this far, thank you for reading! Here are some more resources for you to get started:\n\n- [Generic connections for Fabric items or Azure resources](https://learn.microsoft.com/fabric/data-engineering/user-data-functions/python-programming-model#generic-connections-for-fabric-items-or-azure-resources)\n- The [Service details and limitations of Fabric User Data Functions](https://learn.microsoft.com/fabric/data-engineering/user-data-functions/user-data-functions-service-limits)\n- New to User Data Functions?\n- Refer to the [Create a Fabric User data functions item](https://learn.microsoft.com/fabric/data-engineering/user-data-functions/create-user-data-functions-portal) documentation.",
  "FeedName": "Microsoft Fabric Blog",
  "Title": "What’s new in Fabric User Data Functions? Ignite 2025 edition",
  "PubDate": "2025-11-20T11:00:00+00:00",
  "ProcessedDate": "2025-11-20 19:02:40",
  "FeedLevelAuthor": "Microsoft Fabric Blog",
  "FeedUrl": "https://blog.fabric.microsoft.com/en-us/blog/feed/",
  "Author": "Microsoft Fabric Blog",
  "Description": "User Data Functions has been hard at work to bring you the functionality you need to tie together your Fabric architectures and create robust data solutions. This blog post will introduce the latest features in Fabric User Data Functions for Microsoft Ignite 2025. The following are the features and integrations that are now available in …\n\n[Continue reading “What’s new in Fabric User Data Functions? Ignite 2025 edition”](https://blog.fabric.microsoft.com/en-us/blog/whats-new-in-fabric-user-data-functions-ignite-2025-edition/)",
  "OutputDir": "_news",
  "Link": "https://blog.fabric.microsoft.com/en-US/blog/whats-new-in-fabric-user-data-functions-ignite-2025-edition/",
  "Tags": []
}
