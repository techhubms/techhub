{
  "ProcessedDate": "2025-10-14 23:03:27",
  "PubDate": "2025-10-14T18:29:03+00:00",
  "OutputDir": "_posts",
  "Tags": [
    "ai",
    "governance",
    "jfrog",
    "JFrog swampUP 2025",
    "NVIDIA",
    "Video Interviews"
  ],
  "FeedLevelAuthor": "DevOps.com",
  "EnhancedContent": "[![](https://devops.com/wp-content/uploads/2025/02/cropped-devops-logo.png)](https://devops.com/)\n\n# Sign up for our newsletter! Stay informed on the latest DevOps news\n\nSecure Governance and Scalable Management for AI Models\n\nAt swampUP 2025, Yuval Fernbach, vice president and CTO of MLOps at JFrog, and Adel El Hallak, senior director of product for NVIDIA AI Enterprise, discuss how JFrog is integrating machine learning operations (MLOps) into its platform strategy. Fernbach, who joined JFrog through its acquisition of Qwak, outlined how JFrog is extending its mission beyond artifact management to embrace AI-driven software supply chain automation. The goal, he noted, is to enable developers to build, deploy, and govern AI models with the same level of trust and traceability that JFrog has long brought to binary and container management.\n\nThey discussed the rapid convergence of MLOps and DevOps, a shift that is redefining how teams manage the entire software and model delivery lifecycle. As organizations accelerate their adoption of generative AI and large language models (LLMs), the challenge is no longer just building or training models—it’s governing and managing them at scale. AI introduces new forms of technical debt, compliance requirements, and operational risk that traditional software management frameworks were never designed to handle. Every model carries dependencies, training data, and inference patterns that must be tracked, versioned, and secured across environments. Without unified governance, enterprises risk exposing sensitive data, violating regulations, or deploying unverified models that behave unpredictably in production.\n\nThe energy at swampUP reflects an industry in transition—where every team, from developers to platform engineers, is rethinking their toolchains for the AI era. As Fernbach and others shared, JFrog’s latest innovations are designed to bridge that gap, ensuring that software—and now models—move from experimentation to production with speed, security, and confidence.\n\nhttps://www.addtoany.com/add_to/x?linkurl=https%3A%2F%2Fdevops.com%2Fsecure-governance-and-scalable-management-for-ai-models%2F&amp;linkname=Secure%20Governance%20and%20Scalable%20Management%20for%20AI%20Modelshttps://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevops.com%2Fsecure-governance-and-scalable-management-for-ai-models%2F&amp;linkname=Secure%20Governance%20and%20Scalable%20Management%20for%20AI%20Modelshttps://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevops.com%2Fsecure-governance-and-scalable-management-for-ai-models%2F&amp;linkname=Secure%20Governance%20and%20Scalable%20Management%20for%20AI%20Modelshttps://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevops.com%2Fsecure-governance-and-scalable-management-for-ai-models%2F&amp;linkname=Secure%20Governance%20and%20Scalable%20Management%20for%20AI%20Modelshttps://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevops.com%2Fsecure-governance-and-scalable-management-for-ai-models%2F&amp;linkname=Secure%20Governance%20and%20Scalable%20Management%20for%20AI%20Modelshttps://www.addtoany.com/share\n\nhttps://www.addtoany.com/add_to/x?linkurl=https%3A%2F%2Fdevops.com%2Fsecure-governance-and-scalable-management-for-ai-models%2F&amp;linkname=Secure%20Governance%20and%20Scalable%20Management%20for%20AI%20Models%20-%20DevOps.comhttps://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevops.com%2Fsecure-governance-and-scalable-management-for-ai-models%2F&amp;linkname=Secure%20Governance%20and%20Scalable%20Management%20for%20AI%20Models%20-%20DevOps.comhttps://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevops.com%2Fsecure-governance-and-scalable-management-for-ai-models%2F&amp;linkname=Secure%20Governance%20and%20Scalable%20Management%20for%20AI%20Models%20-%20DevOps.comhttps://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevops.com%2Fsecure-governance-and-scalable-management-for-ai-models%2F&amp;linkname=Secure%20Governance%20and%20Scalable%20Management%20for%20AI%20Models%20-%20DevOps.comhttps://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevops.com%2Fsecure-governance-and-scalable-management-for-ai-models%2F&amp;linkname=Secure%20Governance%20and%20Scalable%20Management%20for%20AI%20Models%20-%20DevOps.comhttps://www.addtoany.com/share\n\n[« Establishing Visibility and Governance for Your Software Supply Chain](https://devops.com/establishing-visibility-and-governance-for-your-software-supply-chain/)\n\n[Strengthening Software Trust in Modern DevOps Workflows »](https://devops.com/strengthening-software-trust-in-modern-devops-workflows/)\n\n[![](https://devops.com/wp-content/uploads/2024/11/Copy-of-DO-Banners-1540x660-1.png)](https://webinars.devops.com/in-article-newsletter-popup)\n\n×\n\nExecutive Security as a Strategic Priority\n\nStep 1 of 8\n\n12%\n\nWhich best describes your level of influence on cybersecurity, risk and/or data protection in your organization?(Required) I make decisions about or have influence over cybersecurity strategy\n\nI make decisions about or have influence over risk strategy\n\nI am responsible for protecting data at my organization\n\nI am responsible for building and/or implementing solutions that protect the PII of employees and customers\n\nI am responsible for building and/or implementing solutions to underpin our cybersecurity strategy\n\nI am responsible for building and/or implementing solutions to manage and mitigate risk\n\nOther/NA\n\nHave you or members of your family or other executives and members of their families been targets of social engineering attacks? (Select All That Apply)(Required) I have personally been targeted\n\nA member of my family has been targeted\n\nExecutives at my organization have been targets of AI social engineering attacks\n\nWere any of the attacks successful?(Required) Yes\n\nNo\n\nDon’t know\n\nN/A\n\nWhich best describes your organization’s efforts to protect executives and their families against AI social engineering attacks?(Required) Has discussed the potential impact of such attacks but has not executed a strategy\n\nHas taken rudimentary steps to protect executives and their families\n\nHas not addressed the impact of these attacks\n\nHas developed a strategy to protect executives and has begun to execute it\n\nHas made protecting executive PII a strategic priority and has a fully executed plan in place\n\nWhat challenges have prevented you from more fully securing the PII of executives and their families?(Required) Lack of executive/board support\n\nTech spend is too high\n\nPotential disruption to business operations\n\nPoor visibility into what should be protected\n\nEase of use\n\nIntegration into existing security strategies\n\nWhich of the following do you think are true about the level of threat posed by AI social engineering attacks?(Required) My organization doesn’t have a firm understanding of the risk from AI social engineering attacks\n\nAI social engineering attacks raise my organization’s risk exposure\n\nAI social engineering attacks against executives and their families are on the rise, and we struggle to stay ahead of them\n\nProtecting executives—and their families—should be a critical risk management priority\n\nObtaining executives’ available personal data online and that of their families can create extremely important leverage for threat actors seeking access to corporate assets\n\nExecutives have often handled the most sensitive data—often on the fly—and have access to a company’s most valuable assets from their homes and personal devices\n\nWhat steps has your organization taken to protect executives and their families from AI social engineering attacks? (Select All That Apply)(Required) Protect the integrity of confidential information and communications\n\nInvest in training\n\nBlock lateral movement\n\nReduce attack surface\n\nHow valuable do you think it would it be to have an easy to integrate and use tool that protects the PII of executives and their families from AI social engineering attacks?(Required) Extremely valuable\n\nVery valuable\n\nSomewhat valuable\n\nSlightly valuable\n\nNot valuable\n\nΔ\n\n×",
  "FeedName": "DevOps Blog",
  "FeedUrl": "https://devops.com/feed/",
  "Title": "Secure Governance and Scalable Management for AI Models",
  "Link": "https://devops.com/secure-governance-and-scalable-management-for-ai-models/",
  "Author": "Alan Shimel",
  "Description": "![](https://devops.com/wp-content/uploads/2020/06/Machine-learning.jpg)\n\n![](https://devops.com/wp-content/uploads/2020/06/Machine-learning-150x150.jpg)At swampUP 2025, Yuval Fernbach, vice president and CTO of MLOps at JFrog, and Adel El Hallak, senior director of product for NVIDIA AI Enterprise, discuss how JFrog is integrating machine learning operations (MLOps) into its platform strategy. Fernbach, who joined JFrog through its acquisition of Qwak, outlined how JFrog is extending its mission beyond […]"
}
