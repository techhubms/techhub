{
  "Author": "Mike Shi",
  "Tags": [
    "Blogs",
    "Contributed Content",
    "Logging",
    "Monitoring and Observability",
    "observability",
    "OpenTelemetry",
    "Social - Facebook",
    "Social - LinkedIn",
    "Social - X",
    "Splunk",
    "vendor lock-in"
  ],
  "Description": "![](https://devops.com/wp-content/uploads/2020/05/Elastic-Services-for-Cost-Optimization.jpg)\n\n![](https://devops.com/wp-content/uploads/2020/05/Elastic-Services-for-Cost-Optimization-150x150.jpg)Breaking Free from Observability Rising Costs and Vendor Lock-In Observability is meant to give teams confidence when things go wrong. Instead, once systems scale, it often turns into one of the largest line items in the infrastructure budget. What begins as a safeguard against outages and breaches quickly becomes a source of runaway costs. Teams […]",
  "ProcessedDate": "2025-10-23 15:04:39",
  "Title": "Breaking Free from Rising Observability Costs with Open Cost-Efficient Architectures",
  "EnhancedContent": "[![](https://devops.com/wp-content/uploads/2025/02/cropped-devops-logo.png)](https://devops.com/)\n\n# Sign up for our newsletter! Stay informed on the latest DevOps news\n\nBreaking Free from Rising Observability Costs with Open Cost-Efficient Architectures\n\n### **Breaking Free from Observability Rising Costs and Vendor Lock-In**\n\nObservability is meant to give teams confidence when things go wrong. Instead, once systems scale, it often turns into one of the largest line items in the infrastructure budget. What begins as a safeguard against outages and breaches quickly becomes a source of runaway costs.\n\nTeams find themselves constrained: constantly debating what data they can afford to keep, stuck in workflows more about managing spend than solving real problems. Switching platforms seems daunting. The inertia of sunk costs, proprietary technologies, and lock-in can feel overwhelming.\n\n*Observability costs can balloon to staggering levels. In* [*2022 it was reported that a major cryptocurrency exchange*](https://news.ycombinator.com/item?id=35837330) *was spending around $65 million a year on Datadog.*\n\nBut it doesn’t have to be this way. How did we end up here? And more importantly, how might we break free?\n\n### **How We Got Here – The Evolution of Observability**\n\nThe history of observability is really two stories running in parallel: one of technology, and one of pricing. Each wave of innovation brought new capabilities, but also new trade-offs.\n\n![](https://devops.com/wp-content/uploads/2025/10/Screenshot-2025-10-23-at-9.52.03 AM.png)\n\nIn the early days, engineers relied on grep and syslog to manage logs – simple but limited approaches where cost and scale weren’t a concern.\n\n### **The Era of Splunk**\n\nThen came Splunk, and with it a new era. For the first time, logs were queryable at scale, visualized in real time, and explored through SPL – a powerful query language that allowed **schema-on-read** (vs requiring users to define a table schema prior to insert). This flexibility was transformative, but Splunk also set a precedent that still shapes the industry: charging based on how much data you ingest.\n\n### **Open Source and Search-Based Observability**\n\nThe early 2010s brought an open-source alternative in Elasticsearch. The ELK stack was cheaper than Splunk but came with trade-offs: weaker UX, clunky workflows, and an architecture designed for TB volumes and low-cardinality data. As usage grew, Elasticsearch hit hard limits – horizontal scaling constrained by the JVM, reliance on inverted indices, and single-threaded shard execution. It struggled with high-cardinality metrics, slow aggregations, high disk usage, and costly data movement, making it ill-suited to petabyte scale.\n\n*Elastic did innovate on pricing with an early shift to a resource-based model. In theory, it let users optimize costs, but in practice it raised the barrier to entry requiring users to understand internals.*\n\n### **Cloud Based Solutions**\n\nAt the same time, cloud-based observability solutions emerged, with Datadog becoming the dominant success. Elastic lacked the needed SASS abstractions, and Splunk was not designed for a cloud, leaving Datadog to deliver the best user experience. It abstracted many of Elastic’s architectural problems but created a new one: costs that are unmanageable at scale.\n\nDatadog also introduced controversial pricing. Beyond ingest-based billing, it popularized per-host models for APM and traces. This forced engineering teams to make hard decisions about how many hosts and instance types they could deploy. In some cases, observability costs under this model exceeded the cost of running the infrastructure itself.\n\n### **Pillar-Focused Datastores**\n\n![](https://devops.com/wp-content/uploads/2025/10/Screenshot-2025-10-23-at-10.01.18 AM.png)\n\nIn response to rising costs, the industry split observability into specialized datastores optimized for a single signal. Prometheus emerged to handle metrics efficiently but broke down under high cardinality, inspiring Loki for logs and Tempo for traces. Each was cheaper to run but only by limiting functionality – such as dropping fast search and exploratory workflows to label-based lookups. The trade-off was fragmentation: data scattered across multiple engines, limited correlation, and added overhead to run, scale, and secure each one. Instead of solving the pricing problem, this created silos of observability data.\n\n*The idea of logs, metrics, and traces as the “three pillars of observability” came after specialized stores like Splunk, Prometheus, and Zipkin already existed. The pillar models continued to codify and reinforce silos, encouraging yet more single-purpose systems and making fragmentation feel inevitable. Today, those pillars are fundamentally part of the problem we face.*\n\n### **Where We Are Now**\n\nToday, teams face a tough choice: expensive all-in-one platforms that break budgets, or fragmented point solutions that scatter data across silos. In the latter case, users are often left stitching events together with trace IDs or trivial labels, and at worst, entire categories of exploratory workflows and the kind of high-cardinality analysis modern teams rely on become impossible. The result is either financial unsustainability or technical limitations – neither delivers the real goal of observability: giving teams confidence and clarity when they need it most.\n\n### **A Path Forward: OpenTelemetry as a Foundation**\n\n![](https://devops.com/wp-content/uploads/2025/10/Screenshot-2025-10-23-at-10.02.07 AM.png)\n\n*OpenTelemetry is the second most active project in the CNCF, behind only Kubernetes. Credit: CNCF*\n\nOpenTelemetry has loosened vendor lock-in by standardizing data formats and making it possible to collect once and send anywhere. Adoption can be incremental, with new services starting on OTel SDKs while older systems migrate over time, avoiding the need for a full rip-and-replace. Still, solutions must remain flexible enough to support non-OTel formats.\n\nIf OTel is the foundation, the next step is to ask: **what should the full blueprint for observability look like?**\n\n### **What We Really Need from Observability**\n\n![](https://devops.com/wp-content/uploads/2025/10/Screenshot-2025-10-23-at-10.02.58 AM.png)\n\n*The core elements of observability*\n\nThe answer is not another specialized store or proprietary black box. We need **a unified engine** where logs, metrics, and traces live together and can be correlated alongside business data.\n\nWe need **efficiency and performance at scale**. Any viable store must handle high ingest rates while also delivering **fast aggregations over high-cardinality data**.\n\nAny system should make first-class use of **object storage for affordable long-term retention**.\n\nIt should offer **flexible schema handling**, combining **schema-on-read** where necessary but also **schema-on-write** for supporting JSON and wide events efficiently.\n\nWe also need **expressive querying**. SQL remains the lingua franca, but full-text search is still valuable for hot datasets, and natural-language or DSL-style layers (SPL, PromQL, ES|QL) can lower the barrier further.\n\nSolutions must be **OTel-native,** but importantly not **OTel-exclusive**, supporting the familiar data types while also recognizing the potential of wide events.\n\nFinally, we need **deployment flexibility**. Proprietary vendors proved the value of simplicity in managed offerings, but the open-source movement has shown the importance of control. Any future solution must support both: a zero-ops managed cloud for those who want it, and a simple open-source option that anyone can run locally. Without that balance, lock-in becomes inevitable.\n\nObservability should not force teams into trade-offs between what they can afford and what they need. The right solution must deliver all of these properties while making retention and usage costs predictable and sustainable. In the end, this is a data and analytics challenge – and we can solve this by taking learnings from modern data stacks and applying them to observability.\n\n### **The Case for Columnar Databases**\n\n![](https://devops.com/wp-content/uploads/2025/10/Screenshot-2025-10-23-at-10.03.53 AM.png)\n\n*Columnar databases hold columns separately on disk, order these and support codecs such as Delta. The result is high compression and reduced I/O.*\n\nFor observability, the fit is natural. Columnar databases provide **high compression** and storage efficiency, cutting costs at scale. They excel at **fast aggregations over high-cardinality data** and selective filtering by scanning only the needed columns, powering dashboards and exploratory workflows. They combine fast writes with **efficient indices such as Bloom filters**, with modern engines adding optional full-text search at the column level when logs demand it.\n\nColumnar databases also support both **schema-on-read** and **schema-on-write**, with built-in functions for parsing semi-structured data and native handling of JSON and wide events. Because they have **comprehensive SQL support**, they enable expressive queries without forcing teams to learn another DSL. **Sparse primary indices make filtering efficient**, **parallel execution** scales queries across large datasets, and [skip indices](https://clickhouse.com/docs/optimize/skipping-indexes) with support for [full-text search](https://clickhouse.com/docs/engines/table-engines/mergetree-family/invertedindexes) enable exploratory workflows. Query execution is typically parallelized across all available cores.\n\n![](https://devops.com/wp-content/uploads/2025/10/Screenshot-2025-10-23-at-10.04.46 AM.png)\n\n*Query execution within columnar databases is typically parallelized exploiting all the available cores on a machine*\n\nMore modern columnar architectures natively support object storage and separation of compute from storage. When combined with columnar compression, this makes it possible to **retain large volumes of data affordably**, while still scaling compute resources independently as demand changes.\n\n![](https://devops.com/wp-content/uploads/2025/10/Screenshot-2025-10-23-at-10.05.03 AM.png)\n\n*Separation of storage and compute makes retention affordable, isolates workloads, and lets teams scale compute on demand*\n\nIn short, columnar storage reframes observability as **just another data problem**. With compression, cardinality, query speed, and schema flexibility solved in one architecture, columnar databases provide the foundation earlier generations of tools could not.\n\nCompanies such as [Tesla](https://clickhouse.com/blog/how-tesla-built-quadrillion-scale-observability-platform-on-clickhouse), [Anthropic](https://clickhouse.com/blog/how-anthropic-is-using-clickhouse-to-scale-observability-for-ai-era), [OpenAI](https://clickhouse.com/blog/why-openai-uses-clickhouse-for-petabyte-scale-observability) and [Netflix](https://clickhouse.com/videos/meetupsf_march_2025_04) rely on columnar databases for observability at petabyte scale, demonstrating its ability to meet the demands of modern workloads. But what distinguishes these organizations is not only their choice of database – it was their ability to invest in building a custom UI. That approach requires dedicated engineering teams and significant investment – only viable at scale.\n\n### **The Need for a Dedicated UI**\n\nWhile building custom UIs is feasible for large companies and engineering teams, other users turned to Grafana, which has long been a staple of the observability stack. Grafana remains a powerful tool for querying column databases but puts the burden of SQL knowledge and query optimization on users. For developers who simply want to investigate an issue quickly, that barrier can be high – **not everyone is an observability expert**.\n\n*Grafana with columnar databases requires a mastery of SQL*\n\nEveryday developers need faster, simpler ways to investigate issues, including the kind of natural language – style search they already expect from modern tools. Any interface should guide users toward efficient queries, abstract away complexity, and still preserve full SQL access for experts. To avoid repeating past mistakes, it must be open source, not another form of lock-in.\n\nThe logical next step is a **dedicated observability interface for each columnar database**. Such an interface must be developer-friendly, open, and accessible, while preserving direct database access when required. And to avoid repeating the mistakes of the past, it must be open source rather than just another form of vendor lock-in.\n\n### **Conclusion**\n\nColumnar databases are the natural foundation for observability, combining compression, performance, and schema flexibility at scale. Wide events move us beyond the old pillars by capturing full context in a single record. What’s missing is accessibility – an open, developer-friendly interface that brings this power to everyone, not just the few with resources to build custom solutions.\n\n*KubeCon + CloudNativeCon North America 2025 is taking place in Atlanta, Georgia, from November 10 to 13.* [*Register now*](https://events.linuxfoundation.org/kubecon-cloudnativecon-north-america/register/)*.*\n\nhttps://www.addtoany.com/add_to/x?linkurl=https%3A%2F%2Fdevops.com%2Fbreaking-free-from-rising-observability-costs-with-open-cost-efficient-architectures%2F&amp;linkname=Breaking%20Free%20from%20Rising%20Observability%20Costs%20with%20Open%20Cost-Efficient%20Architectureshttps://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevops.com%2Fbreaking-free-from-rising-observability-costs-with-open-cost-efficient-architectures%2F&amp;linkname=Breaking%20Free%20from%20Rising%20Observability%20Costs%20with%20Open%20Cost-Efficient%20Architectureshttps://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevops.com%2Fbreaking-free-from-rising-observability-costs-with-open-cost-efficient-architectures%2F&amp;linkname=Breaking%20Free%20from%20Rising%20Observability%20Costs%20with%20Open%20Cost-Efficient%20Architectureshttps://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevops.com%2Fbreaking-free-from-rising-observability-costs-with-open-cost-efficient-architectures%2F&amp;linkname=Breaking%20Free%20from%20Rising%20Observability%20Costs%20with%20Open%20Cost-Efficient%20Architectureshttps://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevops.com%2Fbreaking-free-from-rising-observability-costs-with-open-cost-efficient-architectures%2F&amp;linkname=Breaking%20Free%20from%20Rising%20Observability%20Costs%20with%20Open%20Cost-Efficient%20Architectureshttps://www.addtoany.com/share\n\nhttps://www.addtoany.com/add_to/x?linkurl=https%3A%2F%2Fdevops.com%2Fbreaking-free-from-rising-observability-costs-with-open-cost-efficient-architectures%2F&amp;linkname=Breaking%20Free%20from%20Rising%20Observability%20Costs%20with%20Open%20Cost-Efficient%20Architectures%20-%20DevOps.comhttps://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevops.com%2Fbreaking-free-from-rising-observability-costs-with-open-cost-efficient-architectures%2F&amp;linkname=Breaking%20Free%20from%20Rising%20Observability%20Costs%20with%20Open%20Cost-Efficient%20Architectures%20-%20DevOps.comhttps://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevops.com%2Fbreaking-free-from-rising-observability-costs-with-open-cost-efficient-architectures%2F&amp;linkname=Breaking%20Free%20from%20Rising%20Observability%20Costs%20with%20Open%20Cost-Efficient%20Architectures%20-%20DevOps.comhttps://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevops.com%2Fbreaking-free-from-rising-observability-costs-with-open-cost-efficient-architectures%2F&amp;linkname=Breaking%20Free%20from%20Rising%20Observability%20Costs%20with%20Open%20Cost-Efficient%20Architectures%20-%20DevOps.comhttps://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevops.com%2Fbreaking-free-from-rising-observability-costs-with-open-cost-efficient-architectures%2F&amp;linkname=Breaking%20Free%20from%20Rising%20Observability%20Costs%20with%20Open%20Cost-Efficient%20Architectures%20-%20DevOps.comhttps://www.addtoany.com/share\n\n[« OpenTelemetry and AI are Unlocking Logs as the Essential Signal for “Why”](https://devops.com/opentelemetry-and-ai-are-unlocking-logs-as-the-essential-signal-for-why/)\n\n[![](https://devops.com/wp-content/uploads/2024/11/Copy-of-DO-Banners-1540x660-1.png)](https://webinars.devops.com/in-article-newsletter-popup)\n\n×",
  "FeedName": "DevOps Blog",
  "Link": "https://devops.com/breaking-free-from-rising-observability-costs-with-open-cost-efficient-architectures/",
  "OutputDir": "_posts",
  "FeedLevelAuthor": "DevOps.com",
  "FeedUrl": "https://devops.com/feed/",
  "PubDate": "2025-10-23T14:10:49+00:00"
}
