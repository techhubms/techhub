---
external_url: https://www.youtube.com/watch?reload=9&v=kCc8FmEb1nY
title: Let's build GPT from scratch, in code, spelled out.
author: Andrej Karpathy
tags:
- GPT
- Language Models
- Neural Networks
- PyTorch
- Machine Learning
- Videos
section_names:
- ml
primary_section: ml
feed_name: TechHub
---
We build a Generatively Pretrained Transformer (GPT), following the paper "Attention is All You Need" and OpenAI's GPT-2 / GPT-3.<!--excerpt_end-->

{% youtube kCc8FmEb1nY %}

We talk about connections to ChatGPT, which has taken the world by storm. We watch GitHub Copilot, itself a GPT, help us write a GPT (meta :D!). I recommend people watch the earlier makemore videos to get comfortable with the autoregressive language modeling framework and basics of tensors and PyTorch.nn, which we take for granted in this video.
