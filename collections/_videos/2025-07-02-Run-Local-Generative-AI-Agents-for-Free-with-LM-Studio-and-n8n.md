---
layout: "post"
title: "Run Local Generative AI Agents for Free with LM Studio and n8n"
description: "This tutorial by Alireza Chegini guides you through installing and running generative AI models (such as LLaMA and Mistral) locally using LM Studio and n8n. The video provides a practical, step-by-step walkthrough for setting up the tools on Windows, Mac, or Linux, building chat agents in n8n, connecting LM Studio via API, and adding conversational memory, all without the need for paid APIs or subscriptions. Aimed at developers and AI experimenters, the video focuses on hands-on use of open-source AI, Docker-based workflow automation, and self-hosting strategies to maximize learning and prototyping efficiency."
author: "Alireza Chegini | AI Skills for Your Career"
excerpt_separator: <!--excerpt_end-->
canonical_url: "https://www.youtube.com/watch?v=hsPMSAzxdtU"
viewing_mode: "internal"
feed_name: "Alireza Chegini's YouTube"
feed_url: "https://www.youtube.com/feeds/videos.xml?channel_id=UCZSAqzABRmDxDHuPS6YuXZA"
date: 2025-07-02 16:01:27 +00:00
permalink: "/2025-07-02-Run-Local-Generative-AI-Agents-for-Free-with-LM-Studio-and-n8n.html"
categories: ["AI", "Coding"]
tags: ["AI", "AI Agents", "AI Automation", "AIautomation", "API Integration", "Chatbots", "Coding", "DeepSeek", "Docker", "DockerNetworking", "Linux", "Llama", "LM Studio", "LMStudio", "Local LLM", "LocalLLM", "MacOS", "Memory in Agents", "Mistral", "N8n", "N8ntutorial", "No Code AI", "NoCodeAI", "Open Source AI", "OpenAIalternative", "OpenSourceAI", "RunLLMLocally", "Self Hosted AI", "SelfHostedAI", "Videos", "Windows", "Workflow Automation"]
tags_normalized: ["ai", "ai agents", "ai automation", "aiautomation", "api integration", "chatbots", "coding", "deepseek", "docker", "dockernetworking", "linux", "llama", "lm studio", "lmstudio", "local llm", "localllm", "macos", "memory in agents", "mistral", "n8n", "n8ntutorial", "no code ai", "nocodeai", "open source ai", "openaialternative", "opensourceai", "runllmlocally", "self hosted ai", "selfhostedai", "videos", "windows", "workflow automation"]
---

Alireza Chegini presents a comprehensive tutorial for developers on how to set up and run generative AI agents locally with LM Studio and n8n, highlighting installation, workflow creation, and free experimentation.<!--excerpt_end-->

{% youtube hsPMSAzxdtU %}

# Run Local Generative AI Agents for Free with LM Studio and n8n

Author: Alireza Chegini | AI Skills for Your Career

## Overview

This video demonstrates how to use open-source generative AI models on your own computer—entirely free and without reliance on paid APIs or subscriptions. It’s intended for developers, automation enthusiasts, and anyone wishing to prototype or learn about AI agents and chat workflows in a hands-on way.

## Key Topics

- Why choose local AI tools vs. paid cloud APIs
- How to install LM Studio on Windows, Mac, or Linux
- Setting up and running local language models (e.g., LLaMA, Mistral)
- Using LM Studio's interface and testing model outputs
- Installing and running n8n via Docker
- Creating chat agent workflows in n8n
- Connecting LM Studio to n8n using API integrations
- Adding conversational memory to your agent
- Tips for further experimentation and learning

## Step-by-Step Guide

### 1. LM Studio Installation

- Download LM Studio from: [https://lmstudio.ai](https://lmstudio.ai)
- Supported on Windows, Mac, and Linux
- Walkthrough of installation and interface basics

### 2. Download & Run Local Models

- Example setup with LLaMA (other models such as Mistral also supported)
- How to fetch models from online repositories, import, and run locally
- Test the generative capabilities inside LM Studio

### 3. n8n Workflow Automation

- Install n8n using Docker for ease of setup: [https://n8n.io](https://n8n.io)
- Overview of workflow builder
- Create a simple chat agent workflow

### 4. Integrate LM Studio and n8n

- Connect LM Studio to n8n via local API endpoints
- Send prompts/receive completions through workflow nodes
- Test the end-to-end chatbot loop

### 5. Add Memory to Your Agent

- Enable conversational memory to help your agent track context across exchanges
- Techniques for storing and retrieving previous messages or states

### 6. Experiment Freely

- No cloud subscription or token costs
- Easily try out AI art, agents, and chat-based solutions locally
- Ideal for proof-of-concept builds and personal exploration

## Useful Links

- LM Studio: [https://lmstudio.ai](https://lmstudio.ai)
- n8n: [https://n8n.io](https://n8n.io)

## Additional Resources

- Support the author: [Buy me a coffee](https://coff.ee/alirezachegini)
- Community: [Skool AI Studio](https://www.skool.com/cac-ai-studio)
- Connect for consulting: [Discovery call](https://calendly.com/alireza-chegini/discovery-call)

## Chapters

- 00:00 Intro – Why go local?
- 01:08 Install LM Studio
- 04:00 LM Studio interface overview
- 06:30 Download & run a local model (LLaMA)
- 09:00 Test model inside LM Studio
- 12:30 Install/run n8n with Docker
- 14:00 Create your first workflow
- 16:30 Connect n8n to LM Studio
- 19:00 Test the agent
- 20:30 Add memory
- 23:00 Final thoughts

## Conclusion

By following this guide, you can build, test, and iterate on generative AI agents and workflows locally, supporting creative experimentation and learning without financial barriers.

---
