---
layout: post
title: 'Do you security check AI models you pull from online repos?: Developer Security Quick Fire Questions'
author: Microsoft Developer
canonical_url: https://www.youtube.com/shorts/Kff78AQ7m9s
viewing_mode: internal
feed_name: Microsoft Developer YouTube
feed_url: https://www.youtube.com/feeds/videos.xml?channel_id=UCsMica-v34Irf9KVTh6xx-g
date: 2025-07-30 16:09:52 +00:00
permalink: /ai/videos/Do-you-security-check-AI-models-you-pull-from-online-repos-Developer-Security-Quick-Fire-Questions
tags:
- AI Models
- Application Security
- Cloud Computing
- Cloud Security
- Dev
- Developer Security
- Development
- Microsoft
- Microsoft Build
- Microsoft Developer
- Online Repositories
- Secure Development
- Secure Future Initiative
- Security Practices
- Tech
- Technology
section_names:
- ai
- security
---
In this video, Microsoft Developer interviews Build 2025 attendees about security practices when sourcing AI models from online repositories, sharing insights into developer security.<!--excerpt_end-->

{% youtube Kff78AQ7m9s %}

# Do you security check AI models you pull from online repos?: Developer Security Quick Fire Questions

*Author: Microsoft Developer*

## Overview

During Microsoft Build 2025, the Microsoft Developer team approached attendees and special guests with quick fire questions focused on developer security—specifically regarding the practice of using AI models sourced from online repositories.

## Key Discussion Points

- **Developer Security Awareness:** Interviewees shared methods and considerations for maintaining a secure software environment when pulling AI models from external sources.
- **Risks of Online AI Models:** The video explores potential risks associated with using AI models found in public repositories, raising awareness about code provenance, model integrity, and hidden vulnerabilities.
- **Security Best Practices:** Suggestions included verifying sources, checking for official or well-maintained repositories, scanning models for malicious content, and using automated tools for dependency and vulnerability checking.
- **Secure Future Initiative:** The video mentions Microsoft's Secure Future Initiative ([SFI](http://aka.ms/SFIwebsite)), which provides resources and frameworks for improving security across development lifecycles, especially as AI integration becomes more commonplace.

## Resources

For more information on secure development and Microsoft's Secure Future Initiative, refer to the [official SFI website](http://aka.ms/SFIwebsite).

## Conclusion

This developer discussion underlines the increasing importance of treating AI artifacts as critical dependencies requiring rigorous security checks, and encourages the adoption of structured security practices for AI-driven development projects.
