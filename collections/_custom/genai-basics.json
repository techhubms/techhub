{
  "sections": [
    {
      "content": "Some fun history facts about AI, showing how long AI has been around and how it has evolved over time.\n\n{{mermaid:foundations-1950s-1990s}}\n\n{{mermaid:deep-learning-era-2010s}}\n\n{{mermaid:genai-revolution-2020s}}",
      "mermaid": [
        {
          "id": "foundations-1950s-1990s",
          "diagram": "graph LR\n    A[\"1956<br/>AI term coined<br/>Dartmouth Conference\"] --> B[\"1966<br/>ELIZA chatbot<br/>MIT\"] --> C[\"1997<br/>Deep Blue beats<br/>Kasparov\"]\n    \n    style A fill:#2d2d4a,color:#e0e0e0,stroke:#64b5f6\n    style B fill:#2d2d4a,color:#e0e0e0,stroke:#64b5f6\n    style C fill:#2d2d4a,color:#e0e0e0,stroke:#64b5f6",
          "title": "Foundations (1950s-1990s)"
        },
        {
          "id": "deep-learning-era-2010s",
          "diagram": "graph LR\n    A[\"2011<br/>IBM Watson<br/>wins Jeopardy!\"] --> B[\"2012<br/>AlexNet<br/>ImageNet breakthrough\"] --> C[\"2014<br/>First GAN<br/>introduced\"] --> D[\"2018<br/>GPT-1<br/>117M parameters\"]\n    \n    style A fill:#2d2d4a,color:#e0e0e0,stroke:#64b5f6\n    style B fill:#2d2d4a,color:#e0e0e0,stroke:#64b5f6\n    style C fill:#2d2d4a,color:#e0e0e0,stroke:#64b5f6\n    style D fill:#2d2d4a,color:#e0e0e0,stroke:#64b5f6",
          "title": "Deep Learning Era (2010s)"
        },
        {
          "id": "genai-revolution-2020s",
          "diagram": "graph LR\n    A[\"2020<br/>GPT-3<br/>175B parameters\"] --> B[\"2023<br/>GPT-4 & Claude<br/>major quality leaps\"] --> C[\"2024<br/>Multimodal LLMs<br/>text, images, audio\"] --> D[\"2025<br/>Agentic AI<br/>GPT-5 released\"]\n    \n    style A fill:#2d2d4a,color:#e0e0e0,stroke:#64b5f6\n    style B fill:#2d2d4a,color:#e0e0e0,stroke:#64b5f6\n    style C fill:#2d2d4a,color:#e0e0e0,stroke:#64b5f6\n    style D fill:#4caf50,color:#1a1a2e,stroke:#4caf50",
          "title": "GenAI Revolution (2020s)"
        }
      ],
      "moreInfo": [
        {
          "text": "History of artificial intelligence (Wikipedia)",
          "url": "https://en.wikipedia.org/wiki/History_of_artificial_intelligence"
        }
      ],
      "title": "History"
    },
    {
      "content": "Understanding the relationship between these three concepts is essential for anyone starting their AI journey. While often used interchangeably, they represent distinct but nested domains—each building upon the other.\n\n{{mermaid:diagram-0}}\n\n### Machine Learning\n\nMachine Learning (ML) is a method of data analysis where computers learn to identify patterns in data without being explicitly programmed for each task. Think of it as teaching a computer to recognize cats in photos by showing it thousands of cat pictures, rather than writing specific code that says \"a cat has pointed ears, whiskers, and four legs.\"\n\n### Artificial Intelligence\n\nArtificial Intelligence (AI) is a broader field that includes machine learning but also encompasses other approaches to creating intelligent systems. AI aims to create machines that can perform tasks that typically require human intelligence, such as reasoning, learning, planning, and understanding language.\n\nMachine learning is one approach within the AI toolkit, but AI also includes:\n\n- **Rule-based systems**: Follow pre-defined logical rules and conditions (like \"if temperature > 80°F, then turn on air conditioning\")\n- **Expert systems**: Capture human expertise in specific domains through knowledge bases and inference engines (like medical diagnosis systems that apply doctor's knowledge)\n- **Symbolic AI**: Uses symbols and logic to represent knowledge and reasoning (like early chess programs that evaluated board positions)\n- **Evolutionary algorithms**: Solve problems by mimicking natural selection and evolution\n- **Fuzzy logic**: Handles uncertainty and partial truths rather than strict true/false logic\n\nThese different approaches can be combined or used independently depending on the problem being solved.\n\n### Generative AI\n\nGenerative AI (GenAI) is a specific type of AI that can create new content - text, images, code, music, or other types of data. When you ask ChatGPT to write a story or use DALL-E to create an image, you're using generative AI. GenAI models learn patterns from existing content and use that knowledge to generate new, original content that follows similar patterns.",
      "mermaid": [
        {
          "id": "diagram-0",
          "diagram": "graph TB\n    subgraph AI[\"Artificial Intelligence\"]\n        subgraph ML[\"Machine Learning\"]\n            subgraph DL[\"Deep Learning\"]\n                GenAI[\"Generative AI\"]\n            end\n        end\n    end\n    \n    style AI fill:#1976d2,color:#fff,stroke:#1976d2\n    style ML fill:#2196f3,color:#fff,stroke:#2196f3\n    style DL fill:#64b5f6,color:#1a1a2e,stroke:#64b5f6\n    style GenAI fill:#f9a825,color:#1a1a2e,stroke:#f9a825",
          "title": null
        }
      ],
      "title": "ML vs AI vs GenAI"
    },
    {
      "content": "Generative AI encompasses a range of technologies that can create new content—text, images, code, audio, and more. This section explores the foundational concepts, from natural language processing to the different types of models powering today's AI applications.\n\n### Natural Language Processing\n\nUnderstanding Generative AI begins with Natural Language Processing (NLP), the foundational branch of AI that enables computers to understand, interpret, and generate human language. NLP represents a major breakthrough in human-computer interaction - instead of requiring users to learn programming languages or use specific commands, it allows people to interact with computers using natural human language, speaking or typing as they would to another person.\n\n### Language models\n\nWithin the broad field of NLP, modern AI systems primarily rely on language models - sophisticated AI systems that learn from vast amounts of text to understand and generate human-like responses. These language models come in different sizes and capabilities, each designed for specific use cases and computational requirements.\n\n### Large Language Models (LLMs)\n\nLarge Language Models (LLMs) represent the current pinnacle of NLP technology. These AI systems are trained on enormous datasets containing billions of text examples from books, articles, websites, and other written sources. Through this training, they learn intricate patterns in how humans use language and develop the ability to generate remarkably human-like text responses. Popular examples include GPT-4, Claude, and Gemini. LLMs typically contain billions of parameters (the internal \"settings\" the AI adjusts during learning) and require significant computational resources to operate effectively.\n\n### Small Language Models (SLMs)\n\nSmall Language Models (SLMs) serve the same fundamental purpose as their larger counterparts but prioritize efficiency and accessibility. These models are trained on more focused datasets and contain fewer parameters, making them suitable for running on local devices like smartphones, laptops, or edge computing environments. Examples include Microsoft's Phi models and various specialized versions optimized for specific tasks or industries.\n\n### Specialized model types\n\nBeyond text-focused language models, the NLP field has expanded to encompass various specialized model types that work with different forms of content:\n\n- **Diffusion models** (such as DALL-E, Stable Diffusion, and Midjourney) generate images from text descriptions\n- **Speech recognition models** (like Whisper) convert spoken words into written text\n- **Music generation models** (such as Suno, Udio) create original musical compositions\n- **Multimodal models** (like GPT-4o) can work seamlessly with multiple types of input and output - text, images, audio, and video\n\nThis diversity of model types reflects the broader evolution of AI from simple text processing to comprehensive understanding and generation across multiple forms of human communication and creative expression.",
      "title": "About Generative AI"
    },
    {
      "content": "AI vendors are companies that develop, train, and provide access to AI models. Each vendor brings different strengths, approaches, and business models to the market.\n\n{{mermaid:diagram-0}}\n\n### Major AI vendors\n\n- **OpenAI**: Creator of the GPT series and DALL-E, known for ChatGPT and pioneering conversational AI\n- **Google**: Develops Gemini models and provides AI services through Google Cloud\n- **Anthropic**: Focuses on AI safety and creates the Claude family of models\n- **Microsoft**: Partners with OpenAI and develops its own models while integrating AI across its product suite\n- **Hugging Face**: Acts as a platform for sharing and hosting AI models, both open-source and commercial\n\n### What vendors do\n\nVendors serve as the bridge between the complex world of AI model development and practical applications. They handle the enormous costs and technical challenges of training models, then make these models available through user-friendly interfaces and APIs. This allows developers and businesses to use sophisticated AI without needing to understand the underlying mathematics or infrastructure.\n\n### Key differences between vendors\n\n- *Research focus*: Some prioritize cutting-edge capabilities, others emphasize safety and reliability\n- *Business models*: Some offer free tiers with paid upgrades, others are enterprise-focused\n- *Specializations*: Different vendors excel in text, images, code, or multimodal applications\n- *Accessibility*: Some focus on easy-to-use consumer interfaces, others provide developer tools and APIs\n- *Data policies*: Vendors differ in how they handle user data and model training",
      "mermaid": [
        {
          "id": "diagram-0",
          "diagram": "graph LR\n    subgraph Vendors[\"AI Vendors\"]\n        OpenAI[\"OpenAI\"]\n        Google[\"Google\"]\n        Anthropic[\"Anthropic\"]\n        Microsoft[\"Microsoft\"]\n        HF[\"Hugging Face\"]\n    end\n    \n    subgraph Models[\"Models\"]\n        LLMs[\"Language Models\"]\n        Vision[\"Vision Models\"]\n        Audio[\"Audio Models\"]\n    end\n    \n    subgraph Users[\"End Users\"]\n        Dev[\"Developers\"]\n        Biz[\"Businesses\"]\n        Consumer[\"Consumers\"]\n    end\n    \n    OpenAI --> LLMs\n    OpenAI --> Vision\n    Google --> LLMs\n    Google --> Vision\n    Anthropic --> LLMs\n    Microsoft --> LLMs\n    HF --> LLMs\n    HF --> Vision\n    HF --> Audio\n    \n    LLMs --> Dev\n    Vision --> Dev\n    Audio --> Dev\n    Dev --> Biz\n    Dev --> Consumer\n    \n    style OpenAI fill:#10a37f,color:#fff,stroke:#10a37f\n    style Google fill:#4285f4,color:#fff,stroke:#4285f4\n    style Anthropic fill:#d4a574,color:#1a1a2e,stroke:#d4a574\n    style Microsoft fill:#00bcf2,color:#fff,stroke:#00bcf2\n    style HF fill:#ff9d00,color:#1a1a2e,stroke:#ff9d00\n    style LLMs fill:#2d2d4a,color:#e0e0e0,stroke:#64b5f6\n    style Vision fill:#2d2d4a,color:#e0e0e0,stroke:#64b5f6\n    style Audio fill:#2d2d4a,color:#e0e0e0,stroke:#64b5f6\n    style Dev fill:#2d2d4a,color:#e0e0e0,stroke:#64b5f6\n    style Biz fill:#2d2d4a,color:#e0e0e0,stroke:#64b5f6\n    style Consumer fill:#2d2d4a,color:#e0e0e0,stroke:#64b5f6",
          "title": null
        }
      ],
      "moreInfo": [
        {
          "text": "Azure OpenAI and Microsoft Foundry models",
          "url": "https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-models/concepts/models-sold-directly-by-azure"
        },
        {
          "text": "Hugging Face model hub",
          "url": "https://huggingface.co/models"
        },
        {
          "text": "OpenAI models documentation",
          "url": "https://platform.openai.com/docs/models"
        }
      ],
      "title": "Vendors"
    },
    {
      "content": "A model is the actual AI system that has been trained to perform specific tasks. Think of it as a specialized brain that has learned patterns from data and can apply that knowledge to new situations.\n\n### Key characteristics that differentiate models\n\n- *Training date*: When the model was trained affects what information it knows\n- *Cut-off date*: The latest date of information the model was trained on\n- *Size*: Larger models generally have more capabilities but require more computational resources\n- *Vendor*: Different companies create models with different strengths and focuses\n- *Specialization*: Some models excel at specific tasks like coding, creative writing, or analysis\n\n### Current popular models\n\n- **GPT series** (4, 4o, 4.1, 5): OpenAI's flagship models for text generation and reasoning\n- **Claude** (3.5 Sonnet, 4 Sonnet, 4 Opus): Anthropic's models focused on helpful, harmless, and honest interactions\n- **Gemini** (Flash, Pro): Google's multimodal models that can process text, images, and other data\n- **Grok**: xAI's conversational AI model with real-time information access\n- **Phi-4**: Microsoft's efficient model designed to run on smaller devices with strong reasoning capabilities\n- **Gemma 2/3**: Google's compact open models optimized for efficiency\n\n#### Specialized Models\n\n- **DALL-E, Stable Diffusion, Midjourney, Flux**: Image generation models (diffusion models)\n- **Whisper**: Speech-to-text conversion model\n- **Suno, Udio**: Music generation models\n\n#### Multimodal Models\n\n- **GPT-4o, GPT-4.1, GPT-5**: OpenAI models handling text, images, audio, and video\n- **Gemini**: Google's multimodal models (also listed above under LLMs)\n- **Claude 4 Opus**: Anthropic's multimodal model with vision capabilities\n\n</div>",
      "moreInfo": [
        {
          "text": "Foundry Models: GPT-5, GPT-4.1, o-series, and more",
          "url": "https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-models/concepts/models-sold-directly-by-azure"
        },
        {
          "text": "Azure OpenAI model versions",
          "url": "https://learn.microsoft.com/en-us/azure/ai-foundry/openai/concepts/model-versions"
        },
        {
          "text": "Explore Foundry Models",
          "url": "https://learn.microsoft.com/en-us/azure/ai-foundry/concepts/foundry-models-overview"
        }
      ],
      "faq": [
        {
          "question": "What is a GPT and why are not all models GPT?",
          "answer": "GPT stands for \"Generative Pre-trained Transformer.\" It's a specific architecture developed by OpenAI. Not all models use this architecture - companies develop different approaches to achieve similar goals. Think of it like cars: not all cars are Toyotas, even though they all serve the same basic purpose of transportation."
        },
        {
          "question": "What does multimodal mean and how can I use it?",
          "answer": "Multimodal models can understand and generate multiple types of content - not just text, but also images, audio, and video. For example, you can upload an image to GPT-4o and ask it to describe what it sees, or ask it to create an image based on your description. This makes interactions more natural and expands what you can accomplish with AI."
        },
        {
          "question": "Why not train a model every month or week to keep it up-to-date?",
          "answer": "Training large AI models requires enormous computational resources, costs millions of dollars, and takes weeks or months to complete. The process involves analyzing billions of text examples and adjusting trillions of parameters. Additionally, frequent retraining could make models less stable and reliable. Instead, vendors typically release new versions periodically with updated knowledge and improved capabilities."
        }
      ],
      "title": "Models"
    },
    {
      "moreInfo": [
        {
          "text": "Microsoft Foundry SDKs and Endpoints",
          "url": "https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/develop/sdk-overview"
        },
        {
          "text": "Azure OpenAI data, privacy, and security",
          "url": "https://learn.microsoft.com/en-us/azure/ai-foundry/responsible-ai/openai/data-privacy"
        },
        {
          "text": "About GitHub Models",
          "url": "https://docs.github.com/en/github-models/about-github-models"
        }
      ],
      "content": "Providers are services that host AI models and make them accessible to users and developers. While vendors create the models, providers handle the infrastructure needed to run them at scale and make them available through APIs, web interfaces, or applications.\n\n{{mermaid:diagram-0}}\n\n### Technical components of hosted AI services\n\n- *Proxy*: Routes requests to available model instances and manages traffic\n- *Load balancer*: Distributes requests across multiple servers to ensure reliable performance\n- *Content filter*: Screens inputs and outputs to prevent harmful or inappropriate content\n- *Rate limiting*: Controls how many requests users can make to prevent abuse\n- *Authentication*: Manages user access and API keys\n- *Monitoring*: Tracks usage, performance, and costs\n\n### Major hosted providers\n\n- **OpenAI**: Direct access to GPT models through their API and ChatGPT interface\n- **Google Cloud**: Hosts Gemini and other Google AI models\n- **Microsoft Azure**:\n  - **Azure OpenAI**: Enterprise-grade access to OpenAI models with enhanced security and compliance\n  - **GitHub Models**: Developer-focused platform with model catalog and development tools\n- **Hugging Face**: Platform for both open-source and commercial models\n- **Anthropic**: Direct access to Claude models\n\n### Self-hosting options\n\nFor organizations that need complete control over their AI infrastructure, self-hosting is possible:\n\n- **Docker containers**: Run models in containerized environments\n- **Ollama**: User-friendly tool for running models locally\n- **Hugging Face Transformers**: Library for deploying models on your own hardware\n\n### Why models refuse certain requests\n\nYou may notice that AI models sometimes decline to answer questions or refuse to generate certain content. This is by design.\n\nDuring training, model providers shape how models behave through a process called *alignment*. One common approach is Constitutional AI: the model learns to critique its own responses against a set of principles (like \"be helpful but avoid harm\") and revise them before responding. This happens during training, not at runtime.\n\nOn top of alignment, providers add *content filters* that screen inputs and outputs in real-time. These filters catch harmful requests that slip past the model's built-in guardrails.\n\nAs an application developer, you don't control the model's alignment—that's baked in by the provider. But you can:\n\n- Choose models with appropriate safety properties for your use case\n- Add your own content filtering layer\n- Use system prompts to guide behavior within the model's boundaries\n- Implement human review for sensitive outputs\n\n</div>",
      "mermaid": [
        {
          "id": "diagram-0",
          "diagram": "graph LR\n    App[\"Your App\"] --> Auth[\"Auth\"] --> Proxy[\"Proxy\"] --> LB[\"Load Balancer\"] --> Filter[\"Content Filter\"] --> Rate[\"Rate Limiter\"] --> Models[\"AI Models\"]\n    \n    style App fill:#2d2d4a,color:#e0e0e0,stroke:#64b5f6\n    style Auth fill:#2d2d4a,color:#e0e0e0,stroke:#64b5f6\n    style Proxy fill:#2d2d4a,color:#e0e0e0,stroke:#64b5f6\n    style LB fill:#2d2d4a,color:#e0e0e0,stroke:#64b5f6\n    style Filter fill:#2d2d4a,color:#e0e0e0,stroke:#64b5f6\n    style Rate fill:#2d2d4a,color:#e0e0e0,stroke:#64b5f6\n    style Models fill:#2d2d4a,color:#e0e0e0,stroke:#64b5f6",
          "title": null
        }
      ],
      "faq": [
        {
          "question": "Do all hosted solutions use my data?",
          "answer": "Data usage policies vary significantly between providers. Some use conversation data to improve their models (with user consent), while others, particularly enterprise-focused services, commit to not using customer data for training. Always check the specific terms of service and privacy policies."
        },
        {
          "question": "Where is my data stored?",
          "answer": "Data storage locations depend on the provider and service tier. Consumer services might store data globally, while enterprise services often allow you to specify geographic regions for compliance with local regulations like GDPR."
        },
        {
          "question": "Can I opt-out of data collection?",
          "answer": "Most providers offer ways to limit data collection, though the options vary. Some allow you to delete conversation history, others provide settings to prevent data from being used for model training."
        },
        {
          "question": "How does Azure OpenAI differ from using OpenAI directly?",
          "answer": "Azure OpenAI provides access to many OpenAI models through Azure, with Azure-native identity, networking, and governance features. Model availability and versions can differ by region and over time. Azure OpenAI states it doesn't use customer data to retrain foundation models; see the [Azure OpenAI data, privacy, and security guide](https://learn.microsoft.com/en-us/azure/ai-foundry/responsible-ai/openai/data-privacy)."
        },
        {
          "question": "How does GitHub Models relate to GitHub Copilot?",
          "answer": "GitHub Models is a development platform that gives developers access to various AI models for building applications, while GitHub Copilot is a specific AI coding assistant. Think of GitHub Models as a toolbox for AI development, and Copilot as one specific tool that helps with coding. [GitHub Models](https://docs.github.com/en/github-models/about-github-models) provides model catalogs, prompt management, and evaluation tools for developers."
        }
      ],
      "title": "Providers"
    },
    {
      "content": "Prompts are the instructions or questions you give to an AI model, while messages are the individual communications in a conversation between you and the AI. Understanding how to structure these effectively is key to getting good results from AI systems.\n\n### Types of prompts and messages\n\n- *User prompt*: Your question, instruction, or request to the AI\n- *System prompt*: Background instructions that set the AI's behavior, role, or constraints (often hidden from users)\n- *Assistant message*: The AI's response to your prompt\n  - *Suggestions*: When the AI offers multiple options or approaches\n  - *Completions*: When the AI finishes or continues text you've started\n\n### Prompt engineering\n\nPrompt engineering is the practice of crafting effective prompts to get better results from AI models. Different techniques work better for different types of tasks:\n\n### Prompt techniques\n\n#### Zero-shot prompts\n\nZero-shot prompts ask the AI to perform a task without providing examples:\n\n- \"Summarize this article in three bullet points.\"\n- \"Classify this email as spam or not spam.\"\n- \"Write a professional response to this customer complaint.\"\n- \"Extract the main topics from this document.\"\n\n#### Few-shot prompts\n\nFew-shot prompts provide a few examples of the desired input-output pattern:\n\n- \"Translate these phrases. English: Hello → Spanish: Hola. English: Thank you → Spanish: Gracias. English: Good morning → Spanish: ?\"\n- \"Sentiment: 'Great product!' → Positive. Sentiment: 'Terrible service' → Negative. Sentiment: 'It was okay' → ?\"\n- \"Format: john.doe@company.com → John Doe (Company). Format: jane.smith@startup.io → ?\"\n- \"Bug type: 'App crashes on login' → Authentication. Bug type: 'Slow page load' → Performance. Bug type: 'Button not clickable' → ?\"\n\n#### Chain of thought prompts\n\nChain of thought prompts ask the AI to show its reasoning process:\n\n- \"Solve this math problem step by step, showing your work.\"\n- \"Analyze this code for potential bugs. Walk through each line and explain what could go wrong.\"\n- \"Evaluate the pros and cons of each option, then recommend the best approach.\"\n- \"Debug this error by explaining what each part of the error message means and what might have caused it.\"\n\n### Reusable prompts\n\nReusable prompts are templates or standardized instructions that you can use repeatedly for similar tasks. These save time and ensure consistency. For example, you might create a standard prompt for code reviews or document summaries that includes specific criteria and formatting instructions.",
      "moreInfo": [
        {
          "text": "Prompt engineering techniques (Microsoft Learn)",
          "url": "https://learn.microsoft.com/en-us/azure/ai-foundry/openai/concepts/prompt-engineering"
        },
        {
          "text": "Craft Prompts That Get Copilot to Deliver What You Need",
          "url": "https://randypagels.com/blog/prompt-engineering-for-github-copilot-part-1-introduction-prompt-engineering-and-prompts-that-get-copilot-to-deliver-what-you-need/"
        },
        {
          "text": "Best Prompt Engineering Tools (2025) for Building and Debugging LLM Agents",
          "url": "https://www.reddit.com/r/AI_Agents/comments/1mc4q9i/best_prompt_engineering_tools_2025_for_building/"
        },
        {
          "text": "Go from Prompt to Playback: Sora Video Generation in Microsoft Foundry's Video Playground",
          "url": "https://devblogs.microsoft.com/azure-ai/go-from-prompt-to-playback-with-sora-from-azure-openai-in-the-video-playground-in-azure-ai-foundry/"
        }
      ],
      "title": "Prompts & messages"
    },
    {
      "content": "Tokens are the basic units that AI models use to process text. Think of them as the \"words\" that the AI actually understands, though they don't always match human words exactly.\n\n{{mermaid:diagram-0}}\n\n### How tokenization works\n\nWhen you send text to an AI model, it first breaks your message into tokens. This process, called tokenization, splits text into manageable pieces. A token might be:\n\n- A whole word (like \"hello\")\n- Part of a word (like \"un\" and \"believable\" for \"unbelievable\")\n- A punctuation mark\n- A space or special character\n\n### How many tokens are in a message?\n\nAs a rough guide, 1 token equals about 0.75 English words. So 100 words would be approximately 133 tokens. However, this varies based on:\n\n- Language (non-English text often uses more tokens)\n- Technical terms and proper nouns\n- Punctuation and formatting\n\n### Why is this important?\n\nTokens directly affect:\n\n- *Cost*: Most AI services charge per token processed\n- *Speed*: More tokens mean longer processing time\n- *Limits*: Models have maximum token limits for conversations\n\n### Token limits and what happens when you exceed them\n\nEvery model has a maximum context window (total tokens it can process at once). When you exceed this limit:\n\n- The model might truncate older parts of the conversation\n- You might get an error message\n- The quality of responses may decrease\n\n### What to do when hitting token limits\n\n- Summarize earlier parts of long conversations\n- Break complex tasks into smaller pieces\n- Use more concise language in your prompts\n- Start a new conversation if context becomes too long\n\n### Switching between tokenizers\n\nDifferent models use different tokenization methods, so you can't directly transfer token counts between models.\n\n### Tokenization differences between content types\n\n- *Text*: Broken into word parts and punctuation\n- *Images*: Converted into fixed-size \"image tokens\" representing visual information\n- *Audio*: Processed into time-based segments representing sound patterns\n- *Code*: Often tokenized similar to text but may handle syntax differently",
      "mermaid": [
        {
          "id": "diagram-0",
          "diagram": "graph LR\n    Text[\"The unbelievable AI!\"] --> Split[\"Tokenizer\"]\n    Split --> T1[\"The\"]\n    Split --> T2[\"un\"]\n    Split --> T3[\"believ\"]\n    Split --> T4[\"able\"]\n    Split --> T5[\"AI\"]\n    Split --> T6[\"!\"]\n    \n    T1 --> ID1[\"791\"]\n    T2 --> ID2[\"359\"]\n    T3 --> ID3[\"25089\"]\n    T4 --> ID4[\"481\"]\n    T5 --> ID5[\"9552\"]\n    T6 --> ID6[\"0\"]\n    \n    style Text fill:#2d2d4a,color:#e0e0e0,stroke:#64b5f6\n    style Split fill:#2d2d4a,color:#e0e0e0,stroke:#64b5f6\n    style T1 fill:#4caf50,color:#fff,stroke:#4caf50\n    style T2 fill:#64b5f6,color:#1a1a2e,stroke:#64b5f6\n    style T3 fill:#64b5f6,color:#1a1a2e,stroke:#64b5f6\n    style T4 fill:#64b5f6,color:#1a1a2e,stroke:#64b5f6\n    style T5 fill:#9c27b0,color:#fff,stroke:#9c27b0\n    style T6 fill:#ff9800,color:#1a1a2e,stroke:#ff9800\n    style ID1 fill:#2d2d4a,color:#e0e0e0,stroke:#64b5f6\n    style ID2 fill:#2d2d4a,color:#e0e0e0,stroke:#64b5f6\n    style ID3 fill:#2d2d4a,color:#e0e0e0,stroke:#64b5f6\n    style ID4 fill:#2d2d4a,color:#e0e0e0,stroke:#64b5f6\n    style ID5 fill:#2d2d4a,color:#e0e0e0,stroke:#64b5f6\n    style ID6 fill:#2d2d4a,color:#e0e0e0,stroke:#64b5f6",
          "title": null
        }
      ],
      "moreInfo": [
        {
          "text": "GPT-5 Launches in Microsoft Foundry: New Era for AI Apps, Agents and Developers",
          "url": "https://devblogs.microsoft.com/azure-ai/gpt-5-launches-in-azure-ai-foundry-new-era-for-ai-apps-agents-and-developers/"
        },
        {
          "text": "Maximize Your ROI for Azure OpenAI: Pricing, Deployment, and Cost Optimization Strategies",
          "url": "https://devblogs.microsoft.com/azure-ai/maximize-your-roi-for-azure-openai-pricing-deployment-and-cost-optimization-strategies/"
        },
        {
          "text": "Introducing Deep Research in Microsoft Foundry Agent Service",
          "url": "https://devblogs.microsoft.com/azure-ai/introducing-deep-research-in-azure-ai-foundry-agent-service/"
        }
      ],
      "title": "Tokens & Tokenization"
    },
    {
      "content": "The core mechanism behind all modern LLMs is remarkably simple in concept: next-token prediction. Given a sequence of tokens, the model predicts what token is most likely to come next.\n\n{{mermaid:diagram-0}}\n\nFor example, given the input **\"The dog...\"**, the model calculates probability scores for every token in its vocabulary:\n\n- \"barks\" might get 32% probability\n- \"runs\" might get 18%\n- \"sleeps\" might get 12%\n- And thousands of other possibilities with smaller probabilities\n\nThe model then samples from this distribution (or picks the highest probability, depending on settings) and appends that token to the sequence. This process repeats: now with \"The dog barks\", it predicts the next token, and so on until a complete response is generated.\n\n{{mermaid:diagram-1}}\n\nThis autoregressive generation is why models can produce coherent, contextually appropriate text—each new token is conditioned on everything that came before it.",
      "mermaid": [
        {
          "id": "diagram-0",
          "diagram": "graph LR\n    Input[\"The dog ...\"] --> LLM[\"Language Model\"]\n    LLM --> O1[\"barks 32%\"]\n    LLM --> O2[\"runs 18%\"]\n    LLM --> O3[\"sleeps 12%\"]\n    LLM --> O4[\"jumped 8%\"]\n    LLM --> O5[\"other ...\"]\n    \n    style Input fill:#2d2d4a,color:#e0e0e0,stroke:#64b5f6\n    style LLM fill:#2d2d4a,color:#e0e0e0,stroke:#64b5f6\n    style O1 fill:#4caf50,color:#fff,stroke:#4caf50\n    style O2 fill:#2d2d4a,color:#e0e0e0,stroke:#64b5f6\n    style O3 fill:#2d2d4a,color:#e0e0e0,stroke:#64b5f6\n    style O4 fill:#2d2d4a,color:#e0e0e0,stroke:#64b5f6\n    style O5 fill:#2d2d4a,color:#e0e0e0,stroke:#64b5f6",
          "title": null
        },
        {
          "id": "diagram-1",
          "diagram": "sequenceDiagram\n    User->>LLM: \"The dog\"\n    LLM->>LLM: predict → \"barks\"\n    LLM->>LLM: predict → \"loudly\"\n    LLM->>LLM: predict → \"at\"...\n    LLM->>User: \"The dog barks loudly at the mailman.\"",
          "title": null
        }
      ],
      "title": "Next-token prediction: How LLMs generate text"
    },
    {
      "content": "Understanding AI costs helps you make informed decisions about which models and approaches to use for different tasks.\n\n{{mermaid:diagram-0}}\n\n### Cost factors\n\n*Context*: The amount of information the model needs to consider affects cost. This includes your current message plus any conversation history or background information (system prompts).\n\n*Chat history*: Longer conversations cost more because the model processes the entire conversation context with each new message. If you have a 50-message conversation, the model reviews all previous messages to understand context when responding to message 51.\n\n*Prompts*: More detailed and longer prompts cost more to process, but they often produce better results. Finding the right balance between prompt detail and cost is important for regular use.\n\n### Cost optimization strategies\n\n- Keep conversations focused and avoid unnecessary context\n- Use smaller, more efficient models for simple tasks\n- Reserve powerful (expensive) models for complex problems\n- Consider using summarization to reduce context length in long conversations\n- Clear conversation history when starting new topics that don't require previous context\n\n### Token math and practical examples\n\n- Basic formula: total_cost ≈ (input_tokens × input_rate) + (output_tokens × output_rate). Rates differ per provider and model. Always check the provider's pricing page.\n- Estimating tokens: a quick rule-of-thumb is 1 token ≈ 0.75 English words (see [Tokens & Tokenization](#tokens--tokenization)).\n- Examples (estimates for planning only):\n  - News article (800–1,200 words) → ~1,060–1,600 tokens. Summarizing such an article once costs 1–2k input tokens plus the summary output tokens.\n  - Email thread (10 messages, ~150 words each) → ~2,000 tokens of history before your next prompt. Each reply re-sends this context unless you trim/summarize.\n  - Image analysis: some multimodal models charge per \"image token\" in addition to text tokens. Budget for both when sending images plus captions.\n  - Long chats: token usage grows with history. Without trimming, costs can rise linearly per turn and you risk context-window truncation.\n\n### How token limits tie to failure modes\n\n- Truncation: when the context window is exceeded, earlier messages may be dropped. The model can \"forget\" critical instructions or facts.\n- Lost grounding: if retrieved citations or data are pushed out of context, the model may revert to guesses (hallucinations).\n- Incomplete tools loop: long tool results + long chat history can crowd out system prompts or tool specs, degrading tool-use accuracy. Prefer structured summaries between steps.",
      "mermaid": [
        {
          "id": "diagram-0",
          "diagram": "graph TB\n    Prompt[\"Your Prompt\"] --> Input[\"Input Tokens\"]\n    System[\"System Prompt\"] --> Input\n    History[\"Chat History\"] --> Input\n    Context[\"RAG Context\"] --> Input\n    \n    Input --> Cost[\"Total Cost\"]\n    Output[\"Output Tokens\"] --> Cost\n    \n    style Prompt fill:#2d2d4a,color:#e0e0e0,stroke:#64b5f6\n    style System fill:#2d2d4a,color:#e0e0e0,stroke:#64b5f6\n    style History fill:#2d2d4a,color:#e0e0e0,stroke:#64b5f6\n    style Context fill:#2d2d4a,color:#e0e0e0,stroke:#64b5f6\n    style Input fill:#2d2d4a,color:#e0e0e0,stroke:#64b5f6\n    style Output fill:#2d2d4a,color:#e0e0e0,stroke:#64b5f6\n    style Cost fill:#2d2d4a,color:#e0e0e0,stroke:#64b5f6",
          "title": null
        }
      ],
      "moreInfo": [
        {
          "text": "Maximize Your ROI for Azure OpenAI: Pricing, Deployment, and Cost Optimization",
          "url": "https://devblogs.microsoft.com/azure-ai/maximize-your-roi-for-azure-openai-pricing-deployment-and-cost-optimization-strategies/"
        },
        {
          "text": "Azure OpenAI deployment types",
          "url": "https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-models/concepts/deployment-types"
        },
        {
          "text": "Azure OpenAI pricing",
          "url": "https://azure.microsoft.com/en-us/pricing/details/cognitive-services/openai-service/"
        }
      ],
      "title": "Costs"
    },
    {
      "content": "Understanding the limitations of AI models helps you use them more effectively and avoid common pitfalls.\n\n{{mermaid:diagram-0}}\n\n### Hallucinations\n\nAI models sometimes generate information that sounds confident and plausible but is factually incorrect. This happens because models predict what text should come next based on patterns they learned, rather than accessing a database of facts. Always verify important information, especially dates, statistics, and specific claims.\n\n### Input-poisoning\n\nMalicious users might try to manipulate AI responses by including hidden instructions or misleading information in their prompts. Well-designed systems include protections against this, but it's important to be aware that AI responses can be influenced by how questions are framed.\n\n### Jailbreaking\n\nThis refers to attempts to bypass an AI's safety guidelines or restrictions through clever prompting techniques. While providers work to prevent this, it highlights the importance of not relying solely on AI systems for content moderation or safety-critical decisions.\n\n### Why AI struggles with calculations and counting\n\nLanguage models are designed to predict text patterns, not perform precise mathematical operations. They might correctly handle simple arithmetic they've seen many times in training data, but they're not calculators. For reliable mathematical results:\n\n- Use dedicated calculation tools\n- Ask the AI to write code that performs the calculation\n- Verify mathematical results independently\n\nWhen you need precise calculations or counting, consider using AI to generate code for a calculator or spreadsheet rather than asking for direct numerical results.\n\n### Human-in-the-loop (HITL) approaches\n\nGiven these limitations, many organizations implement Human-in-the-loop systems where humans remain involved in AI decision-making processes. Instead of fully automated AI systems, HITL approaches include human oversight, validation, or intervention at key points. For example, an AI might flag potentially problematic content, but a human reviews and makes the final decision about whether to remove it. This approach helps mitigate risks while still benefiting from AI's efficiency and capabilities.",
      "mermaid": [
        {
          "id": "diagram-0",
          "diagram": "graph LR\n    subgraph Problems[\"Problems\"]\n        H[\"Hallucinations\"]\n        IP[\"Input Poisoning\"]\n        J[\"Jailbreaking\"]\n        M[\"Math Errors\"]\n    end\n    \n    subgraph Solutions[\"Solutions\"]\n        Verify[\"Verify facts\"]\n        Filter[\"Input filtering\"]\n        Guard[\"Guardrails\"]\n        Tools[\"Use tools\"]\n        HITL[\"Human review\"]\n    end\n    \n    H --> Verify\n    H --> HITL\n    IP --> Filter\n    J --> Guard\n    M --> Tools\n    \n    style H fill:#ef5350,color:#fff,stroke:#ef5350\n    style IP fill:#ef5350,color:#fff,stroke:#ef5350\n    style J fill:#ef5350,color:#fff,stroke:#ef5350\n    style M fill:#ef5350,color:#fff,stroke:#ef5350\n    style Verify fill:#4caf50,color:#fff,stroke:#4caf50\n    style Filter fill:#4caf50,color:#fff,stroke:#4caf50\n    style Guard fill:#4caf50,color:#fff,stroke:#4caf50\n    style Tools fill:#4caf50,color:#fff,stroke:#4caf50\n    style HITL fill:#4caf50,color:#fff,stroke:#4caf50",
          "title": null
        }
      ],
      "moreInfo": [
        {
          "text": "Prompt injection and jailbreak detection",
          "url": "https://learn.microsoft.com/en-us/azure/ai-services/content-safety/concepts/jailbreak-detection"
        },
        {
          "text": "Azure AI Content Safety",
          "url": "https://ai.azure.com/explore/contentsafety"
        },
        {
          "text": "Azure OpenAI transparency note",
          "url": "https://learn.microsoft.com/en-us/azure/ai-foundry/responsible-ai/openai/transparency-note"
        }
      ],
      "title": "Problems with models"
    },
    {
      "content": "Use the right tool for the job. Prefer non-AI or AI-assisted approaches for:\n\n- Exact arithmetic, counting, or unit conversions. Use a calculator, spreadsheet, or ask the model to generate code that computes the result and then run it.\n- Deterministic workflows with strict rules (compliance checks, tax calculations, safety-critical steps). Encode rules in code or rules engines and optionally add AI for explanations.\n- Long-lived, precise memory; summaries drift over time, so store source-of-truth data in databases and use RAG to re-ground when needed.\n- Sensitive data handling beyond approved boundaries; keep PII/PHI within compliant systems and use redaction and data minimization.\n- Legal, medical, or financial decisions without human review. Keep a human in the loop for final approval.\n\nWhen in doubt, let AI help draft, explain, and prototype, but keep calculators, compilers, search, and databases as the \"source of truth.\"",
      "moreInfo": [
        {
          "text": "Is AI the Right Solution? Applying the Framework and Navigating Ethical Risks",
          "url": "https://hiddedesmet.com/ai-project-validation-framework-part2"
        },
        {
          "text": "Azure OpenAI limitations",
          "url": "https://learn.microsoft.com/en-us/azure/ai-foundry/responsible-ai/openai/transparency-note#limitations"
        }
      ],
      "title": "When not to use AI"
    },
    {
      "content": "AI's benefits come with human and environmental costs that show up across society. Key impacts and current risks include:\n\n- Hidden human labor: low‑paid data annotation and content moderation—often outsourced to the Global South—with long hours, low wages, trauma exposure, and poor working conditions documented in reporting (see [The Conversation](https://theconversation.com/long-hours-and-low-wages-the-human-labour-powering-ais-development-217038) and [Guardian report](https://www.theguardian.com/technology/article/2024/jul/06/mercy-anita-african-workers-ai-artificial-intelligence-exploitation-feeding-machine)).\n- Environmental footprint: high electricity demand tied to grid carbon intensity; significant water use for data‑center cooling; upstream mining for chips and batteries; e‑waste and localized environmental burdens near facilities.\n- Bias and discrimination: training‑data and deployment‑context bias can lead to unequal outcomes in hiring, lending, healthcare, education, and policing—often affecting marginalized groups most.\n- Information integrity: synthetic media and confident but wrong outputs accelerate misinformation, deepfakes, and election interference; provenance and content authenticity remain open challenges.\n- Privacy and IP: mass data collection, scraping, and model training without consent raise privacy, surveillance, and creator‑rights concerns.\n- Work and the economy: automation reshapes tasks and wages; some roles are displaced while new ones emerge; growing surveillance and metrics can increase precarity in workplaces.\n- Concentration and access: a few firms control models, compute, and distribution; lock‑in and digital divides influence who benefits and who is excluded.\n- Security and misuse: prompt injection, data poisoning, model extraction, and jailbreaks; voice‑clone fraud, large‑scale phishing, and code generation that lowers the bar for cyberattacks.\n\nSee also: [Is AI the Right Solution? Part 2: Applying the Framework and Navigating Ethical Risks](https://hiddedesmet.com/ai-project-validation-framework-part2).",
      "moreInfo": [
        {
          "text": "Long hours and low wages: The human labour powering AI's development",
          "url": "https://theconversation.com/long-hours-and-low-wages-the-human-labour-powering-ais-development-217038"
        },
        {
          "text": "Hidden exploitation in AI data labeling",
          "url": "https://www.theguardian.com/technology/article/2024/jul/06/mercy-anita-african-workers-ai-artificial-intelligence-exploitation-feeding-machine"
        },
        {
          "text": "Azure OpenAI responsible AI transparency note",
          "url": "https://learn.microsoft.com/en-us/azure/ai-foundry/responsible-ai/openai/transparency-note"
        }
      ],
      "title": "Societal impacts and risks"
    }
  ],
  "description": "Foundational concepts for understanding Generative AI, from history to modern implementations.",
  "title": "GenAI Basics"
}
