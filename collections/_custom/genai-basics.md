---
layout: "custom"
title: "GenAI Basics"
description: "Foundational concepts for understanding Generative AI"
viewing_mode: "internal"
categories: ["AI"]
permalink: "/ai/genai-basics"
tags: ["AI", "Generative AI", "Basics", "Tutorial", "Fundamentals"]
tags_normalized: ["ai", "generative ai", "basics", "tutorial", "fundamentals"]
---

## History {#history}

Some fun history facts about AI, showing how long AI has been around and how it has evolved over time.

- **1956:** AI term coined at Dartmouth Conference
- **1966:** ELIZA chatbot at MIT
- **2020:** GPT-3 with 175B parameters
- **2023:** GPT-4 & Claude major quality leaps

## Models {#models}

A model is the actual AI system that has been trained to perform specific tasks. Think of it as a specialized brain that has learned patterns from data and can apply that knowledge to new situations.

### Current popular models

- **GPT series (4, 4o, 4.1, 5):** OpenAI's flagship models
- **Claude (3.5 Sonnet, 4 Sonnet, 4 Opus):** Anthropic's models
- **Gemini (Flash, Pro):** Google's multimodal models
- **Phi-4:** Microsoft's efficient model

## Tokens & Tokenization {#tokens}

Tokens are the basic units that AI models use to process text. Think of them as the "words" that the AI actually understands, though they don't always match human words exactly.

As a rough guide, 1 token equals about 0.75 English words. So 100 words would be approximately 133 tokens.

## Additional Topics {#additional}

This page covers many more topics including:

- ML vs AI vs GenAI
- Vendors and Providers
- Prompts & Messages
- Costs and Optimization
- Problems with Models
- When not to use AI
- Societal impacts and risks

*Full content migration from Jekyll to Blazor is in progress. This page shows key sections.*
