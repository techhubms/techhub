---
layout: "post"
title: "Microsoft Azure AI Foundry Models and Security Copilot Achieve ISO/IEC 42001:2023 Certification"
description: "Microsoft has achieved ISO/IEC 42001:2023 certification for Azure AI Foundry Models and Microsoft Security Copilot, showcasing their commitment to responsible, secure, and transparent AI management. This globally recognized certification establishes Microsoft’s alignment with international standards in AI governance, risk, and compliance."
author: "Molly Bostic"
excerpt_separator: <!--excerpt_end-->
canonical_url: "https://azure.microsoft.com/en-us/blog/microsoft-azure-ai-foundry-models-and-microsoft-security-copilot-achieve-iso-iec-420012023-certification/"
viewing_mode: "external"
feed_name: "The Azure Blog"
feed_url: "https://azure.microsoft.com/en-us/blog/feed/"
date: 2025-07-17 15:00:00 +00:00
permalink: "/2025-07-17-Microsoft-Azure-AI-Foundry-Models-and-Security-Copilot-Achieve-ISOIEC-420012023-Certification.html"
categories: ["AI", "Azure", "Security"]
tags: ["AI", "AI + Machine Learning", "AI Compliance", "AI Foundry Models", "AI Governance", "AI Lifecycle", "AI Risk Management", "Azure", "Cloud Platform", "Copilot", "ISO/IEC 42001:2023", "Microsoft Azure", "Microsoft Security Copilot", "News", "Operational Resilience", "Regulatory Standards", "Responsible AI", "Security", "Security Certification", "Trust And Transparency"]
tags_normalized: ["ai", "ai plus machine learning", "ai compliance", "ai foundry models", "ai governance", "ai lifecycle", "ai risk management", "azure", "cloud platform", "copilot", "isoslashiec 420012023", "microsoft azure", "microsoft security copilot", "news", "operational resilience", "regulatory standards", "responsible ai", "security", "security certification", "trust and transparency"]
---

In this post, Molly Bostic announces Microsoft's ISO/IEC 42001:2023 certification for Azure AI Foundry Models and Microsoft Security Copilot, detailing the implications for responsible AI, security, and compliance efforts.<!--excerpt_end-->

# Microsoft Azure AI Foundry Models and Security Copilot Achieve ISO/IEC 42001:2023 Certification

*By Molly Bostic*

Microsoft has achieved ISO/IEC 42001:2023 certification—a globally recognized standard for Artificial Intelligence Management Systems (AIMS)—for both Azure AI Foundry Models and Microsoft Security Copilot. This accomplishment reinforces Microsoft’s ongoing commitment to responsible, secure, and transparent AI, and provides customers increased confidence in adopting Microsoft’s AI-powered services.

## Overview of ISO/IEC 42001:2023

[ISO/IEC 42001](https://www.iso.org/standard/42001), developed by the International Organization for Standardization (ISO) and the International Electrotechnical Commission (IEC), establishes a certifiable management framework for AI systems. It covers:

- Risk management and bias mitigation
- Transparency and human oversight
- Organizational accountability

The standard supports organizations in addressing both risks and opportunities throughout the entire AI lifecycle by requiring structured practices to establish, implement, maintain, and improve AI management systems.

## Microsoft’s Achievements in Certification

By achieving ISO/IEC 42001:2023 certification for [Azure AI Foundry Models](https://azure.microsoft.com/en-us/products/ai-model-catalog) (including Azure OpenAI models) and [Microsoft Security Copilot](https://www.microsoft.com/en-us/security/business/ai-machine-learning/microsoft-security-copilot), Microsoft demonstrates validated third-party assurance that its AI services are developed and operated responsibly. This assures customers that Microsoft:

- Aligns with robust governance and risk management
- Adheres to compliance practices outlined in [Microsoft’s Responsible AI Standard](https://cdn-dynmedia-1.microsoft.com/is/content/microsoftcorp/microsoft/final/en-us/microsoft-brand/documents/Microsoft-Responsible-AI-Standard-General-Requirements.pdf?culture=en-us&country=us)
- Fosters innovation in a secure, auditable, and transparent way

## Key Benefits for Customers

Organizations deploying AI in regulated industries, embedding generative AI into products, or exploring new use cases will benefit from Microsoft’s ISO/IEC 42001:2023 certification by:

- **Accelerating their compliance journey**: Leveraging certified AI services with governance controls aligned to emerging regulations
- **Building trust**: Assurance for users, partners, and regulators through transparent, auditable oversight
- **Gaining transparency**: Insight into how Microsoft manages AI risk and delivers responsible AI development

## Microsoft’s Responsible AI Framework

Microsoft’s Responsible AI (RAI) program underpins its trustworthy AI approach through four pillars—[Govern, Map, Measure, and Manage](https://www.microsoft.com/en-us/corporate-responsibility/responsible-ai-transparency-report/).

Key components include:

1. [AI Customer Commitments](https://blogs.microsoft.com/blog/2023/06/08/announcing-microsofts-ai-customer-commitments/) — Supporting customers’ responsible AI adoption.
2. [Responsible AI Transparency Report](https://www.microsoft.com/en-us/corporate-responsibility/responsible-ai-transparency-report/) — Sharing practices, insights, and progress towards responsible AI goals.
3. Transparency resources for both [Azure AI Foundry Models](https://learn.microsoft.com/en-us/azure/ai-foundry/responsible-ai/openai/transparency-note?tabs=text) and [Microsoft Security Copilot](https://learn.microsoft.com/en-us/copilot/security/rai-faqs-security-copilot) — Explaining capabilities, limitations, and operational choices.
4. [Responsible AI resources site](https://www.microsoft.com/en-us/ai/tools-practices) — Providing tools, templates, and practices for customers to establish responsible AI processes.

## Commitment to Ongoing Trust & Compliance

Microsoft supports customers by:

- Continuously improving AI management systems
- Focusing on customer needs and expectations
- Expanding the Microsoft RAI program and AI risk management efforts
- Acting on new opportunities to build and maintain trust
- Collaborating with regulators, researchers, and the responsible AI community

These efforts are reinforced by Azure’s design for security, operational resilience, and transparent governance, providing organizational confidence to scale, innovate, and remain in control amidst evolving regulations.

## Certification Details and Resources

The ISO/IEC 42001:2023 certification for Azure AI Foundry Models and Microsoft Security Copilot was issued by [Mastermind](https://mastermindassurance.com/), an ISO-accredited certification body under the International Accreditation Service (IAS).

Additional resources:

- Discover Microsoft’s security, privacy, and compliance approach at the [Microsoft Trust Center](https://www.microsoft.com/en-us/trust-center).
- View certification documentation on the [Microsoft Service Trust Portal](https://servicetrust.microsoft.com/DocumentPage/63208973-60e7-4d18-882b-bd2425cc881b).

---

*ISO/IEC 42001:2023 certification is a testament to Microsoft’s ongoing investment in secure, ethical, and responsible AI infrastructure, enabling organizations to comply with global standards and foster broader adoption of AI innovation.*

This post appeared first on "The Azure Blog". [Read the entire article here](https://azure.microsoft.com/en-us/blog/microsoft-azure-ai-foundry-models-and-microsoft-security-copilot-achieve-iso-iec-420012023-certification/)
